<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Block Storage | OpenStack Administrator Guide | SUSE OpenStack Cloud 8</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.2.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.81.0 (based on DocBook XSL Stylesheets 1.79.2) - chunked" /><meta name="product-name" content="SUSE OpenStack Cloud" /><meta name="product-number" content="8" /><meta name="book-title" content="OpenStack Administrator Guide" /><meta name="chapter-title" content="Chapter 7. Block Storage" /><meta name="description" content="The OpenStack Block Storage service works through the interaction of a series of daemon processes named cinder-* that reside persistently on the host machine or machines. You can run all the binaries from a single node, or spread across multiple nodes. You can also run them on the same node as other…" /><meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi" /><meta name="tracker-type" content="bsc" /><meta name="tracker-bsc-component" content="Documentation" /><meta name="tracker-bsc-product" content="SUSE OpenStack Cloud 8" /><link rel="home" href="index.html" title="SUSE OpenStack Cloud Crowbar 8 Documentation" /><link rel="up" href="book-upstream-admin.html" title="OpenStack Administrator Guide" /><link rel="prev" href="bk02ch06.html" title="Chapter 6. Object Storage" /><link rel="next" href="bk02ch08.html" title="Chapter 8. Shared File Systems" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-navigation">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #E11;"><div id="_header"><div id="_logo"><img src="static/images/logo.svg" alt="Logo" /></div><div class="crumbs"><a class="book-link" href="index.html" title="OpenStack Administrator Guide"><span class="book-icon">OpenStack Administrator Guide</span></a><span> › </span><a class="crumb" href="bk02ch07.html">Block Storage</a></div><div class="clearme"></div></div></div><div id="_toolbar-wrap"><div id="_toolbar"><div id="_toc-area" class="inactive"><a id="_toc-area-button" class="tool" title="Contents" accesskey="c" href="index.html"><span class="tool-spacer"><span class="toc-icon">Contents</span><span class="clearme"></span></span><span class="tool-label">Contents</span></a><div class="active-contents bubble-corner"></div><div class="active-contents bubble"><div class="bubble-container"><h6>OpenStack Administrator Guide</h6><div id="_bubble-toc"><ol><li class="inactive"><a href="bk02ch01.html"><span class="number">1 </span><span class="name">Documentation Conventions</span></a></li><li class="inactive"><a href="bk02ch02.html"><span class="number">2 </span><span class="name">Get started with OpenStack</span></a></li><li class="inactive"><a href="cha-identity.html"><span class="number">3 </span><span class="name">Identity management</span></a></li><li class="inactive"><a href="bk02ch04.html"><span class="number">4 </span><span class="name">Dashboard</span></a></li><li class="inactive"><a href="bk02ch05.html"><span class="number">5 </span><span class="name">Compute</span></a></li><li class="inactive"><a href="bk02ch06.html"><span class="number">6 </span><span class="name">Object Storage</span></a></li><li class="inactive"><a href="bk02ch07.html"><span class="number">7 </span><span class="name">Block Storage</span></a></li><li class="inactive"><a href="bk02ch08.html"><span class="number">8 </span><span class="name">Shared File Systems</span></a></li><li class="inactive"><a href="networking.html"><span class="number">9 </span><span class="name">Networking</span></a></li><li class="inactive"><a href="bk02ch10.html"><span class="number">10 </span><span class="name">Telemetry</span></a></li><li class="inactive"><a href="bk02ch11.html"><span class="number">11 </span><span class="name">Database</span></a></li><li class="inactive"><a href="bk02ch12.html"><span class="number">12 </span><span class="name">Bare Metal</span></a></li><li class="inactive"><a href="bk02ch13.html"><span class="number">13 </span><span class="name">Orchestration</span></a></li><li class="inactive"><a href="osadm-os-cli.html"><span class="number">14 </span><span class="name">OpenStack command-line clients</span></a></li><li class="inactive"><a href="bk02ch15.html"><span class="number">15 </span><span class="name">Cross-project features</span></a></li><li class="inactive"><a href="bk02ch16.html"><span class="number">16 </span><span class="name">Appendix</span></a></li><li class="inactive"><a href="bk02go01.html"><span class="number"> </span><span class="name">Glossary</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_nav-area" class="inactive"><div class="tool"><span class="nav-inner"><span class="tool-label">Navigation</span><a accesskey="p" class="tool-spacer" title="Chapter 6. Object Storage" href="bk02ch06.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 8. Shared File Systems" href="bk02ch08.html"><span class="next-icon">→</span></a></span></div></div></div></div><div id="_fixed-header-wrap" style="background-color: #E11;" class="inactive"><div id="_fixed-header"><div class="crumbs"><a class="book-link" href="index.html" title="OpenStack Administrator Guide"><span class="book-icon">OpenStack Administrator Guide</span></a><span> › </span><a class="crumb" href="bk02ch07.html">Block Storage</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="button"><a accesskey="p" class="tool-spacer" title="Chapter 6. Object Storage" href="bk02ch06.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 8. Shared File Systems" href="bk02ch08.html"><span class="next-icon">→</span></a></div><div class="clearme"></div></div><div class="clearme"></div></div></div><div id="_content" class="draft "><div class="documentation"><div class="chapter " id="id-1.4.9"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname ">SUSE OpenStack Cloud</span> <span class="productnumber ">8</span></div><div><h1 class="title"><span class="number">7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block Storage</span> <a title="Permalink" class="permalink" href="bk02ch07.html#">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="bk02ch07.html#id-1.4.9.6"><span class="number">7.1 </span><span class="name">Increase Block Storage API service throughput</span></a></span></dt><dt><span class="sect1"><a href="bk02ch07.html#id-1.4.9.7"><span class="number">7.2 </span><span class="name">Manage volumes</span></a></span></dt><dt><span class="sect1"><a href="bk02ch07.html#id-1.4.9.8"><span class="number">7.3 </span><span class="name">Troubleshoot your installation</span></a></span></dt></dl></div></div><p>The OpenStack Block Storage service works through the interaction of
a series of daemon processes named <code class="literal">cinder-*</code> that reside
persistently on the host machine or machines. You can run all the
binaries from a single node, or spread across multiple nodes. You can
also run them on the same node as other OpenStack services.</p><p>To administer the OpenStack Block Storage service, it is helpful to
understand a number of concepts. You must make certain choices when
you configure the Block Storage service in OpenStack. The bulk of the
options come down to two choices - single node or multi-node install.
You can read a longer discussion about <a class="link" href="http://docs.openstack.org/ops-guide/arch-storage.html" target="_blank">Storage Decisions</a> in the
<a class="link" href="http://docs.openstack.org/ops-guide/" target="_blank">OpenStack Operations Guide</a>.</p><p>OpenStack Block Storage enables you to add extra block-level storage
to your OpenStack Compute instances. This service is similar to the
Amazon EC2 Elastic Block Storage (EBS) offering.</p><div class="sect1 " id="id-1.4.9.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Increase Block Storage API service throughput</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By default, the Block Storage API service runs in one process. This
limits the number of API requests that the Block Storage service can
process at any given time. In a production environment, you should
increase the Block Storage API throughput by allowing the Block Storage
API service to run in as many processes as the machine capacity allows.</p><div id="id-1.4.9.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The Block Storage API service is named <code class="literal">openstack-cinder-api</code> on
the following distributions: CentOS, Fedora, openSUSE, Red Hat
Enterprise Linux, and SUSE Linux Enterprise. In Ubuntu and Debian
distributions, the Block Storage API service is named <code class="literal">cinder-api</code>.</p></div><p>To do so, use the Block Storage API service option <code class="literal">osapi_volume_workers</code>.
This option allows you to specify the number of API service workers
(or OS processes) to launch for the Block Storage API service.</p><p>To configure this option, open the <code class="literal">/etc/cinder/cinder.conf</code>
configuration file and set the <code class="literal">osapi_volume_workers</code> configuration
key to the number of CPU cores/threads on a machine.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT osapi_volume_workers CORES</pre></div><p>Replace <code class="literal">CORES</code> with the number of CPU cores/threads on a machine.</p></div><div class="sect1 " id="id-1.4.9.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage volumes</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The default OpenStack Block Storage service implementation is an
iSCSI solution that uses <a class="xref" href="bk02go01.html#term-logical-volume-manager-lvm" title="Logical Volume Manager (LVM)">Logical Volume Manager (LVM)</a> for Linux.</p><div id="id-1.4.9.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The OpenStack Block Storage service is not a shared storage
solution like a Network Attached Storage (NAS) of NFS volumes
where you can attach a volume to multiple servers. With the
OpenStack Block Storage service, you can attach a volume to only
one instance at a time.</p><p>The OpenStack Block Storage service also provides drivers that
enable you to use several vendors' back-end storage devices in
addition to the base LVM implementation.  These storage devices can
also be used instead of the base LVM installation.</p></div><p>This high-level procedure shows you how to create and attach a volume
to a server instance.</p><p>
        <span class="bold"><strong>To create and attach a volume to an instance</strong></span>
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure the OpenStack Compute and the OpenStack Block Storage
services through the <code class="literal">/etc/cinder/cinder.conf</code> file.</p></li><li class="step "><p>Use the <code class="command">openstack volume create</code> command to create a volume.
This command creates an LV into the volume group (VG) <code class="literal">cinder-volumes</code>.</p></li><li class="step "><p>Use the <code class="command">openstack server add volume</code> command to attach the
volume to an instance. This command creates a unique <a class="xref" href="bk02go01.html#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a> that is exposed to the compute node.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The compute node, which runs the instance, now has an active
iSCSI session and new local storage (usually a <code class="literal">/dev/sdX</code>
disk).</p></li><li class="listitem "><p>Libvirt uses that local storage as storage for the instance. The
instance gets a new disk (usually a <code class="literal">/dev/vdX</code> disk).</p></li></ul></div></li></ol></div></div><p>For this particular walkthrough, one cloud controller runs
<code class="literal">nova-api</code>, <code class="literal">nova-scheduler</code>, <code class="literal">nova-objectstore</code>,
<code class="literal">nova-network</code> and <code class="literal">cinder-*</code> services. Two additional compute
nodes run <code class="literal">nova-compute</code>. The walkthrough uses a custom
partitioning scheme that carves out 60 GB of space and labels it as
LVM. The network uses the <code class="literal">FlatManager</code> and <code class="literal">NetworkManager</code>
settings for OpenStack Compute.</p><p>The network mode does not interfere with OpenStack Block Storage
operations, but you must set up networking for Block Storage to work.
For details, see <a class="xref" href="networking.html" title="Chapter 9. Networking">Chapter 9, <em>Networking</em></a>.</p><p>To set up Compute to use volumes, ensure that Block Storage is
installed along with <code class="literal">lvm2</code>. This guide describes how to
troubleshoot your installation and back up your Compute volumes.</p><div class="sect2 " id="id-1.4.9.7.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Boot from volume</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In some cases, you can store and run instances from inside volumes.
For information, see the <a class="link" href="http://docs.openstack.org/user-guide/cli-nova-launch-instance-from-volume.html" target="_blank">Launch an instance from a volume</a> section
in the <a class="link" href="http://docs.openstack.org/user-guide/" target="_blank">OpenStack End User Guide</a>.</p></div><div class="sect2 " id="id-1.4.9.7.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure an NFS storage back end</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section explains how to configure OpenStack Block Storage to use
NFS storage. You must be able to access the NFS shares from the server
that hosts the <code class="literal">cinder</code> volume service.</p><div id="id-1.4.9.7.11.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The <code class="literal">cinder</code> volume service is named <code class="literal">openstack-cinder-volume</code>
on the following distributions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div><p>In Ubuntu and Debian distributions, the <code class="literal">cinder</code> volume service is
named <code class="literal">cinder-volume</code>.</p></div><p>
          <span class="bold"><strong>Configure Block Storage to use an NFS storage back end</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in as <code class="literal">root</code> to the system hosting the <code class="literal">cinder</code> volume
service.</p></li><li class="step "><p>Create a text file named <code class="literal">nfsshares</code> in the <code class="literal">/etc/cinder/</code> directory.</p></li><li class="step "><p>Add an entry to <code class="literal">/etc/cinder/nfsshares</code> for each NFS share
that the <code class="literal">cinder</code> volume service should use for back end storage.
Each entry should be a separate line, and should use the following
format:</p><div class="verbatim-wrap highlight ini"><pre class="screen">HOST:SHARE</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>HOST is the IP address or host name of the NFS server.</p></li><li class="listitem "><p>SHARE is the absolute path to an existing and accessible NFS share.</p></li></ul></div></li><li class="step "><p>Set <code class="literal">/etc/cinder/nfsshares</code> to be owned by the <code class="literal">root</code> user and
the <code class="literal">cinder</code> group:</p><div class="verbatim-wrap"><pre class="screen"># chown root:cinder /etc/cinder/nfsshares</pre></div></li><li class="step "><p>Set <code class="literal">/etc/cinder/nfsshares</code> to be readable by members of the
cinder group:</p><div class="verbatim-wrap"><pre class="screen"># chmod 0640 /etc/cinder/nfsshares</pre></div></li><li class="step "><p>Configure the <code class="literal">cinder</code> volume service to use the
<code class="literal">/etc/cinder/nfsshares</code> file created earlier. To do so, open
the <code class="literal">/etc/cinder/cinder.conf</code> configuration file and set
the <code class="literal">nfs_shares_config</code> configuration key
to <code class="literal">/etc/cinder/nfsshares</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_shares_config /etc/cinder/nfsshares</pre></div><p>The following distributions include openstack-config:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div></li><li class="step "><p>Optionally, provide any additional NFS mount options required in
your environment in the <code class="literal">nfs_mount_options</code> configuration key
of <code class="literal">/etc/cinder/cinder.conf</code>. If your NFS shares do not
require any additional mount options (or if you are unsure),
skip this step.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can
configure this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_mount_options OPTIONS</pre></div><p>Replace OPTIONS with the mount options to be used when accessing
NFS shares. See the manual page for NFS for more information on
available mount options (<code class="command">man nfs</code>).</p></li><li class="step "><p>Configure the <code class="literal">cinder</code> volume service to use the correct volume
driver, namely <code class="literal">cinder.volume.drivers.nfs.NfsDriver</code>. To do so,
open the <code class="literal">/etc/cinder/cinder.conf</code> configuration file and
set the volume_driver configuration key
to <code class="literal">cinder.volume.drivers.nfs.NfsDriver</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT volume_driver cinder.volume.drivers.nfs.NfsDriver</pre></div></li><li class="step "><p>You can now restart the service to apply the configuration.</p><div id="id-1.4.9.7.11.5.9.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The <code class="literal">nfs_sparsed_volumes</code> configuration key determines whether
volumes are created as sparse files and grown as needed or fully
allocated up front. The default and recommended value is <code class="literal">true</code>,
which ensures volumes are initially created as sparse files.</p><p>Setting <code class="literal">nfs_sparsed_volumes</code> to <code class="literal">false</code> will result in
volumes being fully allocated at the time of creation. This leads
to increased delays in volume creation.</p><p>However, should you choose to set <code class="literal">nfs_sparsed_volumes</code> to
<code class="literal">false</code>, you can do so directly in <code class="literal">/etc/cinder/cinder.conf</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can
configure this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_sparsed_volumes false</pre></div></div><div id="id-1.4.9.7.11.5.9.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg" /><h6>Warning</h6><p>If a client host has SELinux enabled, the <code class="literal">virt_use_nfs</code>
boolean should also be enabled if the host requires access to
NFS volumes on an instance. To enable this boolean, run the
following command as the <code class="literal">root</code> user:</p><div class="verbatim-wrap"><pre class="screen"># setsebool -P virt_use_nfs on</pre></div><p>This command also makes the boolean persistent across reboots.
Run this command on all client hosts that require access to NFS
volumes on an instance. This includes all compute nodes.</p></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.9.7.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure a GlusterFS back end</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section explains how to configure OpenStack Block Storage to use
GlusterFS as a back end. You must be able to access the GlusterFS shares
from the server that hosts the <code class="literal">cinder</code> volume service.</p><div id="id-1.4.9.7.12.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The cinder volume service is named <code class="literal">openstack-cinder-volume</code> on the
following distributions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div><p>In Ubuntu and Debian distributions, the <code class="literal">cinder</code> volume service is
named <code class="literal">cinder-volume</code>.</p></div><p>Mounting GlusterFS volumes requires utilities and libraries from the
<code class="literal">glusterfs-fuse</code> package. This package must be installed on all systems
that will access volumes backed by GlusterFS.</p><div id="id-1.4.9.7.12.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The utilities and libraries required for mounting GlusterFS volumes on
Ubuntu and Debian distributions are available from the <code class="literal">glusterfs-client</code>
package instead.</p></div><p>For information on how to install and configure GlusterFS, refer to the
<a class="link" href="http://www.gluster.org/community/documentation/index.php/Main_Page" target="_blank">GlusterDocumentation</a> page.</p><p>
          <span class="bold"><strong>Configure GlusterFS for OpenStack Block Storage</strong></span>
        </p><p>The GlusterFS server must also be configured accordingly in order to allow
OpenStack Block Storage to use GlusterFS shares:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in as <code class="literal">root</code> to the GlusterFS server.</p></li><li class="step "><p>Set each Gluster volume to use the same UID and GID as the <code class="literal">cinder</code> user:</p><div class="verbatim-wrap"><pre class="screen"># gluster volume set VOL_NAME storage.owner-uid CINDER_UID
# gluster volume set VOL_NAME storage.owner-gid CINDER_GID</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>VOL_NAME is the Gluster volume name.</p></li><li class="listitem "><p>CINDER_UID is the UID of the <code class="literal">cinder</code> user.</p></li><li class="listitem "><p>CINDER_GID is the GID of the <code class="literal">cinder</code> user.</p></li></ul></div><div id="id-1.4.9.7.12.9.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The default UID and GID of the <code class="literal">cinder</code> user is 165 on
most distributions.</p></div></li><li class="step "><p>Configure each Gluster volume to accept <code class="literal">libgfapi</code> connections.
To do this, set each Gluster volume to allow insecure ports:</p><div class="verbatim-wrap"><pre class="screen"># gluster volume set VOL_NAME server.allow-insecure on</pre></div></li><li class="step "><p>Enable client connections from unprivileged ports. To do this,
add the following line to <code class="literal">/etc/glusterfs/glusterd.vol</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">option rpc-auth-allow-insecure on</pre></div></li><li class="step "><p>Restart the <code class="literal">glusterd</code> service:</p><div class="verbatim-wrap"><pre class="screen"># service glusterd restart</pre></div></li></ol></div></div><p>
          <span class="bold"><strong>Configure Block Storage to use a GlusterFS back end</strong></span>
        </p><p>After you configure the GlusterFS service, complete these steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in as <code class="literal">root</code> to the system hosting the Block Storage service.</p></li><li class="step "><p>Create a text file named <code class="literal">glusterfs</code> in <code class="literal">/etc/cinder/</code> directory.</p></li><li class="step "><p>Add an entry to <code class="literal">/etc/cinder/glusterfs</code> for each GlusterFS
share that OpenStack Block Storage should use for back end storage.
Each entry should be a separate line, and should use the following
format:</p><div class="verbatim-wrap highlight ini"><pre class="screen">HOST:/VOL_NAME</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>HOST is the IP address or host name of the Red Hat Storage server.</p></li><li class="listitem "><p>VOL_NAME is the name of an existing and accessible volume on the
GlusterFS server.</p></li></ul></div><p>Optionally, if your environment requires additional mount options for
a share, you can add them to the share's entry:</p><div class="verbatim-wrap highlight ini"><pre class="screen">HOST:/VOL_NAME -o OPTIONS</pre></div><p>Replace OPTIONS with a comma-separated list of mount options.</p></li><li class="step "><p>Set <code class="literal">/etc/cinder/glusterfs</code> to be owned by the root user
and the <code class="literal">cinder</code> group:</p><div class="verbatim-wrap"><pre class="screen"># chown root:cinder /etc/cinder/glusterfs</pre></div></li><li class="step "><p>Set <code class="literal">/etc/cinder/glusterfs</code> to be readable by members of
the <code class="literal">cinder</code> group:</p><div class="verbatim-wrap"><pre class="screen"># chmod 0640 /etc/cinder/glusterfs</pre></div></li><li class="step "><p>Configure OpenStack Block Storage to use the <code class="literal">/etc/cinder/glusterfs</code>
file created earlier. To do so, open the <code class="literal">/etc/cinder/cinder.conf</code>
configuration file and set the <code class="literal">glusterfs_shares_config</code> configuration
key to <code class="literal">/etc/cinder/glusterfs</code>.</p><p>On distributions that include openstack-config, you can configure this
by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT glusterfs_shares_config /etc/cinder/glusterfs</pre></div><p>The following distributions include <code class="literal">openstack-config</code>:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div></li><li class="step "><p>Configure OpenStack Block Storage to use the correct volume driver,
namely <code class="literal">cinder.volume.drivers.glusterfs.GlusterfsDriver</code>. To do so,
open the <code class="literal">/etc/cinder/cinder.conf</code> configuration file and set
the <code class="literal">volume_driver</code> configuration key to
<code class="literal">cinder.volume.drivers.glusterfs.GlusterfsDriver</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT volume_driver cinder.volume.drivers.glusterfs.GlusterfsDriver</pre></div></li><li class="step "><p>You can now restart the service to apply the configuration.</p></li></ol></div></div><p>OpenStack Block Storage is now configured to use a GlusterFS back end.</p><div id="id-1.4.9.7.12.14" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg" /><h6>Warning</h6><p>If a client host has SELinux enabled, the <code class="literal">virt_use_fusefs</code> boolean
should also be enabled if the host requires access to GlusterFS volumes
on an instance. To enable this Boolean, run the following command as
the <code class="literal">root</code> user:</p><div class="verbatim-wrap"><pre class="screen"># setsebool -P virt_use_fusefs on</pre></div><p>This command also makes the Boolean persistent across reboots. Run
this command on all client hosts that require access to GlusterFS
volumes on an instance. This includes all compute nodes.</p></div></div><div class="sect2 " id="multi-backend"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure multiple-storage back ends</span> <a title="Permalink" class="permalink" href="bk02ch07.html#multi-backend">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>multi-backend</li></ul></div></div></div></div><p>When you configure multiple-storage back ends, you can create several
back-end storage solutions that serve the same OpenStack Compute
configuration and one <code class="literal">cinder-volume</code> is launched for each back-end
storage or back-end storage pool.</p><p>In a multiple-storage back-end configuration, each back end has a name
(<code class="literal">volume_backend_name</code>). Several back ends can have the same name.
In that case, the scheduler properly decides which back end the volume
has to be created in.</p><p>The name of the back end is declared as an extra-specification of a
volume type (such as, <code class="literal">volume_backend_name=LVM</code>). When a volume
is created, the scheduler chooses an appropriate back end to handle the
request, according to the volume type specified by the user.</p><div class="sect3 " id="id-1.4.9.7.13.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable multiple-storage back ends</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.13.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable a multiple-storage back ends, you must set the
<code class="literal">enabled_backends</code> flag in the <code class="literal">cinder.conf</code> file.
This flag defines the names (separated by a comma) of the configuration
groups for the different back ends: one name is associated to one
configuration group for a back end (such as, <code class="literal">[lvmdriver-1]</code>).</p><div id="id-1.4.9.7.13.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The configuration group name is not related to the <code class="literal">volume_backend_name</code>.</p></div><div id="id-1.4.9.7.13.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>After setting the <code class="literal">enabled_backends</code> flag on an existing cinder
service, and restarting the Block Storage services, the original <code class="literal">host</code>
service is replaced with a new host service. The new service appears
with a name like <code class="literal">host@backend</code>. Use:</p><div class="verbatim-wrap"><pre class="screen">$ cinder-manage volume update_host --currenthost CURRENTHOST --newhost CURRENTHOST@BACKEND</pre></div><p>to convert current block devices to the new host name.</p></div><p>The options for a configuration group must be defined in the group
(or default options are used). All the standard Block Storage
configuration options (<code class="literal">volume_group</code>, <code class="literal">volume_driver</code>, and so on)
might be used in a configuration group. Configuration values in
the <code class="literal">[DEFAULT]</code> configuration group are not used.</p><p>These examples show three back ends:</p><div class="verbatim-wrap highlight ini"><pre class="screen">enabled_backends=lvmdriver-1,lvmdriver-2,lvmdriver-3
[lvmdriver-1]
volume_group=cinder-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
[lvmdriver-2]
volume_group=cinder-volumes-2
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
[lvmdriver-3]
volume_group=cinder-volumes-3
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM_b</pre></div><p>In this configuration, <code class="literal">lvmdriver-1</code> and <code class="literal">lvmdriver-2</code> have the same
<code class="literal">volume_backend_name</code>. If a volume creation requests the <code class="literal">LVM</code>
back end name, the scheduler uses the capacity filter scheduler to choose
the most suitable driver, which is either <code class="literal">lvmdriver-1</code> or <code class="literal">lvmdriver-2</code>.
The capacity filter scheduler is enabled by default. The next section
provides more information. In addition, this example presents a
<code class="literal">lvmdriver-3</code> back end.</p><div id="id-1.4.9.7.13.5.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>For Fiber Channel drivers that support multipath, the configuration group
requires the <code class="literal">use_multipath_for_image_xfer=true</code> option. In
the example below, you can see details for HPE 3PAR and EMC Fiber
Channel drivers.</p></div><div class="verbatim-wrap highlight ini"><pre class="screen">[3par]
use_multipath_for_image_xfer = true
volume_driver = cinder.volume.drivers.hpe.hpe_3par_fc.HPE3PARFCDriver
volume_backend_name = 3parfc

[emc]
use_multipath_for_image_xfer = true
volume_driver = cinder.volume.drivers.emc.emc_smis_fc.EMCSMISFCDriver
volume_backend_name = emcfc</pre></div></div><div class="sect3 " id="id-1.4.9.7.13.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Block Storage scheduler multi back end</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.13.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must enable the <code class="literal">filter_scheduler</code> option to use
multiple-storage back ends. The filter scheduler:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Filters the available back ends. By default, <code class="literal">AvailabilityZoneFilter</code>,
<code class="literal">CapacityFilter</code> and <code class="literal">CapabilitiesFilter</code> are enabled.</p></li><li class="step "><p>Weights the previously filtered back ends. By default, the
<code class="literal">CapacityWeigher</code> option is enabled. When this option is
enabled, the filter scheduler assigns the highest weight to back
ends with the most available capacity.</p></li></ol></div></div><p>The scheduler uses filters and weights to pick the best back end to
handle the request. The scheduler uses volume types to explicitly create
volumes on specific back ends. For more information about filter and weighing,
see <a class="xref" href="bk02ch07.html#filter-weigh-scheduler" title="7.2.13. Configure and use driver filter and weighing for scheduler">Section 7.2.13, “Configure and use driver filter and weighing for scheduler”</a>.</p></div><div class="sect3 " id="id-1.4.9.7.13.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume type</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.13.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Before using it, a volume type has to be declared to Block Storage.
This can be done by the following command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-username admin --os-tenant-name admin volume type create lvm</pre></div><p>Then, an extra-specification has to be created to link the volume
type to a back end name. Run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-username admin --os-tenant-name admin volume type set lvm \
  --property volume_backend_name=LVM_iSCSI</pre></div><p>This example creates a <code class="literal">lvm</code> volume type with
<code class="literal">volume_backend_name=LVM_iSCSI</code> as extra-specifications.</p><p>Create another volume type:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-username admin --os-tenant-name admin volume type create lvm_gold

$ openstack --os-username admin --os-tenant-name admin volume type set lvm_gold \
  --property volume_backend_name=LVM_iSCSI_b</pre></div><p>This second volume type is named <code class="literal">lvm_gold</code> and has <code class="literal">LVM_iSCSI_b</code> as
back end name.</p><div id="id-1.4.9.7.13.7.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To list the extra-specifications, use this command:</p><div class="verbatim-wrap"><pre class="screen">$ cinder --os-username admin --os-tenant-name admin extra-specs-list</pre></div></div><div id="id-1.4.9.7.13.7.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If a volume type points to a <code class="literal">volume_backend_name</code> that does not
exist in the Block Storage configuration, the <code class="literal">filter_scheduler</code>
returns an error that it cannot find a valid host with the suitable
back end.</p></div></div><div class="sect3 " id="id-1.4.9.7.13.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.13.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you create a volume, you must specify the volume type.
The extra-specifications of the volume type are used to determine which
back end has to be used.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --size 1 --type lvm test_multi_backend</pre></div><p>Considering the <code class="literal">cinder.conf</code> described previously, the scheduler
creates this volume on <code class="literal">lvmdriver-1</code> or <code class="literal">lvmdriver-2</code>.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --size 1 --type lvm_gold test_multi_backend</pre></div><p>This second volume is created on <code class="literal">lvmdriver-3</code>.</p></div></div><div class="sect2 " id="id-1.4.9.7.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Back up Block Storage service disks</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>While you can use the LVM snapshot to create snapshots, you can also use
it to back up your volumes. By using LVM snapshot, you reduce the size
of the backup; only existing data is backed up instead of the entire
volume.</p><p>To back up a volume, you must create a snapshot of it. An LVM snapshot
is the exact copy of a logical volume, which contains data in a frozen
state. This prevents data corruption because data cannot be manipulated
during the volume creation process. Remember that the volumes created
through a <code class="command">nova volume-create</code> command exist in an LVM logical
volume.</p><p>You must also make sure that the operating system is not using the
volume and that all data has been flushed on the guest file systems.
This usually means that those file systems have to be unmounted during
the snapshot creation. They can be mounted again as soon as the logical
volume snapshot has been created.</p><p>Before you create the snapshot you must have enough space to save it.
As a precaution, you should have at least twice as much space as the
potential snapshot size. If insufficient space is available, the snapshot
might become corrupted.</p><p>For this example assume that a 100 GB volume named <code class="literal">volume-00000001</code>
was created for an instance while only 4 GB are used. This example uses
these commands to back up only those 4 GB:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="command">lvm2</code> command. Directly manipulates the volumes.</p></li><li class="listitem "><p><code class="command">kpartx</code> command. Discovers the partition table created inside the
instance.</p></li><li class="listitem "><p><code class="command">tar</code> command. Creates a minimum-sized backup.</p></li><li class="listitem "><p><code class="command">sha1sum</code> command. Calculates the backup checksum to check its
consistency.</p></li></ul></div><p>You can apply this process to volumes of any size.</p><p>
          <span class="bold"><strong>To back up Block Storage service disks</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create a snapshot of a used volume</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Use this command to list all volumes</p><div class="verbatim-wrap"><pre class="screen"># lvdisplay</pre></div></li><li class="listitem "><p>Create the snapshot; you can do this while the volume is attached
to an instance:</p><div class="verbatim-wrap"><pre class="screen"># lvcreate --size 10G --snapshot --name volume-00000001-snapshot \
  /dev/cinder-volumes/volume-00000001</pre></div><p>Use the <code class="literal">--snapshot</code> configuration option to tell LVM that you want a
snapshot of an already existing volume. The command includes the size
of the space reserved for the snapshot volume, the name of the snapshot,
and the path of an already existing volume. Generally, this path
is <code class="literal">/dev/cinder-volumes/VOLUME_NAME</code>.</p><p>The size does not have to be the same as the volume of the snapshot.
The <code class="literal">--size</code> parameter defines the space that LVM reserves
for the snapshot volume. As a precaution, the size should be the same
as that of the original volume, even if the whole space is not
currently used by the snapshot.</p></li><li class="listitem "><p>Run the <code class="command">lvdisplay</code> command again to verify the snapshot:</p><div class="verbatim-wrap"><pre class="screen">--- Logical volume ---
LV Name                /dev/cinder-volumes/volume-00000001
VG Name                cinder-volumes
LV UUID                gI8hta-p21U-IW2q-hRN1-nTzN-UC2G-dKbdKr
LV Write Access        read/write
LV snapshot status     source of
                       /dev/cinder-volumes/volume-00000026-snap [active]
LV Status              available
# open                 1
LV Size                15,00 GiB
Current LE             3840
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           251:13

--- Logical volume ---
LV Name                /dev/cinder-volumes/volume-00000001-snap
VG Name                cinder-volumes
LV UUID                HlW3Ep-g5I8-KGQb-IRvi-IRYU-lIKe-wE9zYr
LV Write Access        read/write
LV snapshot status     active destination for /dev/cinder-volumes/volume-00000026
LV Status              available
# open                 0
LV Size                15,00 GiB
Current LE             3840
COW-table size         10,00 GiB
COW-table LE           2560
Allocated to snapshot  0,00%
Snapshot chunk size    4,00 KiB
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           251:14</pre></div></li></ul></div></li><li class="step "><p>Partition table discovery</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To exploit the snapshot with the <code class="command">tar</code> command, mount
your partition on the Block Storage service server.</p><p>The <code class="command">kpartx</code> utility discovers and maps table partitions.
You can use it to view partitions that are created inside the
instance. Without using the partitions created inside instances,
you cannot see its content and create efficient backups.</p><div class="verbatim-wrap"><pre class="screen"># kpartx -av /dev/cinder-volumes/volume-00000001-snapshot</pre></div><div id="id-1.4.9.7.14.10.2.2.1.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>On a Debian-based distribution, you can use the
<code class="command">apt-get install kpartx</code> command to install
<code class="command">kpartx</code>.</p></div><p>If the tools successfully find and map the partition table,
no errors are returned.</p></li><li class="listitem "><p>To check the partition table map, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ ls /dev/mapper/nova*</pre></div><p>You can see the <code class="literal">cinder--volumes-volume--00000001--snapshot1</code>
partition.</p><p>If you created more than one partition on that volume, you see
several partitions; for example:
<code class="literal">cinder--volumes-volume--00000001--snapshot2</code>,
<code class="literal">cinder--volumes-volume--00000001--snapshot3</code>, and so on.</p></li><li class="listitem "><p>Mount your partition</p><div class="verbatim-wrap"><pre class="screen"># mount /dev/mapper/cinder--volumes-volume--volume--00000001--snapshot1 /mnt</pre></div><p>If the partition mounts successfully, no errors are returned.</p><p>You can directly access the data inside the instance. If a message
prompts you for a partition or you cannot mount it, determine whether
enough space was allocated for the snapshot or the <code class="command">kpartx</code>
command failed to discover the partition table.</p><p>Allocate more space to the snapshot and try the process again.</p></li></ul></div></li><li class="step "><p>Use the <code class="command">tar</code> command to create archives</p><p>Create a backup of the volume:</p><div class="verbatim-wrap"><pre class="screen">$ tar --exclude="lost+found" --exclude="some/data/to/exclude" -czf \
  volume-00000001.tar.gz -C /mnt/ /backup/destination</pre></div><p>This command creates a <code class="literal">tar.gz</code> file that contains the data,
<span class="emphasis"><em>and data only</em></span>. This ensures that you do not waste space by backing
up empty sectors.</p></li><li class="step "><p>Checksum calculation I</p><p>You should always have the checksum for your backup files. When you
transfer the same file over the network, you can run a checksum
calculation to ensure that your file was not corrupted during its
transfer. The checksum is a unique ID for a file. If the checksums are
different, the file is corrupted.</p><p>Run this command to run a checksum for your file and save the result
to a file:</p><div class="verbatim-wrap"><pre class="screen">$ sha1sum volume-00000001.tar.gz &gt; volume-00000001.checksum</pre></div><div id="id-1.4.9.7.14.10.4.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Use the <code class="command">sha1sum</code> command carefully because the time it
takes to complete the calculation is directly proportional to the
size of the file.</p><p>Depending on your CPU, the process might take a long time for
files larger than around 4 to 6 GB.</p></div></li><li class="step "><p>After work cleaning</p><p>Now that you have an efficient and consistent backup, use this command
to clean up the file system:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Unmount the volume.</p><div class="verbatim-wrap"><pre class="screen">$ umount /mnt</pre></div></li><li class="listitem "><p>Delete the partition table.</p><div class="verbatim-wrap"><pre class="screen">$ kpartx -dv /dev/cinder-volumes/volume-00000001-snapshot</pre></div></li><li class="listitem "><p>Remove the snapshot.</p><div class="verbatim-wrap"><pre class="screen">$ lvremove -f /dev/cinder-volumes/volume-00000001-snapshot</pre></div></li></ul></div><p>Repeat these steps for all your volumes.</p></li><li class="step "><p>Automate your backups</p><p>Because more and more volumes might be allocated to your Block Storage
service, you might want to automate your backups.
The <a class="link" href="https://github.com/Razique/BashStuff/blob/master/SYSTEMS/OpenStack/SCR_5005_V01_NUAC-OPENSTACK-EBS-volumes-backup.sh" target="_blank">SCR_5005_V01_NUAC-OPENSTACK-EBS-volumes-backup.sh</a> script assists
you with this task. The script performs the operations from the previous
example, but also provides a mail report and runs the backup based on
the <code class="literal">backups_retention_days</code> setting.</p><p>Launch this script from the server that runs the Block Storage service.</p><p>This example shows a mail report:</p><div class="verbatim-wrap"><pre class="screen">Backup Start Time - 07/10 at 01:00:01
Current retention - 7 days

The backup volume is mounted. Proceed...
Removing old backups...  : /BACKUPS/EBS-VOL/volume-00000019/volume-00000019_28_09_2011.tar.gz
     /BACKUPS/EBS-VOL/volume-00000019 - 0 h 1 m and 21 seconds. Size - 3,5G

The backup volume is mounted. Proceed...
Removing old backups...  : /BACKUPS/EBS-VOL/volume-0000001a/volume-0000001a_28_09_2011.tar.gz
     /BACKUPS/EBS-VOL/volume-0000001a - 0 h 4 m and 15 seconds. Size - 6,9G
---------------------------------------
Total backups size - 267G - Used space : 35%
Total execution time - 1 h 75 m and 35 seconds</pre></div><p>The script also enables you to SSH to your instances and run a
<code class="command">mysqldump</code> command into them. To make this work, enable
the connection to the Compute project keys. If you do not want to
run the <code class="command">mysqldump</code> command, you can add
<code class="literal">enable_mysql_dump=0</code> to the script to turn off this functionality.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.9.7.15"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate volumes</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.15">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack has the ability to migrate volumes between back ends which support
its volume-type. Migrating a volume transparently moves its data from the
current back end for the volume to a new one. This is an administrator
function, and can be used for functions including storage evacuation (for
maintenance or decommissioning), or manual optimizations (for example,
performance, reliability, or cost).</p><p>These workflows are possible for a migration:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>If the storage can migrate the volume on its own, it is given the
opportunity to do so. This allows the Block Storage driver to enable
optimizations that the storage might be able to perform. If the back end
is not able to perform the migration, the Block Storage uses one of two
generic flows, as follows.</p></li><li class="step "><p>If the volume is not attached, the Block Storage service creates a volume
and copies the data from the original to the new volume.</p><div id="id-1.4.9.7.15.4.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>While most back ends support this function, not all do. See the <a class="link" href="http://docs.openstack.org/newton/config-reference/block-storage/volume-drivers.html" target="_blank">driver
documentation</a>
in the OpenStack Configuration Reference for more details.</p></div></li><li class="step "><p>If the volume is attached to a VM instance, the Block Storage creates a
volume, and calls Compute to copy the data from the original to the new
volume. Currently this is supported only by the Compute libvirt driver.</p></li></ol></div></div><p>As an example, this scenario shows two LVM back ends and migrates an attached
volume from one to the other. This scenario uses the third migration flow.</p><p>First, list the available back ends:</p><div class="verbatim-wrap"><pre class="screen"># cinder get-pools
+----------+----------------------------------------------------+
| Property |                       Value                        |
+----------+----------------------------------------------------+
|   name   |           server1@lvmstorage-1#lvmstorage-1        |
+----------+----------------------------------------------------+
+----------+----------------------------------------------------+
| Property |                      Value                         |
+----------+----------------------------------------------------+
|   name   |           server2@lvmstorage-2#lvmstorage-2        |
+----------+----------------------------------------------------+</pre></div><div id="id-1.4.9.7.15.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Only Block Storage V2 API supports <code class="command">cinder get-pools</code>.</p></div><p>You can also get available back ends like following:</p><div class="verbatim-wrap"><pre class="screen"># cinder-manage host list
server1@lvmstorage-1    zone1
server2@lvmstorage-2    zone1</pre></div><p>But it needs to add pool name in the end. For example,
<code class="literal">server1@lvmstorage-1#zone1</code>.</p><p>Next, as the admin user, you can see the current status of the volume
(replace the example ID with your own):</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume show 6088f80a-f116-4331-ad48-9afb0dfb196c

+--------------------------------+--------------------------------------+
| Field                          | Value                                |
+--------------------------------+--------------------------------------+
| attachments                    | []                                   |
| availability_zone              | zone1                                |
| bootable                       | false                                |
| consistencygroup_id            | None                                 |
| created_at                     | 2013-09-01T14:53:22.000000           |
| description                    | test                                 |
| encrypted                      | False                                |
| id                             | 6088f80a-f116-4331-ad48-9afb0dfb196c |
| migration_status               | None                                 |
| multiattach                    | False                                |
| name                           | test                                 |
| os-vol-host-attr:host          | controller@lvm#LVM                   |
| os-vol-mig-status-attr:migstat | None                                 |
| os-vol-mig-status-attr:name_id | None                                 |
| os-vol-tenant-attr:tenant_id   | d88310717a8e4ebcae84ed075f82c51e     |
| properties                     | readonly='False'                     |
| replication_status             | disabled                             |
| size                           | 1                                    |
| snapshot_id                    | None                                 |
| source_volid                   | None                                 |
| status                         | in-use                               |
| type                           | None                                 |
| updated_at                     | 2016-07-31T07:22:19.000000           |
| user_id                        | d8e5e5727f3a4ce1886ac8ecec058e83     |
+--------------------------------+--------------------------------------+</pre></div><p>Note these attributes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">os-vol-host-attr:host</code> - the volume's current back end.</p></li><li class="listitem "><p><code class="literal">os-vol-mig-status-attr:migstat</code> - the status of this volume's migration
(None means that a migration is not currently in progress).</p></li><li class="listitem "><p><code class="literal">os-vol-mig-status-attr:name_id</code> - the volume ID that this volume's name
on the back end is based on. Before a volume is ever migrated, its name on
the back end storage may be based on the volume's ID (see the
<code class="literal">volume_name_template</code> configuration parameter). For example, if
<code class="literal">volume_name_template</code> is kept as the default value (<code class="literal">volume-%s</code>), your
first LVM back end has a logical volume named
<code class="literal">volume-6088f80a-f116-4331-ad48-9afb0dfb196c</code>. During the course of a
migration, if you create a volume and copy over the data, the volume get
the new name but keeps its original ID. This is exposed by the <code class="literal">name_id</code>
attribute.</p><div id="id-1.4.9.7.15.15.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If you plan to decommission a block storage node, you must stop the
<code class="literal">cinder</code> volume service on the node after performing the migration.</p><p>On nodes that run CentOS, Fedora, openSUSE, Red Hat Enterprise Linux,
or SUSE Linux Enterprise, run:</p><div class="verbatim-wrap"><pre class="screen"># service openstack-cinder-volume stop
# chkconfig openstack-cinder-volume off</pre></div><p>On nodes that run Ubuntu or Debian, run:</p><div class="verbatim-wrap"><pre class="screen"># service cinder-volume stop
# chkconfig cinder-volume off</pre></div><p>Stopping the cinder volume service will prevent volumes from being
allocated to the node.</p></div></li></ul></div><p>Migrate this volume to the second LVM back end:</p><div class="verbatim-wrap"><pre class="screen">$ cinder migrate 6088f80a-f116-4331-ad48-9afb0dfb196c \
  server2@lvmstorage-2#lvmstorage-2</pre></div><p>You can use the <code class="command">openstack volume show</code> command to see the status of
the migration. While migrating, the <code class="literal">migstat</code> attribute shows states such as
<code class="literal">migrating</code> or <code class="literal">completing</code>. On error, <code class="literal">migstat</code> is set to None and the
host attribute shows the original <code class="literal">host</code>. On success, in this example, the
output looks like:</p><div class="verbatim-wrap"><pre class="screen">+--------------------------------+--------------------------------------+
| Field                          | Value                                |
+--------------------------------+--------------------------------------+
| attachments                    | []                                   |
| availability_zone              | zone1                                |
| bootable                       | false                                |
| consistencygroup_id            | None                                 |
| created_at                     | 2013-09-01T14:53:22.000000           |
| description                    | test                                 |
| encrypted                      | False                                |
| id                             | 6088f80a-f116-4331-ad48-9afb0dfb196c |
| migration_status               | None                                 |
| multiattach                    | False                                |
| name                           | test                                 |
| os-vol-host-attr:host          | controller@lvm#LVM                   |
| os-vol-mig-status-attr:migstat | None                                 |
| os-vol-mig-status-attr:name_id | None                                 |
| os-vol-tenant-attr:tenant_id   | d88310717a8e4ebcae84ed075f82c51e     |
| properties                     | readonly='False'                     |
| replication_status             | disabled                             |
| size                           | 1                                    |
| snapshot_id                    | None                                 |
| source_volid                   | None                                 |
| status                         | in-use                               |
| type                           | None                                 |
| updated_at                     | 2016-07-31T07:22:19.000000           |
| user_id                        | d8e5e5727f3a4ce1886ac8ecec058e83     |
+--------------------------------+--------------------------------------+</pre></div><p>Note that <code class="literal">migstat</code> is None, host is the new host, and <code class="literal">name_id</code> holds the
ID of the volume created by the migration. If you look at the second LVM back
end, you find the logical volume
<code class="literal">volume-133d1f56-9ffc-4f57-8798-d5217d851862</code>.</p><div id="id-1.4.9.7.15.21" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The migration is not visible to non-admin users (for example, through the
volume <code class="literal">status</code>). However, some operations are not allowed while a
migration is taking place, such as attaching/detaching a volume and
deleting a volume. If a user performs such an action during a migration,
an error is returned.</p></div><div id="id-1.4.9.7.15.22" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Migrating volumes that have snapshots are currently not allowed.</p></div></div><div class="sect2 " id="id-1.4.9.7.16"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Gracefully remove a GlusterFS volume from usage</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.16">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Configuring the <code class="literal">cinder</code> volume service to use GlusterFS involves creating a
shares file (for example, <code class="literal">/etc/cinder/glusterfs</code>). This shares file
lists each GlusterFS volume (with its corresponding storage server) that
the <code class="literal">cinder</code> volume service can use for back end storage.</p><p>To remove a GlusterFS volume from usage as a back end, delete the volume's
corresponding entry from the shares file. After doing so, restart the Block
Storage services.</p><p>Restarting the Block Storage services will prevent the <code class="literal">cinder</code> volume
service from exporting the deleted GlusterFS volume. This will prevent any
instances from mounting the volume from that point onwards.</p><p>However, the removed GlusterFS volume might still be mounted on an instance
at this point. Typically, this is the case when the volume was already
mounted while its entry was deleted from the shares file.
Whenever this occurs, you will have to unmount the volume as normal after
the Block Storage services are restarted.</p></div><div class="sect2 " id="volume-backups"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Back up and restore volumes and snapshots</span> <a title="Permalink" class="permalink" href="bk02ch07.html#volume-backups">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>volume-backups</li></ul></div></div></div></div><p>The <code class="literal">openstack</code> command-line interface provides the tools for creating a
volume backup. You can restore a volume from a backup as long as the
backup's associated database information (or backup metadata) is intact
in the Block Storage database.</p><p>Run this command to create a backup of a volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume backup create [--incremental] [--force] VOLUME</pre></div><p>Where <code class="literal">VOLUME</code> is the name or ID of the volume, <code class="literal">incremental</code> is
a flag that indicates whether an incremental backup should be performed,
and <code class="literal">force</code> is a flag that allows or disallows backup of a volume
when the volume is attached to an instance.</p><p>Without the <code class="literal">incremental</code> flag, a full backup is created by default.
With the <code class="literal">incremental</code> flag, an incremental backup is created.</p><p>Without the <code class="literal">force</code> flag, the volume will be backed up only if its
status is <code class="literal">available</code>. With the <code class="literal">force</code> flag, the volume will be
backed up whether its status is <code class="literal">available</code> or <code class="literal">in-use</code>. A volume
is <code class="literal">in-use</code> when it is attached to an instance. The backup of an
<code class="literal">in-use</code> volume means your data is crash consistent. The <code class="literal">force</code>
flag is False by default.</p><div id="id-1.4.9.7.17.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The <code class="literal">incremental</code> and <code class="literal">force</code> flags are only available for block
storage API v2. You have to specify <code class="literal">[--os-volume-api-version 2]</code> in the
<code class="literal">cinder</code> command-line interface to use this parameter.</p></div><div id="id-1.4.9.7.17.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The <code class="literal">force</code> flag is new in OpenStack Liberty.</p></div><p>The incremental backup is based on a parent backup which is an existing
backup with the latest timestamp. The parent backup can be a full backup
or an incremental backup depending on the timestamp.</p><div id="id-1.4.9.7.17.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The first backup of a volume has to be a full backup. Attempting to do
an incremental backup without any existing backups will fail.
There is an <code class="literal">is_incremental</code> flag that indicates whether a backup is
incremental when showing details on the backup.
Another flag, <code class="literal">has_dependent_backups</code>, returned when showing backup
details, will indicate whether the backup has dependent backups.
If it is <code class="literal">true</code>, attempting to delete this backup will fail.</p></div><p>A new configure option <code class="literal">backup_swift_block_size</code> is introduced into
<code class="literal">cinder.conf</code> for the default Swift backup driver. This is the size in
bytes that changes are tracked for incremental backups. The existing
<code class="literal">backup_swift_object_size</code> option, the size in bytes of Swift backup
objects, has to be a multiple of <code class="literal">backup_swift_block_size</code>. The default
is 32768 for <code class="literal">backup_swift_block_size</code>, and the default is 52428800 for
<code class="literal">backup_swift_object_size</code>.</p><p>The configuration option <code class="literal">backup_swift_enable_progress_timer</code> in
<code class="literal">cinder.conf</code> is used when backing up the volume to Object Storage
back end. This option enables or disables the timer. It is enabled by default
to send the periodic progress notifications to the Telemetry service.</p><p>This command also returns a backup ID. Use this backup ID when restoring
the volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume backup restore BACKUP_ID VOLUME_ID</pre></div><p>When restoring from a full backup, it is a full restore.</p><p>When restoring from an incremental backup, a list of backups is built based
on the IDs of the parent backups. A full restore is performed based on the
full backup first, then restore is done based on the incremental backup,
laying on top of it in order.</p><p>You can view a backup list with the <code class="command">cinder backup-list</code>
command. Optional arguments to clarify the status of your backups
include: running <code class="literal">--name</code>, <code class="literal">--status</code>, and
<code class="literal">--volume-id</code> to filter through backups by the specified name,
status, or volume-id. Search with <code class="literal">--all-tenants</code> for details of the
projects associated with the listed backups.</p><p>Because volume backups are dependent on the Block Storage database, you must
also back up your Block Storage database regularly to ensure data recovery.</p><div id="id-1.4.9.7.17.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Alternatively, you can export and save the metadata of selected volume
backups. Doing so precludes the need to back up the entire Block Storage
database. This is useful if you need only a small subset of volumes to
survive a catastrophic database failure.</p><p>If you specify a UUID encryption key when setting up the volume
specifications, the backup metadata ensures that the key will remain valid
when you back up and restore the volume.</p><p>For more information about how to export and import volume backup metadata,
see the section called <a class="xref" href="bk02ch07.html#volume-backups-export-import" title="7.2.9. Export and import backup metadata">Section 7.2.9, “Export and import backup metadata”</a>.</p></div><p>By default, the swift object store is used for the backup repository.</p><p>If instead you want to use an NFS export as the backup repository, add the
following configuration options to the <code class="literal">[DEFAULT]</code> section of the
<code class="literal">cinder.conf</code> file and restart the Block Storage services:</p><div class="verbatim-wrap highlight ini"><pre class="screen">backup_driver = cinder.backup.drivers.nfs
backup_share = HOST:EXPORT_PATH</pre></div><p>For the <code class="literal">backup_share</code> option, replace <code class="literal">HOST</code> with the DNS resolvable
host name or the IP address of the storage server for the NFS share, and
<code class="literal">EXPORT_PATH</code> with the path to that share. If your environment requires
that non-default mount options be specified for the share, set these as
follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">backup_mount_options = MOUNT_OPTIONS</pre></div><p><code class="literal">MOUNT_OPTIONS</code> is a comma-separated string of NFS mount options as detailed
in the NFS man page.</p><p>There are several other options whose default values may be overridden as
appropriate for your environment:</p><div class="verbatim-wrap highlight ini"><pre class="screen">backup_compression_algorithm = zlib
backup_sha_block_size_bytes = 32768
backup_file_size = 1999994880</pre></div><p>The option <code class="literal">backup_compression_algorithm</code> can be set to <code class="literal">bz2</code> or <code class="literal">None</code>.
The latter can be a useful setting when the server providing the share for the
backup repository itself performs deduplication or compression on the backup
data.</p><p>The option <code class="literal">backup_file_size</code> must be a multiple of
<code class="literal">backup_sha_block_size_bytes</code>. It is effectively the maximum file size to be
used, given your environment, to hold backup data. Volumes larger than this
will be stored in multiple files in the backup repository. The
<code class="literal">backup_sha_block_size_bytes</code> option determines the size of blocks from the
cinder volume being backed up on which digital signatures are calculated in
order to enable incremental backup capability.</p><p>You also have the option of resetting the state of a backup. When creating or
restoring a backup, sometimes it may get stuck in the creating or restoring
states due to problems like the database or rabbitmq being down. In situations
like these resetting the state of the backup can restore it to a functional
status.</p><p>Run this command to restore the state of a backup:</p><div class="verbatim-wrap"><pre class="screen">$ cinder backup-reset-state [--state STATE] BACKUP_ID-1 BACKUP_ID-2 ...</pre></div><p>Run this command to create a backup of a snapshot:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume backup create [--incremental] [--force] \
  [--snapshot SNAPSHOT_ID] VOLUME</pre></div><p>Where <code class="literal">VOLUME</code> is the name or ID of the volume, <code class="literal">SNAPSHOT_ID</code> is the ID of
the volume's snapshot.</p></div><div class="sect2 " id="volume-backups-export-import"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Export and import backup metadata</span> <a title="Permalink" class="permalink" href="bk02ch07.html#volume-backups-export-import">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>volume-backups-export-import</li></ul></div></div></div></div><p>A volume backup can only be restored on the same Block Storage service. This
is because restoring a volume from a backup requires metadata available on
the database used by the Block Storage service.</p><div id="id-1.4.9.7.18.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>For information about how to back up and restore a volume, see
the section called <a class="xref" href="bk02ch07.html#volume-backups" title="7.2.8. Back up and restore volumes and snapshots">Section 7.2.8, “Back up and restore volumes and snapshots”</a>.</p></div><p>You can, however, export the metadata of a volume backup. To do so, run
this command as an OpenStack <code class="literal">admin</code> user (presumably, after creating
a volume backup):</p><div class="verbatim-wrap"><pre class="screen">$ cinder backup-export BACKUP_ID</pre></div><p>Where <code class="literal">BACKUP_ID</code> is the volume backup's ID. This command should return the
backup's corresponding database information as encoded string metadata.</p><p>Exporting and storing this encoded string metadata allows you to completely
restore the backup, even in the event of a catastrophic database failure.
This will preclude the need to back up the entire Block Storage database,
particularly if you only need to keep complete backups of a small subset
of volumes.</p><p>If you have placed encryption on your volumes, the encryption will still be
in place when you restore the volume if a UUID encryption key is specified
when creating volumes. Using backup metadata support, UUID keys set up for
a volume (or volumes) will remain valid when you restore a backed-up volume.
The restored volume will remain encrypted, and will be accessible with your
credentials.</p><p>In addition, having a volume backup and its backup metadata also provides
volume portability. Specifically, backing up a volume and exporting its
metadata will allow you to restore the volume on a completely different Block
Storage database, or even on a different cloud service. To do so, first
import the backup metadata to the Block Storage database and then restore
the backup.</p><p>To import backup metadata, run the following command as an OpenStack
<code class="literal">admin</code>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder backup-import METADATA</pre></div><p>Where <code class="literal">METADATA</code> is the backup metadata exported earlier.</p><p>Once you have imported the backup metadata into a Block Storage database,
restore the volume (see the section called <a class="xref" href="bk02ch07.html#volume-backups" title="7.2.8. Back up and restore volumes and snapshots">Section 7.2.8, “Back up and restore volumes and snapshots”</a>).</p></div><div class="sect2 " id="id-1.4.9.7.19"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use LIO iSCSI support</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.19">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The default mode for the <code class="literal">iscsi_helper</code> tool is <code class="literal">tgtadm</code>.
To use LIO iSCSI, install the <code class="literal">python-rtslib</code> package, and set
<code class="literal">iscsi_helper=lioadm</code> in the <code class="literal">cinder.conf</code> file.</p><p>Once configured, you can use the <code class="command">cinder-rtstool</code> command to
manage the volumes. This command enables you to create, delete, and
verify volumes and determine targets and add iSCSI initiators to the
system.</p></div><div class="sect2 " id="id-1.4.9.7.20"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure and use volume number weigher</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.20">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage enables you to choose a volume back end according
to <code class="literal">free_capacity</code> and <code class="literal">allocated_capacity</code>. The volume number weigher
feature lets the scheduler choose a volume back end based on its volume
number in the volume back end. This can provide another means to improve
the volume back ends' I/O balance and the volumes' I/O performance.</p><div class="sect3 " id="id-1.4.9.7.20.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable volume number weigher</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.20.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable a volume number weigher, set the
<code class="literal">scheduler_default_weighers</code> to <code class="literal">VolumeNumberWeigher</code> flag in the
<code class="literal">cinder.conf</code> file to define <code class="literal">VolumeNumberWeigher</code>
as the selected weigher.</p></div><div class="sect3 " id="id-1.4.9.7.20.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure multiple-storage back ends</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.20.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To configure <code class="literal">VolumeNumberWeigher</code>, use <code class="literal">LVMVolumeDriver</code>
as the volume driver.</p><p>This configuration defines two LVM volume groups: <code class="literal">stack-volumes</code> with
10 GB capacity and <code class="literal">stack-volumes-1</code> with 60 GB capacity.
This example configuration defines two back ends:</p><div class="verbatim-wrap highlight ini"><pre class="screen">scheduler_default_weighers=VolumeNumberWeigher
enabled_backends=lvmdriver-1,lvmdriver-2
[lvmdriver-1]
volume_group=stack-volumes
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM

[lvmdriver-2]
volume_group=stack-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM</pre></div></div><div class="sect3 " id="id-1.4.9.7.20.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume type</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.20.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Define a volume type in Block Storage:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type create lvm</pre></div><p>Create an extra specification that links the volume type to a back-end name:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type set lvm --property volume_backend_name=LVM</pre></div><p>This example creates a lvm volume type with
<code class="literal">volume_backend_name=LVM</code> as extra specifications.</p></div><div class="sect3 " id="id-1.4.9.7.20.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.20.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create six 1-GB volumes, run the
<code class="command">openstack volume create --size 1 --type lvm volume1</code> command
six times:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --size 1 --type lvm volume1</pre></div><p>This command creates three volumes in <code class="literal">stack-volumes</code> and
three volumes in <code class="literal">stack-volumes-1</code>.</p><p>List the available volumes:</p><div class="verbatim-wrap"><pre class="screen"># lvs
LV                                          VG              Attr      LSize  Pool Origin Data%  Move Log Copy%  Convert
volume-3814f055-5294-4796-b5e6-1b7816806e5d stack-volumes   -wi-a----  1.00g
volume-72cf5e79-99d2-4d23-b84e-1c35d3a293be stack-volumes   -wi-a----  1.00g
volume-96832554-0273-4e9d-902b-ad421dfb39d1 stack-volumes   -wi-a----  1.00g
volume-169386ef-3d3e-4a90-8439-58ceb46889d9 stack-volumes-1 -wi-a----  1.00g
volume-460b0bbb-d8a0-4bc3-9882-a129a5fe8652 stack-volumes-1 -wi-a----  1.00g
volume-9a08413b-0dbc-47c9-afb8-41032ab05a41 stack-volumes-1 -wi-a----  1.00g</pre></div></div></div><div class="sect2 " id="id-1.4.9.7.21"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Consistency groups</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.21">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Consistency group support is available in OpenStack Block Storage. The
support is added for creating snapshots of consistency groups. This
feature leverages the storage level consistency technology. It allows
snapshots of multiple volumes in the same consistency group to be taken
at the same point-in-time to ensure data consistency. The consistency
group operations can be performed using the Block Storage command line.</p><div id="id-1.4.9.7.21.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Only Block Storage V2 API supports consistency groups. You can
specify <code class="literal">--os-volume-api-version 2</code> when using Block Storage
command line for consistency group operations.</p></div><p>Before using consistency groups, make sure the Block Storage driver that
you are running has consistency group support by reading the Block
Storage manual or consulting the driver maintainer. There are a small
number of drivers that have implemented this feature. The default LVM
driver does not support consistency groups yet because the consistency
technology is not available at the storage level.</p><p>Before using consistency groups, you must change policies for the
consistency group APIs in the <code class="literal">/etc/cinder/policy.json</code> file.
By default, the consistency group APIs are disabled.
Enable them before running consistency group operations.</p><p>Here are existing policy entries for consistency groups:</p><div class="verbatim-wrap highlight json"><pre class="screen">"consistencygroup:create": "group:nobody",
"consistencygroup:delete": "group:nobody",
"consistencygroup:update": "group:nobody",
"consistencygroup:get": "group:nobody",
"consistencygroup:get_all": "group:nobody",
"consistencygroup:create_cgsnapshot" : "group:nobody",
"consistencygroup:delete_cgsnapshot": "group:nobody",
"consistencygroup:get_cgsnapshot": "group:nobody",
"consistencygroup:get_all_cgsnapshots": "group:nobody",</pre></div><p>Remove <code class="literal">group:nobody</code> to enable these APIs:</p><div class="verbatim-wrap highlight json"><pre class="screen">"consistencygroup:create": "",
"consistencygroup:delete": "",
"consistencygroup:update": "",
"consistencygroup:get": "",
"consistencygroup:get_all": "",
"consistencygroup:create_cgsnapshot" : "",
"consistencygroup:delete_cgsnapshot": "",
"consistencygroup:get_cgsnapshot": "",
"consistencygroup:get_all_cgsnapshots": "",</pre></div><p>Restart Block Storage API service after changing policies.</p><p>The following consistency group operations are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a consistency group, given volume types.</p><div id="id-1.4.9.7.21.12.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A consistency group can support more than one volume type. The
scheduler is responsible for finding a back end that can support
all given volume types.</p><p>A consistency group can only contain volumes hosted by the same
back end.</p><p>A consistency group is empty upon its creation. Volumes need to
be created and added to it later.</p></div></li><li class="listitem "><p>Show a consistency group.</p></li><li class="listitem "><p>List consistency groups.</p></li><li class="listitem "><p>Create a volume and add it to a consistency group, given volume type
and consistency group id.</p></li><li class="listitem "><p>Create a snapshot for a consistency group.</p></li><li class="listitem "><p>Show a snapshot of a consistency group.</p></li><li class="listitem "><p>List consistency group snapshots.</p></li><li class="listitem "><p>Delete a snapshot of a consistency group.</p></li><li class="listitem "><p>Delete a consistency group.</p></li><li class="listitem "><p>Modify a consistency group.</p></li><li class="listitem "><p>Create a consistency group from the snapshot of another consistency
group.</p></li><li class="listitem "><p>Create a consistency group from a source consistency group.</p></li></ul></div><p>The following operations are not allowed if a volume is in a consistency
group:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume migration.</p></li><li class="listitem "><p>Volume retype.</p></li><li class="listitem "><p>Volume deletion.</p><div id="id-1.4.9.7.21.14.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A consistency group has to be deleted as a whole with all the
volumes.</p></div></li></ul></div><p>The following operations are not allowed if a volume snapshot is in a
consistency group snapshot:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume snapshot deletion.</p><div id="id-1.4.9.7.21.16.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A consistency group snapshot has to be deleted as a whole with
all the volume snapshots.</p></div></li></ul></div><p>The details of consistency group operations are shown in the following.</p><div id="id-1.4.9.7.21.18" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Currently, no OpenStack client command is available to run in
place of the cinder consistency group creation commands. Use the
cinder commands detailed in the following examples.</p></div><p><span class="bold"><strong>Create a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder consisgroup-create
[--name name]
[--description description]
[--availability-zone availability-zone]
volume-types</pre></div><div id="id-1.4.9.7.21.21" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">volume-types</code> is required. It can be a list of
names or UUIDs of volume types separated by commas without spaces in
between. For example, <code class="literal">volumetype1,volumetype2,volumetype3.</code>.</p></div><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create --name bronzeCG2 volume_type_1

+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
| availability_zone |                 nova                 |
|     created_at    |      2014-12-29T12:59:08.000000      |
|    description    |                 None                 |
|         id        | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|        name       |              bronzeCG2               |
|       status      |               creating               |
+-------------------+--------------------------------------+</pre></div><p><span class="bold"><strong>Show a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-show 1de80c27-3b2f-47a6-91a7-e867cbe36462

+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
| availability_zone |                 nova                 |
|     created_at    |      2014-12-29T12:59:08.000000      |
|    description    |                 None                 |
|         id        | 2a6b2bda-1f43-42ce-9de8-249fa5cbae9a |
|        name       |              bronzeCG2               |
|       status      |              available               |
|     volume_types  |              volume_type_1           |
+-------------------+--------------------------------------+</pre></div><p><span class="bold"><strong>List consistency groups</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-list

+--------------------------------------+-----------+-----------+
|                  ID                  |   Status  |    Name   |
+--------------------------------------+-----------+-----------+
| 1de80c27-3b2f-47a6-91a7-e867cbe36462 | available | bronzeCG2 |
| 3a2b3c42-b612-479a-91eb-1ed45b7f2ad5 |   error   |  bronzeCG |
+--------------------------------------+-----------+-----------+</pre></div><p><span class="bold"><strong>Create a volume and add it to a consistency group</strong></span>:</p><div id="id-1.4.9.7.21.28" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>When creating a volume and adding it to a consistency group, a
volume type and a consistency group id must be provided. This is
because a consistency group can support more than one volume type.</p></div><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --type volume_type_1 --consistency-group \
  1de80c27-3b2f-47a6-91a7-e867cbe36462 --size 1 cgBronzeVol

+---------------------------------------+--------------------------------------+
| Field                                 | Value                                |
+---------------------------------------+--------------------------------------+
|              attachments              |                  []                  |
|           availability_zone           |                 nova                 |
|                bootable               |                false                 |
|          consistencygroup_id          | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|               created_at              |      2014-12-29T13:16:47.000000      |
|              description              |                 None                 |
|               encrypted               |                False                 |
|                   id                  | 5e6d1386-4592-489f-a56b-9394a81145fe |
|                metadata               |                  {}                  |
|                  name                 |             cgBronzeVol              |
|         os-vol-host-attr:host         |      server-1@backend-1#pool-1       |
|     os-vol-mig-status-attr:migstat    |                 None                 |
|     os-vol-mig-status-attr:name_id    |                 None                 |
|      os-vol-tenant-attr:tenant_id     |   1349b21da2a046d8aa5379f0ed447bed   |
|   os-volume-replication:driver_data   |                 None                 |
| os-volume-replication:extended_status |                 None                 |
|           replication_status          |               disabled               |
|                  size                 |                  1                   |
|              snapshot_id              |                 None                 |
|              source_volid             |                 None                 |
|                 status                |               creating               |
|                user_id                |   93bdea12d3e04c4b86f9a9f172359859   |
|              volume_type              |            volume_type_1             |
+---------------------------------------+--------------------------------------+</pre></div><p><span class="bold"><strong>Create a snapshot for a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-create 1de80c27-3b2f-47a6-91a7-e867cbe36462

+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
| consistencygroup_id | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|      created_at     |      2014-12-29T13:19:44.000000      |
|     description     |                 None                 |
|          id         | d4aff465-f50c-40b3-b088-83feb9b349e9 |
|         name        |                 None                 |
|        status       |               creating               |
+---------------------+-------------------------------------+</pre></div><p><span class="bold"><strong>Show a snapshot of a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-show d4aff465-f50c-40b3-b088-83feb9b349e9</pre></div><p><span class="bold"><strong>List consistency group snapshots</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-list

+--------------------------------------+--------+----------+
|                  ID                  | Status | Name     |
+--------------------------------------+--------+----------+
| 6d9dfb7d-079a-471e-b75a-6e9185ba0c38 | available  | None |
| aa129f4d-d37c-4b97-9e2d-7efffda29de0 | available  | None |
| bb5b5d82-f380-4a32-b469-3ba2e299712c | available  | None |
| d4aff465-f50c-40b3-b088-83feb9b349e9 | available  | None |
+--------------------------------------+--------+----------+</pre></div><p><span class="bold"><strong>Delete a snapshot of a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-delete d4aff465-f50c-40b3-b088-83feb9b349e9</pre></div><p><span class="bold"><strong>Delete a consistency group</strong></span>:</p><div id="id-1.4.9.7.21.39" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The force flag is needed when there are volumes in the consistency
group:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-delete --force 1de80c27-3b2f-47a6-91a7-e867cbe36462</pre></div></div><p><span class="bold"><strong>Modify a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder consisgroup-update
[--name NAME]
[--description DESCRIPTION]
[--add-volumes UUID1,UUID2,......]
[--remove-volumes UUID3,UUID4,......]
CG</pre></div><p>The parameter <code class="literal">CG</code> is required. It can be a name or UUID of a consistency
group. UUID1,UUID2,...... are UUIDs of one or more volumes to be added
to the consistency group, separated by commas. Default is None.
UUID3,UUID4,...... are UUIDs of one or more volumes to be removed from
the consistency group, separated by commas. Default is None.</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-update --name 'new name' --description 'new descripti\
  on' --add-volumes 0b3923f5-95a4-4596-a536-914c2c84e2db,1c02528b-3781-4e3\
  2-929c-618d81f52cf3 --remove-volumes 8c0f6ae4-efb1-458f-a8fc-9da2afcc5fb\
  1,a245423f-bb99-4f94-8c8c-02806f9246d8 1de80c27-3b2f-47a6-91a7-e867cbe36462</pre></div><p><span class="bold"><strong>Create a consistency group from the snapshot of another consistency
group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src
[--cgsnapshot CGSNAPSHOT]
[--name NAME]
[--description DESCRIPTION]</pre></div><p>The parameter <code class="literal">CGSNAPSHOT</code> is a name or UUID of a snapshot of a
consistency group:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src --cgsnapshot 6d9dfb7d-079a-471e-b75a-\
  6e9185ba0c38 --name 'new cg' --description 'new cg from cgsnapshot'</pre></div><p><span class="bold"><strong>Create a consistency group from a source consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src
[--source-cg SOURCECG]
[--name NAME]
[--description DESCRIPTION]</pre></div><p>The parameter <code class="literal">SOURCECG</code> is a name or UUID of a source
consistency group:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src --source-cg 6d9dfb7d-079a-471e-b75a-\
  6e9185ba0c38 --name 'new cg' --description 'new cloned cg'</pre></div></div><div class="sect2 " id="filter-weigh-scheduler"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure and use driver filter and weighing for scheduler</span> <a title="Permalink" class="permalink" href="bk02ch07.html#filter-weigh-scheduler">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>filter-weigh-scheduler</li></ul></div></div></div></div><p>OpenStack Block Storage enables you to choose a volume back end based on
back-end specific properties by using the DriverFilter and
GoodnessWeigher for the scheduler. The driver filter and weigher
scheduling can help ensure that the scheduler chooses the best back end
based on requested volume properties as well as various back-end
specific properties.</p><div class="sect3 " id="id-1.4.9.7.22.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What is driver filter and weigher and when to use it</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The driver filter and weigher gives you the ability to more finely
control how the OpenStack Block Storage scheduler chooses the best back
end to use when handling a volume request. One example scenario where
using the driver filter and weigher can be if a back end that utilizes
thin-provisioning is used. The default filters use the <code class="literal">free capacity</code>
property to determine the best back end, but that is not always perfect.
If a back end has the ability to provide a more accurate back-end
specific value you can use that as part of the weighing. Another example
of when the driver filter and weigher can prove useful is if a back end
exists where there is a hard limit of 1000 volumes. The maximum volume
size is 500 GB. Once 75% of the total space is occupied the performance
of the back end degrades. The driver filter and weigher can provide a
way for these limits to be checked for.</p></div><div class="sect3 " id="id-1.4.9.7.22.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable driver filter and weighing</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable the driver filter, set the <code class="literal">scheduler_default_filters</code> option in
the <code class="literal">cinder.conf</code> file to <code class="literal">DriverFilter</code> or add it to the list if
other filters are already present.</p><p>To enable the goodness filter as a weigher, set the
<code class="literal">scheduler_default_weighers</code> option in the <code class="literal">cinder.conf</code> file to
<code class="literal">GoodnessWeigher</code> or add it to the list if other weighers are already
present.</p><p>You can choose to use the <code class="literal">DriverFilter</code> without the
<code class="literal">GoodnessWeigher</code> or vice-versa. The filter and weigher working
together, however, create the most benefits when helping the scheduler
choose an ideal back end.</p><div id="id-1.4.9.7.22.4.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg" /><h6>Important</h6><p>The support for the <code class="literal">DriverFilter</code> and <code class="literal">GoodnessWeigher</code> is
optional for back ends. If you are using a back end that does not
support the filter and weigher functionality you may not get the
full benefit.</p></div><p>Example <code class="literal">cinder.conf</code> configuration file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher</pre></div><div id="id-1.4.9.7.22.4.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>It is useful to use the other filters and weighers available in
OpenStack in combination with these custom ones. For example, the
<code class="literal">CapacityFilter</code> and <code class="literal">CapacityWeigher</code> can be combined with
these.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Defining your own filter and goodness functions</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can define your own filter and goodness functions through the use of
various properties that OpenStack Block Storage has exposed. Properties
exposed include information about the volume request being made,
<code class="literal">volume_type</code> settings, and back-end specific information about drivers.
All of these allow for a lot of control over how the ideal back end for
a volume request will be decided.</p><p>The <code class="literal">filter_function</code> option is a string defining an equation that
will determine whether a back end should be considered as a potential
candidate in the scheduler.</p><p>The <code class="literal">goodness_function</code> option is a string defining an equation that
will rate the quality of the potential host (0 to 100, 0 lowest, 100
highest).</p><div id="id-1.4.9.7.22.5.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg" /><h6>Important</h6><p>The drive filter and weigher will use default values for filter and
goodness functions for each back end if you do not define them
yourself. If complete control is desired then a filter and goodness
function should be defined for each of the back ends in
the <code class="literal">cinder.conf</code> file.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported operations in filter and goodness functions</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Below is a table of all the operations currently usable in custom filter
and goodness functions created by you:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operations</p>
                  </th><th>
                    <p>Type</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>+, -, *, /, ^</p>
                  </td><td>
                    <p>standard math</p>
                  </td></tr><tr><td>
                    <p>not, and, or, &amp;, |, !</p>
                  </td><td>
                    <p>logic</p>
                  </td></tr><tr><td>
                    <p>&gt;, &gt;=, &lt;, &lt;=, ==, &lt;&gt;, !=</p>
                  </td><td>
                    <p>equality</p>
                  </td></tr><tr><td>
                    <p>+, -</p>
                  </td><td>
                    <p>sign</p>
                  </td></tr><tr><td>
                    <p>x ? a : b</p>
                  </td><td>
                    <p>ternary</p>
                  </td></tr><tr><td>
                    <p>abs(x), max(x, y), min(x, y)</p>
                  </td><td>
                    <p>math helper functions</p>
                  </td></tr></tbody></table></div><div id="id-1.4.9.7.22.6.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg" /><h6>Important</h6><p>Syntax errors you define in filter or goodness strings
are thrown at a volume request time.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Available properties when creating custom functions</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are various properties that can be used in either the
<code class="literal">filter_function</code> or the <code class="literal">goodness_function</code> strings. The properties allow
access to volume info, qos settings, extra specs, and so on.</p><p>The following properties and their sub-properties are currently
available for use:</p><div class="sect4 " id="id-1.4.9.7.22.7.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.2.13.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Host stats for a back end</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.7.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.9.7.22.7.4.2.1"><span class="term ">host</span></dt><dd><p>The host's name</p></dd><dt id="id-1.4.9.7.22.7.4.2.2"><span class="term ">volume_backend_name</span></dt><dd><p>The volume back end name</p></dd><dt id="id-1.4.9.7.22.7.4.2.3"><span class="term ">vendor_name</span></dt><dd><p>The vendor name</p></dd><dt id="id-1.4.9.7.22.7.4.2.4"><span class="term ">driver_version</span></dt><dd><p>The driver version</p></dd><dt id="id-1.4.9.7.22.7.4.2.5"><span class="term ">storage_protocol</span></dt><dd><p>The storage protocol</p></dd><dt id="id-1.4.9.7.22.7.4.2.6"><span class="term ">QoS_support</span></dt><dd><p>Boolean signifying whether QoS is supported</p></dd><dt id="id-1.4.9.7.22.7.4.2.7"><span class="term ">total_capacity_gb</span></dt><dd><p>The total capacity in GB</p></dd><dt id="id-1.4.9.7.22.7.4.2.8"><span class="term ">allocated_capacity_gb</span></dt><dd><p>The allocated capacity in GB</p></dd><dt id="id-1.4.9.7.22.7.4.2.9"><span class="term ">reserved_percentage</span></dt><dd><p>The reserved storage percentage</p></dd></dl></div></div><div class="sect4 " id="id-1.4.9.7.22.7.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.2.13.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capabilities specific to a back end</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.7.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These properties are determined by the specific back end
you are creating filter and goodness functions for. Some back ends
may not have any properties available here.</p></div><div class="sect4 " id="id-1.4.9.7.22.7.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.2.13.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Requested volume properties</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.7.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.9.7.22.7.6.2.1"><span class="term ">status</span></dt><dd><p>Status for the requested volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.2"><span class="term ">volume_type_id</span></dt><dd><p>The volume type ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.3"><span class="term ">display_name</span></dt><dd><p>The display name of the volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.4"><span class="term ">volume_metadata</span></dt><dd><p>Any metadata the volume has</p></dd><dt id="id-1.4.9.7.22.7.6.2.5"><span class="term ">reservations</span></dt><dd><p>Any reservations the volume has</p></dd><dt id="id-1.4.9.7.22.7.6.2.6"><span class="term ">user_id</span></dt><dd><p>The volume's user ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.7"><span class="term ">attach_status</span></dt><dd><p>The attach status for the volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.8"><span class="term ">display_description</span></dt><dd><p>The volume's display description</p></dd><dt id="id-1.4.9.7.22.7.6.2.9"><span class="term ">id</span></dt><dd><p>The volume's ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.10"><span class="term ">replication_status</span></dt><dd><p>The volume's replication status</p></dd><dt id="id-1.4.9.7.22.7.6.2.11"><span class="term ">snapshot_id</span></dt><dd><p>The volume's snapshot ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.12"><span class="term ">encryption_key_id</span></dt><dd><p>The volume's encryption key ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.13"><span class="term ">source_volid</span></dt><dd><p>The source volume ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.14"><span class="term ">volume_admin_metadata</span></dt><dd><p>Any admin metadata for this volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.15"><span class="term ">source_replicaid</span></dt><dd><p>The source replication ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.16"><span class="term ">consistencygroup_id</span></dt><dd><p>The consistency group ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.17"><span class="term ">size</span></dt><dd><p>The size of the volume in GB</p></dd><dt id="id-1.4.9.7.22.7.6.2.18"><span class="term ">metadata</span></dt><dd><p>General metadata</p></dd></dl></div><p>The property most used from here will most likely be the <code class="literal">size</code> sub-property.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Extra specs for the requested volume type</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>View the available properties for volume types by running:</p><div class="verbatim-wrap"><pre class="screen">$ cinder extra-specs-list</pre></div></div><div class="sect3 " id="id-1.4.9.7.22.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Current QoS specs for the requested volume type</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>View the available properties for volume types by running:</p><div class="verbatim-wrap"><pre class="screen">$ cinder qos-list</pre></div><p>In order to access these properties in a custom string use the following
format:</p><p>
            <code class="literal">&lt;property&gt;.&lt;sub_property&gt;</code>
          </p></div><div class="sect3 " id="id-1.4.9.7.22.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Driver filter and weigher usage examples</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.22.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Below are examples for using the filter and weigher separately,
together, and using driver-specific properties.</p><p>Example <code class="literal">cinder.conf</code> file configuration for customizing the filter
function:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_filters = DriverFilter
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "volume.size &lt; 10"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "volume.size &gt;= 10"</pre></div><p>The above example will filter volumes to different back ends depending
on the size of the requested volume. Default OpenStack Block Storage
scheduler weighing is done. Volumes with a size less than 10 GB are sent
to lvm-1 and volumes with a size greater than or equal to 10 GB are sent
to lvm-2.</p><p>Example <code class="literal">cinder.conf</code> file configuration for customizing the goodness
function:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
goodness_function = "(volume.size &lt; 5) ? 100 : 50"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
goodness_function = "(volume.size &gt;= 5) ? 100 : 25"</pre></div><p>The above example will determine the goodness rating of a back end based
off of the requested volume's size. Default OpenStack Block Storage
scheduler filtering is done. The example shows how the ternary if
statement can be used in a filter or goodness function. If a requested
volume is of size 10 GB then lvm-1 is rated as 50 and lvm-2 is rated as
100. In this case lvm-2 wins. If a requested volume is of size 3 GB then
lvm-1 is rated 100 and lvm-2 is rated 25. In this case lvm-1 would win.</p><p>Example <code class="literal">cinder.conf</code> file configuration for customizing both the
filter and goodness functions:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "stats.total_capacity_gb &lt; 500"
goodness_function = "(volume.size &lt; 25) ? 100 : 50"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "stats.total_capacity_gb &gt;= 500"
goodness_function = "(volume.size &gt;= 25) ? 100 : 75"</pre></div><p>The above example combines the techniques from the first two examples.
The best back end is now decided based off of the total capacity of the
back end and the requested volume's size.</p><p>Example <code class="literal">cinder.conf</code> file configuration for accessing driver specific
properties:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1,lvm-2,lvm-3

[lvm-1]
volume_group = stack-volumes-lvmdriver-1
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = lvmdriver-1
filter_function = "volume.size &lt; 5"
goodness_function = "(capabilities.total_volumes &lt; 3) ? 100 : 50"

[lvm-2]
volume_group = stack-volumes-lvmdriver-2
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = lvmdriver-2
filter_function = "volumes.size &lt; 5"
goodness_function = "(capabilities.total_volumes &lt; 8) ? 100 : 50"

[lvm-3]
volume_group = stack-volumes-lvmdriver-3
volume_driver = cinder.volume.drivers.LVMVolumeDriver
volume_backend_name = lvmdriver-3
goodness_function = "55"</pre></div><p>The above is an example of how back-end specific properties can be used
in the filter and goodness functions. In this example the LVM driver's
<code class="literal">total_volumes</code> capability is being used to determine which host gets
used during a volume request. In the above example, lvm-1 and lvm-2 will
handle volume requests for all volumes with a size less than 5 GB. The
lvm-1 host will have priority until it contains three or more volumes.
After than lvm-2 will have priority until it contains eight or more
volumes. The lvm-3 will collect all volumes greater or equal to 5 GB as
well as all volumes once lvm-1 and lvm-2 lose priority.</p></div></div><div class="sect2 " id="id-1.4.9.7.23"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Rate-limit volume copy bandwidth</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.23">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you create a new volume from an image or an existing volume, or
when you upload a volume image to the Image service, large data copy
may stress disk and network bandwidth. To mitigate slow down of data
access from the instances, OpenStack Block Storage supports rate-limiting
of volume data copy bandwidth.</p><div class="sect3 " id="id-1.4.9.7.23.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure volume copy bandwidth limit</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.23.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To configure the volume copy bandwidth limit, set the
<code class="literal">volume_copy_bps_limit</code> option in the configuration groups for each
back end in the <code class="literal">cinder.conf</code> file. This option takes the integer of
maximum bandwidth allowed for volume data copy in byte per second. If
this option is set to <code class="literal">0</code>, the rate-limit is disabled.</p><p>While multiple volume data copy operations are running in the same back
end, the specified bandwidth is divided to each copy.</p><p>Example <code class="literal">cinder.conf</code> configuration file to limit volume copy bandwidth
of <code class="literal">lvmdriver-1</code> up to 100 MiB/s:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[lvmdriver-1]
volume_group=cinder-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
volume_copy_bps_limit=104857600</pre></div><div id="id-1.4.9.7.23.3.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>This feature requires libcgroup to set up blkio cgroup for disk I/O
bandwidth limit. The libcgroup is provided by the cgroup-bin package
in Debian and Ubuntu, or by the libcgroup-tools package in Fedora,
Red Hat Enterprise Linux, CentOS, openSUSE, and SUSE Linux Enterprise.</p></div><div id="id-1.4.9.7.23.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Some back ends which use remote file systems such as NFS are not
supported by this feature.</p></div></div></div><div class="sect2 " id="id-1.4.9.7.24"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Oversubscription in thin provisioning</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage enables you to choose a volume back end based on
virtual capacities for thin provisioning using the oversubscription ratio.</p><p>A reference implementation is provided for the default LVM driver. The
illustration below uses the LVM driver as an example.</p><div class="sect3 " id="id-1.4.9.7.24.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure oversubscription settings</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To support oversubscription in thin provisioning, a flag
<code class="literal">max_over_subscription_ratio</code> is introduced into <code class="literal">cinder.conf</code>.
This is a float representation of the oversubscription ratio when thin
provisioning is involved. Default ratio is 20.0, meaning provisioned
capacity can be 20 times of the total physical capacity. A ratio of 10.5
means provisioned capacity can be 10.5 times of the total physical capacity.
A ratio of 1.0 means provisioned capacity cannot exceed the total physical
capacity. A ratio lower than 1.0 is ignored and the default value is used
instead.</p><div id="id-1.4.9.7.24.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p><code class="literal">max_over_subscription_ratio</code> can be configured for each back end when
multiple-storage back ends are enabled. It is provided as a reference
implementation and is used by the LVM driver. However, it is not a
requirement for a driver to use this option from <code class="literal">cinder.conf</code>.</p><p><code class="literal">max_over_subscription_ratio</code> is for configuring a back end. For a
driver that supports multiple pools per back end, it can report this
ratio for each pool. The LVM driver does not support multiple pools.</p></div><p>The existing <code class="literal">reserved_percentage</code> flag is used to prevent over provisioning.
This flag represents the percentage of the back-end capacity that is reserved.</p><div id="id-1.4.9.7.24.4.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>There is a change on how <code class="literal">reserved_percentage</code> is used. It was measured
against the free capacity in the past. Now it is measured against the total
capacity.</p></div></div><div class="sect3 " id="id-1.4.9.7.24.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capabilities</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Drivers can report the following capabilities for a back end or a pool:</p><div class="verbatim-wrap highlight ini"><pre class="screen">thin_provisioning_support = True(or False)
thick_provisioning_support = True(or False)
provisioned_capacity_gb = PROVISIONED_CAPACITY
max_over_subscription_ratio = MAX_RATIO</pre></div><p>Where <code class="literal">PROVISIONED_CAPACITY</code> is the apparent allocated space indicating
how much capacity has been provisioned and <code class="literal">MAX_RATIO</code> is the maximum
oversubscription ratio. For the LVM driver, it is
<code class="literal">max_over_subscription_ratio</code> in <code class="literal">cinder.conf</code>.</p><p>Two capabilities are added here to allow a back end or pool to claim support
for thin provisioning, or thick provisioning, or both.</p><p>The LVM driver reports <code class="literal">thin_provisioning_support=True</code> and
<code class="literal">thick_provisioning_support=False</code> if the <code class="literal">lvm_type</code> flag in
<code class="literal">cinder.conf</code> is <code class="literal">thin</code>. Otherwise it reports
<code class="literal">thin_provisioning_support=False</code> and <code class="literal">thick_provisioning_support=True</code>.</p></div><div class="sect3 " id="id-1.4.9.7.24.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume type extra specs</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If volume type is provided as part of the volume creation request, it can
have the following extra specs defined:</p><div class="verbatim-wrap highlight ini"><pre class="screen">'capabilities:thin_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'
'capabilities:thick_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'</pre></div><div id="id-1.4.9.7.24.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p><code class="literal">capabilities</code> scope key before <code class="literal">thin_provisioning_support</code> and
<code class="literal">thick_provisioning_support</code> is not required. So the following works too:</p></div><div class="verbatim-wrap highlight ini"><pre class="screen">'thin_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'
'thick_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'</pre></div><p>The above extra specs are used by the scheduler to find a back end that
supports thin provisioning, thick provisioning, or both to match the needs
of a specific volume type.</p></div><div class="sect3 " id="id-1.4.9.7.24.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume replication extra specs</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage has the ability to create volume replicas.
Administrators can define a storage policy that includes
replication by adjusting the cinder volume driver. Volume replication
for OpenStack Block Storage helps safeguard OpenStack environments from
data loss during disaster recovery.</p><p>To enable replication when creating volume types, configure the cinder
volume with <code class="literal">capabilities:replication="&lt;is&gt; True"</code>.</p><p>Each volume created with the replication capability set to <code class="literal">True</code>
generates a copy of the volume on a storage back end.</p><p>One use case for replication involves an OpenStack cloud environment
installed across two data centers located nearby each other. The
distance between the two data centers in this use case is the length of
a city.</p><p>At each data center, a cinder host supports the Block Storage service.
Both data centers include storage back ends.</p><p>Depending on the storage requirements, there can be one or two cinder
hosts. The administrator accesses the
<code class="literal">/etc/cinder/cinder.conf</code> configuration file and sets
<code class="literal">capabilities:replication="&lt;is&gt; True"</code>.</p><p>If one data center experiences a service failure, administrators
can redeploy the VM. The VM will run using a replicated, backed up
volume on a host in the second data center.</p></div><div class="sect3 " id="id-1.4.9.7.24.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capacity filter</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the capacity filter, <code class="literal">max_over_subscription_ratio</code> is used when
choosing a back end if <code class="literal">thin_provisioning_support</code> is True and
<code class="literal">max_over_subscription_ratio</code> is greater than 1.0.</p></div><div class="sect3 " id="id-1.4.9.7.24.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capacity weigher</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.24.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the capacity weigher, virtual free capacity is used for ranking if
<code class="literal">thin_provisioning_support</code> is True. Otherwise, real free capacity
will be used as before.</p></div></div><div class="sect2 " id="id-1.4.9.7.25"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image-Volume cache</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.25">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage has an optional Image cache which can dramatically
improve the performance of creating a volume from an image. The improvement
depends on many factors, primarily how quickly the configured back end can
clone a volume.</p><p>When a volume is first created from an image, a new cached image-volume
will be created that is owned by the Block Storage Internal Tenant. Subsequent
requests to create volumes from that image will clone the cached version
instead of downloading the image contents and copying data to the volume.</p><p>The cache itself is configurable per back end and will contain the most
recently used images.</p><div class="sect3 " id="id-1.4.9.7.25.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Internal Tenant</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.25.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Image-Volume cache requires that the Internal Tenant be configured for
the Block Storage services. This project will own the cached image-volumes so
they can be managed like normal users including tools like volume quotas. This
protects normal users from having to see the cached image-volumes, but does
not make them globally hidden.</p><p>To enable the Block Storage services to have access to an Internal Tenant, set
the following options in the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">cinder_internal_tenant_project_id = PROJECT_ID
cinder_internal_tenant_user_id = USER_ID</pre></div><p>An example <code class="literal">cinder.conf</code> configuration file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">cinder_internal_tenant_project_id = b7455b8974bb4064ad247c8f375eae6c
cinder_internal_tenant_user_id = f46924c112a14c80ab0a24a613d95eef</pre></div><div id="id-1.4.9.7.25.5.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The actual user and project that are configured for the Internal Tenant do
not require any special privileges. They can be the Block Storage service
project or can be any normal project and user.</p></div></div><div class="sect3 " id="id-1.4.9.7.25.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Image-Volume cache</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.25.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable the Image-Volume cache, set the following configuration option in
the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_volume_cache_enabled = True</pre></div><div id="id-1.4.9.7.25.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If you use Ceph as a back end, set the following configuration option in
the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ceph]
image_volume_cache_enabled = True</pre></div></div><p>This can be scoped per back end definition or in the default options.</p><p>There are optional configuration settings that can limit the size of the cache.
These can also be scoped per back end or in the default options in
the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_volume_cache_max_size_gb = SIZE_GB
image_volume_cache_max_count = MAX_COUNT</pre></div><p>By default they will be set to 0, which means unlimited.</p><p>For example, a configuration which would limit the max size to 200 GB and 50
cache entries will be configured as:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_volume_cache_max_size_gb = 200
image_volume_cache_max_count = 50</pre></div></div><div class="sect3 " id="id-1.4.9.7.25.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notifications</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.25.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Cache actions will trigger Telemetry messages. There are several that will be
sent.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">image_volume_cache.miss</code> - A volume is being created from an image which
was not found in the cache. Typically this will mean a new cache entry would
be created for it.</p></li><li class="listitem "><p><code class="literal">image_volume_cache.hit</code> - A volume is being created from an image which
was found in the cache and the fast path can be taken.</p></li><li class="listitem "><p><code class="literal">image_volume_cache.evict</code> - A cached image-volume has been deleted from
the cache.</p></li></ul></div></div><div class="sect3 " id="id-1.4.9.7.25.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing cached Image-Volumes</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.25.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In normal usage there should be no need for manual intervention with the cache.
The entries and their backing Image-Volumes are managed automatically.</p><p>If needed, you can delete these volumes manually to clear the cache.
By using the standard volume deletion APIs, the Block Storage service will
clean up correctly.</p></div></div><div class="sect2 " id="id-1.4.9.7.26"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.17 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume-backed image</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.26">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage can quickly create a volume from an image that refers
to a volume storing image data (Image-Volume). Compared to the other stores
such as file and swift, creating a volume from a Volume-backed image performs
better when the block storage driver supports efficient volume cloning.</p><p>If the image is set to public in the Image service, the volume data can be
shared among projects.</p><div class="sect3 " id="id-1.4.9.7.26.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.17.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Volume-backed image</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.26.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Volume-backed image feature requires locations information from the cinder
store of the Image service. To enable the Image service to use the cinder
store, add <code class="literal">cinder</code> to the <code class="literal">stores</code> option in the <code class="literal">glance_store</code> section
of the <code class="literal">glance-api.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">stores = file, http, swift, cinder</pre></div><p>To expose locations information, set the following options in the <code class="literal">DEFAULT</code>
section of the <code class="literal">glance-api.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">show_multiple_locations = True</pre></div><p>To enable the Block Storage services to create a new volume by cloning Image-
Volume, set the following options in the <code class="literal">DEFAULT</code> section of the
<code class="literal">cinder.conf</code> file. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">glance_api_version = 2
allowed_direct_url_schemes = cinder</pre></div><p>To enable the <code class="command">openstack image create --volume &lt;volume&gt;</code> command to
create an image that refers an <code class="literal">Image-Volume</code>, set the following options in
each back-end section of the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_upload_use_cinder_backend = True</pre></div><p>By default, the <code class="command">openstack image create --volume &lt;volume&gt;</code> command
creates the Image-Volume in the current project. To store the Image-Volume into
the internal project, set the following options in each back-end section of the
<code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_upload_use_internal_tenant = True</pre></div><p>To make the Image-Volume in the internal project accessible from the Image
service, set the following options in the <code class="literal">glance_store</code> section of
the <code class="literal">glance-api.conf</code> file:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">cinder_store_auth_address</code>
              </p></li><li class="listitem "><p>
                <code class="literal">cinder_store_user_name</code>
              </p></li><li class="listitem "><p>
                <code class="literal">cinder_store_password</code>
              </p></li><li class="listitem "><p>
                <code class="literal">cinder_store_project_name</code>
              </p></li></ul></div></div><div class="sect3 " id="id-1.4.9.7.26.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.17.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Volume-backed image</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.26.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To register an existing volume as a new Volume-backed image, use the following
commands:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --disk-format raw --container-format bare IMAGE_NAME

$ glance location-add &lt;image-uuid&gt; --url cinder://&lt;volume-uuid&gt;</pre></div><p>If the <code class="literal">image_upload_use_cinder_backend</code> option is enabled, the following
command creates a new Image-Volume by cloning the specified volume and then
registers its location to a new image. The disk format and the container format
must be raw and bare (default). Otherwise, the image is uploaded to the default
store of the Image service.</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --volume SOURCE_VOLUME IMAGE_NAME</pre></div></div></div><div class="sect2 " id="id-1.4.9.7.27"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.18 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Get capabilities</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.27">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When an administrator configures <code class="literal">volume type</code> and <code class="literal">extra specs</code> of storage
on the back end, the administrator has to read the right documentation that
corresponds to the version of the storage back end. Deep knowledge of
storage is also required.</p><p>OpenStack Block Storage enables administrators to configure <code class="literal">volume type</code>
and <code class="literal">extra specs</code> without specific knowledge of the storage back end.</p><div id="id-1.4.9.7.27.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">Volume Type</code>: A group of volume policies.</p></li><li class="listitem "><p><code class="literal">Extra Specs</code>: The definition of a volume type. This is a group of
policies. For example, provision type, QOS that will be used to
define a volume at creation time.</p></li><li class="listitem "><p><code class="literal">Capabilities</code>: What the current deployed back end in Cinder is able
to do. These correspond to extra specs.</p></li></ul></div></div><div class="sect3 " id="id-1.4.9.7.27.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage of cinder client</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.27.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When an administrator wants to define new volume types for their
OpenStack cloud, the administrator would fetch a list of <code class="literal">capabilities</code>
for a particular back end using the cinder client.</p><p>First, get a list of the services:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume service list
+------------------+-------------------+------+---------+-------+----------------------------+
| Binary           | Host              | Zone | Status  | State | Updated At                 |
+------------------+-------------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller        | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
| cinder-volume    | block1@ABC-driver | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
+------------------+-------------------+------+---------+-------+----------------------------+</pre></div><p>With one of the listed hosts, pass that to <code class="literal">get-capabilities</code>, then
the administrator can obtain volume stats and also back end <code class="literal">capabilities</code>
as listed below.</p><div class="verbatim-wrap"><pre class="screen">$ cinder get-capabilities block1@ABC-driver
+---------------------+----------------------------------------------+
|     Volume stats    |                    Value                     |
+---------------------+----------------------------------------------+
|     description     |                     None                     |
|     display_name    |   Capabilities of Cinder Vendor ABC driver   |
|    driver_version   |                    2.0.0                     |
|      namespace      | OS::Storage::Capabilities::block1@ABC-driver |
|      pool_name      |                     None                     |
| replication_targets |                      []                      |
|   storage_protocol  |                    iSCSI                     |
|     vendor_name     |                  Vendor ABC                  |
|      visibility     |                     pool                     |
| volume_backend_name |                  ABC-driver                  |
+---------------------+----------------------------------------------+
+----------------------+-----------------------------------------------------+
|  Backend properties  |                     Value                           |
+----------------------+-----------------------------------------------------+
|      compression     | {u'type':u'boolean', u'title':u'Compression',  ...} |
| ABC:compression_type | {u'enum':u'['lossy', 'lossless', 'special']',  ...} |
|         qos          | {u'type':u'boolean', u'title':u'QoS',          ...} |
|     replication      | {u'type':u'boolean', u'title':u'Replication',  ...} |
|  thin_provisioning   | {u'type':u'boolean', u'title':u'Thin Provisioning'} |
|     ABC:minIOPS      | {u'type':u'integer', u'title':u'Minimum IOPS QoS',} |
|     ABC:maxIOPS      | {u'type':u'integer', u'title':u'Maximum IOPS QoS',} |
|    ABC:burstIOPS     | {u'type':u'integer', u'title':u'Burst IOPS QoS',..} |
+----------------------+-----------------------------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.9.7.27.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disable a service</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.27.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When an administrator wants to disable a service, identify the Binary
and the Host of the service. Use the <code class="command">cinder service-disable</code>
command combined with the Binary and Host to disable the service:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Determine the binary and host of the service you want to remove
initially.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume service list
+------------------+----------------------+------+---------+-------+----------------------------+
| Binary           | Host                 | Zone | Status  | State | Updated At                 |
+------------------+----------------------+------+---------+-------+----------------------------+
| cinder-scheduler | devstack             | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
| cinder-volume    | devstack@lvmdriver-1 | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
+------------------+----------------------+------+---------+-------+----------------------------+</pre></div></li><li class="step "><p>Disable the service using the Binary and Host name, placing the Host
before the Binary name.</p><div class="verbatim-wrap"><pre class="screen">$ cinder service-disable HOST_NAME BINARY_NAME</pre></div></li><li class="step "><p>Remove the service from the database.</p><div class="verbatim-wrap"><pre class="screen">$ cinder-manage service remove BINARY_NAME HOST_NAME</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.9.7.27.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage of REST API</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.27.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>New endpoint to <code class="literal">get capabilities</code> list for specific storage back end
is also available. For more details, refer to the Block Storage API reference.</p><p>API request:</p><div class="verbatim-wrap"><pre class="screen">GET /v2/{tenant_id}/capabilities/{hostname}</pre></div><p>Example of return value:</p><div class="verbatim-wrap highlight json"><pre class="screen">{
  "namespace": "OS::Storage::Capabilities::block1@ABC-driver",
  "volume_backend_name": "ABC-driver",
  "pool_name": "pool",
  "driver_version": "2.0.0",
  "storage_protocol": "iSCSI",
  "display_name": "Capabilities of Cinder Vendor ABC driver",
  "description": "None",
  "visibility": "public",
  "properties": {
   "thin_provisioning": {
      "title": "Thin Provisioning",
      "description": "Sets thin provisioning.",
      "type": "boolean"
    },
    "compression": {
      "title": "Compression",
      "description": "Enables compression.",
      "type": "boolean"
    },
    "ABC:compression_type": {
      "title": "Compression type",
      "description": "Specifies compression type.",
      "type": "string",
      "enum": [
        "lossy", "lossless", "special"
      ]
    },
    "replication": {
      "title": "Replication",
      "description": "Enables replication.",
      "type": "boolean"
    },
    "qos": {
      "title": "QoS",
      "description": "Enables QoS.",
      "type": "boolean"
    },
    "ABC:minIOPS": {
      "title": "Minimum IOPS QoS",
      "description": "Sets minimum IOPS if QoS is enabled.",
      "type": "integer"
    },
    "ABC:maxIOPS": {
      "title": "Maximum IOPS QoS",
      "description": "Sets maximum IOPS if QoS is enabled.",
      "type": "integer"
    },
    "ABC:burstIOPS": {
      "title": "Burst IOPS QoS",
      "description": "Sets burst IOPS if QoS is enabled.",
      "type": "integer"
    },
  }
}</pre></div></div><div class="sect3 " id="id-1.4.9.7.27.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage of volume type access extension</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.27.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Some volume types should be restricted only. For example, test volume types
where you are testing a new technology or ultra high performance volumes
(for special cases) where you do not want most users to be able to select
these volumes. An administrator/operator can then define private volume types
using cinder client.
Volume type access extension adds the ability to manage volume type access.
Volume types are public by default. Private volume types can be created by
setting the <code class="literal">is_public</code> Boolean field to <code class="literal">False</code> at creation time. Access to a
private volume type can be controlled by adding or removing a project from it.
Private volume types without projects are only visible by users with the
admin role/context.</p><p>Create a public volume type by setting <code class="literal">is_public</code> field to <code class="literal">True</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type create vol_Type1 --description test1 --public
+-------------+--------------------------------------+
| Field       | Value                                |
+-------------+--------------------------------------+
| description | test1                                |
| id          | b7dbed9e-de78-49f8-a840-651ae7308592 |
| is_public   | True                                 |
| name        | vol_Type1                            |
+-------------+--------------------------------------+</pre></div><p>Create a private volume type by setting <code class="literal">is_public</code> field to <code class="literal">False</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type create vol_Type2 --description test2 --private
+-------------+--------------------------------------+
| Field       | Value                                |
+-------------+--------------------------------------+
| description | test2                                |
| id          | 154baa73-d2c4-462f-8258-a2df251b0d39 |
| is_public   | False                                |
| name        | vol_Type2                            |
+-------------+--------------------------------------+</pre></div><p>Get a list of the volume types:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type list
+--------------------------------------+-------------+
| ID                                   | Name        |
+--------------------------------------+-------------+
| 0a948c84-bad5-4fba-88a2-c062006e4f6b | vol_Type1   |
| 87e5be6f-9491-4ea5-9906-9ac56494bb91 | lvmdriver-1 |
| fd508846-213f-4a07-aaf2-40518fb9a23f | vol_Type2   |
+--------------------------------------+-------------+</pre></div><p>Get a list of the projects:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| 4105ead90a854100ab6b121266707f2b | alt_demo           |
| 4a22a545cedd4fcfa9836eb75e558277 | admin              |
| 71f9cdb1a3ab4b8e8d07d347a2e146bb | service            |
| c4860af62ffe465e99ed1bc08ef6082e | demo               |
| e4b648ba5108415cb9e75bff65fa8068 | invisible_to_admin |
+----------------------------------+--------------------+</pre></div><p>Add volume type access for the given demo project, using its project-id:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type set --project c4860af62ffe465e99ed1bc08ef6082e \
  vol_Type2</pre></div><p>List the access information about the given volume type:</p><div class="verbatim-wrap"><pre class="screen">$ cinder type-access-list --volume-type vol_Type2
+--------------------------------------+----------------------------------+
|            Volume_type_ID            |            Project_ID            |
+--------------------------------------+----------------------------------+
| fd508846-213f-4a07-aaf2-40518fb9a23f | c4860af62ffe465e99ed1bc08ef6082e |
+--------------------------------------+----------------------------------+</pre></div><p>Remove volume type access for the given project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type unset --project c4860af62ffe465e99ed1bc08ef6082e \
  vol_Type2
$ cinder type-access-list --volume-type vol_Type2
+----------------+------------+
| Volume_type_ID | Project_ID |
+----------------+------------+
+----------------+------------+</pre></div></div></div><div class="sect2 " id="id-1.4.9.7.28"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.19 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Generic volume groups</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.7.28">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Generic volume group support is available in OpenStack Block Storage (cinder)
since the Newton release. The support is added for creating group types and
group specs, creating groups of volumes, and creating snapshots of groups.
The group operations can be performed using the Block Storage command line.</p><p>A group type is a type for a group just like a volume type for a volume.
A group type can also have associated group specs similar to extra specs
for a volume type.</p><p>In cinder, there is a group construct called <code class="literal">consistency group</code>. Consistency
groups only support consistent group snapshots and only a small number of
drivers can support it. The following is a list of drivers that support
consistency groups and the release when the support was added:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Juno: EMC VNX</p></li><li class="listitem "><p>Kilo: EMC VMAX, IBM (GPFS, Storwize, SVC, and XIV), ProphetStor, Pure</p></li><li class="listitem "><p>Liberty: Dell Storage Center, EMC XtremIO, HPE 3Par and LeftHand</p></li><li class="listitem "><p>Mitaka: EMC ScaleIO, NetApp Data ONTAP and E-Series, SolidFire</p></li><li class="listitem "><p>Newton: CoprHD, FalconStor, Huawei</p></li></ul></div><p>Consistency group cannot be extended easily to serve other purposes. A tenant
may want to put volumes used in the same application together in a group so
that it is easier to manage them together, and this group of volumes may or
may not support consistent group snapshot. Generic volume group is introduced
to solve this problem.</p><p>There is a plan to migrate existing consistency group operations to use
generic volume group operations in future releases. More information can be
found in <a class="link" href="https://github.com/openstack/cinder-specs/blob/master/specs/newton/group-snapshots.rst" target="_blank">Cinder specs</a>.</p><div id="id-1.4.9.7.28.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Only Block Storage V3 API supports groups. You can
specify <code class="literal">--os-volume-api-version 3.x</code> when using the <code class="literal">cinder</code>
command line for group operations where <code class="literal">3.x</code> contains a microversion value
for that command. The generic volume group feature was completed in several
patches. As a result, the minimum required microversion is different for
group types, groups, and group snapshots APIs.</p></div><p>The following group type operations are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a group type.</p></li><li class="listitem "><p>Delete a group type.</p></li><li class="listitem "><p>Set group spec for a group type.</p></li><li class="listitem "><p>Unset group spec for a group type.</p></li><li class="listitem "><p>List group types.</p></li><li class="listitem "><p>Show a group type details.</p></li><li class="listitem "><p>Update a group.</p></li><li class="listitem "><p>List group types and group specs.</p></li></ul></div><p>The following group and group snapshot operations are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a group, given group type and volume types.</p><div id="id-1.4.9.7.28.12.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A group must have one group type. A group can support more than one
volume type. The scheduler is responsible for finding a back end that
can support the given group type and volume types.</p><p>A group can only contain volumes hosted by the same back end.</p><p>A group is empty upon its creation. Volumes need to be created and added
to it later.</p></div></li><li class="listitem "><p>Show a group.</p></li><li class="listitem "><p>List groups.</p></li><li class="listitem "><p>Delete a group.</p></li><li class="listitem "><p>Modify a group.</p></li><li class="listitem "><p>Create a volume and add it to a group.</p></li><li class="listitem "><p>Create a snapshot for a group.</p></li><li class="listitem "><p>Show a group snapshot.</p></li><li class="listitem "><p>List group snapshots.</p></li><li class="listitem "><p>Delete a group snapshot.</p></li><li class="listitem "><p>Create a group from a group snapshot.</p></li><li class="listitem "><p>Create a group from a source group.</p></li></ul></div><p>The following operations are not allowed if a volume is in a group:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume migration.</p></li><li class="listitem "><p>Volume retype.</p></li><li class="listitem "><p>Volume deletion.</p><div id="id-1.4.9.7.28.14.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A group has to be deleted as a whole with all the volumes.</p></div></li></ul></div><p>The following operations are not allowed if a volume snapshot is in a
group snapshot:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume snapshot deletion.</p><div id="id-1.4.9.7.28.16.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A group snapshot has to be deleted as a whole with all the volume
snapshots.</p></div></li></ul></div><p>The details of group type operations are shown in the following. The minimum
microversion to support group type and group specs is 3.11:</p><p><span class="bold"><strong>Create a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-create
[--description DESCRIPTION]
[--is-public IS_PUBLIC]
NAME</pre></div><div id="id-1.4.9.7.28.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">NAME</code> is required. The
<code class="literal">--is-public IS_PUBLIC</code> determines whether the group type is
accessible to the public. It is <code class="literal">True</code> by default. By default, the
policy on privileges for creating a group type is admin-only.</p></div><p><span class="bold"><strong>Show a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-show
GROUP_TYPE</pre></div><div id="id-1.4.9.7.28.23" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE</code> is the name or UUID of a group type.</p></div><p><span class="bold"><strong>List group types</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-list</pre></div><div id="id-1.4.9.7.28.26" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Only admin can see private group types.</p></div><p><span class="bold"><strong>Update a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-update
[--name NAME]
[--description DESCRIPTION]
[--is-public IS_PUBLIC]
GROUP_TYPE_ID</pre></div><div id="id-1.4.9.7.28.29" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE_ID</code> is the UUID of a group type. By default,
the policy on privileges for updating a group type is admin-only.</p></div><p><span class="bold"><strong>Delete group type or types</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-delete
GROUP_TYPE [GROUP_TYPE ...]</pre></div><div id="id-1.4.9.7.28.32" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE</code> is name or UUID of the group type or
group types to be deleted. By default, the policy on privileges for
deleting a group type is admin-only.</p></div><p><span class="bold"><strong>Set or unset group spec for a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-key
GROUP_TYPE ACTION KEY=VALUE [KEY=VALUE ...]</pre></div><div id="id-1.4.9.7.28.35" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE</code> is the name or UUID of a group type. Valid
values for the parameter <code class="literal">ACTION</code> are <code class="literal">set</code> or <code class="literal">unset</code>.
<code class="literal">KEY=VALUE</code> is the group specs key and value pair to set or unset.
For unset, specify only the key. By default, the policy on privileges
for setting or unsetting group specs key is admin-only.</p></div><p><span class="bold"><strong>List group types and group specs</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-specs-list</pre></div><div id="id-1.4.9.7.28.38" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>By default, the policy on privileges for seeing group specs is admin-only.</p></div><p>The details of group operations are shown in the following. The minimum
microversion to support groups operations is 3.13.</p><p><span class="bold"><strong>Create a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-create
[--name NAME]
[--description DESCRIPTION]
[--availability-zone AVAILABILITY_ZONE]
GROUP_TYPE VOLUME_TYPES</pre></div><div id="id-1.4.9.7.28.42" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameters <code class="literal">GROUP_TYPE</code> and <code class="literal">VOLUME_TYPES</code> are required.
<code class="literal">GROUP_TYPE</code> is the name or UUID of a group type. <code class="literal">VOLUME_TYPES</code>
can be a list of names or UUIDs of volume types separated by commas
without spaces in between. For example,
<code class="literal">volumetype1,volumetype2,volumetype3.</code>.</p></div><p><span class="bold"><strong>Show a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-show
GROUP</pre></div><div id="id-1.4.9.7.28.45" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP</code> is the name or UUID of a group.</p></div><p><span class="bold"><strong>List groups</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-list
[--all-tenants [&lt;0|1&gt;]]</pre></div><div id="id-1.4.9.7.28.48" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p><code class="literal">--all-tenants</code> specifies whether to list groups for all tenants.
Only admin can use this option.</p></div><p><span class="bold"><strong>Create a volume and add it to a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 create
--volume-type VOLUME_TYPE
--group-id GROUP_ID SIZE</pre></div><div id="id-1.4.9.7.28.51" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>When creating a volume and adding it to a group, the parameters
<code class="literal">VOLUME_TYPE</code> and <code class="literal">GROUP_ID</code> must be provided. This is because a group
can support more than one volume type.</p></div><p><span class="bold"><strong>Delete a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-delete
[--delete-volumes]
GROUP [GROUP ...]</pre></div><div id="id-1.4.9.7.28.54" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p><code class="literal">--delete-volumes</code> allows or disallows groups to be deleted
if they are not empty. If the group is empty, it can be deleted without
<code class="literal">--delete-volumes</code>. If the group is not empty, the flag is
required for it to be deleted. When the flag is specified, the group
and all volumes in the group will be deleted.</p></div><p><span class="bold"><strong>Modify a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-update
[--name NAME]
[--description DESCRIPTION]
[--add-volumes UUID1,UUID2,......]
[--remove-volumes UUID3,UUID4,......]
GROUP</pre></div><div id="id-1.4.9.7.28.57" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">UUID1,UUID2,......</code> is the UUID of one or more volumes
to be added to the group, separated by commas. Similarly the parameter
<code class="literal">UUID3,UUID4,......</code> is the UUID of one or more volumes to be removed
from the group, separated by commas.</p></div><p>The details of group snapshots operations are shown in the following. The
minimum microversion to support group snapshots operations is 3.14.</p><p><span class="bold"><strong>Create a snapshot for a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-create
[--name NAME]
[--description DESCRIPTION]
GROUP</pre></div><div id="id-1.4.9.7.28.61" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP</code> is the name or UUID of a group.</p></div><p><span class="bold"><strong>Show a group snapshot</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-show
GROUP_SNAPSHOT</pre></div><div id="id-1.4.9.7.28.64" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_SNAPSHOT</code> is the name or UUID of a group snapshot.</p></div><p><span class="bold"><strong>List group snapshots</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-list
[--all-tenants [&lt;0|1&gt;]]
[--status STATUS]
[--group-id GROUP_ID]</pre></div><div id="id-1.4.9.7.28.67" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p><code class="literal">--all-tenants</code> specifies whether to list group snapshots for
all tenants. Only admin can use this option. <code class="literal">--status STATUS</code>
filters results by a status. <code class="literal">--group-id GROUP_ID</code> filters
results by a group id.</p></div><p><span class="bold"><strong>Delete group snapshot</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-delete
GROUP_SNAPSHOT [GROUP_SNAPSHOT ...]</pre></div><div id="id-1.4.9.7.28.70" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_SNAPSHOT</code> specifies the name or UUID of one or more
group snapshots to be deleted.</p></div><p><span class="bold"><strong>Create a group from a group snapshot or a source group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder --os-volume-api-version 3.14 group-create-from-src
[--group-snapshot GROUP_SNAPSHOT]
[--source-group SOURCE_GROUP]
[--name NAME]
[--description DESCRIPTION]</pre></div><div id="id-1.4.9.7.28.73" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_SNAPSHOT</code> is a name or UUID of a group snapshot.
The parameter <code class="literal">SOURCE_GROUP</code> is a name or UUID of a source group.
Either <code class="literal">GROUP_SNAPSHOT</code> or <code class="literal">SOURCE_GROUP</code> must be specified, but not
both.</p></div></div></div><div class="sect1 " id="id-1.4.9.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot your installation</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section provides useful tips to help you troubleshoot your Block
Storage installation.</p><div class="sect2 " id="id-1.4.9.8.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot the Block Storage configuration</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Most Block Storage errors are caused by incorrect volume configurations
that result in volume creation failures. To resolve these failures,
review these logs:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">cinder-api</code> log (<code class="literal">/var/log/cinder/api.log</code>)</p></li><li class="listitem "><p><code class="literal">cinder-volume</code> log (<code class="literal">/var/log/cinder/volume.log</code>)</p></li></ul></div><p>The <code class="literal">cinder-api</code> log is useful for determining if you have endpoint or
connectivity issues. If you send a request to create a volume and it
fails, review the <code class="literal">cinder-api</code> log to determine whether the request made
it to the Block Storage service. If the request is logged and you see no
errors or tracebacks, check the <code class="literal">cinder-volume</code> log for errors or
tracebacks.</p><div id="id-1.4.9.8.3.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Create commands are listed in the <code class="literal">cinder-api</code> log.</p></div><p>These entries in the <code class="literal">cinder.openstack.common.log</code> file can be used to
assist in troubleshooting your Block Storage configuration.</p><div class="verbatim-wrap"><pre class="screen"># Print debugging output (set logging level to DEBUG instead
# of default WARNING level). (boolean value)
# debug=false

# Print more verbose output (set logging level to INFO instead
# of default WARNING level). (boolean value)
# verbose=false

# Log output to standard error (boolean value)
# use_stderr=true

# Default file mode used when creating log files (string
# value)
# logfile_mode=0644

# format string to use for log messages with context (string
# value)
# logging_context_format_string=%(asctime)s.%(msecs)03d %(levelname)s
# %(name)s [%(request_id)s %(user)s %(tenant)s] %(instance)s%(message)s

# format string to use for log mes #logging_default_format_string=%(asctime)s.
# %(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s

# data to append to log format when level is DEBUG (string
# value)
# logging_debug_format_suffix=%(funcName)s %(pathname)s:%(lineno)d

# prefix each line of exception output with this format
# (string value)
# logging_exception_prefix=%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s
# %(instance)s

# list of logger=LEVEL pairs (list value)
# default_log_levels=amqplib=WARN,sqlalchemy=WARN,boto=WARN,suds=INFO,
# keystone=INFO,eventlet.wsgi.server=WARNsages without context
# (string value)

# If an instance is passed with the log message, format it
# like this (string value)
# instance_format="[instance: %(uuid)s]"

# If an instance UUID is passed with the log message, format
# it like this (string value)
#instance_uuid_format="[instance: %(uuid)s] "

# Format string for %%(asctime)s in log records. Default:
# %(default)s (string value)
# log_date_format=%Y-%m-%d %H:%M:%S

# (Optional) Name of log file to output to. If not set,
# logging will go to stdout. (string value)
# log_file=&lt;None&gt;

# (Optional) The directory to keep log files in (will be
# prepended to --log-file) (string value)
# log_dir=&lt;None&gt;
# instance_uuid_format="[instance: %(uuid)s]"

# If this option is specified, the logging configuration file
# specified is used and overrides any other logging options
# specified. Please see the Python logging module
# documentation for details on logging configuration files.
# (string value)
# Use syslog for logging. (boolean value)
# use_syslog=false

# syslog facility to receive log lines (string value)
# syslog_log_facility=LOG_USER
# log_config=&lt;None&gt;</pre></div><p>These common issues might occur during configuration, and the following
potential solutions describe how to address the issues.</p><div class="sect3 " id="id-1.4.9.8.3.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Issues with <code class="literal">state_path</code> and <code class="literal">volumes_dir</code> settings</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.9.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.9.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Block Storage uses <code class="literal">tgtd</code> as the default iSCSI helper
and implements persistent targets. This means that in the case of a
<code class="literal">tgt</code> restart, or even a node reboot, your existing volumes on that
node will be restored automatically with their original <a class="xref" href="bk02go01.html#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a>.</p><p>By default, Block Storage uses a <code class="literal">state_path</code> variable, which if
installing with Yum or APT should be set to <code class="literal">/var/lib/cinder/</code>.
The next part is the <code class="literal">volumes_dir</code> variable, by default this appends
a <code class="literal">volumes</code> directory to the <code class="literal">state_path</code>. The result is a
file-tree: <code class="literal">/var/lib/cinder/volumes/</code>.</p></div><div class="sect4 " id="id-1.4.9.8.3.9.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.9.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In order to ensure nodes are restored to their original IQN,
the iSCSI target information needs to be stored in a file on creation
that can be queried in case of restart of the <code class="literal">tgt daemon</code>. While the
installer should handle all this, it can go wrong.</p><p>If you have trouble creating volumes and this directory does not exist
you should see an error message in the <code class="literal">cinder-volume</code> log indicating
that the <code class="literal">volumes_dir</code> does not exist, and it should provide
information about which path it was looking for.</p></div></div><div class="sect3 " id="id-1.4.9.8.3.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The persistent tgt include file</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.10.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.10.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Block Storage service may have issues locating the persistent
<code class="literal">tgt include</code> file. Along with the <code class="literal">volumes_dir</code> option, the
iSCSI target driver also needs to be configured to look in the correct
place for the persistent <code class="literal">tgt include `` file. This is an entry
in the ``/etc/tgt/conf.d</code> file that should have been set during the
OpenStack installation.</p></div><div class="sect4 " id="id-1.4.9.8.3.10.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.10.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If issues occur, verify that you have a <code class="literal">/etc/tgt/conf.d/cinder.conf</code>
file. If the file is not present, create it with:</p><div class="verbatim-wrap"><pre class="screen"># echo 'include /var/lib/cinder/volumes/ *' &gt;&gt; /etc/tgt/conf.d/cinder.conf</pre></div></div></div><div class="sect3 " id="id-1.4.9.8.3.11"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">No sign of attach call in the <code class="literal">cinder-api</code> log</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.11">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.11.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.11.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The attach call is unavailable, or not appearing in the <code class="literal">cinder-api</code> log.</p></div><div class="sect4 " id="id-1.4.9.8.3.11.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.11.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Adjust the <code class="literal">nova.conf</code> file, and make sure that your <code class="literal">nova.conf</code>
has this entry:</p><div class="verbatim-wrap highlight ini"><pre class="screen">volume_api_class=nova.volume.cinder.API</pre></div></div></div><div class="sect3 " id="id-1.4.9.8.3.12"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to create iscsi target error in the <code class="literal">cinder-volume.log</code> file</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.12">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.12.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.12.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">2013-03-12 01:35:43 1248 TRACE cinder.openstack.common.rpc.amqp \
ISCSITargetCreateFailed: \
Failed to create iscsi target for volume \
volume-137641b2-af72-4a2f-b243-65fdccd38780.</pre></div><p>You might see this error in <code class="literal">cinder-volume.log</code> after trying to
create a volume that is 1 GB.</p></div><div class="sect4 " id="id-1.4.9.8.3.12.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.3.12.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To fix this issue, change the content of the <code class="literal">/etc/tgt/targets.conf</code>
file from <code class="literal">include /etc/tgt/conf.d/*.conf</code> to
<code class="literal">include /etc/tgt/conf.d/cinder_tgt.conf</code>, as follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">include /etc/tgt/conf.d/cinder_tgt.conf
include /etc/tgt/conf.d/cinder.conf
default-driver iscsi</pre></div><p>Restart <code class="literal">tgt</code> and <code class="literal">cinder-*</code> services, so they pick up the new
configuration.</p></div></div></div><div class="sect2 " id="id-1.4.9.8.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Multipath call failed exit</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.4.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.4.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Multipath call failed exit. This warning occurs in the Compute log
if you do not have the optional <code class="literal">multipath-tools</code> package installed
on the compute node. This is an optional package and the volume
attachment does work without the multipath tools installed.
If the <code class="literal">multipath-tools</code> package is installed on the compute node,
it is used to perform the volume attachment.
The IDs in your message are unique to your system.</p><div class="verbatim-wrap"><pre class="screen">WARNING nova.storage.linuxscsi [req-cac861e3-8b29-4143-8f1b-705d0084e571
    admin admin|req-cac861e3-8b29-4143-8f1b-705d0084e571 admin admin]
    Multipath call failed exit (96)</pre></div></div><div class="sect3 " id="id-1.4.9.8.4.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.4.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run the following command on the compute node to install the
<code class="literal">multipath-tools</code> packages.</p><div class="verbatim-wrap"><pre class="screen"># apt-get install multipath-tools</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Addressing discrepancies in reported volume sizes for EqualLogic storage</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.5.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.5.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There is a discrepancy between both the actual volume size in EqualLogic
(EQL) storage and the image size in the Image service, with what is
reported to OpenStack database. This could lead to confusion
if a user is creating volumes from an image that was uploaded from an EQL
volume (through the Image service). The image size is slightly larger
than the target volume size; this is because EQL size reporting accounts
for additional storage used by EQL for internal volume metadata.</p><p>To reproduce the issue follow the steps in the following procedure.</p><p>This procedure assumes that the EQL array is provisioned, and that
appropriate configuration settings have been included in
<code class="literal">/etc/cinder/cinder.conf</code> to connect to the EQL array.</p><p>Create a new volume. Note the ID and size of the volume. In the
following example, the ID and size are
<code class="literal">74cf9c04-4543-47ae-a937-a9b7c6c921e7</code> and <code class="literal">1</code>, respectively:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create volume1 --size 1

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-12-06T11:33:30.957318           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | 74cf9c04-4543-47ae-a937-a9b7c6c921e7 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | volume1                              |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | iscsi                                |
| updated_at          | None                                 |
| user_id             | c36cec73b0e44876a4478b1e6cd749bb     |
+---------------------+--------------------------------------+</pre></div><p>Verify the volume size on the EQL array by using its command-line
interface.</p><p>The actual size (<code class="literal">VolReserve</code>) is 1.01 GB. The EQL Group Manager
should also report a volume size of 1.01 GB:</p><div class="verbatim-wrap"><pre class="screen">eql&gt; volume select volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
eql (volume_volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7)&gt; show
_______________________________ Volume Information ________________________________
Name: volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
Size: 1GB
VolReserve: 1.01GB
VolReservelnUse: 0MB
ReplReservelnUse: 0MB
iSCSI Alias: volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
iSCSI Name: iqn.2001-05.com.equallogic:0-8a0906-19f91850c-067000000b4532cl-volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
ActualMembers: 1
Snap-Warn: 10%
Snap-Depletion: delete-oldest
Description:
Snap-Reserve: 100%
Snap-Reserve-Avail: 100% (1.01GB)
Permission: read-write
DesiredStatus: online
Status: online
Connections: O
Snapshots: O
Bind:
Type: not-replicated
ReplicationReserveSpace: 0MB</pre></div><p>Create a new image from this volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --volume volume1 \
  --disk-format raw --container-format bare image_from_volume1

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| container_format    | bare                                 |
| disk_format         | raw                                  |
| display_description | None                                 |
| id                  | 850fd393-a968-4259-9c65-6b495cba5209 |
| image_id            | 3020a21d-ba37-4495-8899-07fc201161b9 |
| image_name          | image_from_volume1                   |
| is_public           | False                                |
| protected           | False                                |
| size                | 1                                    |
| status              | uploading                            |
| updated_at          | 2016-12-05T12:43:56.000000           |
| volume_type         | iscsi                                |
+---------------------+--------------------------------------+</pre></div><p>When you uploaded the volume in the previous step, the Image service
reported the volume's size as <code class="literal">1</code> (GB). However, when using
<code class="command">openstack image show</code> to show the image, the displayed size is
1085276160 bytes, or roughly 1.01 GB:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                    <p>Property</p>
                  </td><td>
                    <p>Value</p>
                  </td></tr><tr><td>
                    <p>checksum
container_format
created_at
disk_format
id
min_disk
min_ram
name
owner
protected
size
status
tags
updated_at
virtual_size
visibility</p>
                  </td><td>
                    <p>cd573cfaace07e7949bc0c46028904ff
bare
2016-12-06T11:39:06Z
raw
3020a21d-ba37-4495-8899-07fc201161b9
0
0
image_from_volume1
5669caad86a04256994cdf755df4d3c1
False
1085276160
active
[]
2016-12-06T11:39:24Z
None
private</p>
                  </td></tr></tbody></table></div><p>Create a new volume using the previous image (<code class="literal">image_id 3020a21d-ba37-4495
-8899-07fc201161b9</code> in this example) as
the source. Set the target volume size to 1 GB; this is the size
reported by the <code class="literal">cinder</code> tool when you uploaded the volume to the
Image service:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create volume2 --size 1 --image 3020a21d-ba37-4495-8899-07fc201161b9
ERROR: Invalid input received: Size of specified image 2 is larger
than volume size 1. (HTTP 400) (Request-ID: req-4b9369c0-dec5-4e16-a114-c0cdl6bSd210)</pre></div><p>The attempt to create a new volume based on the size reported by the
<code class="literal">cinder</code> tool will then fail.</p></div><div class="sect3 " id="id-1.4.9.8.5.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.5.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To work around this problem, increase the target size of the new image
to the next whole number. In the problem example, you created a 1 GB
volume to be used as volume-backed image, so a new volume using this
volume-backed image should use a size of 2 GB:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create volume2 --size 1 --image 3020a21d-ba37-4495-8899-07fc201161b9
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-12-06T11:49:06.031768           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | a70d6305-f861-4382-84d8-c43128be0013 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | volume2                              |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | iscsi                                |
| updated_at          | None                                 |
| user_id             | c36cec73b0e44876a4478b1e6cd749bb     |
+---------------------+--------------------------------------+</pre></div><div id="id-1.4.9.8.5.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The dashboard suggests a suitable size when you create a new volume
based on a volume-backed image.</p></div><p>You can then check this new volume into the EQL array:</p><div class="verbatim-wrap"><pre class="screen">eql&gt; volume select volume-64e8eb18-d23f-437b-bcac-b352afa6843a
eql (volume_volume-61e8eb18-d23f-437b-bcac-b352afa6843a)&gt; show
______________________________ Volume Information _______________________________
Name: volume-64e8eb18-d23f-437b-bcac-b352afa6843a
Size: 2GB
VolReserve: 2.01GB
VolReserveInUse: 1.01GB
ReplReserveInUse: 0MB
iSCSI Alias: volume-64e8eb18-d23f-437b-bcac-b352afa6843a
iSCSI Name: iqn.2001-05.com.equallogic:0-8a0906-e3091850e-eae000000b7S32cl-volume-64e8eb18-d23f-437b-bcac-b3S2afa6Bl3a
ActualMembers: 1
Snap-Warn: 10%
Snap-Depletion: delete-oldest
Description:
Snap-Reserve: 100%
Snap-Reserve-Avail: 100% (2GB)
Permission: read-write
DesiredStatus: online
Status: online
Connections: 1
Snapshots: O
Bind:
Type: not-replicated
ReplicationReserveSpace: 0MB</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to Attach Volume, Missing sg_scan</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.6.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.6.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Failed to attach volume to an instance, <code class="literal">sg_scan</code> file not found. This
error occurs when the sg3-utils package is not installed on the compute node.
The IDs in your message are unique to your system:</p><div class="verbatim-wrap"><pre class="screen">ERROR nova.compute.manager [req-cf2679fd-dd9e-4909-807f-48fe9bda3642 admin admin|req-cf2679fd-dd9e-4909-807f-48fe9bda3642 admin admin]
[instance: 7d7c92e0-49fa-4a8e-87c7-73f22a9585d5|instance:  7d7c92e0-49fa-4a8e-87c7-73f22a9585d5]
Failed to attach volume  4cc104c4-ac92-4bd6-9b95-c6686746414a at /dev/vdcTRACE nova.compute.manager
[instance:  7d7c92e0-49fa-4a8e-87c7-73f22a9585d5|instance: 7d7c92e0-49fa-4a8e-87c7-73f22a9585d5]
Stdout: '/usr/local/bin/nova-rootwrap: Executable not found: /usr/bin/sg_scan'</pre></div></div><div class="sect3 " id="id-1.4.9.8.6.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.6.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run this command on the compute node to install the <code class="literal">sg3-utils</code> package:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install sg3-utils</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">HTTP bad request in cinder volume log</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.7.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.7.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These errors appear in the <code class="literal">cinder-volume.log</code> file:</p><div class="verbatim-wrap"><pre class="screen">2013-05-03 15:16:33 INFO [cinder.volume.manager] Updating volume status
2013-05-03 15:16:33 DEBUG [hp3parclient.http]
REQ: curl -i https://10.10.22.241:8080/api/v1/cpgs -X GET -H "X-Hp3Par-Wsapi-Sessionkey: 48dc-b69ed2e5
f259c58e26df9a4c85df110c-8d1e8451" -H "Accept: application/json" -H "User-Agent: python-3parclient"

2013-05-03 15:16:33 DEBUG [hp3parclient.http] RESP:{'content-length': 311, 'content-type': 'text/plain',
'status': '400'}

2013-05-03 15:16:33 DEBUG [hp3parclient.http] RESP BODY:Second simultaneous read on fileno 13 detected.
Unless you really know what you're doing, make sure that only one greenthread can read any particular socket.
Consider using a pools.Pool. If you do know what you're doing and want to disable this error,
call eventlet.debug.hub_multiple_reader_prevention(False)

2013-05-03 15:16:33 ERROR [cinder.manager] Error during VolumeManager._report_driver_status: Bad request (HTTP 400)
Traceback (most recent call last):
File "/usr/lib/python2.7/dist-packages/cinder/manager.py", line 167, in periodic_tasks task(self, context)
File "/usr/lib/python2.7/dist-packages/cinder/volume/manager.py", line 690, in _report_driver_status volume_stats =
self.driver.get_volume_stats(refresh=True)
File "/usr/lib/python2.7/dist-packages/cinder/volume/drivers/san/hp/hp_3par_fc.py", line 77, in get_volume_stats stats =
self.common.get_volume_stats(refresh, self.client)
File "/usr/lib/python2.7/dist-packages/cinder/volume/drivers/san/hp/hp_3par_common.py", line 421, in get_volume_stats cpg =
client.getCPG(self.config.hp3par_cpg)
File "/usr/lib/python2.7/dist-packages/hp3parclient/client.py", line 231, in getCPG cpgs = self.getCPGs()
File "/usr/lib/python2.7/dist-packages/hp3parclient/client.py", line 217, in getCPGs response, body = self.http.get('/cpgs')
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 255, in get return self._cs_request(url, 'GET', **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 224, in _cs_request **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 198, in _time_request resp, body = self.request(url, method, **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 192, in request raise exceptions.from_response(resp, body)
HTTPBadRequest: Bad request (HTTP 400)</pre></div></div><div class="sect3 " id="id-1.4.9.8.7.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.7.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You need to update your copy of the <code class="literal">hp_3par_fc.py</code> driver which
contains the synchronization code.</p></div></div><div class="sect2 " id="id-1.4.9.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Duplicate 3PAR host</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.8.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This error may be caused by a volume being exported outside of OpenStack
using a host name different from the system name that OpenStack expects.
This error could be displayed with the <a class="xref" href="bk02go01.html#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a> if the host was exported using iSCSI:</p><div class="verbatim-wrap"><pre class="screen">Duplicate3PARHost: 3PAR Host already exists: Host wwn 50014380242B9750 \
already used by host cld4b5ubuntuW(id = 68. The hostname must be called\
'cld4b5ubuntu'.</pre></div></div><div class="sect3 " id="id-1.4.9.8.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Change the 3PAR host name to match the one that OpenStack expects. The
3PAR host constructed by the driver uses just the local host name, not
the fully qualified domain name (FQDN) of the compute host. For example,
if the FQDN was <span class="emphasis"><em>myhost.example.com</em></span>, just <span class="emphasis"><em>myhost</em></span> would be used as the
3PAR host name. IP addresses are not allowed as host names on the 3PAR
storage server.</p></div></div><div class="sect2 " id="id-1.4.9.8.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to attach volume after detaching</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.9.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.9.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Failed to attach a volume after detaching the same volume.</p></div><div class="sect3 " id="id-1.4.9.8.9.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.9.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must change the device name on the <code class="command">nova-attach</code> command. The VM
might not clean up after a <code class="command">nova-detach</code> command runs. This example
shows how the <code class="command">nova-attach</code> command fails when you use the <code class="literal">vdb</code>,
<code class="literal">vdc</code>, or <code class="literal">vdd</code> device names:</p><div class="verbatim-wrap"><pre class="screen"># ls -al /dev/disk/by-path/
total 0
drwxr-xr-x 2 root root 200 2012-08-29 17:33 .
drwxr-xr-x 5 root root 100 2012-08-29 17:33 ..
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0 -&gt; ../../vda
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part1 -&gt; ../../vda1
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part2 -&gt; ../../vda2
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part5 -&gt; ../../vda5
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:06.0-virtio-pci-virtio2 -&gt; ../../vdb
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:08.0-virtio-pci-virtio3 -&gt; ../../vdc
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:09.0-virtio-pci-virtio4 -&gt; ../../vdd
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:09.0-virtio-pci-virtio4-part1 -&gt; ../../vdd1</pre></div><p>You might also have this problem after attaching and detaching the same
volume from the same VM with the same mount point multiple times. In
this case, restart the KVM host.</p></div></div><div class="sect2 " id="id-1.4.9.8.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to attach volume, systool is not installed</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.10.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.10.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This warning and error occurs if you do not have the required
<code class="literal">sysfsutils</code> package installed on the compute node:</p><div class="verbatim-wrap"><pre class="screen">WARNING nova.virt.libvirt.utils [req-1200f887-c82b-4e7c-a891-fac2e3735dbb\
admin admin|req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin admin] systool\
is not installed
ERROR nova.compute.manager [req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin\
admin|req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin admin]
[instance: df834b5a-8c3f-477a-be9b-47c97626555c|instance: df834b5a-8c3f-47\
7a-be9b-47c97626555c]
Failed to attach volume 13d5c633-903a-4764-a5a0-3336945b1db1 at /dev/vdk.</pre></div></div><div class="sect3 " id="id-1.4.9.8.10.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.10.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run the following command on the compute node to install the
<code class="literal">sysfsutils</code> packages:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install sysfsutils</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to connect volume in FC SAN</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.11.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.11.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The compute node failed to connect to a volume in a Fibre Channel (FC) SAN
configuration. The WWN may not be zoned correctly in your FC SAN that
links the compute host to the storage array:</p><div class="verbatim-wrap"><pre class="screen">ERROR nova.compute.manager [req-2ddd5297-e405-44ab-aed3-152cd2cfb8c2 admin\
demo|req-2ddd5297-e405-44ab-aed3-152cd2cfb8c2 admin demo] [instance: 60ebd\
6c7-c1e3-4bf0-8ef0-f07aa4c3d5f3|instance: 60ebd6c7-c1e3-4bf0-8ef0-f07aa4c3\
d5f3]
Failed to connect to volume 6f6a6a9c-dfcf-4c8d-b1a8-4445ff883200 while\
attaching at /dev/vdjTRACE nova.compute.manager [instance: 60ebd6c7-c1e3-4\
bf0-8ef0-f07aa4c3d5f3|instance: 60ebd6c7-c1e3-4bf0-8ef0-f07aa4c3d5f3]
Traceback (most recent call last):…f07aa4c3d5f3\] ClientException: The\
server has either erred or is incapable of performing the requested\
operation.(HTTP 500)(Request-ID: req-71e5132b-21aa-46ee-b3cc-19b5b4ab2f00)</pre></div></div><div class="sect3 " id="id-1.4.9.8.11.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.11.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The network administrator must configure the FC SAN fabric by correctly
zoning the WWN (port names) from your compute node HBAs.</p></div></div><div class="sect2 " id="id-1.4.9.8.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cannot find suitable emulator for x86_64</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.12.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.12.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you attempt to create a VM, the error shows the VM is in the
<code class="literal">BUILD</code> then <code class="literal">ERROR</code> state.</p></div><div class="sect3 " id="id-1.4.9.8.12.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.12.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>On the KVM host, run <code class="command">cat /proc/cpuinfo</code>. Make sure the <code class="literal">vmx</code> or
<code class="literal">svm</code> flags are set.</p><p>Follow the instructions in the <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/hypervisor-kvm.html#enable-kvm" target="_blank">Enable KVM</a> section in the OpenStack Configuration Reference to enable hardware
virtualization support in your BIOS.</p></div></div><div class="sect2 " id="id-1.4.9.8.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Non-existent host</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.13.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.13.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This error could be caused by a volume being exported outside of
OpenStack using a host name different from the system name that
OpenStack expects. This error could be displayed with the <a class="xref" href="bk02go01.html#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a> if the host was exported using iSCSI.</p><div class="verbatim-wrap"><pre class="screen">2013-04-19 04:02:02.336 2814 ERROR cinder.openstack.common.rpc.common [-] Returning exception Not found (HTTP 404)
NON_EXISTENT_HOST - HOST '10' was not found to caller.</pre></div></div><div class="sect3 " id="id-1.4.9.8.13.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.13.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Host names constructed by the driver use just the local host name, not
the fully qualified domain name (FQDN) of the Compute host. For example,
if the FQDN was <span class="bold"><strong>myhost.example.com</strong></span>, just <span class="bold"><strong>myhost</strong></span> would be used as the
3PAR host name. IP addresses are not allowed as host names on the 3PAR
storage server.</p></div></div><div class="sect2 " id="id-1.4.9.8.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Non-existent VLUN</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.14.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.14.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This error occurs if the 3PAR host exists with the correct host name
that the OpenStack Block Storage drivers expect but the volume was
created in a different domain.</p><div class="verbatim-wrap"><pre class="screen">HTTPNotFound: Not found (HTTP 404) NON_EXISTENT_VLUN - VLUN 'osv-DqT7CE3mSrWi4gZJmHAP-Q' was not found.</pre></div></div><div class="sect3 " id="id-1.4.9.8.14.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="bk02ch07.html#id-1.4.9.8.14.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">hpe3par_domain</code> configuration items either need to be updated to
use the domain the 3PAR host currently resides in, or the 3PAR host
needs to be moved to the domain that the volume was created in.</p></div></div></div></div></div><div class="page-bottom"><div id="_bottom-navigation"><a class="nav-link" href="bk02ch08.html"><span class="next-icon">→</span><span class="nav-label"><span class="number">Chapter 8 </span>Shared File Systems</span></a><a class="nav-link" href="bk02ch06.html"><span class="prev-icon">←</span><span class="nav-label"><span class="number">Chapter 6 </span>Object Storage</span></a></div><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2021 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>