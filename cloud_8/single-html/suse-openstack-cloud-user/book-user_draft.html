<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>User Guide | SUSE OpenStack Cloud 8</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.0.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.0.17 (based on DocBook XSL Stylesheets 1.79.2)" /><meta name="product-name" content="SUSE OpenStack Cloud" /><meta name="product-number" content="8" /><meta name="book-title" content="User Guide" /><meta name="description" content="This section contains user tasks for your SUSE OpenStack Cloud 8 cloud." /><meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi" /><meta name="tracker-type" content="bsc" /><meta name="tracker-bsc-component" content="Documentation" /><meta name="tracker-bsc-product" content="SUSE OpenStack Cloud 8" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css"></link>');
}
else {
  document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft single offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #FABEBE;"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs inactive"><a class="single-crumb" href="#book-user" accesskey="c"><span class="single-contents-icon"></span>User Guide</a><div class="bubble-corner active-contents"></div></div><div class="clearme"></div></div></div><div id="_fixed-header-wrap" style="background-color: #FABEBE;" class="inactive"><div id="_fixed-header"><div class="crumbs inactive"><a class="single-crumb" href="#book-user" accesskey="c"><span class="single-contents-icon"></span>Show Contents: User Guide</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="clearme"></div></div><div class="clearme"></div></div><div class="active-contents bubble"><div class="bubble-container"><div id="_bubble-toc"><ol><li class="inactive"><a href="#user-cloudadmin"><span class="number">I </span><span class="name">Cloud Admin User Guide</span></a><ol><li class="inactive"><a href="#using-opsconsole"><span class="number">1 </span><span class="name">Using the Operations Console</span></a></li><li class="inactive"><a href="#user-dashboard-overview"><span class="number">2 </span><span class="name">Using the Dashboard</span></a></li><li class="inactive"><a href="#cloudadmin-gui"><span class="number">3 </span><span class="name">Cloud Admin Actions with the Dashboard</span></a></li><li class="inactive"><a href="#CreateCloudAdmin"><span class="number">4 </span><span class="name">Cloud Admin Actions with the Command Line</span></a></li><li class="inactive"><a href="#install-cli"><span class="number">5 </span><span class="name">Installing the Command-Line Clients</span></a></li><li class="inactive"><a href="#CreateHARouter"><span class="number">6 </span><span class="name">Creating a Highly Available Router</span></a></li></ol></li><li class="inactive"><a href="#user-nonadmin"><span class="number">II </span><span class="name">Project User Guide</span></a><ol><li class="inactive"><a href="#using-container-as-a-service-overview"><span class="number">7 </span><span class="name">Using Container as a Service (Magnum)</span></a></li><li class="inactive"><a href="#idg-all-userguide-create-network-xml-1"><span class="number">8 </span><span class="name">Creating a Private Network</span></a></li><li class="inactive"><a href="#create-keypair"><span class="number">9 </span><span class="name">Creating a Key Pair</span></a></li><li class="inactive"><a href="#user-image-upload"><span class="number">10 </span><span class="name">Creating and Uploading a Glance Image</span></a></li><li class="inactive"><a href="#lbaas-dashboard"><span class="number">11 </span><span class="name">Creating a Load Balancer with the Dashboard</span></a></li><li class="inactive"><a href="#HP2-0LBaaS"><span class="number">12 </span><span class="name">Using Load Balancing as a Service (LBaaS)</span></a></li><li class="inactive"><a href="#LBaaSHeat"><span class="number">13 </span><span class="name">Using Load Balancing as a Service with Orchestration Service</span></a></li><li class="inactive"><a href="#HP2-0FWaaS"><span class="number">14 </span><span class="name">Using Firewall as a Service (FWaaS)</span></a></li><li class="inactive"><a href="#UsingVPNaaS"><span class="number">15 </span><span class="name">Using VPN as a Service (VPNaaS)</span></a></li></ol></li></ol></div><div class="clearme"></div></div></div></div><div id="_toc-bubble-wrap"></div><div id="_content" class="draft "><div class="documentation"><div class="book" id="book-user"><div class="titlepage"><div><h6 class="version-info"><span class="productname "><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span></span> <span class="productnumber "><span class="phrase"><span class="phrase">8</span></span></span></h6><div><h1 class="title">User Guide <a title="Permalink" class="permalink" href="#book-user">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/book.userguide-suse-hpe.xml" title="Edit the source file for this section">Edit source</a></h1></div><div class="abstract "><p>
    This section contains user tasks for your <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> cloud.
   </p></div><div class="date"><span class="imprint-label">Publication Date: </span>03/04/2021</div></div></div><div class="toc"><dl><dt><span class="part"><a href="#user-cloudadmin"><span class="number">I </span><span class="name">Cloud Admin User Guide</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#using-opsconsole"><span class="number">1 </span><span class="name">Using the Operations Console</span></a></span></dt><dd><dl><dt><span class="section"><a href="#opsconsole"><span class="number">1.1 </span><span class="name">Operations Console Overview</span></a></span></dt><dt><span class="section"><a href="#connect-opsconsole"><span class="number">1.2 </span><span class="name">Connecting to the Operations Console</span></a></span></dt><dt><span class="section"><a href="#manage-compute-instances"><span class="number">1.3 </span><span class="name">Managing Compute Hosts</span></a></span></dt><dt><span class="section"><a href="#manage-swift-perf"><span class="number">1.4 </span><span class="name">Managing Swift Performance</span></a></span></dt><dt><span class="section"><a href="#charts"><span class="number">1.5 </span><span class="name">Visualizing Data in Charts</span></a></span></dt><dt><span class="section"><a href="#help-opsconsole"><span class="number">1.6 </span><span class="name">Getting Help with the Operations Console</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#user-dashboard-overview"><span class="number">2 </span><span class="name">Using the Dashboard</span></a></span></dt><dd><dl><dt><span class="section"><a href="#access-horizon"><span class="number">2.1 </span><span class="name">Accessing Horizon</span></a></span></dt><dt><span class="section"><a href="#browser-support-horizon"><span class="number">2.2 </span><span class="name">Browser support for Horizon</span></a></span></dt><dt><span class="section"><a href="#dashboard-limitations"><span class="number">2.3 </span><span class="name">Dashboard Use</span></a></span></dt><dt><span class="section"><a href="#DashProject"><span class="number">2.4 </span><span class="name">Project dashboard</span></a></span></dt><dt><span class="section"><a href="#DashAdmin"><span class="number">2.5 </span><span class="name">Admin dashboard</span></a></span></dt><dt><span class="section"><a href="#DashSettings"><span class="number">2.6 </span><span class="name">Settings dashboard</span></a></span></dt><dt><span class="section"><a href="#login-dashboard"><span class="number">2.7 </span><span class="name">Accessing the Dashboard</span></a></span></dt><dt><span class="section"><a href="#horizon-dashboard-examples"><span class="number">2.8 </span><span class="name">Horizon Dashboard</span></a></span></dt><dt><span class="section"><a href="#other-panels"><span class="number">2.9 </span><span class="name">Other Panels</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cloudadmin-gui"><span class="number">3 </span><span class="name">Cloud Admin Actions with the Dashboard</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-operations-cloudadmin-dashboard-xml-4"><span class="number">3.1 </span><span class="name">Cloud Admin</span></a></span></dt><dt><span class="section"><a href="#idg-all-operations-cloudadmin-dashboard-xml-5"><span class="number">3.2 </span><span class="name">Accessing the dashboard</span></a></span></dt><dt><span class="section"><a href="#id-1.7.3.4.6"><span class="number">3.3 </span><span class="name">Cloud Admin Activities</span></a></span></dt><dt><span class="section"><a href="#create-new-domain"><span class="number">3.4 </span><span class="name">Create a New Domain</span></a></span></dt><dt><span class="section"><a href="#domain-context"><span class="number">3.5 </span><span class="name">Set Domain context to the newly created Domain</span></a></span></dt><dt><span class="section"><a href="#new-project"><span class="number">3.6 </span><span class="name">Create a New Project</span></a></span></dt><dt><span class="section"><a href="#new-user"><span class="number">3.7 </span><span class="name">Create a New User</span></a></span></dt><dt><span class="section"><a href="#remove-user"><span class="number">3.8 </span><span class="name">Remove a user from a project</span></a></span></dt><dt><span class="section"><a href="#admin-role-user"><span class="number">3.9 </span><span class="name">Assign Admin role to User within the new Domain</span></a></span></dt><dt><span class="section"><a href="#quotas"><span class="number">3.10 </span><span class="name">Setting and managing quotas</span></a></span></dt><dt><span class="section"><a href="#dashboard-signout"><span class="number">3.11 </span><span class="name">Sign out of the Dashboard</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#CreateCloudAdmin"><span class="number">4 </span><span class="name">Cloud Admin Actions with the Command Line</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-operations-cloudadmin-cli-xml-4"><span class="number">4.1 </span><span class="name">Creating Additional Cloud Admins</span></a></span></dt><dt><span class="section"><a href="#idg-all-operations-cloudadmin-cli-xml-5"><span class="number">4.2 </span><span class="name">Command Line Examples</span></a></span></dt><dt><span class="section"><a href="#default-service-admin-roles"><span class="number">4.3 </span><span class="name">Assigning the default service admin roles</span></a></span></dt><dt><span class="section"><a href="#customize-policy"><span class="number">4.4 </span><span class="name">Customize policy.json on the Cloud Lifecycle Manager</span></a></span></dt><dt><span class="section"><a href="#service-roles"><span class="number">4.5 </span><span class="name">Roles</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#install-cli"><span class="number">5 </span><span class="name">Installing the Command-Line Clients</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-userguide-installing-cli-xml-5"><span class="number">5.1 </span><span class="name">Installing the CLI tools using the input model</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-installing-cli-xml-6"><span class="number">5.2 </span><span class="name">Installing the CLI tools using Ansible</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#CreateHARouter"><span class="number">6 </span><span class="name">Creating a Highly Available Router</span></a></span></dt><dd><dl><dt><span class="section"><a href="#CVRDVR"><span class="number">6.1 </span><span class="name">CVR and DVR High Available Routers</span></a></span></dt><dt><span class="section"><a href="#CreateRouter"><span class="number">6.2 </span><span class="name">Creating a High Availability Router</span></a></span></dt><dt><span class="section"><a href="#TestRouter"><span class="number">6.3 </span><span class="name">Test Router for High Availability</span></a></span></dt></dl></dd></dl></dd><dt><span class="part"><a href="#user-nonadmin"><span class="number">II </span><span class="name">Project User Guide</span></a></span></dt><dd><dl><dt><span class="chapter"><a href="#using-container-as-a-service-overview"><span class="number">7 </span><span class="name">Using Container as a Service (Magnum)</span></a></span></dt><dd><dl><dt><span class="section"><a href="#deploying-kubernetes-fedora-atomic"><span class="number">7.1 </span><span class="name">Deploying a Kubernetes Cluster on Fedora Atomic</span></a></span></dt><dt><span class="section"><a href="#deploying-kubernetes-coreos"><span class="number">7.2 </span><span class="name">Deploying a Kubernetes Cluster on CoreOS</span></a></span></dt><dt><span class="section"><a href="#deploying-docker-fedora-atomic"><span class="number">7.3 </span><span class="name">Deploying a Docker Swarm Cluster on Fedora Atomic</span></a></span></dt><dt><span class="section"><a href="#deploying-apache-mesos-ubuntu"><span class="number">7.4 </span><span class="name">Deploying an Apache Mesos Cluster on Ubuntu</span></a></span></dt><dt><span class="section"><a href="#create-magnum-cluster"><span class="number">7.5 </span><span class="name">Creating a Magnum Cluster with the Dashboard</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#idg-all-userguide-create-network-xml-1"><span class="number">8 </span><span class="name">Creating a Private Network</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-userguide-create-network-xml-6"><span class="number">8.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="section"><a href="#create-router"><span class="number">8.2 </span><span class="name">Creating a Router</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-create-network-xml-8"><span class="number">8.3 </span><span class="name">Creating a Network and Subnet</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#create-keypair"><span class="number">9 </span><span class="name">Creating a Key Pair</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-userguide-create-keypair-xml-5"><span class="number">9.1 </span><span class="name">Creating a Key Pair using Horizon</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-create-keypair-xml-6"><span class="number">9.2 </span><span class="name">Creating a Key Pair using the Command Line</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#user-image-upload"><span class="number">10 </span><span class="name">Creating and Uploading a Glance Image</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-userguide-create-image-xml-7"><span class="number">10.1 </span><span class="name">How to Curate Your Own Images</span></a></span></dt><dt><span class="section"><a href="#upload-cirros-img"><span class="number">10.2 </span><span class="name">Example: Uploading a Cirros Linux Image for Use</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-create-image-xml-11"><span class="number">10.3 </span><span class="name">Using Horizon to Upload an Image</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#lbaas-dashboard"><span class="number">11 </span><span class="name">Creating a Load Balancer with the Dashboard</span></a></span></dt><dt><span class="chapter"><a href="#HP2-0LBaaS"><span class="number">12 </span><span class="name">Using Load Balancing as a Service (LBaaS)</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-userguide-lbaas-xml-6"><span class="number">12.1 </span><span class="name">Configuration</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-lbaas-xml-15"><span class="number">12.2 </span><span class="name">For More Information</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#LBaaSHeat"><span class="number">13 </span><span class="name">Using Load Balancing as a Service with Orchestration Service</span></a></span></dt><dd><dl><dt><span class="section"><a href="#Intro"><span class="number">13.1 </span><span class="name">Orchestration Service</span></a></span></dt><dt><span class="section"><a href="#HeatSupport"><span class="number">13.2 </span><span class="name">Orchestration Service support for LBaaS v2</span></a></span></dt><dt><span class="section"><a href="#loadbalancer-limitations"><span class="number">13.3 </span><span class="name">Limitations</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-lbaas-heat-xml-8"><span class="number">13.4 </span><span class="name">More Information</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#HP2-0FWaaS"><span class="number">14 </span><span class="name">Using Firewall as a Service (FWaaS)</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-networking-fwaas-xml-8"><span class="number">14.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="section"><a href="#idg-all-networking-fwaas-xml-9"><span class="number">14.2 </span><span class="name"><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> FWaaS Configuration</span></a></span></dt><dt><span class="section"><a href="#sec-hp20fwaas-more"><span class="number">14.3 </span><span class="name">More Information</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#UsingVPNaaS"><span class="number">15 </span><span class="name">Using VPN as a Service (VPNaaS)</span></a></span></dt><dd><dl><dt><span class="section"><a href="#idg-all-networking-vpnaas-xml-7"><span class="number">15.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="section"><a href="#Considerations"><span class="number">15.2 </span><span class="name">Considerations</span></a></span></dt><dt><span class="section"><a href="#idg-all-networking-vpnaas-xml-9"><span class="number">15.3 </span><span class="name">Configuration</span></a></span></dt><dt><span class="section"><a href="#sec-vpnaas-more"><span class="number">15.4 </span><span class="name">More Information</span></a></span></dt></dl></dd></dl></dd></dl></div><div class="part" id="user-cloudadmin"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part I </span><span class="name">Cloud Admin User Guide </span><a title="Permalink" class="permalink" href="#user-cloudadmin">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_cloudadmin.xml" title="Edit the source file for this section">Edit source</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#using-opsconsole"><span class="number">1 </span><span class="name">Using the Operations Console</span></a></span></dt><dd class="toc-abstract"><p>
  Often referred to as the Ops Console, you can use this web-based graphical
  user interface (GUI) to view data about your cloud infrastructure and ensure
  your cloud is operating correctly.
 </p></dd><dt><span class="chapter"><a href="#user-dashboard-overview"><span class="number">2 </span><span class="name">Using the Dashboard</span></a></span></dt><dd class="toc-abstract"><p>
  Often referred to as Horizon or the Horizon dashboard, you can use this
  console to manage resources on a domain and project level in a web-based
  graphical user interface (GUI).
 </p></dd><dt><span class="chapter"><a href="#cloudadmin-gui"><span class="number">3 </span><span class="name">Cloud Admin Actions with the Dashboard</span></a></span></dt><dd class="toc-abstract"><p>
  The Horizon dashboard provides cloud admins a web GUI to perform domain admin
  tasks such as user and project administration and managing project quotas.
 </p></dd><dt><span class="chapter"><a href="#CreateCloudAdmin"><span class="number">4 </span><span class="name">Cloud Admin Actions with the Command Line</span></a></span></dt><dd class="toc-abstract"><p>
  Cloud admins can use the command line tools to perform domain admin tasks
  such as user and project administration.
 </p></dd><dt><span class="chapter"><a href="#install-cli"><span class="number">5 </span><span class="name">Installing the Command-Line Clients</span></a></span></dt><dd class="toc-abstract"><p>During the installation, by default, the suite of OpenStack command-line tools are installed on the Cloud Lifecycle Manager and the control plane in your environment. This includes the OpenStack Command-Line Interface as well as the clients for the individual services such as the NovaClient, CinderC…</p></dd><dt><span class="chapter"><a href="#CreateHARouter"><span class="number">6 </span><span class="name">Creating a Highly Available Router</span></a></span></dt><dd class="toc-abstract"><p>CVR (Centralized Virtual Routing) and DVR (Distributed Virtual Routing) are two types of technologies which can be used to provide routing processes in SUSE OpenStack Cloud 8. You can create Highly Available (HA) versions of CVR and DVR routers by using the options in the table below when creating y…</p></dd></dl></div><div class="chapter " id="using-opsconsole"><div class="titlepage"><div><div><h2 class="title"><span class="number">1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the Operations Console</span> <a title="Permalink" class="permalink" href="#using-opsconsole">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-using_opsconsole.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-using_opsconsole.xml</li><li><span class="ds-label">ID: </span>using-opsconsole</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#opsconsole"><span class="number">1.1 </span><span class="name">Operations Console Overview</span></a></span></dt><dt><span class="section"><a href="#connect-opsconsole"><span class="number">1.2 </span><span class="name">Connecting to the Operations Console</span></a></span></dt><dt><span class="section"><a href="#manage-compute-instances"><span class="number">1.3 </span><span class="name">Managing Compute Hosts</span></a></span></dt><dt><span class="section"><a href="#manage-swift-perf"><span class="number">1.4 </span><span class="name">Managing Swift Performance</span></a></span></dt><dt><span class="section"><a href="#charts"><span class="number">1.5 </span><span class="name">Visualizing Data in Charts</span></a></span></dt><dt><span class="section"><a href="#help-opsconsole"><span class="number">1.6 </span><span class="name">Getting Help with the Operations Console</span></a></span></dt></dl></div></div><div class="sect1" id="opsconsole"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Operations Console Overview</span> <a title="Permalink" class="permalink" href="#opsconsole">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole_overview.xml</li><li><span class="ds-label">ID: </span>opsconsole</li></ul></div></div></div></div><p>
  Often referred to as the Ops Console, you can use this web-based graphical
  user interface (GUI) to view data about your cloud infrastructure and ensure
  your cloud is operating correctly.
 </p><p>
  You can use the Operations Console for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> to view
  data about your <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> infrastructure in a web-based graphical user
  interface (GUI) and ensure your cloud is operating correctly. By logging on
  to the console, <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> administrators can manage data in the following
  ways: <span class="bold"><strong>Triage alarm notifications</strong></span>.
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Alarm Definitions and notifications now have their own screens and are
    collected under the <span class="bold"><strong>Alarm Explorer</strong></span> menu
    item which can be accessed from the Central Dashboard. Central Dashboard
    now allows you to customize the view in the following ways:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Rename or re-configure existing alarm cards to include services
      different from the defaults
     </p></li><li class="listitem "><p>
      Create a new alarm card with the services you want to select
     </p></li><li class="listitem "><p>
      Reorder alarm cards using drag and drop
     </p></li><li class="listitem "><p>
      View all alarms that have no service dimension now grouped in an
      <span class="bold"><strong>Uncategorized Alarms</strong></span> card
     </p></li><li class="listitem "><p>
      View all alarms that have a service dimension that does not match any of
      the other cards -now grouped in an <span class="bold"><strong>Other
      Alarms</strong></span> card
     </p></li></ul></div></li><li class="listitem "><p>
    You can also easily access alarm data for a specific component. On the
    Summary page for the following components, a link is provided to an alarms
    screen specifically for that component:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Compute Instances: <a class="xref" href="#manage-compute-instances" title="1.3. Managing Compute Hosts">Section 1.3, “Managing Compute Hosts”</a>
     </p></li><li class="listitem "><p>
      Object Storage: <a class="xref" href="#Ops-Swift-AlarmSumm" title="1.4.4. Alarm Summary">Section 1.4.4, “Alarm Summary”</a>
     </p></li></ul></div></li></ul></div><div class="sect2" id="monitor-env"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Monitor the environment by giving priority to alarms that take precedence.</span> <a title="Permalink" class="permalink" href="#monitor-env">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole_overview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole_overview.xml</li><li><span class="ds-label">ID: </span>monitor-env</li></ul></div></div></div></div><p>
   Alarm Explorer now allows you to manage alarms in the following ways:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Refine the monitoring environment by creating new alarms to specify a
     combination of metrics, services, and hosts that match the triggers unique
     to an environment
    </p></li><li class="listitem "><p>
     Filter alarms in one place using an enumerated filter box instead of
     service badges
    </p></li><li class="listitem "><p>
     Specify full alarm IDs as dimension key-value pairs in the form of
     <span class="bold"><strong>dimension=value</strong></span>
    </p></li></ul></div></div><div class="sect2" id="support-changes"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Support Changes</span> <a title="Permalink" class="permalink" href="#support-changes">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole_overview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole_overview.xml</li><li><span class="ds-label">ID: </span>support-changes</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     To resolve scalability issues, plain text search through alarm sets is no
     longer supported
    </p></li></ul></div><p>
   The Business Logic Layer of Operations Console is a middleware component that
   serves as a single point of contact for the user interface to communicate
   with OpenStack services such as Monasca, Nova, and others.
  </p></div></div><div class="sect1" id="connect-opsconsole"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connecting to the Operations Console</span> <a title="Permalink" class="permalink" href="#connect-opsconsole">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-connect_opsconsole.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-connect_opsconsole.xml</li><li><span class="ds-label">ID: </span>connect-opsconsole</li></ul></div></div></div></div><p>
  Instructions for accessing the Operations Console through a web browser.
 </p><p>
  To connect to Operations Console, perform the following:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Ensure your login has the required access credentials:
    <a class="xref" href="#access-creds" title="1.2.1. Required Access Credentials">Section 1.2.1, “Required Access Credentials”</a>
   </p></li><li class="listitem "><p>
    Connect through a browser: <a class="xref" href="#command" title="1.2.2. Connect Through a Browser">Section 1.2.2, “Connect Through a Browser”</a>
   </p></li><li class="listitem "><p>
    Optionally use a Hostname OR virtual IP address to access Operations Console:
    <a class="xref" href="#find-nameIP" title="1.2.3. Optionally use a Hostname OR virtual IP address to access Operations Console">Section 1.2.3, “Optionally use a Hostname OR virtual IP address to access Operations Console”</a>
   </p></li></ul></div><p>
  Operations Console will always be accessed over port 9095.
 </p><div class="sect2" id="access-creds"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Required Access Credentials</span> <a title="Permalink" class="permalink" href="#access-creds">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-connect_opsconsole.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-connect_opsconsole.xml</li><li><span class="ds-label">ID: </span>access-creds</li></ul></div></div></div></div><p>
   In previous versions of Operations Console you were required to have only the
   password for the Administrator account (admin by default). Now the
   Administrator user account must also have all of the following credentials:
  </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>Project</th><th>Domain</th><th>Role</th><th>Description</th></tr></thead><tbody><tr><td>*All projects*</td><td>*not specific*</td><td>Admin</td><td>Admin role on at least one project</td></tr><tr><td>*All projects*</td><td>*not specific*</td><td>Admin</td><td>Admin role in default domain</td></tr><tr><td>Admin</td><td>default</td><td>Admin or Monasca-user</td><td>Admin or Monasca-user role on admin project</td></tr></tbody></table></div><div id="id-1.7.3.2.3.6.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    If your login account has administrator role on the administrator project,
    then you only need to make sure you have the administrator role on the
    default domain.
   </p></div><p>
   <span class="bold"><strong>Administrator account</strong></span>
  </p><p>
   During installation, an administrator account called
   <code class="systemitem">admin</code> is created by default.
  </p><p>
   <span class="bold"><strong>Administrator password</strong></span>
  </p><p>
   During installation, an administrator password is randomly created by
   default. It is not recommend that you change the default password.
  </p><p>
   To find the randomized password:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To display the password, log on to the Cloud Lifecycle Manager and run:
    </p><div class="verbatim-wrap"><pre class="screen">cat ~/service.osrc</pre></div></li></ol></div></div><div class="sect2" id="command"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connect Through a Browser</span> <a title="Permalink" class="permalink" href="#command">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-connect_opsconsole.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-connect_opsconsole.xml</li><li><span class="ds-label">ID: </span>command</li></ul></div></div></div></div><p>
   The following instructions will show you how to find the URL to access
   Operations Console. You will use SSH, also known as Secure Socket Shell, which provides
   administrators with a secure way to access a remote computer.
  </p><p>
   <span class="bold"><strong>To access Operations Console:</strong></span>
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Log in to the Cloud Lifecycle Manager.
    </p></li><li class="listitem "><p>
     Locate the URL or IP address for the Operations Console with the following
     command:
    </p><div class="verbatim-wrap"><pre class="screen">source ~/service.osrc &amp;&amp; openstack endpoint list | grep opsconsole | grep admin</pre></div><p>
     <span class="bold"><strong>Sample output:</strong></span>
    </p><div class="verbatim-wrap"><pre class="screen">| 8ef10dd9c00e4abdb18b5b22adc93e87 | region1 | opsconsole | opsconsole | True | admin | https://192.168.24.169:9095/api/v1/</pre></div><p>
     To access Operations Console, in the sample output, remove everything after port
     9095 (api/v1/) and in a browser, type:
    </p><div class="verbatim-wrap"><pre class="screen">https://192.168.24.169:9095</pre></div></li></ol></div></div><div class="sect2" id="find-nameIP"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Optionally use a Hostname OR virtual IP address to access Operations Console</span> <a title="Permalink" class="permalink" href="#find-nameIP">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-connect_opsconsole.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-connect_opsconsole.xml</li><li><span class="ds-label">ID: </span>find-nameIP</li></ul></div></div></div></div><div id="id-1.7.3.2.3.8.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    If you can access Operations Console using the above instructions, then you can
    skip this section. These steps provide an alternate way to access Operations Console
    if the above steps do not work for you.
   </p></div><p>
   To find your hostname OR IP address:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Navigate to and open in a text editor the following file:
    </p><div class="verbatim-wrap"><pre class="screen">network_groups.yml</pre></div></li><li class="listitem "><p>
     Find the following entry:
    </p><div class="verbatim-wrap"><pre class="screen">external-name</pre></div></li><li class="listitem "><p>
     If your administrator set a hostname value in the external-name field, you
     will use that hostname when logging in to Operations Console. or example, in a
     browser you would type:
    </p><div class="verbatim-wrap"><pre class="screen">https://VIP:9095</pre></div></li><li class="listitem "><p>
     If your administrator did not set a hostname value, then to determine the
     IP address to use, from your Cloud Lifecycle Manager, run:
    </p><div class="verbatim-wrap"><pre class="screen">grep HZN-WEB /etc/hosts</pre></div><p>
     The output of that command will show you the virtual IP address you should
     use. For example, in a browser you would type:
    </p><div class="verbatim-wrap"><pre class="screen">https://VIP:9095</pre></div></li></ol></div></div></div><div class="sect1" id="manage-compute-instances"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing Compute Hosts</span> <a title="Permalink" class="permalink" href="#manage-compute-instances">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-manage_compute_instances.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-manage_compute_instances.xml</li><li><span class="ds-label">ID: </span>manage-compute-instances</li></ul></div></div></div></div><p>
  Operations Console (Ops Console) provides a graphical interface for you to
  add and delete compute hosts.
 </p><p>
  As your deployment grows and changes, you may need to add more compute hosts
  to increase your capacity for VMs, or delete a host to reallocate hardware
  for a different use. To accomplish these tasks, in previous versions of
  <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> you had to use the command line to update configuration files and
  run ansible playbooks. Now Operations Console provides a
  graphical interface for you to complete the same tasks quickly using menu
  items in the console.
 </p><div id="id-1.7.3.2.4.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   Do not refresh the Operations Console page or open Operations Console in another window
   during the following tasks. If you do, you will not see any notifications or
   be able to review the error log for more information. This would make
   troubleshooting difficult since you would not know the error that was
   encountered, or why it occurred.
  </p></div><p>
  Use Operations Console to perform the following tasks:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Create a Compute Host: <a class="xref" href="#ops-create-hosts" title="1.3.1. Create a Compute Host">Section 1.3.1, “Create a Compute Host”</a>
   </p></li><li class="listitem "><p>
    Deactivate a Compute Host: <a class="xref" href="#ops-deactivate" title="1.3.2. Deactivate a Compute Host">Section 1.3.2, “Deactivate a Compute Host”</a>
   </p></li><li class="listitem "><p>
    Activate a Compute Host: <a class="xref" href="#ops-activate" title="1.3.3. Activate a Compute Host">Section 1.3.3, “Activate a Compute Host”</a>
   </p></li><li class="listitem "><p>
    Delete a Compute Host: <a class="xref" href="#ops-delete" title="1.3.4. Delete a Compute Host">Section 1.3.4, “Delete a Compute Host”</a>
   </p></li></ul></div><div id="id-1.7.3.2.4.7" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   To use Operations Console, you need to have the correct permissions and
   know the URL or VIP connected to Operations Console during installation. For steps
   on how to complete these tasks, see
   <a class="xref" href="#opsconsole" title="1.1. Operations Console Overview">Section 1.1, “Operations Console Overview”</a>.
  </p></div><div class="sect2" id="ops-create-hosts"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a Compute Host</span> <a title="Permalink" class="permalink" href="#ops-create-hosts">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-manage_compute_instances.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-manage_compute_instances.xml</li><li><span class="ds-label">ID: </span>ops-create-hosts</li></ul></div></div></div></div><p>
   If you need to create additional compute hosts for more virtual machine
   capacity, you can do this easily on the Compute Hosts screen.
  </p><p>
   To add a compute host:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser, enter either the URL or Virtual
     IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Home</strong></span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     From the menu that slides in on the left side, click
     <span class="bold"><strong>Compute</strong></span>, and
     then <span class="bold"><strong>Compute Hosts</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Compute Hosts</strong></span> page, click
     <span class="bold"><strong>Create Host</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Add &amp; Activate Compute Host</strong></span>
     tab that slides in from the right, enter the following information:
    </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.2.4.8.4.5.2.1"><span class="term ">Host ID</span></dt><dd><p>
        Cloud Lifecycle Manager model's server ID
       </p></dd><dt id="id-1.7.3.2.4.8.4.5.2.2"><span class="term ">Host Role</span></dt><dd><p>
        Defined in the Cloud Lifecycle Manager model and cannot be modified in Operations Console
       </p></dd><dt id="id-1.7.3.2.4.8.4.5.2.3"><span class="term ">Host Group</span></dt><dd><p>
        Defined in the Cloud Lifecycle Manager model and cannot be modified in Operations Console
       </p></dd><dt id="id-1.7.3.2.4.8.4.5.2.4"><span class="term ">Host NIC Mapping</span></dt><dd><p>
        Defined in the Cloud Lifecycle Manager model and cannot be modified in Operations Console
       </p></dd><dt id="id-1.7.3.2.4.8.4.5.2.5"><span class="term ">Encryption Key</span></dt><dd><p>
        If the configuration is encrypted, enter the encryption key here
       </p></dd></dl></div></li><li class="listitem "><p>
     Click <span class="guimenu ">Create Host</span>, and in the
     confirmation screen that opens, click
     <span class="guimenu ">Confirm</span>.
    </p></li><li class="listitem "><p>
     Wait for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> to complete the pre deployment steps. This process can
     take up to 2 minutes.
    </p></li><li class="listitem "><p>
     If pre-deployment is successful, you will see a notification that
     deployment has started.
    </p><div id="id-1.7.3.2.4.8.4.8.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      If you receive a notice that pre-deployment did not complete
      successfully, read the notification explaining at which step the error
      occured. You can click on the error notification and see the ansible log
      for the configuration processor playbook. Then you can click
      <span class="bold"><strong>Create Host</strong></span>
      in step 4 again and correct the mistake.
     </p></div></li><li class="listitem "><p>
     Wait for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> to complete the deployments steps. This process can take
     up to 20 minutes.
    </p></li><li class="listitem "><p>
     If deployment is successful, you will see a notification and a new entry
     will appear in the compute hosts table.
    </p><div id="id-1.7.3.2.4.8.4.10.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      If you receive a notice that deployment did not complete successfully,
      read the notification explaining at which step the error occured. You can
      click on the error notification for more details.
     </p></div></li></ol></div></div><div class="sect2" id="ops-deactivate"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deactivate a Compute Host</span> <a title="Permalink" class="permalink" href="#ops-deactivate">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-manage_compute_instances.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-manage_compute_instances.xml</li><li><span class="ds-label">ID: </span>ops-deactivate</li></ul></div></div></div></div><p>
   If you have multiple compute hosts and for debugging reasons you want to
   disable them all except one, you may need to deactivate and then activate a
   compute host. If you want to delete a host, you will also have to deactivate
   it first. This can be done easily in the Operations Console.
  </p><div id="id-1.7.3.2.4.9.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    The host must be in the following state:
    <span class="bold"><strong>ACTIVATED</strong></span>
   </p></div><p>
   To deactivate a compute host:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser, enter either the URL or Virtual
     IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Home</strong></span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     From the menu that slides in on the left side, click
     <span class="bold"><strong>Compute</strong></span>, and
     then <span class="bold"><strong>Compute Hosts</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Compute Hosts</strong></span> page, in the row for
     the host you want to deactivate, click the details button
     (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-DetailDots.png" width="" alt="Ellipsis Icon" /></span>).
    </p></li><li class="listitem "><p>
     Click <span class="bold"><strong>Deactivate</strong></span>, and in the confirmation
     screen that opens, click <span class="bold"><strong>Confirm</strong></span>.
    </p></li><li class="listitem "><p>
     Wait for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> to complete the operation. This process can take up to 2
     minutes.
    </p></li><li class="listitem "><p>
     If deactivation is successful, you will see a notification and in the
     compute hosts table the <span class="bold"><strong>STATE</strong></span> will change
     to <span class="bold"><strong>DEACTIVATED</strong></span>.
    </p><div id="id-1.7.3.2.4.9.5.7.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      If you receive a notice that the operation did not complete successfully,
      read the notification explaining at which step the error occured. You can
      click on the link in the error notification for more details. In the
      compute hosts table the <span class="bold"><strong>STATE</strong></span> will
      remain
      <span class="bold"><strong>ACTIVATED</strong></span>.
     </p></div></li></ol></div></div><div class="sect2" id="ops-activate"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Activate a Compute Host</span> <a title="Permalink" class="permalink" href="#ops-activate">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-manage_compute_instances.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-manage_compute_instances.xml</li><li><span class="ds-label">ID: </span>ops-activate</li></ul></div></div></div></div><div id="id-1.7.3.2.4.10.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    The host must be in the following state:
    <span class="bold"><strong>DEACTIVATED</strong></span>
   </p></div><p>
   To activate a compute host:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser, enter either the URL or Virtual
     IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Home</strong></span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     From the menu that slides in on the left side, click
     <span class="bold"><strong>Compute</strong></span>, and
     then <span class="bold"><strong>Compute Hosts</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Compute Hosts</strong></span> page, in the row for
     the host you want to activate, click the details button
     (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-DetailDots.png" width="" alt="Ellipsis Icon" /></span>).
    </p></li><li class="listitem "><p>
     Click <span class="bold"><strong>Activate</strong></span>, and in the confirmation
     screen that opens, click <span class="bold"><strong>Confirm</strong></span>.
    </p></li><li class="listitem "><p>
     Wait for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> to complete the operation. This process can take up to 2
     minutes.
    </p></li><li class="listitem "><p>
     If activation is successful, you will see a notification and in the
     compute hosts table the <span class="bold"><strong>STATE</strong></span> will change
     to <span class="bold"><strong>ACTIVATED</strong></span>.
    </p><div id="id-1.7.3.2.4.10.4.7.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      If you receive a notice that the operation did not complete successfully,
      read the notification explaining at which step the error occured. You can
      click on the link in the error notification for more details. In the
      compute hosts table the <span class="bold"><strong>STATE</strong></span> will
      remain
      <span class="bold"><strong>DEACTIVATED</strong></span>.
     </p></div></li></ol></div></div><div class="sect2" id="ops-delete"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a Compute Host</span> <a title="Permalink" class="permalink" href="#ops-delete">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-manage_compute_instances.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-manage_compute_instances.xml</li><li><span class="ds-label">ID: </span>ops-delete</li></ul></div></div></div></div><p>
   If you need to scale down the size of your current deployment to use the
   hardware for other purposes, you may want to delete a compute host.
  </p><div id="id-1.7.3.2.4.11.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    Complete the following steps before deleting a host:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      host must be in the following state:
      <span class="bold"><strong>DEACTIVATED</strong></span>
     </p></li><li class="listitem "><p>
      Optionally you can migrate the instance off the host to be deleted. To do
      this, complete the following sections in
      <span class="intraxref">Book “Operations Guide”, Chapter 13 “System Maintenance”, Section 13.1 “Planned System Maintenance”, Section 13.1.3 “Planned Compute Maintenance”, Section 13.1.3.5 “Removing a Compute Node”</span>:
     </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
        Disable provisioning on the compute host.
       </p></li><li class="listitem "><p>
        Use live migration to move any instances on this host to other hosts.
       </p></li></ol></div></li></ul></div></div><p>
   To delete a compute host:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser, enter either the URL or Virtual
     IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Home</strong></span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     From the menu that slides in on the left side, click
     <span class="bold"><strong>Compute</strong></span>, and
     then <span class="bold"><strong>Compute Hosts</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Compute Hosts</strong></span> page, in the row for
     the host you want to delete, click the details button
     (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-DetailDots.png" width="" alt="Ellipsis Icon" /></span>).
    </p></li><li class="listitem "><p>
     Click <span class="bold"><strong>Delete</strong></span>, and if the configuration is
     encrypted, enter the encryption key.
    </p></li><li class="listitem "><p>
     in the confirmation screen that opens, click
     <span class="bold"><strong>Confirm</strong></span>.
    </p></li><li class="listitem "><p>
     In the compute hosts table you will see the
     <span class="bold"><strong>STATE</strong></span> change to
     <span class="bold"><strong>Deleting</strong></span>.
    </p></li><li class="listitem "><p>
     Wait for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> to complete the operation. This process can take up to 2
     minutes.
    </p></li><li class="listitem "><p>
     If deletion is successful, you will see a notification and in the compute
     hosts table the host will not be listed.
    </p><div id="id-1.7.3.2.4.11.5.9.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      If you receive a notice that the operation did not complete successfully,
      read the notification explaining at which step the error occured. You can
      click on the link in the error notification for more details. In the
      compute hosts table the <span class="bold"><strong>STATE</strong></span> will
      remain <span class="bold"><strong>DEACTIVATED</strong></span>.
     </p></div></li></ol></div></div><div class="sect2" id="more-info"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">For More Information</span> <a title="Permalink" class="permalink" href="#more-info">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-manage_compute_instances.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-manage_compute_instances.xml</li><li><span class="ds-label">ID: </span>more-info</li></ul></div></div></div></div><p>
   For more information on how to complete these tasks through the command
   line, see the following topics:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     <span class="intraxref">Book “Operations Guide”, Chapter 13 “System Maintenance”, Section 13.1 “Planned System Maintenance”, Section 13.1.3 “Planned Compute Maintenance”, Section 13.1.3.4 “Adding Compute Node”</span>
    </p></li><li class="listitem "><p>
     <span class="intraxref">Book “Operations Guide”, Chapter 13 “System Maintenance”, Section 13.1 “Planned System Maintenance”, Section 13.1.3 “Planned Compute Maintenance”, Section 13.1.3.5 “Removing a Compute Node”</span>
    </p></li></ul></div></div></div><div class="sect1" id="manage-swift-perf"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing Swift Performance</span> <a title="Permalink" class="permalink" href="#manage-swift-perf">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-OpsConsole_manage_swift.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-OpsConsole_manage_swift.xml</li><li><span class="ds-label">ID: </span>manage-swift-perf</li></ul></div></div></div></div><p>
  In Operations Console you can monitor your Swift cluster to ensure long-term
  data protection as well as sufficient performance.
 </p><p>
  OpenStack Swift is an object storage solution with a focus on availability.
  While there are various mechanisms inside Swift to protect stored data and
  ensure a high availability, you must still closely monitor your Swift cluster
  to ensure long-term data protection as well as sufficient performance. The
  best way to manage Swift is to collect useful data that will detect possible
  performance impacts early on.
 </p><p>
  The new Object Summary Dashboard in Operations Console provides
  an overview of your Swift environment.
 </p><div id="id-1.7.3.2.5.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   If Swift is not installed and configured, you will not be able to access
   this dashboard. The Swift endpoint must be present in Keystone for the
   Object Summary to be present in the menu.
  </p></div><p>
  In Operations Console's object storage dashboard, you can easily review the
  following information:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Performance Summary: <a class="xref" href="#Ops-Swift-PerfSumm" title="1.4.1. Performance Summary">Section 1.4.1, “Performance Summary”</a>
   </p></li><li class="listitem "><p>
    Inventory Summary: <a class="xref" href="#Ops-Swift-Inventory" title="1.4.2. Inventory Summary">Section 1.4.2, “Inventory Summary”</a>
   </p></li><li class="listitem "><p>
    Capacity Summary: <a class="xref" href="#Ops-Swift-Capacity" title="1.4.3. Capacity Summary">Section 1.4.3, “Capacity Summary”</a>
   </p></li><li class="listitem "><p>
    Alarm Summary: <a class="xref" href="#Ops-Swift-AlarmSumm" title="1.4.4. Alarm Summary">Section 1.4.4, “Alarm Summary”</a>
   </p></li></ul></div><div class="sect2" id="Ops-Swift-PerfSumm"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Performance Summary</span> <a title="Permalink" class="permalink" href="#Ops-Swift-PerfSumm">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-OpsConsole_manage_swift.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-OpsConsole_manage_swift.xml</li><li><span class="ds-label">ID: </span>Ops-Swift-PerfSumm</li></ul></div></div></div></div><p>
   View a comprehensive summary of current performance values.
  </p><p>
   To access the object storage performance dashboard:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser enter either the URL or
     Virtual IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Home</strong></span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     In the menu, click <span class="guimenu ">Storage</span> › <span class="guimenu ">Object Storage Summary</span>.
    </p></li></ol></div><p>
   Performance data includes:
  </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.2.5.8.6.1"><span class="term ">Healthcheck Latency from Monasca</span></dt><dd><p>
      This latency is the average time it takes for Swift to respond to a
      healthcheck, or ping, request. The swiftlm-uptime monitor program reports
      the value. A large difference between average and maximum may indicate a
      problem with one node.
     </p></dd><dt id="id-1.7.3.2.5.8.6.2"><span class="term ">Operational Latency from Monasca</span></dt><dd><p>
      Operational latency is the average time it takes for Swift to respond to
      an upload, download, or object delete request. The swiftlm-uptime monitor
      program reports the value. A large difference between average and maximum
      may indicate a problem with one node.
     </p></dd><dt id="id-1.7.3.2.5.8.6.3"><span class="term ">Service Availability</span></dt><dd><p>
      This is the availability over the last 24 hours as a percentage.
     </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
        <span class="bold"><strong>100%</strong></span> - No outages in the last 24 hours
       </p></li><li class="listitem "><p>
        <span class="bold"><strong>50%</strong></span> - Swift was unavailable for a
        total of 12 hours in the last 24-hour period
       </p></li></ul></div></dd><dt id="id-1.7.3.2.5.8.6.4"><span class="term ">Graph of Performance Over Time</span></dt><dd><p>
      Create a visual representation of performance data to see when Swift
      encountered longer-than-normal response times.
     </p><p>
      To create a graph:
     </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
        Choose the length of time you want to graph in
        <span class="guimenu ">Date Range</span>.
        This sets the length of time for the x-axis which
        counts backwards until it reaches the present time. In the example
        below, 1 day is selected, and so the x axis shows performance starting
        from 24 hours ago (-24) until the present time.
       </p></li><li class="listitem "><p>
        Look at the y-axis to understand the range of response times. The first
        number is the smallest value in the data collected from the backend,
        and the last number is the longest amount of time it took Swift to
        respond to a request. In the example below, the shortest time for a
        response from Swift was 16.1 milliseconds.
       </p></li><li class="listitem "><p>
        Look for spikes which represent longer than normal response times. In
        the example below, Swift experienced long response times 21 hours ago
        and again 1 hour ago.
       </p></li><li class="listitem "><p>
        Look for the latency value at the present time. The line running across
        the x-axis at 16.1 milliseconds shows you what the response time is
        currently.
       </p></li></ol></div></dd></dl></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-ObjStorageSumm2.png" target="_blank"><img src="images/media-opsconsole-ObjStorageSumm2.png" width="" /></a></div></div></div><div class="sect2" id="Ops-Swift-Inventory"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Inventory Summary</span> <a title="Permalink" class="permalink" href="#Ops-Swift-Inventory">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-OpsConsole_manage_swift.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-OpsConsole_manage_swift.xml</li><li><span class="ds-label">ID: </span>Ops-Swift-Inventory</li></ul></div></div></div></div><p>
   Monitor details about all the Swift resources deployed in your cloud.
  </p><p>
   To access the object storage inventory screen:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser enter either the URL or
     Virtual IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="guimenu ">Home</span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     In the menu, click
     <span class="guimenu ">Storage</span> › <span class="guimenu ">Object Storage Summary</span>.
    </p></li><li class="listitem "><p>
     On the <span class="guimenu ">Summary</span> page, click
     <span class="guimenu ">Inventory Summary</span>.
    </p></li></ol></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-ObjStorageInventory1.png" target="_blank"><img src="images/media-opsconsole-ObjStorageInventory1.png" width="" /></a></div></div><p>
   General Swift metrics are available for the following attributes:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     <span class="guimenu ">Time to replicate</span>: The average time in
     seconds it takes all hosts to complete a replication cycle.
    </p></li><li class="listitem "><p>
     <span class="guimenu ">Oldest replication</span>: The time in seconds
     that has elapsed since the object replication process completed its last
     replication cycle.
    </p></li><li class="listitem "><p>
     <span class="guimenu ">Async Pending</span>: This is the number of
     failed requests to add an entry in the container server's database.There
     is one async queue per Swift disk, and a cron job queries all Swift
     servers to calculate the total. When an object is uploaded into Swift, and
     it is successfully stored, a request is sent to the container server to
     add a new entry for the object in the database. If the container update
     fails, the request is stored in what Swift calls an Async Pending Queue.
    </p><div id="id-1.7.3.2.5.9.7.3.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      On a public cloud deployment, this value can reach millions. If it
      continues to grow, it means that the container updates are not keeping up
      with the requests. It is also normal for it this number to grow if a node
      hosting the Swift container service is down.
     </p></div></li><li class="listitem "><p>
     <span class="guimenu ">Total number of alarms</span>: This number
     includes all nodes that host Swift services, including proxy, account,
     container, and object storage services.
    </p></li><li class="listitem "><p>
     <span class="guimenu ">Total nodes</span>: This number includes all
     nodes that host Swift services, including proxy, account, container, and
     object storage services. The number in the colored box represents the
     number of alarms in that state. The following colors are used to show the
     most severe alarm triggered on all nodes:
    </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.2.5.9.7.5.2.1"><span class="term ">Green</span></dt><dd><p>
        Indicates all alarms are in a known and untriggered state. For example,
        if there are 5 nodes and they are all known with no alarms, you will
        see the number 5 in the green box, and a zero in all the other colored
        boxes.
       </p></dd><dt id="id-1.7.3.2.5.9.7.5.2.2"><span class="term ">Yellow</span></dt><dd><p>
        Indicates that some low or medium alarms have been triggered but no
        critical or high alarms. For example, if there are 5 nodes, and there
        are 3 nodes with untriggered alarms and 2 nodes with medium severity
        alarms, you will see the number 3 in the green box, the number 2 in the
        yellow box, and zeros in all the other colored boxes.
       </p></dd><dt id="id-1.7.3.2.5.9.7.5.2.3"><span class="term ">Red</span></dt><dd><p>
        Indicates at least one critical or high severity alarm has been
        triggered on a node. For example, if there are 5 nodes, and there are 3
        nodes with untriggered alarms, 1 node with a low severity, and 1 node
        with a critical alarm, you will see the number 3 in the green box, the
        number 1 in the yellow box, the number 1 in the red box,and a zero in
        the gray box.
       </p></dd><dt id="id-1.7.3.2.5.9.7.5.2.4"><span class="term ">Gray</span></dt><dd><p>
        Indicates that all alarms on the nodes are unknown. For example, if
        there are 5 nodes with no data reported, you will see the number 5 in
        the gray box, and zeros in all the other colored boxes.
       </p></dd></dl></div></li><li class="listitem "><p>
     <span class="guimenu ">Cluster breakdown of nodes</span>: In the
     example screen above, the cluster consists of 2 nodes named SWPAC and
     SWOBJ. Click a node name to bring up more detailed information about
     that node.
    </p></li></ul></div></div><div class="sect2" id="Ops-Swift-Capacity"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capacity Summary</span> <a title="Permalink" class="permalink" href="#Ops-Swift-Capacity">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-OpsConsole_manage_swift.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-OpsConsole_manage_swift.xml</li><li><span class="ds-label">ID: </span>Ops-Swift-Capacity</li></ul></div></div></div></div><p>
   Use this screen to view the size of the file system space on all nodes and
   disk drives assigned to Swift. Also shown is the remaining space available
   and the total size of all file systems used by Swift. Values are given in
   megabytes (MB).
  </p><p>
   To access the object storage alarm summary screen:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser enter either the URL or
     Virtual IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="guimenu ">Home</span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     In the menu, click <span class="guimenu ">Storage</span> › <span class="guimenu ">Object Storage Summary</span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Summary</strong></span> page, click
     <span class="bold"><strong>Capacity Summary</strong></span>.
    </p></li></ol></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-ObjStorageCapacity.png" target="_blank"><img src="images/media-opsconsole-ObjStorageCapacity.png" width="" /></a></div></div></div><div class="sect2" id="Ops-Swift-AlarmSumm"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm Summary</span> <a title="Permalink" class="permalink" href="#Ops-Swift-AlarmSumm">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-OpsConsole_manage_swift.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-OpsConsole_manage_swift.xml</li><li><span class="ds-label">ID: </span>Ops-Swift-AlarmSumm</li></ul></div></div></div></div><p>
   Use this page to quickly see the most recent alarms and triage all alarms
   related to object storage.
  </p><p>
   To access the object storage alarm summary screen:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser enter either the URL or
     Virtual IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="guimenu ">Home</span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     In the menu, click <span class="guimenu ">Storage</span> › <span class="guimenu ">Object Storage Summary</span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Summary</strong></span> page, click
     <span class="bold"><strong>Alarm Summary</strong></span>.
    </p></li></ol></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-OpsConsoleSwiftAlarmSumm.png" target="_blank"><img src="images/media-opsconsole-OpsConsoleSwiftAlarmSumm.png" width="" /></a></div></div><p>
   Each row has a checkbox to allow you to select multiple alarms and set the
   same condition on them.
  </p><p>
   The <span class="guimenu ">State</span> column displays a graphical
   indicator representing the state of each alarm:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Green indicator: OK. Good operating state.
    </p></li><li class="listitem "><p>
     Yellow indicator: Warning. Low severity, not requiring
     immediate action.
    </p></li><li class="listitem "><p>
     Red indicator: Alarm. Varying severity levels and must be
     addressed.
    </p></li><li class="listitem "><p>
     Gray indicator: Undetermined.
    </p></li></ul></div><p>
   The <span class="guimenu ">Alarm</span> column identifies the alarm by
   the name it was given when it was originally created.
  </p><p>
   The <span class="guimenu ">Last Check</span> column displays the date and
   time the most recent occurrence of the alarm.
  </p><p>
   The <span class="guimenu ">Dimension</span> column describes the
   components to check in order to clear the alarm.
  </p><p>
   The last column, depicted by three dots, reveals an
   <span class="guimenu ">Actions</span> menu that allows
   you to choose:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     <span class="guimenu ">View Details</span>, which opens a separate window that shows
     all the information from the table view and the alarm history.
    </p><p>
     Comments can be updated by clicking <span class="guimenu ">Update Comment</span>.
     Click <span class="guimenu ">View Alarm Definition</span> to go
     to the <span class="guimenu ">Alarm Definition</span> tab showing that specific alarm
     definition.
    </p></li></ul></div></div></div><div class="sect1" id="charts"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Visualizing Data in Charts</span> <a title="Permalink" class="permalink" href="#charts">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-charts.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-charts.xml</li><li><span class="ds-label">ID: </span>charts</li></ul></div></div></div></div><p>
  Operations Console allows you to create a new chart and select the time range
  and the metric you want to chart, based on Monasca metrics.
 </p><p>
  Present data in a pictorial or graphical format to enable administrators and
  decision makers to grasp difficult concepts or identify new patterns.
 </p><p>
  <span class="bold"><strong>Create new time-series graphs from
  <span class="emphasis"><em>My Dashboard</em></span>.</strong></span>
 </p><p>
  <span class="emphasis"><em>My Dashboard</em></span> also allows you to customize the view in
  the following ways:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Include alarm cards from the Central Dashboard
   </p></li><li class="listitem "><p>
    Customize graphs in new ways
   </p></li><li class="listitem "><p>
    Reorder items using drag and drop
   </p></li></ul></div><p>
  <span class="bold"><strong>Plan for future storage</strong></span>
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Track capacity over time to predict with some degree of reliability the
    amount of additional storage needed.
   </p></li></ul></div><p>
  Charts and graphs provide a quick way to visualize large amounts of complex
  data. It is especially useful when trying to find relationships and
  understand your data, which could include thousands or even millions of
  variables. You can create a new chart in Operations Console from
  <span class="bold"><strong>My Dashboard</strong></span>.
 </p><p>
  The charts in Operations Console are based on Monasca data. When you create a
  new chart you will be able to select the time range and the metric you want
  to chart. The list of Metrics you can choose from is equivalent to using the
  <span class="bold"><strong>monasca metric-name-list</strong></span> on the command
  line. After you select a metric, you can then specify a dimension, which is
  derived from the <span class="bold"><strong>monasca metric-list –name
  &lt;metric_name&gt;</strong></span> command line results. The dimension list
  changes based on the selected metric.
 </p><p>
  This topic provides instructions on how to create a basic chart, and how to
  create a chart specifically to visualize your Cinder capacity.
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    Create a Chart: <a class="xref" href="#ops-create-charts" title="1.5.1. Create a Chart">Section 1.5.1, “Create a Chart”</a>
   </p></li><li class="listitem "><p>
    Chart Cinder Capacity: <a class="xref" href="#ops-Cinder-chart" title="1.5.2. Chart Cinder Capacity">Section 1.5.2, “Chart Cinder Capacity”</a>
   </p></li></ul></div><div class="sect2" id="ops-create-charts"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a Chart</span> <a title="Permalink" class="permalink" href="#ops-create-charts">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-charts.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-charts.xml</li><li><span class="ds-label">ID: </span>ops-create-charts</li></ul></div></div></div></div><p>
   Create a chart to visually display data for up to 6 metrics over a period of
   time.
  </p><p>
   To create a chart:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To open Operations Console, in a browser, enter either the URL or Virtual
     IP connected to Operations Console.
    </p><p>
     For example:
    </p><div class="verbatim-wrap"><pre class="screen">https://myardana.test:9095
https://VIP:9095</pre></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Home</strong></span> screen, click the menu
     represented by 3 horizontal lines (<span class="inlinemediaobject"><img xmlns="" src="images/media-opsconsole-OpsConsoleBurgerMenu.png" width="" alt="Three-Line Icon" /></span>).
    </p></li><li class="listitem "><p>
     From the menu that slides in on the left, select
     <span class="bold"><strong>Home</strong></span>, and then
     select <span class="bold"><strong>My Dashboard</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>My Dashboard</strong></span> screen, select
     <span class="bold"><strong>Create New Chart</strong></span>.
    </p></li><li class="listitem "><p>
     On the <span class="bold"><strong>Add New Time Series Chart</strong></span> screen,
     in <span class="bold"><strong>Chart Definition</strong></span> complete any of the
     optional fields:
    </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.2.6.13.4.5.2.1"><span class="term ">Name</span></dt><dd><p>
        Short description of chart.
       </p></dd><dt id="id-1.7.3.2.6.13.4.5.2.2"><span class="term ">Time Range</span></dt><dd><p>
        Specifies the interval between metric collection. The default is
        <span class="bold"><strong>1 hour</strong></span>. Can be set to hours
        (1,2,4,8,24) or days (7,30,45).
       </p></dd><dt id="id-1.7.3.2.6.13.4.5.2.3"><span class="term ">Chart Update Rate</span></dt><dd><p>
        Collects metric data and adds it to the chart at the specified
        interval. The default is <span class="bold"><strong>1 minute</strong></span>. Can
        be set to minutes (1,5,10,30) or 1 hour.
       </p></dd><dt id="id-1.7.3.2.6.13.4.5.2.4"><span class="term ">Chart Type</span></dt><dd><p>
        Determines how the data is displayed. The default type is
        <span class="bold"><strong>Line</strong></span>. Can be set to the following
        values:
       </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-LineChartIcon.png" target="_blank"><img src="images/media-opsconsole-LineChartIcon.png" width="" /></a></div></div><p>
          Line
         </p></li><li class="listitem "><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-BarChartIcon.png" target="_blank"><img src="images/media-opsconsole-BarChartIcon.png" width="" /></a></div></div><p>
          Bar
         </p></li><li class="listitem "><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-StackedBarIcon.png" target="_blank"><img src="images/media-opsconsole-StackedBarIcon.png" width="" /></a></div></div><p>
          Stacked Bar
         </p></li><li class="listitem "><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-AreaIcon.png" target="_blank"><img src="images/media-opsconsole-AreaIcon.png" width="" /></a></div></div><p>
          Area
         </p></li><li class="listitem "><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-AreaStackedIcon.png" target="_blank"><img src="images/media-opsconsole-AreaStackedIcon.png" width="" /></a></div></div><p>
          Stacked Area
         </p></li></ul></div></dd><dt id="id-1.7.3.2.6.13.4.5.2.5"><span class="term ">Chart Size</span></dt><dd><p>
        This controls the visual display of the chart width as it appears on
        <span class="bold"><strong>My Dashboard</strong></span>. The default is
        <span class="bold"><strong>Small</strong></span>. This field can be set to
        <span class="bold"><strong>Small</strong></span> to display it at 50% or
        <span class="bold"><strong>Large</strong></span> for 100%.
       </p></dd></dl></div></li><li class="listitem "><p>
     On the <span class="bold"><strong>Add New Time Series Chart</strong></span> screen,
     in <span class="bold"><strong>Added Chart Data</strong></span> complete the
     following fields:
    </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.2.6.13.4.6.2.1"><span class="term ">Metric</span></dt><dd><p>
        In Monasca, a metric is a multi-dimensional description that consists
        of the following fields: name, dimensions, timestamp, value and
        value_meta. The pre-populated list is equivalent to using the
        <span class="bold"><strong>monasca metric-name-list</strong></span> on the
        command line.
       </p></dd><dt id="id-1.7.3.2.6.13.4.6.2.2"><span class="term ">Dimension</span></dt><dd><p>
        The set of unique dimensions that are defined for a specific metric.
        Dimensions are a dictionary of key-value pairs. This pre-populated list
        is equivalent to using the
        <span class="bold"><strong>monasca
        metric-list –name &lt;metric_name&gt;</strong></span> on the command line.
       </p></dd><dt id="id-1.7.3.2.6.13.4.6.2.3"><span class="term ">Function</span></dt><dd><p>
        Operations Console uses Monasca to provide the results of all
        mathematical functions. Monasca in turns uses Graphite to perform the
        mathematical calculations and return the results. The default is
        <span class="bold"><strong>AVG</strong></span>. The
        <span class="bold"><strong>Function</strong></span>
        field can be set to
        <span class="bold"><strong>AVG</strong></span>
        (default), <span class="bold"><strong>MIN</strong></span>,
        <span class="bold"><strong>MAX</strong></span>. and
        <span class="bold"><strong>COUNT</strong></span>.
        For more information on these functions, see the Graphite
        documentation at
        <a class="link" href="http://www.aosabook.org/en/graphite.html" target="_blank">http://www.aosabook.org/en/graphite.html</a>.
       </p></dd></dl></div></li><li class="listitem "><p>
     Click <span class="bold"><strong>Add Data To Chart</strong></span>. To add another
     metric to the chart, repeat the previous step until all metrics are added.
     The maximum you can have in one chart is 6 metrics.
    </p></li><li class="listitem "><p>
     To create the chart, click <span class="bold"><strong>Create New
     Chart</strong></span>.
    </p></li></ol></div><p>
   After you click <span class="bold"><strong>Create New Chart</strong></span>, you will
   be returned to <span class="emphasis"><em>My Dashboard</em></span> where the new chart will be
   shown. From the <span class="emphasis"><em>My Dashboard</em></span> screen you can use the menu
   in the top-right corner of the card to
   delete or edit the chart. You can also select an option to create a
   comma-delimited file of the data in the chart.
  </p></div><div class="sect2" id="ops-Cinder-chart"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Chart Cinder Capacity</span> <a title="Permalink" class="permalink" href="#ops-Cinder-chart">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-charts.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-charts.xml</li><li><span class="ds-label">ID: </span>ops-Cinder-chart</li></ul></div></div></div></div><p>
   To visualize the use of storage capacity over time, you can create a chart
   that graphs the total block storage backend capacity. To find out how much
   of that total is being used, you can also create a chart that graphs the
   available block storage capacity.
  </p><p>
   <span class="bold"><strong>Visualizing Cinder:</strong></span>
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Chart Total Capacity: <a class="xref" href="#ops-Cinder-chart-total" title="1.5.3. Chart Total Capacity">Section 1.5.3, “Chart Total Capacity”</a>
    </p></li><li class="listitem "><p>
     Chart Available Capacity: <a class="xref" href="#ops-Cinder-chart-avail" title="1.5.4. Chart Available Capacity">Section 1.5.4, “Chart Available Capacity”</a>
    </p></li></ul></div><div id="id-1.7.3.2.6.14.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    The total and free capacity values are based on the available capacity
    reported by the Cinder backend. Be aware that some backends can be
    configured to thinly provision.
   </p></div></div><div class="sect2" id="ops-Cinder-chart-total"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Chart Total Capacity</span> <a title="Permalink" class="permalink" href="#ops-Cinder-chart-total">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-charts.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-charts.xml</li><li><span class="ds-label">ID: </span>ops-Cinder-chart-total</li></ul></div></div></div></div><p>
   To chart the total block-storage backend capacity:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Log in to Operations Console.
    </p></li><li class="listitem "><p>
     Follow the steps in the previous instructions to start creating a chart.
    </p></li><li class="listitem "><p>
     To chart the total backend capacity, on the <span class="bold"><strong>Add New
     Time Series Chart</strong></span> screen, in <span class="bold"><strong>Chart
     Definition</strong></span> use the following settings:
    </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>Field</th><th>Setting</th></tr></thead><tbody><tr><td>Metrics</td><td>cinderlm.cinder.backend.total.size</td></tr><tr><td>Dimension</td><td><p>any hostname. If multiple backends are available, select any one. The backends will all return the same metric data.</p></td></tr></tbody></table></div></li><li class="listitem "><p>
     Add the data to the chart and click
     <span class="bold"><strong>Create</strong></span>.
    </p></li></ol></div><p>
   Example of a Cinder Total Capacity Chart:
  </p></div><div class="sect2" id="ops-Cinder-chart-avail"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Chart Available Capacity</span> <a title="Permalink" class="permalink" href="#ops-Cinder-chart-avail">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-charts.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-charts.xml</li><li><span class="ds-label">ID: </span>ops-Cinder-chart-avail</li></ul></div></div></div></div><p>
   To chart the available block-storage backend capacity:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Log in to Operations Console.
    </p></li><li class="listitem "><p>
     Follow the steps in the previous instructions to start creating a chart.
    </p></li><li class="listitem "><p>
     To chart the available backend capacity, on the <span class="bold"><strong>Add
     New Time Series Chart</strong></span> screen, in <span class="bold"><strong>Chart
     Definition</strong></span> use the following settings:
    </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>Field</th><th>Setting</th></tr></thead><tbody><tr><td>Metrics</td><td>cinderlm.cinder.backend.total.avail</td></tr><tr><td>Dimension</td><td><p>any hostname. If multiple backends are available, select any one. The backends will all return the same metric data.</p></td></tr></tbody></table></div></li><li class="listitem "><p>
     Add the data to the chart and click
     <span class="bold"><strong>Create</strong></span>.
    </p></li></ol></div><p>
   Example of a chart showing Cinder Available Capacity:
  </p><div id="id-1.7.3.2.6.16.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    The source data for the Capacity Summary pages is only refreshed at the top
    of each hour. This affects the latency of the displayed data on those
    pages.
   </p></div></div></div><div class="sect1" id="help-opsconsole"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Getting Help with the Operations Console</span> <a title="Permalink" class="permalink" href="#help-opsconsole">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-opsconsole-help_opsconsole.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-opsconsole-help_opsconsole.xml</li><li><span class="ds-label">ID: </span>help-opsconsole</li></ul></div></div></div></div><p>
  On each of the Operations Console pages there is a help menu that you can
  click on to take you to a help page specific to the console you are
  currently viewing.
 </p><p>
  To reach the help page:
 </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
    Click the help menu option in the upper-right corner of the page, depicted
    by the question mark seen in the screenshot below.
   </p></li><li class="listitem "><p>
    Click the <span class="guimenu ">Get Help For This Page</span> link which will
    open the help page in a new tab in your browser.
   </p></li></ol></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-opsconsole-OpsConsoleGetHelp.png" target="_blank"><img src="images/media-opsconsole-OpsConsoleGetHelp.png" width="" /></a></div></div></div></div><div class="chapter " id="user-dashboard-overview"><div class="titlepage"><div><div><h2 class="title"><span class="number">2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the Dashboard</span> <a title="Permalink" class="permalink" href="#user-dashboard-overview">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>user-dashboard-overview</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#access-horizon"><span class="number">2.1 </span><span class="name">Accessing Horizon</span></a></span></dt><dt><span class="section"><a href="#browser-support-horizon"><span class="number">2.2 </span><span class="name">Browser support for Horizon</span></a></span></dt><dt><span class="section"><a href="#dashboard-limitations"><span class="number">2.3 </span><span class="name">Dashboard Use</span></a></span></dt><dt><span class="section"><a href="#DashProject"><span class="number">2.4 </span><span class="name">Project dashboard</span></a></span></dt><dt><span class="section"><a href="#DashAdmin"><span class="number">2.5 </span><span class="name">Admin dashboard</span></a></span></dt><dt><span class="section"><a href="#DashSettings"><span class="number">2.6 </span><span class="name">Settings dashboard</span></a></span></dt><dt><span class="section"><a href="#login-dashboard"><span class="number">2.7 </span><span class="name">Accessing the Dashboard</span></a></span></dt><dt><span class="section"><a href="#horizon-dashboard-examples"><span class="number">2.8 </span><span class="name">Horizon Dashboard</span></a></span></dt><dt><span class="section"><a href="#other-panels"><span class="number">2.9 </span><span class="name">Other Panels</span></a></span></dt></dl></div></div><p>
  Often referred to as Horizon or the Horizon dashboard, you can use this
  console to manage resources on a domain and project level in a web-based
  graphical user interface (GUI).
 </p><p>
  Horizon is the OpenStack service that serves as the basis for the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span>
  dashboards.
 </p><p>
  The dashboards provide a web-based user interface to <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> services
  including Compute, Volume Operations, Networking, and Identity.
 </p><div class="sect1" id="access-horizon"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accessing Horizon</span> <a title="Permalink" class="permalink" href="#access-horizon">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>access-horizon</li></ul></div></div></div></div><p>
   To access the Horizon dashboard as a non cloud administrator, you should ask
   the cloud admin for the host name or public IP address of the dashboard, and
   for your user name and password. If you are a cloud admin, you can determine
   the URL and credentials by following the steps in
   <a class="xref" href="#cloudadmin-gui" title="Chapter 3. Cloud Admin Actions with the Dashboard">Chapter 3, <em>Cloud Admin Actions with the Dashboard</em></a>.
  </p><div id="id-1.7.3.3.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    If you are authenticating against an external source such as an LDAP
    directory or via WebSSO you cannot change your password via the change
    password option in User settings.
   </p></div><p>
   Along the left side of the Horizon user interface are sections that provide
   access to Project and Settings sections. If your login credentials have been
   assigned the 'admin' role you will also see a separate Admin section that
   provides additional system-wide setting options.
  </p><p>
   Across the top are menus to switch between projects and menus where you can
   access user settings.
  </p></div><div class="sect1" id="browser-support-horizon"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Browser support for Horizon</span> <a title="Permalink" class="permalink" href="#browser-support-horizon">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>browser-support-horizon</li></ul></div></div></div></div><p>
   According to OpenStack.org, Horizon is tested and supported on the latest
   versions of Firefox and Chrome, and IE9+. Below is a summary of browser
   support for Horizon
  </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.3.6.3.1"><span class="term ">Very good</span></dt><dd><p>
      Very well tested; should work as expected
     </p></dd><dt id="id-1.7.3.3.6.3.2"><span class="term "> Good</span></dt><dd><p>
      Moderately tested; should look nice and work fine, may have a few visual
      issues
     </p></dd><dt id="id-1.7.3.3.6.3.3"><span class="term ">Poor</span></dt><dd><p>
      Visually inferior
     </p></dd><dt id="id-1.7.3.3.6.3.4"><span class="term ">Broken</span></dt><dd><p>
      Essential functionality not working
     </p></dd><dt id="id-1.7.3.3.6.3.5"><span class="term ">No</span></dt><dd><p>
      Not supported
     </p></dd></dl></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>Browser</th><th>Status</th><th>Versions </th></tr></thead><tbody><tr><td>Chrome</td><td>HPE Tested</td><td>43.0.2357.81</td></tr><tr><td>Firefox </td><td>HPE Tested</td><td>31+</td></tr><tr><td>Firefox ESR</td><td>HPE Tested</td><td>31+</td></tr><tr><td>Internet Explorer 11</td><td>HPE Tested</td><td>11.0.9600.18314</td></tr><tr><td>Internet Explorer 10</td><td>Not HPE Tested</td><td> </td></tr><tr><td>Internet Explorer 9</td><td>Not HPE Tested</td><td> </td></tr><tr><td>Internet Explorer 8 and below</td><td>Not supported</td><td> </td></tr><tr><td>Safari</td><td>Not HPE Tested</td><td> </td></tr><tr><td>Opera</td><td>Not HPE Tested</td><td> </td></tr></tbody></table></div><div id="id-1.7.3.3.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    Please refer to the
    <a class="link" href="https://wiki.openstack.org/wiki/Horizon" target="_blank">OpenStack
    Dashboard ("Horizon") wiki</a> for additional compatibility and testing
    information.
   </p></div><p>
   At the bottom of this page, you can see some of the services you can manage
   right from the dashboard. Remember that Horizon runs over TLS so you will
   need to use the HTTPS protocol with your Horizon IP address.
  </p></div><div class="sect1" id="dashboard-limitations"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dashboard Use</span> <a title="Permalink" class="permalink" href="#dashboard-limitations">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>dashboard-limitations</li></ul></div></div></div></div><p>
   As a Cloud or Domain admin of the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> dashboard, you should follow the
   included recommendations for continued success with your cloud.
  </p><div id="id-1.7.3.3.7.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      Do not create projects in the <span class="emphasis"><em>default</em></span> domain. If you
      would like to create projects for your users, please create a new domain
      to host the new projects.
     </p></li><li class="listitem "><p>
      If you are a Cloud admin, you may make changes to the
      <span class="emphasis"><em>default</em></span> domain, however changes should be made from
      the command-line and not through the dashboard.
     </p></li><li class="listitem "><p>
      If you are a Domain admin, you will need to modify the domain from the
      command-line and not from the dashboard.
     </p></li></ul></div></div></div><div class="sect1" id="DashProject"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Project dashboard</span> <a title="Permalink" class="permalink" href="#DashProject">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>DashProject</li></ul></div></div></div></div><p>
   Use the <span class="bold"><strong>Project</strong></span> dashboard to implement and
   build out your cloud. This dashboard contains tools to create virtual server
   instances, create and configure your network, configure access tools (such
   as key pairs and security groups) and cloud resource templates (stacks).
  </p></div><div class="sect1" id="DashAdmin"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Admin dashboard</span> <a title="Permalink" class="permalink" href="#DashAdmin">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>DashAdmin</li></ul></div></div></div></div><p>
   Use the <span class="bold"><strong>Admin</strong></span> dashboard to view, allocate,
   and manage all resources within the cloud.
  </p><p>
   The Admin dashboard allows you to manage instances, define flavors, create
   and configure images, manage networks, view system resources, manage
   projects, and manage users.
  </p></div><div class="sect1" id="DashSettings"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Settings dashboard</span> <a title="Permalink" class="permalink" href="#DashSettings">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>DashSettings</li></ul></div></div></div></div><p>
   Use the <span class="bold"><strong>Settings</strong></span> dashboard to change your
   display language and settings, your time zone, and your password.
  </p><p>
   Click <span class="bold"><strong>Settings</strong></span> in the user menu to display
   the Settings dashboard.
  </p></div><div class="sect1" id="login-dashboard"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accessing the Dashboard</span> <a title="Permalink" class="permalink" href="#login-dashboard">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>login-dashboard</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Open a web browser that has both JavaScript and cookies enabled.
    </p></li><li class="step "><p>
     In the address bar, enter the host name or IP address for the dashboard.
    </p><div id="id-1.7.3.3.11.2.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      If a certificate warning appears when you try to access the URL for the
      first time, a self-signed certificate is in use. These certificates are
      not considered trustworthy by default. Verify the certificate or add an
      exception in the browser to bypass the warning. For information about
      managing certificates, see
      <span class="intraxref">Book “Security Guide”, Chapter 7 “Transport Layer Security (TLS) Overview”, Section 7.2 “TLS Configuration”</span>.
     </p></div></li><li class="step "><p>
     On the <span class="bold"><strong>Log In</strong></span> page, enter your user name
     and password and then click <span class="bold"><strong>Connect</strong></span>.
    </p></li><li class="step "><p>
     The UserID with the <code class="literal">admin</code> role is provided with a
     special tab called Admin. The menu options underneath this tab are similar
     to the non-admin user views but cover all projects as well as some
     additional panels not available to general users.
    </p><p>
     The Overview page provides a summary by project of the current utilization
     of major OpenStack resources. The information on this screen is drawn
     directly from the Compute or Nova service API and provides the ability to
     filter the query by date range and an option to download results into a
     CSV file that is compatible with Microsoft Excel or can be imported into a
     database.
    </p></li><li class="step "><p>
     If you are a non-admin user, you will only be able to select a project
     from the list at the top of the screen.
    </p></li></ol></div></div></div><div class="sect1" id="horizon-dashboard-examples"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Horizon Dashboard</span> <a title="Permalink" class="permalink" href="#horizon-dashboard-examples">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>horizon-dashboard-examples</li></ul></div></div></div></div><p>
   There are several services you can manage in the Horizon dashboard.
  </p><p>
   <span class="bold"><strong>Viewing System Information</strong></span>
  </p><p>
   The <code class="literal">System Information</code> panel provides a list of all
   currently installed <span class="productname">OpenStack</span> services and their operation status.
  </p><p>
   Additional panels on the <code class="literal">System Information</code> display
   sub-service status for services like Compute, Block Storage, and Network
   services. This are tabs for Compute Services, Block Storage Services,
   Network Agents, and Orchestration Services.
  </p><p>
   <span class="bold"><strong>Managing Quotas</strong></span>
  </p><p>
   In the left hand menu, <span class="guimenu ">Admin</span> › <span class="guimenu ">Systems</span> › <span class="guimenu ">Defaults</span> shows a list of
   Quota Names such as VCPUs, RAM, Instances, and storage. Click
   <span class="guimenu ">Update Defaults</span> to manage Default Quotas.
  </p><p>
   <span class="bold"><strong>Managing Routers</strong></span>
  </p><p>
   In the menu,
   <span class="guimenu ">Project</span> › <span class="guimenu ">Network</span> › <span class="guimenu ">Routers</span>
   displays a list of routers. Routers connect end user networks together as
   well as to provide external connectivity. This panel shows all currently
   deployed routers and associated metadata. From here the system administrator
   can create, edit, and delete routers.
  </p><p>
   <span class="bold"><strong>Managing Host Aggregates</strong></span>
  </p><p>
   Selecting <span class="guimenu ">Admin</span> › <span class="guimenu ">Compute</span> › <span class="guimenu ">Host Aggregates</span> displays a list of host aggregates along
   with Availability Zones and Hosts. You can manage Host Aggregates in the
   <span class="guimenu ">Actions</span> drop-down box.
  </p><p>
   <span class="bold"><strong>Hypervisor Status</strong></span>
  </p><p>
   Selecting
   <span class="guimenu ">Admin</span> › <span class="guimenu ">Compute</span> › <span class="guimenu ">Hypervisors</span>
   displays a view of total consumed resources, the hypervisors currently
   running, the physical server for each hypervisor instance, the type of
   hypervisor, and the infrastructure resources consumed by the hypervisor.
  </p><p>
   The <span class="guimenu ">Compute Host</span> tab lists the currently configured
   physical hosts, the Availability Zone of each host, status, and a button to
   <span class="guimenu ">Disable Service</span>.
  </p></div><div class="sect1" id="other-panels"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Other Panels</span> <a title="Permalink" class="permalink" href="#other-panels">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_dashboard_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-user_dashboard_overview.xml</li><li><span class="ds-label">ID: </span>other-panels</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The <span class="bold"><strong>Updates and Extensions </strong></span>panel provides
     a list of available files that can be downloaded and installed. This view
     is also only available to UserIDs with the <code class="literal">admin</code> role.
    </p><div id="id-1.7.3.3.13.2.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      Administrators should be cautious to ensure that Horizon Extensions
      they install come from a trusted source and/or have undergone
      appropriate review and testing. Administrators should be aware of the
      risk of spear phishing, by which they may receive an offer to install
      an apparently useful application which also performs malicious actions.
     </p></div></li><li class="listitem "><p>
     <span class="bold"><strong>Host aggregates </strong></span>are a grouping of
     physical servers or hosts with associated metadata. A host can belong to
     multiple aggregates.
    </p></li><li class="listitem "><p>
     Common use cases for host aggregates include supporting the scheduling of
     instances to a subset of hosts that have a specific capability or flavor
     such as a specific type of storage, lots of RAM, and/or large numbers of
     processors.
    </p><p>
     Another use case of host aggregates is to support the arrangement of hosts
     into logical groups for load balancing and instance distribution. Host
     aggregates are configured and only viewable by system admins. The end user
     view of a host aggregate is called an Availability Zone. Availability
     zones are created via the Nova API and the host aggregates function. End
     users can use availability zones for similar use cases. For example, an
     application could be deployed on hosts in multiple availability zones. A
     load balancer can then be configured and the instances running each
     deployment of the application in each availability zone can be assigned to
     the load balancer thus providing a measure of failover and high
     availability support.
    </p><p>
     Additional information on host aggregates and availability zones is
     available at
     <a class="link" href="http://blog.russellbryant.net/2013/05/21/availability-zones-and-host-aggregates-in-openstack-compute-nova/" target="_blank">http://blog.russellbryant.net/2013/05/21/availability-zones-and-host-aggregates-in-openstack-compute-nova/</a>
     and
     <a class="link" href="http://docs.openstack.org/openstack-ops/content/scaling.html" target="_blank">http://docs.openstack.org/openstack-ops/content/scaling.html</a>.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>The Instances panel</strong></span> provides a view of
     all deployed end user instances across all projects, the images applied to
     those instances, the status of each instance, flavor type, and network
     information. This information is also supplied by the Nova API.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>The Volumes panel</strong></span> is displayed if the
     OpenStack Cinder service is available. Cinder provides block storage
     infrastructure. Block storage provides the ability for end users to attach
     storage as discrete drives to a compute instance. These drives are
     persistent and can be reassigned to a different instance. The Volumes tab
     on this view shows all currently created volumes and associated metadata
     and status, which physical host the volume is hosted on, and the ability
     for the admin to manage each volume.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>Flavors</strong></span> are virtual hardware templates.
     Flavors are used to define a virtual compute host. Flavors are assigned
     during the creation of a new instance. This panel displays all of the
     current flavor types and provides the ability for the admin to create,
     edit or delete flavors. Hosting organizations often use flavors as a form
     of billing unit; flavors with more resources are charged at a higher rate
     than flavors with fewer resources.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>Images</strong></span> are discrete software builds that
     can be loaded onto an instance. An image can be a standalone operating
     system implementation or a bundle of operating system and other
     pre-configured applications. This panel displays all currently available
     images and associated metadata and enables the system administrator to
     create, edit and delete images.
    </p><div id="id-1.7.3.3.13.2.7.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      If you encounter the following error:
     </p><div class="verbatim-wrap"><pre class="screen">ERROR: Unable to create new image. URL scheme not supported.</pre></div><p>
      The error message indicates that the Glance service has not been
      configured to support the import of Glance images via the
      <span class="emphasis"><em>http</em></span> option. This option can be enabled by your
      system administrator by enabling this function in the Glance
      configuration file.
     </p></div></li><li class="listitem "><p>
     <span class="bold"><strong>Networks</strong></span> are used by end users to provide
     connectivity to and between their deployed instances. This panel provides
     a list of all currently deployed networks and associated metadata and
     enables the system administrator the ability to created, edit, and delete
     networks.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>Quotas</strong></span> provide the means to limit
     resource usage. Quotas are assigned per project. This panel provides a
     view of all current quotas and enables a system administrator with the
     ability to edit quota line items.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>The Identity panel</strong></span> has two major panels.
     The Projects panel provides a list of all current projects and enables a
     system administrator the ability to create, modify, and delete panels and
     panel membership.
    </p></li><li class="listitem "><p>
     <span class="bold"><strong>The Users panel</strong></span> is available only to
     system administrators and provides the ability to create, modify, and
     delete users. These users are considered "local" to Keystone and are
     authenticated by Keystone.
    </p></li></ul></div></div></div><div class="chapter " id="cloudadmin-gui"><div class="titlepage"><div><div><h2 class="title"><span class="number">3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cloud Admin Actions with the Dashboard</span> <a title="Permalink" class="permalink" href="#cloudadmin-gui">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>cloudadmin-gui</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-operations-cloudadmin-dashboard-xml-4"><span class="number">3.1 </span><span class="name">Cloud Admin</span></a></span></dt><dt><span class="section"><a href="#idg-all-operations-cloudadmin-dashboard-xml-5"><span class="number">3.2 </span><span class="name">Accessing the dashboard</span></a></span></dt><dt><span class="section"><a href="#id-1.7.3.4.6"><span class="number">3.3 </span><span class="name">Cloud Admin Activities</span></a></span></dt><dt><span class="section"><a href="#create-new-domain"><span class="number">3.4 </span><span class="name">Create a New Domain</span></a></span></dt><dt><span class="section"><a href="#domain-context"><span class="number">3.5 </span><span class="name">Set Domain context to the newly created Domain</span></a></span></dt><dt><span class="section"><a href="#new-project"><span class="number">3.6 </span><span class="name">Create a New Project</span></a></span></dt><dt><span class="section"><a href="#new-user"><span class="number">3.7 </span><span class="name">Create a New User</span></a></span></dt><dt><span class="section"><a href="#remove-user"><span class="number">3.8 </span><span class="name">Remove a user from a project</span></a></span></dt><dt><span class="section"><a href="#admin-role-user"><span class="number">3.9 </span><span class="name">Assign Admin role to User within the new Domain</span></a></span></dt><dt><span class="section"><a href="#quotas"><span class="number">3.10 </span><span class="name">Setting and managing quotas</span></a></span></dt><dt><span class="section"><a href="#dashboard-signout"><span class="number">3.11 </span><span class="name">Sign out of the Dashboard</span></a></span></dt></dl></div></div><p>
  The Horizon dashboard provides cloud admins a web GUI to perform domain admin
  tasks such as user and project administration and managing project quotas.
 </p><p>
  Cloud admins can use the dashboard GUI to perform domain admin tasks such as
  user and project administration and managing project quotas.
 </p><div class="sect1" id="idg-all-operations-cloudadmin-dashboard-xml-4"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cloud Admin</span> <a title="Permalink" class="permalink" href="#idg-all-operations-cloudadmin-dashboard-xml-4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>idg-all-operations-cloudadmin-dashboard-xml-4</li></ul></div></div></div></div><p>
   As a Cloud Admin, you can create new domains, projects, users or remove
   them. You can also give admin privileges to users you create.
  </p></div><div class="sect1" id="idg-all-operations-cloudadmin-dashboard-xml-5"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accessing the dashboard</span> <a title="Permalink" class="permalink" href="#idg-all-operations-cloudadmin-dashboard-xml-5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>idg-all-operations-cloudadmin-dashboard-xml-5</li></ul></div></div></div></div><p>
   Prior to accessing the dashboard you will need to retrieve your admin user
   password. For more details, see
   <span class="intraxref">Book “Operations Guide”, Chapter 4 “Managing Identity”, Section 4.6 “Retrieving the Admin Password”</span>.
  </p><p>
   If your administrator set a hostname value for
   <code class="literal">external_name</code> in your
   <code class="literal">network_groups.yml</code> file during the configuration process
   for your cloud then Horizon will be accessed over port 443 (https) on that
   hostname.
  </p><p>
   If your administrator did not set a hostname value then in order to
   determine which IP address to use to access Horizon you can use this command
   from your Cloud Lifecycle Manager node:
  </p><div class="verbatim-wrap"><pre class="screen">grep HZN-WEB /etc/hosts</pre></div><p>
   The output of that command will show you the virtual IP address for Horizon
   that you should use.
  </p><p>
   The default username for the Administrator user is <code class="literal">admin</code>.
   You will use that along with the password you retrieved earlier and your
   domain name when logging in.
  </p></div><div class="sect1" id="id-1.7.3.4.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cloud Admin Activities</span> <a title="Permalink" class="permalink" href="#id-1.7.3.4.6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/cloud.adm.activities" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>cloud.adm.activities</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   You must log into the Dashboard via the default domain using a cloud admin
   username and password to create, modify or remove domains, projects or
   users. Look at the Project picker at the top of the Dashboard UI and ensure
   that the <span class="bold"><strong>Default</strong></span> domain and the <span class="bold"><strong>admin</strong></span> project BOTH have checks beside them.  The
   <span class="bold"><strong>demo</strong></span> project is selected by default, and
   this will cause issues if not changed.
  </p></div><div class="sect1" id="create-new-domain"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a New Domain</span> <a title="Permalink" class="permalink" href="#create-new-domain">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>create-new-domain</li></ul></div></div></div></div><p>
   You can create new domains as a Cloud Admin.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Select <span class="bold"><strong>Identity</strong></span> and
     <span class="bold"><strong>Domains</strong></span> in the sidebar
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Create Domain</strong></span> from the list above
     the domains table
    </p></li><li class="step "><p>
     Enter a domain name and description.
    </p></li><li class="step "><p>
     The <span class="bold"><strong>Enabled</strong></span> checkbox is checked by
     default
    </p></li><li class="step "><p>
     Click the <span class="bold"><strong>Create Domain</strong></span> button
    </p></li></ol></div></div></div><div class="sect1" id="domain-context"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Set Domain context to the newly created Domain</span> <a title="Permalink" class="permalink" href="#domain-context">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>domain-context</li></ul></div></div></div></div><p>
   After you have created a new domain as the Cloud Admin, set the context.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Select <span class="bold"><strong>Identity</strong></span> and
     <span class="bold"><strong>Domains</strong></span> in the sidebar.
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Set Domain Context</strong></span> button on the
     newly created domain.
    </p></li></ol></div></div></div><div class="sect1" id="new-project"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a New Project</span> <a title="Permalink" class="permalink" href="#new-project">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>new-project</li></ul></div></div></div></div><p>
   You can create new projects.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Select <span class="bold"><strong>Identity</strong></span> and
     <span class="bold"><strong>Projects</strong></span> in the sidebar.
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Create Project</strong></span> from the list above
     the projects table
    </p></li><li class="step "><p>
     The <code class="literal">Domain ID</code> and <code class="literal">Name</code> are immutably
     set to the new domain.
    </p></li><li class="step "><p>
     Enter a project name and description
    </p></li><li class="step "><p>
     The <span class="bold"><strong>Enabled</strong></span> checkbox is checked by
     default.
    </p></li><li class="step "><p>
     Click <span class="guimenu ">Create Project</span> button.
    </p></li><li class="step "><p>
     The project created will be displayed.
    </p></li></ol></div></div></div><div class="sect1" id="new-user"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a New User</span> <a title="Permalink" class="permalink" href="#new-user">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>new-user</li></ul></div></div></div></div><div id="id-1.7.3.4.10.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
    Do not create users in the default domain with admin privileges unless you
    want them to act as Cloud Admin users.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Select <span class="bold"><strong>Identity</strong></span> and
     <span class="bold"><strong>Users</strong></span> in the sidebar
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Create User</strong></span> from the list above the
     users table
    </p></li><li class="step "><p>
     <code class="literal">Domain ID</code> and <code class="literal">Name</code> are immutably set
     to the new domain.
    </p></li><li class="step "><p>
     Enter a user name, description, email address, password.
    </p></li><li class="step "><p>
     The new project is preselected.
    </p></li><li class="step "><p>
     The role <code class="literal">_Member_</code> is preselected.
    </p></li><li class="step "><p>
     The <code class="literal">Enabled</code> checkbox is checked by default.
    </p></li><li class="step "><p>
     Click <span class="guimenu ">Create User</span> button.
    </p></li><li class="step "><p>
     The user created will be displayed.
    </p></li></ol></div></div></div><div class="sect1" id="remove-user"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Remove a user from a project</span> <a title="Permalink" class="permalink" href="#remove-user">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>remove-user</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Select <span class="bold"><strong>Identity</strong></span> and
     <span class="bold"><strong>Projects</strong></span> in the sidebar
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Manage Members</strong></span> in the actions
     column for the project.
    </p></li><li class="step "><p>
     In the right column, click the minus ("") beside the user to remove them
     from the project
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Save</strong></span> to save the change
    </p></li></ol></div></div></div><div class="sect1" id="admin-role-user"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Assign Admin role to User within the new Domain</span> <a title="Permalink" class="permalink" href="#admin-role-user">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>admin-role-user</li></ul></div></div></div></div><p>
   You can assign admin privileges to a user within a domain.
  </p><div id="id-1.7.3.4.12.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
    Assigning admin privileges to a user in the default domain gives them Cloud
    Admin privileges.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Select <span class="bold"><strong>Identity</strong></span> and
     <span class="bold"><strong>Domains</strong></span> in the sidebar
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Manage Members</strong></span> in the actions
     column for the domain
    </p></li><li class="step "><p>
     If necessary, in the left column, click the plus ("+") beside the user
     that should be the domain admin.
    </p></li><li class="step "><p>
     In the right column, click the dropdown beside the domain admin user and
     ensure that ONLY the <span class="bold"><strong>admin</strong></span> role is
     selected by clicking it. Unselect any other roles selected by clicking
     them.
    </p></li><li class="step "><p>
     Click <span class="bold"><strong>Save</strong></span> to save the change
    </p></li></ol></div></div></div><div class="sect1" id="quotas"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting and managing quotas</span> <a title="Permalink" class="permalink" href="#quotas">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>quotas</li></ul></div></div></div></div><p>
   Infrastructure resource quotas are also defined within the OpenStack cloud.
   Quotas are defined per service but can be assigned via the Horizon user
   interface in the Projects section; thus, this function is often associated
   with the Keystone API.
  </p><p>
   Quotas are assigned per each project.
  </p><p>
   Quotas can be managed using the CLI. Instructions can be found on OpenStack
   web site in
   <a class="link" href="http://docs.openstack.org/user-guide-admin/cli_set_quotas.html" target="_blank">Managing
   Quotas</a>
  </p><p>
   In Horizon, selecting
   <span class="guimenu ">Admin</span> › <span class="guimenu ">Systems</span> › <span class="guimenu ">Defaults</span>
   from the menu provides a list of system quotas that can viewed and edited.
  </p></div><div class="sect1" id="dashboard-signout"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Sign out of the Dashboard</span> <a title="Permalink" class="permalink" href="#dashboard-signout">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_dashboard.xml</li><li><span class="ds-label">ID: </span>dashboard-signout</li></ul></div></div></div></div><p>
   Sign out of the Dashboard by clicking <span class="guimenu ">Sign Out</span>.
  </p></div></div><div class="chapter " id="CreateCloudAdmin"><div class="titlepage"><div><div><h2 class="title"><span class="number">4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cloud Admin Actions with the Command Line</span> <a title="Permalink" class="permalink" href="#CreateCloudAdmin">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_cli.xml</li><li><span class="ds-label">ID: </span>CreateCloudAdmin</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-operations-cloudadmin-cli-xml-4"><span class="number">4.1 </span><span class="name">Creating Additional Cloud Admins</span></a></span></dt><dt><span class="section"><a href="#idg-all-operations-cloudadmin-cli-xml-5"><span class="number">4.2 </span><span class="name">Command Line Examples</span></a></span></dt><dt><span class="section"><a href="#default-service-admin-roles"><span class="number">4.3 </span><span class="name">Assigning the default service admin roles</span></a></span></dt><dt><span class="section"><a href="#customize-policy"><span class="number">4.4 </span><span class="name">Customize policy.json on the Cloud Lifecycle Manager</span></a></span></dt><dt><span class="section"><a href="#service-roles"><span class="number">4.5 </span><span class="name">Roles</span></a></span></dt></dl></div></div><p>
  Cloud admins can use the command line tools to perform domain admin tasks
  such as user and project administration.
 </p><div class="sect1" id="idg-all-operations-cloudadmin-cli-xml-4"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating Additional Cloud Admins</span> <a title="Permalink" class="permalink" href="#idg-all-operations-cloudadmin-cli-xml-4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_cli.xml</li><li><span class="ds-label">ID: </span>idg-all-operations-cloudadmin-cli-xml-4</li></ul></div></div></div></div><p>
   You can create additional Cloud Admins to help with the administration of
   your cloud.
  </p><p>
   Keystone identity service query and administration tasks can be performed
   using the <span class="productname">OpenStack</span> command line utility. The utility is installed by the
   Cloud Lifecycle Manager onto the Cloud Lifecycle Manager.
  </p><div id="id-1.7.3.5.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    Keystone administration tasks should be performed by an
    <span class="emphasis"><em>admin</em></span> user with a token scoped to the
    <span class="emphasis"><em>default</em></span> domain via the Keystone v3 identity API.
    These settings are preconfigured in the file
    <code class="filename">~/keystone.osrc</code>. By default,
    <code class="filename">keystone.osrc</code> is configured with the admin endpoint of
    Keystone. If the admin endpoint is not accessible from your network, change
    <code class="literal">OS_AUTH_URL</code> to point to the public endpoint.
   </p></div></div><div class="sect1" id="idg-all-operations-cloudadmin-cli-xml-5"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Command Line Examples</span> <a title="Permalink" class="permalink" href="#idg-all-operations-cloudadmin-cli-xml-5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_cli.xml</li><li><span class="ds-label">ID: </span>idg-all-operations-cloudadmin-cli-xml-5</li></ul></div></div></div></div><p>
   For a full list of OpenStackClient commands, see
   <a class="link" href="http://docs.openstack.org/developer/python-openstackclient/command-list.html" target="_blank">OpenStackClient
   Command List</a>.
  </p><p>
   <span class="bold"><strong>Sourcing the Keystone Administration
   Credentials</strong></span>
  </p><p>
   You can set the environment variables needed for identity administration by
   sourcing the <code class="literal">keystone.osrc</code> file created by the lifecycle
   manager:
  </p><div class="verbatim-wrap"><pre class="screen">source ~/keystone.osrc</pre></div><p>
   <span class="bold"><strong>List users in the default domain</strong></span>
  </p><p>
   These users are created by the Cloud Lifecycle Manager in the MySQL back end:
  </p><div class="verbatim-wrap"><pre class="screen">openstack user list</pre></div><p>
   Example output:
  </p><div class="verbatim-wrap"><pre class="screen">$ openstack user list
+----------------------------------+------------------+
| ID                               | Name             |
+----------------------------------+------------------+
| 155b68eda9634725a1d32c5025b91919 | heat             |
| 303375d5e44d48f298685db7e6a4efce | octavia          |
| 40099e245a394e7f8bb2aa91243168ee | logging          |
| 452596adbf4d49a28cb3768d20a56e38 | admin            |
| 76971c3ad2274820ad5347d46d7560ec | designate        |
| 7b2dc0b5bb8e4ffb92fc338f3fa02bf3 | hlm_backup       |
| 86d345c960e34c9189519548fe13a594 | barbican         |
| 8e7027ab438c4920b5853d52f1e08a22 | nova_monasca     |
| 9c57dfff57e2400190ab04955e7d82a0 | barbican_service |
| a3f99bcc71b242a1bf79dbc9024eec77 | nova             |
| aeeb56fc4c4f40e0a6a938761f7b154a | glance-check     |
| af1ef292a8bb46d9a1167db4da48ac65 | cinder           |
| af3000158c6d4d3d9257462c9cc68dda | demo             |
| b41a7d0cb1264d949614dc66f6449870 | swift            |
| b78a2b17336b43368fb15fea5ed089e9 | cinderinternal   |
| bae1718dee2d47e6a75cd6196fb940bd | monasca          |
| d4b9b32f660943668c9f5963f1ff43f9 | ceilometer       |
| d7bef811fb7e4d8282f19fb3ee5089e9 | swift-monitor    |
| df58b381ca8a4c9bb42e371f2a78ef4f | freezer          |
| e22bbb2be91342fd9afa20baad4cd490 | neutron          |
| ec0ad2418a644e6b995d8af3eb5ff195 | glance           |
| ef16c37ec7a648338eaf53c029d6e904 | swift-dispersion |
| ef1a6daccb6f4694a27a1c41cc5e7a31 | glance-swift     |
| fed3a599b0864f5b80420c9e387b4901 | monasca-agent    |
+----------------------------------+------------------+</pre></div><p>
   <span class="bold"><strong>List domains created by the installation
   process</strong></span>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack domain list</pre></div><p>
   Example output:
  </p><div class="verbatim-wrap"><pre class="screen">$ openstack domain list
+----------------------------------+---------+---------+----------------------------------------------------------------------+
| ID                               | Name    | Enabled | Description                                                          |
+----------------------------------+---------+---------+----------------------------------------------------------------------+
| 6740dbf7465a4108a36d6476fc967dbd | heat    | True    | Owns users and projects created by heat                              |
| default                          | Default | True    | Owns users and tenants (i.e. projects) available on Identity API v2. |
+----------------------------------+---------+---------+----------------------------------------------------------------------+</pre></div><p>
   <span class="bold"><strong>List the roles</strong></span>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack role list</pre></div><p>
   Example output:
  </p><div class="verbatim-wrap"><pre class="screen">$ openstack role list
+----------------------------------+---------------------------+
| ID                               | Name                      |
+----------------------------------+---------------------------+
| 0be3da26cd3f4cd38d490b4f1a8b0c03 | designate_admin           |
| 13ce16e4e714473285824df8188ee7c0 | monasca-agent             |
| 160f25204add485890bc95a6065b9954 | key-manager:service-admin |
| 27755430b38c411c9ef07f1b78b5ebd7 | monitor                   |
| 2b8eb0a261344fbb8b6b3d5934745fe1 | key-manager:observer      |
| 345f1ec5ab3b4206a7bffdeb5318bd32 | admin                     |
| 49ba3b42696841cea5da8398d0a5d68e | nova_admin                |
| 5129400d4f934d4fbfc2c3dd608b41d9 | ResellerAdmin             |
| 60bc2c44f8c7460a9786232a444b56a5 | neutron_admin             |
| 654bf409c3c94aab8f929e9e82048612 | cinder_admin              |
| 854e542baa144240bfc761cdb5fe0c07 | monitoring-delegate       |
| 8946dbdfa3d346b2aa36fa5941b43643 | key-manager:auditor       |
| 901453d9a4934610ad0d56434d9276b4 | key-manager:admin         |
| 9bc90d1121544e60a39adbfe624a46bc | monasca-user              |
| 9fe2a84a3e7443ae868d1009d6ab4521 | service                   |
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_                  |
| a24d4e0a5de14bffbe166bfd68b36e6a | swiftoperator             |
| ae088fcbf579425580ee4593bfa680e5 | heat_stack_user           |
| bfba56b2562942e5a2e09b7ed939f01b | KeystoneAdmin             |
| c05f54cf4bb34c7cb3a4b2b46c2a448b | glance_admin              |
| cd61735400ca4fa19e80cebe9970d9a7 | Member                    |
| fe010be5c57240db8f559e0114a380c1 | key-manager:creator       |
+----------------------------------+---------------------------+</pre></div><p>
   <span class="bold"><strong>List admin user role assignment within default
   domain</strong></span>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack role assignment list --user admin --domain default</pre></div><p>
   Example output:
  </p><div class="verbatim-wrap"><pre class="screen"># This indicates that the admin user is assigned the admin role within the default domain
<code class="prompt user">ardana &gt; </code> openstack role assignment list --user admin --domain default
+----------------------------------+----------------------------------+-------+---------+---------+
| Role                             | User                             | Group | Project | Domain  |
+----------------------------------+----------------------------------+-------+---------+---------+
| b398322103504546a070d607d02618ad | fed1c038d9e64392890b6b44c38f5bbb |       |         | default |
+----------------------------------+----------------------------------+-------+---------+---------+</pre></div><p>
   <span class="bold"><strong>Create a new user in default domain</strong></span>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack user create --domain default --password-prompt --email &lt;email_address&gt; --description &lt;description&gt; --enable &lt;username&gt;</pre></div><p>
   Example output showing the creation of a user named
   <code class="literal">testuser</code> with email address
   <code class="literal">test@example.com</code> and a description of <code class="literal">Test
   User</code>:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code> openstack user create --domain default --password-prompt --email test@example.com --description "Test User" --enable testuser
User Password:
Repeat User Password:
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | Test User                        |
| domain_id   | default                          |
| email       | test@example.com                 |
| enabled     | True                             |
| id          | 8aad69acacf0457e9690abf8c557754b |
| name        | testuser                         |
+-------------+----------------------------------+</pre></div><p>
   <span class="bold"><strong>Assign admin role for testuser within the default
   domain</strong></span>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack role add admin --user &lt;username&gt; --domain default
openstack role assignment list --user &lt;username&gt; --domain default</pre></div><p>
   Example output:
  </p><div class="verbatim-wrap"><pre class="screen"># Just for demonstration purposes - do not do this in a production environment!
<code class="prompt user">ardana &gt; </code> openstack role add admin --user testuser --domain default
<code class="prompt user">ardana &gt; </code> openstack role assignment list --user testuser --domain default
+----------------------------------+----------------------------------+-------+---------+---------+
| Role                             | User                             | Group | Project | Domain  |
+----------------------------------+----------------------------------+-------+---------+---------+
| b398322103504546a070d607d02618ad | 8aad69acacf0457e9690abf8c557754b |       |         | default |
+----------------------------------+----------------------------------+-------+---------+---------+</pre></div></div><div class="sect1" id="default-service-admin-roles"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Assigning the default service admin roles</span> <a title="Permalink" class="permalink" href="#default-service-admin-roles">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_cli.xml</li><li><span class="ds-label">ID: </span>default-service-admin-roles</li></ul></div></div></div></div><p>
   The following examples illustrate how you can assign each of the new service
   admin roles to a user.
  </p><p>
   <span class="bold"><strong>Assigning the glance_admin role</strong></span>
  </p><p>
   A user must have the role of admin in order to assign the glance_admin role.
   To assign the role, you will set the environment variables needed for the
   identity service administrator.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     First, source the identity service credentials:
    </p><div class="verbatim-wrap"><pre class="screen">source ~/keystone.osrc</pre></div></li><li class="listitem "><p>
     You can add the glance_admin role to a user on a project with this
     command:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role add --user &lt;username&gt; --project &lt;project_name&gt; glance_admin</pre></div><p>
     Example, showing a user named <code class="literal">testuser</code> being granted
     the <code class="literal">glance_admin</code> role in the
     <code class="literal">test_project</code> project:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role add --user testuser --project test_project glance_admin</pre></div></li><li class="listitem "><p>
     You can confirm the role assignment by listing out the roles:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role assignment list --user &lt;username&gt;</pre></div><p>
     Example output:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code> openstack role assignment list --user testuser
+----------------------------------+----------------------------------+-------+----------------------------------+--------+-----------+
| Role                             | User                             | Group | Project                          | Domain | Inherited |
+----------------------------------+----------------------------------+-------+----------------------------------+--------+-----------+
| 46ba80078bc64853b051c964db918816 | 8bcfe10101964e0c8ebc4de391f3e345 |       | 0ebbf7640d7948d2a17ac08bbbf0ca5b |        | False     |
+----------------------------------+----------------------------------+-------+----------------------------------+--------+-----------+</pre></div></li><li class="listitem "><p>
     Note that only the role ID is displayed. To get the role name, execute the
     following:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role show &lt;role_id&gt;</pre></div><p>
     Example output:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code> openstack role show 46ba80078bc64853b051c964db918816
+-------+----------------------------------+
| Field | Value                            |
+-------+----------------------------------+
| id    | 46ba80078bc64853b051c964db918816 |
| name  | glance_admin                     |
+-------+----------------------------------+</pre></div></li><li class="listitem "><p>
     To demonstrate that the user has Glance admin privileges, authenticate
     with those user creds and then upload and publish an image. Only a user
     with an admin role or glance_admin can publish an image.
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       The easiest way to do this will be to make a copy of the
       <code class="literal">service.osrc</code> file and edit it with your user
       credentials. You can do that with this command:
      </p><div class="verbatim-wrap"><pre class="screen">cp ~/service.osrc ~/user.osrc</pre></div></li><li class="listitem "><p>
       Using your preferred editor, edit the <code class="literal">user.osrc</code> file
       and replace the values for the following entries to match your user
       credentials:
      </p><div class="verbatim-wrap"><pre class="screen">export OS_USERNAME=&lt;username&gt;
export OS_PASSWORD=&lt;password&gt;</pre></div></li><li class="listitem "><p>
       You will also need to edit the following lines for your environment:
      </p><div class="verbatim-wrap"><pre class="screen">## Change these values from 'unset' to 'export'
export OS_PROJECT_NAME=&lt;project_name&gt;
export OS_PROJECT_DOMAIN_NAME=Default</pre></div><p>
       Here is an example output:
      </p><div class="verbatim-wrap"><pre class="screen">unset OS_DOMAIN_NAME
export OS_IDENTITY_API_VERSION=3
export OS_AUTH_VERSION=3
export OS_PROJECT_NAME=test_project
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USERNAME=testuser
export OS_USER_DOMAIN_NAME=Default
export OS_PASSWORD=testuser
export OS_AUTH_URL=http://192.168.245.9:35357/v3
export OS_ENDPOINT_TYPE=internalURL
# OpenstackClient uses OS_INTERFACE instead of OS_ENDPOINT
export OS_INTERFACE=internal
export OS_CACERT=/etc/ssl/certs/ca-certificates.crt</pre></div></li></ol></div></li><li class="listitem "><p>
     Source the environment variables for your user:
    </p><div class="verbatim-wrap"><pre class="screen">source ~/user.osrc</pre></div></li><li class="listitem "><p>
     Upload an image and publicize it:
    </p><div class="verbatim-wrap"><pre class="screen">glance image-create --name "upload me" --visibility public --container-format bare --disk-format qcow2 --file uploadme.txt</pre></div><p>
     Example output:
    </p><div class="verbatim-wrap"><pre class="screen">+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | dd75c3b840a16570088ef12f6415dd15     |
| container_format | bare                                 |
| created_at       | 2016-01-06T23:31:27Z                 |
| disk_format      | qcow2                                |
| id               | cf1490f4-1eb1-477c-92e8-15ebbe91da03 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | upload me                            |
| owner            | bd24897932074780a20b780c4dde34c7     |
| protected        | False                                |
| size             | 10                                   |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2016-01-06T23:31:31Z                 |
| virtual_size     | None                                 |
| visibility       | public                               |
+------------------+--------------------------------------+</pre></div><div id="id-1.7.3.5.5.5.7.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      You can use the command <code class="command">glance help image-create</code> to
      get the full syntax for this command.
     </p></div></li></ol></div><p>
   <span class="bold"><strong>Assigning the nova_admin role</strong></span>
  </p><p>
   A user must have the role of admin in order to assign the nova_admin role.
   To assign the role, you will set the environment variables needed for the
   identity service administrator.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     First, source the identity service credentials:
    </p><div class="verbatim-wrap"><pre class="screen">source ~/keystone.osrc</pre></div></li><li class="listitem "><p>
     You can add the glance_admin role to a user on a project with this
     command:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role add --user &lt;username&gt; --project &lt;project_name&gt; nova_admin</pre></div><p>
     Example, showing a user named <code class="literal">testuser</code> being granted
     the <code class="literal">glance_admin</code> role in the
     <code class="literal">test_project</code> project:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role add --user testuser --project test_project nova_admin</pre></div></li><li class="listitem "><p>
     You can confirm the role assignment by listing out the roles:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role assignment list --user &lt;username&gt;</pre></div><p>
     Example output:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code> openstack role assignment list --user testuser
+----------------------------------+----------------------------------+-------+----------------------------------+--------+-----------+
| Role                             | User                             | Group | Project                          | Domain | Inherited |
+----------------------------------+----------------------------------+-------+----------------------------------+--------+-----------+
| 8cdb02bab38347f3b65753099f3ab73c | 8bcfe10101964e0c8ebc4de391f3e345 |       | 0ebbf7640d7948d2a17ac08bbbf0ca5b |        | False     |
+----------------------------------+----------------------------------+-------+----------------------------------+--------+-----------+</pre></div></li><li class="listitem "><p>
     Note that only the role ID is displayed. To get the role name, execute the
     following:
    </p><div class="verbatim-wrap"><pre class="screen">openstack role show &lt;role_id&gt;</pre></div><p>
     Example output:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code> openstack role show 8cdb02bab38347f3b65753099f3ab73c
+-------+----------------------------------+
| Field | Value                            |
+-------+----------------------------------+
| id    | 8cdb02bab38347f3b65753099f3ab73c |
| name  | nova_admin                       |
+-------+----------------------------------+</pre></div></li><li class="listitem "><p>
     To demonstrate that the user has Nova admin privileges, authenticate with
     those user creds and then upload and publish an image. Only a user with an
     admin role or glance_admin can publish an image.
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       The easiest way to do this will be to make a copy of the
       <code class="literal">service.osrc</code> file and edit it with your user
       credentials. You can do that with this command:
      </p><div class="verbatim-wrap"><pre class="screen">cp ~/service.osrc ~/user.osrc</pre></div></li><li class="listitem "><p>
       Using your preferred editor, edit the <code class="literal">user.osrc</code> file
       and replace the values for the following entries to match your user
       credentials:
      </p><div class="verbatim-wrap"><pre class="screen">export OS_USERNAME=&lt;username&gt;
export OS_PASSWORD=&lt;password&gt;</pre></div></li><li class="listitem "><p>
       You will also need to edit the following lines for your environment:
      </p><div class="verbatim-wrap"><pre class="screen">## Change these values from 'unset' to 'export'
export OS_PROJECT_NAME=&lt;project_name&gt;
export OS_PROJECT_DOMAIN_NAME=Default</pre></div><p>
       Here is an example output:
      </p><div class="verbatim-wrap"><pre class="screen">unset OS_DOMAIN_NAME
export OS_IDENTITY_API_VERSION=3
export OS_AUTH_VERSION=3
export OS_PROJECT_NAME=test_project
export OS_PROJECT_DOMAIN_NAME=Default
export OS_USERNAME=testuser
export OS_USER_DOMAIN_NAME=Default
export OS_PASSWORD=testuser
export OS_AUTH_URL=http://192.168.245.9:35357/v3
export OS_ENDPOINT_TYPE=internalURL
# OpenstackClient uses OS_INTERFACE instead of OS_ENDPOINT
export OS_INTERFACE=internal
export OS_CACERT=/etc/ssl/certs/ca-certificates.crt</pre></div></li></ol></div></li><li class="listitem "><p>
     Source the environment variables for your user:
    </p><div class="verbatim-wrap"><pre class="screen">source ~/user.osrc</pre></div></li><li class="listitem "><p>
     List all of the virtual machines in the project specified in user.osrc:
    </p><div class="verbatim-wrap"><pre class="screen">openstack server list</pre></div><p>
     Example output showing no virtual machines, because there are no virtual
     machines created on the project specified in the user.osrc file:
    </p><div class="verbatim-wrap"><pre class="screen">+--------------------------------------+-------------------------------------------------------+--------+-----------------------------------------------------------------+
| ID                                   | Name                                                  | Status | Networks                                                        |
+--------------------------------------+-------------------------------------------------------+--------+-----------------------------------------------------------------+
+--------------------------------------+-------------------------------------------------------+--------+-----------------------------------------------------------------+</pre></div></li><li class="listitem "><p>
     For this demonstration, we do have a virtual machine associated with a
     different project and because your user has nova_admin permissions, you
     can view those virtual machines using a slightly different command:
    </p><div class="verbatim-wrap"><pre class="screen">openstack server list --all-projects</pre></div><p>
     Example output, now showing a virtual machine:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code> openstack server list --all-projects
+--------------------------------------+-------------------------------------------------------+--------+-----------------------------------------------------------------+
| ID                                   | Name                                                  | Status | Networks                                                        |
+--------------------------------------+-------------------------------------------------------+--------+-----------------------------------------------------------------+
| da4f46e2-4432-411b-82f7-71ab546f91f3 | testvml                                               | ACTIVE |                                                                 |
+--------------------------------------+-------------------------------------------------------+--------+-----------------------------------------------------------------+</pre></div></li><li class="listitem "><p>
     You can also now delete virtual machines in other projects by using the
     <code class="literal">--all-tenants</code> switch:
    </p><div class="verbatim-wrap"><pre class="screen">openstack server delete --all-projects &lt;instance_id&gt;</pre></div><p>
     Example, showing us deleting the instance in the previous step:
    </p><div class="verbatim-wrap"><pre class="screen">openstack server delete --all-projects da4f46e2-4432-411b-82f7-71ab546f91f3</pre></div></li><li class="listitem "><p>
     You can get a full list of available commands by using this:
    </p><div class="verbatim-wrap"><pre class="screen">openstack -h</pre></div></li></ol></div><p>
   You can perform the same steps as above for the Neutron and Cinder service
   admin roles:
  </p><div class="verbatim-wrap"><pre class="screen">neutron_admin
cinder_admin</pre></div></div><div class="sect1" id="customize-policy"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Customize policy.json on the Cloud Lifecycle Manager</span> <a title="Permalink" class="permalink" href="#customize-policy">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_cli.xml</li><li><span class="ds-label">ID: </span>customize-policy</li></ul></div></div></div></div><p>
   One way to deploy <code class="filename">policy.json</code> for a service is by going to each of the
   target nodes and making changes there. This is not necessary anymore. This
   process has been streamlined and policy.json files can be edited on the
   Cloud Lifecycle Manager and then deployed to nodes. Please exercise caution when modifying
   policy.json files. It is best to validate the changes in a non-production
   environment before rolling out policy.json changes into production. It is
   not recommended that you make policy.json changes without a way to validate
   the desired policy behavior. Updated policy.json files can be deployed using
   the appropriate <code class="literal">&lt;service_name&gt;-reconfigure.yml</code>
   playbook.
  </p></div><div class="sect1" id="service-roles"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Roles</span> <a title="Permalink" class="permalink" href="#service-roles">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/operations-cloudadmin_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>operations-cloudadmin_cli.xml</li><li><span class="ds-label">ID: </span>service-roles</li></ul></div></div></div></div><p>
   Service roles represent the functionality used to implement the <span class="productname">OpenStack</span>
   role based access control (RBAC) model. This is used to manage access to
   each <span class="productname">OpenStack</span> service. Roles are named and assigned per user or group for
   each project by the identity service. Role definition and policy enforcement
   are defined outside of the identity service independently by each <span class="productname">OpenStack</span>
   service.
  </p><p>
   The token generated by the identity service for each user authentication
   contains the role(s) assigned to that user for a particular project. When a
   user attempts to access a specific <span class="productname">OpenStack</span> service, the role is parsed by
   the service, compared to the service-specific policy file, and then granted
   the resource access defined for that role by the service policy file.
  </p><p>
   Each service has its own service policy file with the
   <code class="literal">/etc/[SERVICE_CODENAME]/policy.json</code> file name format
   where <code class="literal">[SERVICE_CODENAME]</code> represents a specific <span class="productname">OpenStack</span>
   service name. For example, the <span class="productname">OpenStack</span> Nova service would have a policy
   file called <code class="literal">/etc/nova/policy.json</code>.
  </p><p>
   Service policy files can be modified and deployed to control nodes from the
   Cloud Lifecycle Manager. Administrators are advised to validate policy changes before checking
   in the changes to the site branch of the local git repository before rolling
   the changes into production. Do not make changes to policy files without
   having a way to validate them.
  </p><p>
   The policy files are located at the following site branch directory on the
   Cloud Lifecycle Manager.
  </p><div class="verbatim-wrap"><pre class="screen">~/openstack/ardana/ansible/roles/</pre></div><p>
   For test and validation, policy files can be modified in a non-production
   environment from the <code class="literal">~/scratch/</code> directory. For a specific
   policy file, run a search for <code class="literal">policy.json</code>. To deploy
   policy changes for a service, run the service specific reconfiguration
   playbook (for example, <code class="literal">nova-reconfigure.yml</code>). For a
   complete list of reconfiguration playbooks, change directories to
   <code class="literal">~/scratch/ansible/next/ardana/ansible</code> and run this
   command:
  </p><div class="verbatim-wrap"><pre class="screen">ls –l | grep reconfigure</pre></div><div id="note-j2-comments" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    Comments added to any <code class="filename">*.j2</code> files (including templates)
    must follow proper comment syntax. Otherwise you may see errors when
    running the config-processor or any of the service playbooks.
   </p></div></div></div><div class="chapter " id="install-cli"><div class="titlepage"><div><div><h2 class="title"><span class="number">5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing the Command-Line Clients</span> <a title="Permalink" class="permalink" href="#install-cli">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-installing_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-installing_cli.xml</li><li><span class="ds-label">ID: </span>install-cli</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-userguide-installing-cli-xml-5"><span class="number">5.1 </span><span class="name">Installing the CLI tools using the input model</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-installing-cli-xml-6"><span class="number">5.2 </span><span class="name">Installing the CLI tools using Ansible</span></a></span></dt></dl></div></div><p>
  During the installation, by default, the suite of OpenStack command-line
  tools are installed on the Cloud Lifecycle Manager and the control plane in your
  environment. This includes the OpenStack Command-Line Interface as well as
  the clients for the individual services such as the NovaClient, CinderClient,
  and SwiftClient. You can learn more about these in the OpenStack
  documentation here:
  <a class="link" href="http://docs.openstack.org/cli-reference/" target="_blank">OpenStack
  Command-Line Interface Reference</a>.
 </p><p>
  If you wish to install the command-line interfaces on other nodes in your
  environment, there are two methods you can use to do so that we describe
  below.
 </p><div class="sect1" id="idg-all-userguide-installing-cli-xml-5"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing the CLI tools using the input model</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-installing-cli-xml-5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-installing_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-installing_cli.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-installing-cli-xml-5</li></ul></div></div></div></div><p>
   During the initial install phase of your cloud you can edit your input model
   to request that the command-line clients be installed on any of the node
   clusters in your environment. To do so, follow these steps:
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Log in to the Cloud Lifecycle Manager.
    </p></li><li class="step "><p>
     Edit your <code class="literal">control_plane.yml</code> file. Full path:
    </p><div class="verbatim-wrap"><pre class="screen">~/openstack/my_cloud/definition/data/control_plane.yml</pre></div></li><li class="step "><p>
     In this file you will see a list of <code class="literal">service-components</code>
     to be installed on each of your clusters. These clusters will be divided
     per role, with your controller node cluster likely coming at the
     beginning. Here you will see a list of each of the clients that can be
     installed. These include:
    </p><div class="verbatim-wrap"><pre class="screen">keystone-client
glance-client
cinder-client
nova-client
neutron-client
swift-client
heat-client
openstack-client
ceilometer-client
monasca-client
barbican-client
designate-client</pre></div></li><li class="step "><p>
     For each client you want to install, specify the name under the
     <code class="literal">service-components</code> section for the cluster you want to
     install it on.
    </p><p>
     So, for example, if you would like to install the Nova and Neutron clients on
     your Compute node cluster, you can do so by adding the
     <code class="literal">nova-client</code> and <code class="literal">neutron-client</code>
     services, like this:
    </p><div class="verbatim-wrap"><pre class="screen">      resources:
        - name: compute
          resource-prefix: comp
          server-role: COMPUTE-ROLE
          allocation-policy: any
          min-count: 0
          service-components:
            - ntp-client
            - nova-compute
            - nova-compute-kvm
            - neutron-l3-agent
            - neutron-metadata-agent
            - neutron-openvswitch-agent
            - neutron-lbaasv2-agent
            <span class="bold"><strong>- nova-client
            - neutron-client</strong></span></pre></div><div id="id-1.7.3.6.4.3.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      This example uses the <code class="literal">entry-scale-kvm</code> sample
      file. Your model may be different so use this as a guide but do not
      copy and paste the contents of this example into your input model.
     </p></div></li><li class="step "><p>
     Commit your configuration to the local git repo, as follows:
    </p><div class="verbatim-wrap"><pre class="screen">cd ~/openstack/ardana/ansible
git add -A
git commit -m "My config or other commit message"</pre></div></li><li class="step "><p>
     Continue with the rest of your installation.
    </p></li></ol></div></div></div><div class="sect1" id="idg-all-userguide-installing-cli-xml-6"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing the CLI tools using Ansible</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-installing-cli-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-installing_cli.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-installing_cli.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-installing-cli-xml-6</li></ul></div></div></div></div><p>
   At any point after your initial installation you can install the
   command-line clients on any of the nodes in your environment. To do so,
   follow these steps:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Log in to the Cloud Lifecycle Manager.
    </p></li><li class="listitem "><p>
     Obtain the hostname for the nodes you want to install the clients on by
     looking in your hosts file:
    </p><div class="verbatim-wrap"><pre class="screen">cat /etc/hosts</pre></div></li><li class="listitem "><p>
     Install the clients using this playbook, specifying your hostnames using
     commas:
    </p><div class="verbatim-wrap"><pre class="screen">cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts -e "install_package=&lt;client_name&gt;" client-deploy.yml -e "install_hosts=&lt;hostname&gt;"</pre></div><p>
     So, for example, if you would like to install the NovaClient on two of your
     Compute nodes with hostnames <code class="literal">ardana-cp1-comp0001-mgmt</code>
     and <code class="literal">ardana-cp1-comp0002-mgmt</code> you can use this syntax:
    </p><div class="verbatim-wrap"><pre class="screen">cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts -e "install_package=novaclient" client-deploy.yml -e "install_hosts=ardana-cp1-comp0001-mgmt,ardana-cp1-comp0002-mgmt"</pre></div></li><li class="listitem "><p>
     Once the playbook completes successfully, you should be able to SSH to
     those nodes and, using the proper credentials, authenticate and use the
     command-line interfaces you have installed.
    </p></li></ol></div></div></div><div class="chapter " id="CreateHARouter"><div class="titlepage"><div><div><h2 class="title"><span class="number">6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Highly Available Router</span> <a title="Permalink" class="permalink" href="#CreateHARouter">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-create_ha_router.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-create_ha_router.xml</li><li><span class="ds-label">ID: </span>CreateHARouter</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#CVRDVR"><span class="number">6.1 </span><span class="name">CVR and DVR High Available Routers</span></a></span></dt><dt><span class="section"><a href="#CreateRouter"><span class="number">6.2 </span><span class="name">Creating a High Availability Router</span></a></span></dt><dt><span class="section"><a href="#TestRouter"><span class="number">6.3 </span><span class="name">Test Router for High Availability</span></a></span></dt></dl></div></div><div class="sect1" id="CVRDVR"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">CVR and DVR High Available Routers</span> <a title="Permalink" class="permalink" href="#CVRDVR">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-create_ha_router.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-create_ha_router.xml</li><li><span class="ds-label">ID: </span>CVRDVR</li></ul></div></div></div></div><p>
   CVR (Centralized Virtual Routing) and DVR (Distributed Virtual Routing) are
   two types of technologies which can be used to provide routing processes in
   <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span>. You can create Highly Available (HA) versions of CVR and
   DVR routers by using the options in the table below when creating your
   router.
  </p><p>
   The neutron command for creating a router <code class="literal">neutron router-create
   router_name --distributed=True|False --ha=True|False</code> requires
   administrative permissions. See the example in the next section, Creating a
   High Availability Router.
  </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col align="center" class="c1" /><col align="center" class="c2" /><col align="center" class="c3" /><col align="left" class="c4" /></colgroup><thead><tr><th align="center">--distributed</th><th align="center">--ha</th><th align="center">Router Type</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">False</td><td align="center">False</td><td align="center">CVR</td><td align="left">Centralized Virtual Router</td></tr><tr><td align="center">False</td><td align="center">True</td><td align="center">CVRHA</td><td align="left">Centralized Virtual Router with L3 High Availablity</td></tr><tr><td align="center">True</td><td align="center">False</td><td align="center">DVR</td><td align="left">Distributed Virtual Router without SNAT High Availability</td></tr><tr><td align="center">True</td><td align="center">True</td><td align="center">DVRHA</td><td align="left">Distributed Virtual Router with SNAT High Availability</td></tr></tbody></table></div></div><div class="sect1" id="CreateRouter"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a High Availability Router</span> <a title="Permalink" class="permalink" href="#CreateRouter">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-create_ha_router.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-create_ha_router.xml</li><li><span class="ds-label">ID: </span>CreateRouter</li></ul></div></div></div></div><p>
   You can create a highly available router using the neutron command line
   interface.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     To create the HA router simply add <code class="literal">--ha=True</code> to the
     neutron router-create command. If you want to also make the router
     distributed, add <code class="literal">--distributed=True</code>. In this example, a
     DVR SNAT HA router is created with the name <code class="literal">routerHA</code>.
    </p><div class="verbatim-wrap"><pre class="screen">$ neutron router-create routerHA --distributed=True --ha=True</pre></div></li><li class="listitem "><p>
     Set the gateway for the external network and add interface
    </p><div class="verbatim-wrap"><pre class="screen">$ neutron router-gateway-set routerHA &lt;ext-net-id&gt;
$ neutron router-interface-add routerHA &lt;private_subnet_id&gt;</pre></div></li><li class="listitem "><p>
     Once the router is created, gateway set and interface attached, you now
     have a router with high availability.
    </p></li></ol></div></div><div class="sect1" id="TestRouter"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Test Router for High Availability</span> <a title="Permalink" class="permalink" href="#TestRouter">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-create_ha_router.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-create_ha_router.xml</li><li><span class="ds-label">ID: </span>TestRouter</li></ul></div></div></div></div><p>
   You can demonstrate that the router is HA by running a continuous ping from
   a VM instance that is running on the private network to an external server
   such as a public DNS. As the ping is running, list the l3 agents hosting the
   router and identify the agent that is responsible for hosting the active
   router. Induce the failover mechanism by creating a catastrophic event like
   shutting down node hosting the l3 agent. Once the node is shut down, you
   will see that the ping from the VM to the external network continues to run
   as the backup l3 agent takes over. To verify the agent hosting the primary
   router has changed, list the agents hosting the router. You will see a
   different agent is now hosting the active router.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Boot an instance on the private network
    </p><div class="verbatim-wrap"><pre class="screen">$ nova boot --image &lt;image_id&gt; --flavor &lt;flavor_id&gt; --nic net_id=&lt;private_net_id&gt; --key_name &lt;key&gt; VM1</pre></div></li><li class="listitem "><p>
     Log into the VM using the ssh keys
    </p><div class="verbatim-wrap"><pre class="screen">ssh -i &lt;key&gt; &lt;ipaddress of VM1&gt;</pre></div></li><li class="listitem "><p>
     Start a ping to X.X.X.X. While pinging, make sure there is no packet loss
     and leave the ping running.
    </p><div class="verbatim-wrap"><pre class="screen">$ ping X.X.X.X</pre></div></li><li class="listitem "><p>
     Check which agent is hosting the active router
    </p><div class="verbatim-wrap"><pre class="screen">$ neutron l3-agent-list-hosting-router &lt;router_id&gt;</pre></div></li><li class="listitem "><p>
     Shutdown the node hosting the agent.
    </p></li><li class="listitem "><p>
     Within 10 seconds, check again to see which L3 agent is hosting the active
     router
    </p><div class="verbatim-wrap"><pre class="screen">$ neutron l3-agent-list-hosting-router &lt;router_id&gt;</pre></div></li><li class="listitem "><p>
     You will see a different agent.
    </p></li></ol></div></div></div></div><div class="part" id="user-nonadmin"><div class="titlepage"><div><div><h1 class="title"><span class="number">Part II </span><span class="name">Project User Guide </span><a title="Permalink" class="permalink" href="#user-nonadmin">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-user_nonadmin.xml" title="Edit the source file for this section">Edit source</a></h1></div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#using-container-as-a-service-overview"><span class="number">7 </span><span class="name">Using Container as a Service (Magnum)</span></a></span></dt><dd class="toc-abstract"><p>The SUSE OpenStack Cloud Magnum Service provides container orchestration engines such as Docker Swarm, Kubernetes, and Apache Mesos available as first class resources. SUSE OpenStack Cloud Magnum uses Heat to orchestrate an OS image which contains Docker and Kubernetes and runs that image in either …</p></dd><dt><span class="chapter"><a href="#idg-all-userguide-create-network-xml-1"><span class="number">8 </span><span class="name">Creating a Private Network</span></a></span></dt><dd class="toc-abstract"><p>
   These steps assume the following have been completed:
  </p></dd><dt><span class="chapter"><a href="#create-keypair"><span class="number">9 </span><span class="name">Creating a Key Pair</span></a></span></dt><dd class="toc-abstract"><p>
  Key pairs are used to provide SSH access to Nova compute instances. These
  steps will show you how to create them with either the Horizon dashboard UI
  or the command-line tools.
 </p></dd><dt><span class="chapter"><a href="#user-image-upload"><span class="number">10 </span><span class="name">Creating and Uploading a Glance Image</span></a></span></dt><dd class="toc-abstract"><p>
  This guide will assist you in obtaining, creating, or modifying cloud images
  for your Image (Glance) repository and uploading them for use.
 </p></dd><dt><span class="chapter"><a href="#lbaas-dashboard"><span class="number">11 </span><span class="name">Creating a Load Balancer with the Dashboard</span></a></span></dt><dd class="toc-abstract"><p>
  In <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> you can create a Load Balancer with the Load Balancer
  Panel in the Dashboard.
 </p></dd><dt><span class="chapter"><a href="#HP2-0LBaaS"><span class="number">12 </span><span class="name">Using Load Balancing as a Service (LBaaS)</span></a></span></dt><dd class="toc-abstract"><p>Load Balancing as a Service (LBaaS) is an advanced networking service that allows load balancing of multi-node environments. It provides the ability to spread requests across multiple servers thereby reducing the load on any single server. The following examples depict usage of the various OpenStack…</p></dd><dt><span class="chapter"><a href="#LBaaSHeat"><span class="number">13 </span><span class="name">Using Load Balancing as a Service with Orchestration Service</span></a></span></dt><dd class="toc-abstract"><p>
   HPE Orchestration service, based on OpenStack Heat, enables the design and
   coordination of multiple composite cloud applications using templates.
  </p></dd><dt><span class="chapter"><a href="#HP2-0FWaaS"><span class="number">14 </span><span class="name">Using Firewall as a Service (FWaaS)</span></a></span></dt><dd class="toc-abstract"><p>The Firewall as a Service (FWaaS) provides the ability to assign network-level, port security for all traffic entering and existing a tenant network. More information on this service can be found via the public OpenStack documentation located at http://specs.openstack.org/openstack/neutron-specs/spe…</p></dd><dt><span class="chapter"><a href="#UsingVPNaaS"><span class="number">15 </span><span class="name">Using VPN as a Service (VPNaaS)</span></a></span></dt><dd class="toc-abstract"><p>
  <span class="bold"><strong><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> VPNaaS Configuration</strong></span>
 </p></dd></dl></div><div class="chapter " id="using-container-as-a-service-overview"><div class="titlepage"><div><div><h2 class="title"><span class="number">7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Container as a Service (Magnum)</span> <a title="Permalink" class="permalink" href="#using-container-as-a-service-overview">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-using_container_as_a_service.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-using_container_as_a_service.xml</li><li><span class="ds-label">ID: </span>using-container-as-a-service-overview</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#deploying-kubernetes-fedora-atomic"><span class="number">7.1 </span><span class="name">Deploying a Kubernetes Cluster on Fedora Atomic</span></a></span></dt><dt><span class="section"><a href="#deploying-kubernetes-coreos"><span class="number">7.2 </span><span class="name">Deploying a Kubernetes Cluster on CoreOS</span></a></span></dt><dt><span class="section"><a href="#deploying-docker-fedora-atomic"><span class="number">7.3 </span><span class="name">Deploying a Docker Swarm Cluster on Fedora Atomic</span></a></span></dt><dt><span class="section"><a href="#deploying-apache-mesos-ubuntu"><span class="number">7.4 </span><span class="name">Deploying an Apache Mesos Cluster on Ubuntu</span></a></span></dt><dt><span class="section"><a href="#create-magnum-cluster"><span class="number">7.5 </span><span class="name">Creating a Magnum Cluster with the Dashboard</span></a></span></dt></dl></div></div><p>
  The <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Magnum Service provides container orchestration engines such as
  Docker Swarm, Kubernetes, and Apache Mesos available as first class
  resources. <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Magnum uses Heat to orchestrate an OS image which
  contains Docker and Kubernetes and runs that image in either virtual machines
  or bare metal in a cluster configuration.
 </p><div class="sect1" id="deploying-kubernetes-fedora-atomic"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying a Kubernetes Cluster on Fedora Atomic</span> <a title="Permalink" class="permalink" href="#deploying-kubernetes-fedora-atomic">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_kubernetes_fedora_atomic.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_kubernetes_fedora_atomic.xml</li><li><span class="ds-label">ID: </span>deploying-kubernetes-fedora-atomic</li></ul></div></div></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-kubernetes-fedora-atomic-xml-6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-kubernetes-fedora-atomic-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_kubernetes_fedora_atomic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_kubernetes_fedora_atomic.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-kubernetes-fedora-atomic-xml-6</li></ul></div></div></div></div><p>
   These steps assume the following have been completed:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The Magnum service has been installed. For more information, see
     <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 14 “Magnum Overview”, Section 14.2 “Install the Magnum Service”</span>.
    </p></li><li class="listitem "><p>
     Deploying a Kubernetes Cluster on Fedora Atomic requires the Fedora Atomic
     image <span class="bold"><strong>fedora-atomic-26-20170723.0.x86_64.qcow2</strong></span> prepared
     specifically for the OpenStack release. You can download the
     <span class="bold"><strong>fedora-atomic-26-20170723.0.x86_64.qcow2</strong></span>
     image from
     <a class="link" href="https://fedorapeople.org/groups/magnum/" target="_blank">https://fedorapeople.org/groups/magnum/</a>
    </p></li></ul></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-kubernetes-fedora-atomic-xml-7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating the Cluster</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-kubernetes-fedora-atomic-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_kubernetes_fedora_atomic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_kubernetes_fedora_atomic.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-kubernetes-fedora-atomic-xml-7</li></ul></div></div></div></div><p>
   The following example is created using Kubernetes Container Orchestration
   Engine (COE) running on Fedora Atomic guest OS on <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> VMs.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     As <span class="bold"><strong>stack</strong></span> user, login to the lifecycle
     manager.
    </p></li><li class="listitem "><p>
     Source openstack admin credentials.
    </p><div class="verbatim-wrap"><pre class="screen">$ source service.osrc</pre></div></li><li class="listitem "><p>
     If you haven't already, download Fedora Atomic image, prepared for the
     Openstack Pike release.
    </p><div class="verbatim-wrap"><pre class="screen">$ wget https://download.fedoraproject.org/pub/alt/atomic/stable/Fedora-Atomic-26-20170723.0/CloudImages/x86_64/images/Fedora-Atomic-26-20170723.0.x86_64.qcow2</pre></div></li><li class="listitem "><p>
     Create a Glance image.
    </p><div class="verbatim-wrap"><pre class="screen">$ glance image-create --name fedora-atomic-26-20170723.0.x86_64 --visibility public \
  --disk-format qcow2 --os-distro fedora-atomic --container-format bare \
  --file Fedora-Atomic-26-20170723.0.x86_64.qcow2 --progress
[=============================&gt;] 100%
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 9d233b8e7fbb7ea93f20cc839beb09ab     |
| container_format | bare                                 |
| created_at       | 2017-04-10T21:13:48Z                 |
| disk_format      | qcow2                                |
| id               | 4277115a-f254-46c0-9fb0-fffc45d2fd38 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | fedora-atomic-26-20170723.0.x86_64   |
| os_distro        | fedora-atomic                        |
| owner            | 2f5b83ab49d54aaea4b39f5082301d09     |
| protected        | False                                |
| size             | 515112960                            |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2017-04-10T21:13:56Z                 |
| virtual_size     | None                                 |
| visibility       | public                               |
+------------------+--------------------------------------+</pre></div></li><li class="listitem "><p>
     Create a Nova keypair.
    </p><div class="verbatim-wrap"><pre class="screen">$ test -f ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa
$ nova keypair-add --pub-key ~/.ssh/id_rsa.pub testkey</pre></div></li><li class="listitem "><p>
     Create a Magnum cluster template.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-template-create --name my-template \
  --image-id 4277115a-f254-46c0-9fb0-fffc45d2fd38 \
  --keypair-id testkey \
  --external-network-id ext-net \
  --dns-nameserver 8.8.8.8 \
  --flavor-id m1.small \
  --docker-volume-size 5 \
  --network-driver flannel \
  --coe kubernetes \
  --http-proxy http://proxy.yourcompany.net:8080/ \
  --https-proxy http://proxy.yourcompany.net:8080/</pre></div><div id="id-1.7.4.2.3.3.3.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
        Use the <span class="emphasis"><em>image_id</em></span> from <code class="literal">glance
        image-create</code> command output in the previous step.
       </p></li><li class="listitem "><p>
        Use your organization's DNS server. If the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> public endpoint is
        configured with the hostname, this server should provide resolution for
        this hostname.
       </p></li><li class="listitem "><p>
        The proxy is only needed if public internet (for example,
        <code class="literal">https://discovery.etcd.io/</code> or
        <code class="literal">https://gcr.io/</code>) is not accessible without proxy.
       </p></li></ol></div></div></li><li class="listitem "><p>
     Create cluster. The command below will create a minimalistic cluster
     consisting of a single Kubernetes Master (kubemaster) and single
     Kubernetes Node (worker, kubeminion).
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-create --name my-cluster --cluster-template my-template --node-count 1 --master-count 1</pre></div></li><li class="listitem "><p>
     Immediately after issuing <code class="literal">cluster-create</code> command,
     cluster status should turn to
     <span class="bold"><strong>CREATE_IN_PROGRESS</strong></span> and stack_id assigned.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-show my-cluster
+---------------------+------------------------------------------------------------+
| Property            | Value                                                      |
+---------------------+------------------------------------------------------------+
| status              | CREATE_IN_PROGRESS                                         |
| cluster_template_id | 245c6bf8-c609-4ea5-855a-4e672996cbbc                       |
| uuid                | 0b78a205-8543-4589-8344-48b8cfc24709                       |
| stack_id            | 22385a42-9e15-49d9-a382-f28acef36810                       |
| status_reason       | -                                                          |
| created_at          | 2017-04-10T21:25:11+00:00                                  |
| name                | my-cluster                                                 |
| updated_at          | -                                                          |
| discovery_url       | https://discovery.etcd.io/193d122f869c497c2638021eae1ab0f7 |
| api_address         | -                                                          |
| coe_version         | -                                                          |
| master_addresses    | []                                                         |
| create_timeout      | 60                                                         |
| node_addresses      | []                                                         |
| master_count        | 1                                                          |
| container_version   | -                                                          |
| node_count          | 1                                                          |
+---------------------+------------------------------------------------------------+</pre></div></li><li class="listitem "><p>
     You can monitor cluster creation progress by listing the resources of the
     Heat stack. Use the <code class="literal">stack_id</code> value from the
     <code class="literal">magnum cluster-status</code> output above in the following
     command:
    </p><div class="verbatim-wrap"><pre class="screen">$ heat resource-list -n2 22385a42-9e15-49d9-a382-f28acef36810
WARNING (shell) "heat resource-list" is deprecated, please use "openstack stack resource list" instead
+-------------------------------+--------------------------------------+-----------------------------------+--------------------+----------------------+-------------------------+
| resource_name                 | physical_resource_id                 | resource_type                     | resource_status    | updated_time         | stack_name              |
+-------------------------------+--------------------------------------+-----------------------------------+--------------------+----------------------+-------------------------+
| api_address_floating_switch   | 06b2cc0d-77f9-4633-8d96-f51e2db1faf3 | Magnum::FloatingIPAddressSwitcher | CREATE_COMPLETE    | 2017-04-10T21:25:10Z | my-cluster-z4aquda2mgpv |
| api_address_lb_switch         | 965124ca-5f62-4545-bbae-8d9cda7aff2e | Magnum::ApiGatewaySwitcher        | CREATE_COMPLETE    | 2017-04-10T21:25:10Z | my-cluster-z4aquda2mgpv |
. . .</pre></div></li><li class="listitem "><p>
     The cluster is complete when all resources show
     <span class="bold"><strong>CREATE_COMPLETE</strong></span>.
    </p></li><li class="listitem "><p>
     Install kubectl onto your Cloud Lifecycle Manager.
    </p><div class="verbatim-wrap"><pre class="screen">$ export https_proxy=http://proxy.yourcompany.net:8080
$ wget https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
$ chmod +x ./kubectl
$ sudo mv ./kubectl /usr/local/bin/kubectl</pre></div></li><li class="listitem "><p>
     Generate the cluster configuration using
     <code class="command">magnum cluster-config</code>. If the CLI option 
     <code class="option">--tls-disabled</code> was not
     specified during cluster template creation, authentication in the cluster
     will be turned on. In this case, <code class="command">magnum cluster-config</code>
     command will generate client authentication certificate
     (<code class="filename">cert.pem</code>) and key (<code class="filename">key.pem</code>).
     Copy and paste <code class="command">magnum cluster-config</code> output
     to your command line input to finalize configuration (that is, export
     KUBECONFIG environment variable).
    </p><div class="verbatim-wrap"><pre class="screen">$ mkdir my_cluster
$ cd my_cluster
/my_cluster $ ls
/my_cluster $ magnum cluster-config my-cluster
export KUBECONFIG=./config
/my_cluster $ ls
ca.pem cert.pem config key.pem
/my_cluster $ export KUBECONFIG=./config
/my_cluster $ kubectl version
Client Version: version.Info{Major:"1", Minor:"2", GitVersion:"v1.2.0", GitCommit:"5cb86ee022267586db386f62781338b0483733b3", GitTreeState:"clean"}
Server Version: version.Info{Major:"1", Minor:"2", GitVersion:"v1.2.0", GitCommit:"cffae0523cfa80ddf917aba69f08508b91f603d5", GitTreeState:"clean"}</pre></div></li><li class="listitem "><p>
     Create a simple Nginx replication controller, exposed as a service of type
     NodePort.
    </p><div class="verbatim-wrap"><pre class="screen">$ cat &gt;nginx.yml &lt;&lt;-EOF
apiVersion: v1
kind: ReplicationController
metadata:
  name: nginx-controller
spec:
  replicas: 1
  selector:
    app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  ports:
  - port: 80
    nodePort: 30080
  selector:
    app: nginx
EOF

$ kubectl create -f nginx.yml</pre></div></li><li class="listitem "><p>
     Check pod status until it turns from
     <span class="bold"><strong>Pending</strong></span> to
     <span class="bold"><strong>Running</strong></span>.
    </p><div class="verbatim-wrap"><pre class="screen">$ kubectl get pods
NAME                      READY    STATUS     RESTARTS    AGE
nginx-controller-5cmev    1/1      Running    0           2m</pre></div></li><li class="listitem "><p>
     Ensure that the Nginx welcome page is displayed at port 30080 using the
     kubemaster floating IP.
    </p><div class="verbatim-wrap"><pre class="screen">$ http_proxy= curl http://172.31.0.6:30080
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;</pre></div></li><li class="listitem "><p>
     If LBaaS v2 is enabled in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> environment, and your cluster was
     created with more than one kubemaster, a new load balancer can be created
     to perform request rotation between several masters. For more
     information about LBaaS v2 support, see <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 31 “Configuring Load Balancer as a Service”</span>.
    </p></li></ol></div></div></div><div class="sect1" id="deploying-kubernetes-coreos"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying a Kubernetes Cluster on CoreOS</span> <a title="Permalink" class="permalink" href="#deploying-kubernetes-coreos">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_kubernetes_coreos.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_kubernetes_coreos.xml</li><li><span class="ds-label">ID: </span>deploying-kubernetes-coreos</li></ul></div></div></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-kubernetes-coreos-xml-6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-kubernetes-coreos-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_kubernetes_coreos.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_kubernetes_coreos.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-kubernetes-coreos-xml-6</li></ul></div></div></div></div><p>
   These steps assume the following have been completed:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The Magnum service has been installed. For more information, see
     <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 14 “Magnum Overview”, Section 14.2 “Install the Magnum Service”</span>.
    </p></li><li class="listitem "><p>
     Creating the Magnum cluster requires the CoreOS image for OpenStack. You
     can download compressed image file
     <span class="bold"><strong>coreos_production_openstack_image.img.bz2</strong></span>
     from
     <a class="link" href="http://stable.release.core-os.net/amd64-usr/current/" target="_blank">http://stable.release.core-os.net/amd64-usr/current/</a>.
    </p></li></ul></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-kubernetes-coreos-xml-7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating the Cluster</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-kubernetes-coreos-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_kubernetes_coreos.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_kubernetes_coreos.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-kubernetes-coreos-xml-7</li></ul></div></div></div></div><p>
   The following example is created using Kubernetes Container Orchestration
   Engine (COE) running on CoreOS guest OS on <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> VMs.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Login to the Cloud Lifecycle Manager.
    </p></li><li class="listitem "><p>
     Source openstack admin credentials.
    </p><div class="verbatim-wrap"><pre class="screen">$ source service.osrc</pre></div></li><li class="listitem "><p>
     If you haven't already, download CoreOS image that is compatible for the OpenStack
     release.
    </p><div id="id-1.7.4.2.4.3.3.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      The https_proxy is only needed if your environment requires a proxy.
     </p></div><div class="verbatim-wrap"><pre class="screen">$ export https_proxy=http://proxy.yourcompany.net:8080
$ wget https://stable.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2
$ bunzip2 coreos_production_openstack_image.img.bz2</pre></div></li><li class="listitem "><p>
     Create a Glance image.
    </p><div class="verbatim-wrap"><pre class="screen">$ glance image-create --name coreos-magnum --visibility public \
  --disk-format raw --os-distro coreos --container-format bare \
  --file coreos_production_openstack_image.img --progress
[=============================&gt;] 100%
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 4110469bb15af72ec0cf78c2da4268fa     |
| container_format | bare                                 |
| created_at       | 2017-04-25T18:10:52Z                 |
| disk_format      | raw                                  |
| id               | c25fc719-2171-437f-9542-fcb8a534fbd1 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | coreos-magnum                        |
| os_distro        | coreos                               |
| owner            | 2f5b83ab49d54aaea4b39f5082301d09     |
| protected        | False                                |
| size             | 806551552                            |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2017-04-25T18:11:07Z                 |
| virtual_size     | None                                 |
| visibility       | public                               |
+------------------+--------------------------------------+</pre></div></li><li class="listitem "><p>
     Create a Nova keypair.
    </p><div class="verbatim-wrap"><pre class="screen">$ test -f ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa
$ nova keypair-add --pub-key ~/.ssh/id_rsa.pub testkey</pre></div></li><li class="listitem "><p>
     Create a Magnum cluster template.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-template-create --name my-coreos-template \
  --image-id c25fc719-2171-437f-9542-fcb8a534fbd1 \
  --keypair-id testkey \
  --external-network-id ext-net \
  --dns-nameserver 8.8.8.8 \
  --flavor-id m1.small \
  --docker-volume-size 5 \
  --network-driver flannel \
  --coe kubernetes \
  --http-proxy http://proxy.yourcompany.net:8080/ \
  --https-proxy http://proxy.yourcompany.net:8080/</pre></div><div id="id-1.7.4.2.4.3.3.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
         Use the <span class="emphasis"><em>image_id</em></span> from
         <code class="literal">glance image-create</code> command output in the
         previous step.
        </p></li><li class="listitem "><p>
         Use your organization's DNS server. If the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> public endpoint
         is configured with the hostname, this server should provide
         resolution for this hostname.
        </p></li><li class="listitem "><p>
         The proxy is only needed if public internet (for example,
         <code class="literal">https://discovery.etcd.io/</code> or
         <code class="literal">https://gcr.io/</code>) is not accessible without proxy.
        </p></li></ol></div></div></li><li class="listitem "><p>
     Create cluster. The command below will create a minimalistic cluster
     consisting of a single Kubernetes Master (kubemaster) and single
     Kubernetes Node (worker, kubeminion).
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-create --name my-coreos-cluster --cluster-template my-coreos-template --node-count 1 --master-count 1</pre></div></li><li class="listitem "><p>
     Almost immediately after issuing <code class="literal">cluster-create</code>
     command, cluster status should turn to
     <span class="bold"><strong>CREATE_IN_PROGRESS</strong></span> and stack_id assigned.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-show my-coreos-cluster
+---------------------+------------------------------------------------------------+
| Property            | Value                                                      |
+---------------------+------------------------------------------------------------+
| status              | CREATE_IN_PROGRESS                                         |
| cluster_template_id | c48fa7c0-8dd9-4da4-b599-9e62dc942ca5                       |
| uuid                | 6b85e013-f7c3-4fd3-81ea-4ea34201fd45                       |
| stack_id            | c93f873a-d563-4721-9bd9-3bae2340750a                       |
| status_reason       | -                                                          |
| created_at          | 2017-04-25T22:38:43+00:00                                  |
| name                | my-coreos-cluster                                          |
| updated_at          | -                                                          |
| discovery_url       | https://discovery.etcd.io/6e4c0e5ff5e5b9872173d06880886a0c |
| api_address         | -                                                          |
| coe_version         | -                                                          |
| master_addresses    | []                                                         |
| create_timeout      | 60                                                         |
| node_addresses      | []                                                         |
| master_count        | 1                                                          |
| container_version   | -                                                          |
| node_count          | 1                                                          |
+---------------------+------------------------------------------------------------+</pre></div></li><li class="listitem "><p>
     You can monitor cluster creation progress by listing the resources of the
     Heat stack. Use the <code class="literal">stack_id</code> value from the
     <code class="literal">magnum cluster-status</code> output above in the following
     command:
    </p><div class="verbatim-wrap"><pre class="screen">$ heat resource-list -n2 c93f873a-d563-4721-9bd9-3bae2340750a
WARNING (shell) "heat resource-list" is deprecated, please use "openstack stack resource list" instead
+--------------------------------+-------------------------------------------------------------------------------------+-------------------------------------------------------------------
----------------------------------------------------------------+--------------------+----------------------+-------------------------------------------------------------------------+
| resource_name                  | physical_resource_id                                                                | resource_type
                                                                | resource_status    | updated_time         | stack_name                                                              |
+--------------------------------+-------------------------------------------------------------------------------------+-------------------------------------------------------------------
----------------------------------------------------------------+--------------------+----------------------+-------------------------------------------------------------------------+
| api_address_switch             |                                                                                     | Magnum::ApiGatewaySwitcher
                                                                | INIT_COMPLETE      | 2017-04-25T22:38:42Z | my-coreos-cluster-mscybll54eoj                                          |
| api_listener                   | 1dc1c599-b552-4f03-94e9-936fbb889741                                                | Magnum::Optional::Neutron::LBaaS::Listener
                                                                | CREATE_COMPLETE    | 2017-04-25T22:38:42Z | my-coreos-cluster-mscybll54eoj                                          |
| api_loadbalancer               | bf1d8c64-a75f-4eec-8f2f-373d49aee581                                                | Magnum::Optional::Neutron::LBaaS::LoadBalancer
                                                                | CREATE_COMPLETE    | 2017-04-25T22:38:42Z | my-coreos-cluster-mscybll54eoj                                          |
. . .</pre></div></li><li class="listitem "><p>
     The cluster is complete when all resources show
     <span class="bold"><strong>CREATE_COMPLETE</strong></span>.
    </p></li><li class="listitem "><p>
     Install kubectl onto your Cloud Lifecycle Manager.
    </p><div class="verbatim-wrap"><pre class="screen">$ export https_proxy=http://proxy.yourcompany.net:8080
$ wget https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
$ chmod +x ./kubectl
$ sudo mv ./kubectl /usr/local/bin/kubectl</pre></div></li><li class="listitem "><p>
     Generate the cluster configuration using
     <code class="command">magnum cluster-config</code>. If the CLI option 
     <code class="option">--tls-disabled</code> was not
     specified during cluster template creation, authentication in the cluster
     will be turned on. In this case, <code class="command">magnum cluster-config</code>
     command will generate client authentication certificate
     (<code class="filename">cert.pem</code>) and key (<code class="filename">key.pem</code>).
     Copy and paste <code class="command">magnum cluster-config</code> output
     to your command line input to finalize configuration (that is, export
     KUBECONFIG environment variable).
    </p><div class="verbatim-wrap"><pre class="screen">$ mkdir my_cluster
$ cd my_cluster
/my_cluster $ ls
/my_cluster $ magnum cluster-config my-cluster
export KUBECONFIG=./config
/my_cluster $ ls
ca.pem cert.pem config key.pem
/my_cluster $ export KUBECONFIG=./config
/my_cluster $ kubectl version
Client Version: version.Info{Major:"1", Minor:"2", GitVersion:"v1.2.0", GitCommit:"5cb86ee022267586db386f62781338b0483733b3", GitTreeState:"clean"}
Server Version: version.Info{Major:"1", Minor:"2", GitVersion:"v1.2.0", GitCommit:"cffae0523cfa80ddf917aba69f08508b91f603d5", GitTreeState:"clean"}</pre></div></li><li class="listitem "><p>
     Create a simple Nginx replication controller, exposed as a service of type
     NodePort.
    </p><div class="verbatim-wrap"><pre class="screen">$ cat &gt;nginx.yml &lt;&lt;-EOF
apiVersion: v1
kind: ReplicationController
metadata:
  name: nginx-controller
spec:
  replicas: 1
  selector:
    app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: NodePort
  ports:
  - port: 80
    nodePort: 30080
  selector:
    app: nginx
EOF

$ kubectl create -f nginx.yml</pre></div></li><li class="listitem "><p>
     Check pod status until it turns from
     <span class="bold"><strong>Pending</strong></span> to
     <span class="bold"><strong>Running</strong></span>.
    </p><div class="verbatim-wrap"><pre class="screen">$ kubectl get pods
NAME                      READY    STATUS     RESTARTS    AGE
nginx-controller-5cmev    1/1      Running    0           2m</pre></div></li><li class="listitem "><p>
     Ensure that the Nginx welcome page is displayed at port 30080 using the
     kubemaster floating IP.
    </p><div class="verbatim-wrap"><pre class="screen">$ http_proxy= curl http://172.31.0.6:30080
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;</pre></div></li><li class="listitem "><p>
     If LBaaS v2 is enabled in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> environment, and your cluster was
     created with more than one kubemaster, a new load balancer can be created
     to perform request rotation between several masters. For more
     information about LBaaS v2 support, see <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 31 “Configuring Load Balancer as a Service”</span>.
    </p></li></ol></div></div></div><div class="sect1" id="deploying-docker-fedora-atomic"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying a Docker Swarm Cluster on Fedora Atomic</span> <a title="Permalink" class="permalink" href="#deploying-docker-fedora-atomic">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_docker_fedora_atomic.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_docker_fedora_atomic.xml</li><li><span class="ds-label">ID: </span>deploying-docker-fedora-atomic</li></ul></div></div></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-docker-fedora-atomic-xml-6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-docker-fedora-atomic-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_docker_fedora_atomic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_docker_fedora_atomic.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-docker-fedora-atomic-xml-6</li></ul></div></div></div></div><p>
   These steps assume the following have been completed:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The Magnum service has been installed. For more information, see
     <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 14 “Magnum Overview”, Section 14.2 “Install the Magnum Service”</span>.
    </p></li><li class="listitem "><p>
     Deploying a Docker Swarm Cluster on Fedora Atomic requires the Fedora
     Atomic image
     <span class="bold"><strong>fedora-atomic-26-20170723.0.x86_64.qcow2</strong></span>
     prepared specifically for the OpenStack Pike release. You can download
     the <span class="bold"><strong>fedora-atomic-26-20170723.0.x86_64.qcow2</strong></span>
     image from
     <a class="link" href="https://download.fedoraproject.org/pub/alt/atomic/stable/Fedora-Atomic-26-20170723.0/CloudImages/x86_64/" target="_blank">https://download.fedoraproject.org/pub/alt/atomic/stable/Fedora-Atomic-26-20170723.0/CloudImages/x86_64/</a>
    </p></li></ul></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-docker-fedora-atomic-xml-7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating the Cluster</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-docker-fedora-atomic-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_docker_fedora_atomic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_docker_fedora_atomic.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-docker-fedora-atomic-xml-7</li></ul></div></div></div></div><p>
   The following example is created using Kubernetes Container Orchestration
   Engine (COE) running on Fedora Atomic guest OS on <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> VMs.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     As <span class="bold"><strong>stack</strong></span> user, login to the lifecycle
     manager.
    </p></li><li class="listitem "><p>
     Source openstack admin credentials.
    </p><div class="verbatim-wrap"><pre class="screen">$ source service.osrc</pre></div></li><li class="listitem "><p>
     If you haven't already, download Fedora Atomic image, prepared for
     Openstack Pike release.
    </p><div class="verbatim-wrap"><pre class="screen">$ wget https://download.fedoraproject.org/pub/alt/atomic/stable/Fedora-Atomic-26-20170723.0/CloudImages/x86_64/images/Fedora-Atomic-26-20170723.0.x86_64.qcow2</pre></div></li><li class="listitem "><p>
     Create a Glance image.
    </p><div class="verbatim-wrap"><pre class="screen">$ glance image-create --name fedora-atomic-26-20170723.0.x86_64 --visibility public \
  --disk-format qcow2 --os-distro fedora-atomic --container-format bare \
  --file Fedora-Atomic-26-20170723.0.x86_64.qcow2 --progress
[=============================&gt;] 100%
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 9d233b8e7fbb7ea93f20cc839beb09ab     |
| container_format | bare                                 |
| created_at       | 2017-04-10T21:13:48Z                 |
| disk_format      | qcow2                                |
| id               | 4277115a-f254-46c0-9fb0-fffc45d2fd38 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | fedora-atomic-26-20170723.0.x86_64   |
| os_distro        | fedora-atomic                        |
| owner            | 2f5b83ab49d54aaea4b39f5082301d09     |
| protected        | False                                |
| size             | 515112960                            |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2017-04-10T21:13:56Z                 |
| virtual_size     | None                                 |
| visibility       | public                               |
+------------------+--------------------------------------+</pre></div></li><li class="listitem "><p>
     Create a Nova keypair.
    </p><div class="verbatim-wrap"><pre class="screen">$ test -f ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa
$ nova keypair-add --pub-key ~/.ssh/id_rsa.pub testkey</pre></div></li><li class="listitem "><p>
     Create a Magnum cluster template.
    </p><div id="id-1.7.4.2.5.3.3.6.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      The <code class="literal">--tls-disabled</code> flag is not specified in the
      included template. Authentication via client certificate will be turned
      on in clusters created from this template.
     </p></div><div class="verbatim-wrap"><pre class="screen">$  magnum cluster-template-create --name my-swarm-template \
  --image-id 4277115a-f254-46c0-9fb0-fffc45d2fd38 \
  --keypair-id testkey \
  --external-network-id ext-net \
  --dns-nameserver 8.8.8.8 \
  --flavor-id m1.small \
  --docker-volume-size 5 \
  --network-driver docker \
  --coe swarm \
  --http-proxy http://proxy.yourcompany.net:8080/ \
  --https-proxy http://proxy.yourcompany.net:8080/</pre></div><div id="id-1.7.4.2.5.3.3.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
        Use the <code class="literal">image_id</code> from
        <code class="literal">glance image-create</code> command output in the previous
        step.
       </p></li><li class="listitem "><p>
        Use your organization's DNS server. If the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> public endpoint
        is configured with the hostname, this server should provide
        resolution for this hostname.
       </p></li><li class="listitem "><p>
        The proxy is only needed if public internet (for example,
        <code class="literal">https://discovery.etcd.io/</code> or
        <code class="literal">https://gcr.io/</code>) is not accessible without proxy.
       </p></li></ol></div></div></li><li class="listitem "><p>
     Create cluster. The command below will create a minimalistic cluster
     consisting of a single Kubernetes Master (kubemaster) and single
     Kubernetes Node (worker, kubeminion).
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-create --name my-swarm-cluster --cluster-template my-swarm-template \
  --node-count 1 --master-count 1</pre></div></li><li class="listitem "><p>
     Immediately after issuing <code class="literal">cluster-create</code> command,
     cluster status should turn to
     <span class="bold"><strong>CREATE_IN_PROGRESS</strong></span>
     and <code class="literal">stack_id</code> assigned.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-show my-swarm-cluster
+---------------------+------------------------------------------------------------+
| Property            | Value                                                      |
+---------------------+------------------------------------------------------------+
| status              | CREATE_IN_PROGRESS                                         |
| cluster_template_id | 17df266e-f8e1-4056-bdee-71cf3b1483e3                       |
| uuid                | c3e13e5b-85c7-44f4-839f-43878fe5f1f8                       |
| stack_id            | 3265d843-3677-4fed-bbb7-e0f56c27905a                       |
| status_reason       | -                                                          |
| created_at          | 2017-04-21T17:13:08+00:00                                  |
| name                | my-swarm-cluster                                           |
| updated_at          | -                                                          |
| discovery_url       | https://discovery.etcd.io/54e83ea168313b0c2109d0f66cd0aa6f |
| api_address         | -                                                          |
| coe_version         | -                                                          |
| master_addresses    | []                                                         |
| create_timeout      | 60                                                         |
| node_addresses      | []                                                         |
| master_count        | 1                                                          |
| container_version   | -                                                          |
| node_count          | 1                                                          |
+---------------------+------------------------------------------------------------+</pre></div></li><li class="listitem "><p>
     You can monitor cluster creation progress by listing the resources of the
     Heat stack. Use the <code class="literal">stack_id</code> value from the
     <code class="literal">magnum cluster-status</code> output above in the following
     command:
    </p><div class="verbatim-wrap"><pre class="screen">$ heat resource-list -n2 3265d843-3677-4fed-bbb7-e0f56c27905a
WARNING (shell) "heat resource-list" is deprecated, please use "openstack stack resource list" instead
+--------------------+--------------------------------------+--------------------------------------------+-----------------+----------------------+-------------------------------+
| resource_name      | physical_resource_id                 | resource_type                              | resource_status | updated_time         | stack_name                    |
|--------------------+--------------------------------------+--------------------------------------------+-----------------+----------------------+-------------------------------+
| api_address_switch | 430f82f2-03e3-4085-8c07-b4a6b6d7e261 | Magnum::ApiGatewaySwitcher                 | CREATE_COMPLETE | 2017-04-21T17:13:07Z | my-swarm-cluster-j7gbjcxaremy |
| api_listener       | a306fd54-e569-4673-8fd3-7ae5ebdf53c3 | Magnum::Optional::Neutron::LBaaS::Listener | CREATE_COMPLETE | 2017-04-21T17:13:07Z | my-swarm-cluster-j7gbjcxaremy |
. . .</pre></div></li><li class="listitem "><p>
     The cluster is complete when all resources show
     <span class="bold"><strong>CREATE_COMPLETE</strong></span>. You can also obtain the
     floating IP address once the cluster has been created.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-show my-swarm-cluster
+---------------------+------------------------------------------------------------+
| Property            | Value                                                      |
+---------------------+------------------------------------------------------------+
| status              | CREATE_COMPLETE                                            |
| cluster_template_id | 17df266e-f8e1-4056-bdee-71cf3b1483e3                       |
| uuid                | c3e13e5b-85c7-44f4-839f-43878fe5f1f8                       |
| stack_id            | 3265d843-3677-4fed-bbb7-e0f56c27905a                       |
| status_reason       | Stack CREATE completed successfully                        |
| created_at          | 2017-04-21T17:13:08+00:00                                  |
| name                | my-swarm-cluster                                           |
| updated_at          | 2017-04-21T17:18:26+00:00                                  |
| discovery_url       | https://discovery.etcd.io/54e83ea168313b0c2109d0f66cd0aa6f |
| api_address         | tcp://172.31.0.7:2376                                      |
| coe_version         | 1.0.0                                                      |
| master_addresses    | ['172.31.0.7']                                             |
| create_timeout      | 60                                                         |
| node_addresses      | ['172.31.0.5']                                             |
| master_count        | 1                                                          |
| container_version   | 1.9.1                                                      |
| node_count          | 1                                                          |
+---------------------+------------------------------------------------------------+</pre></div></li><li class="listitem "><p>
     Generate and sign client certificate using <code class="literal">magnum
     cluster-config</code> command.
    </p><div class="verbatim-wrap"><pre class="screen">$ mkdir my_swarm_cluster
$ cd my_swarm_cluster/
~/my_swarm_cluster $ magnum cluster-config my-swarm-cluster
{'tls': True, 'cfg_dir': '.', 'docker_host': u'tcp://172.31.0.7:2376'}
~/my_swarm_cluster $ ls
ca.pem  cert.pem  key.pem</pre></div></li><li class="listitem "><p>
     Copy generated certificates and key to ~/.docker folder on first cluster
     master node.
    </p><div class="verbatim-wrap"><pre class="screen">$ scp -r ~/my_swarm_cluster fedora@172.31.0.7:.docker
ca.pem                                             100% 1066     1.0KB/s   00:00
key.pem                                            100% 1679     1.6KB/s   00:00
cert.pem                                           100% 1005     1.0KB/s   00:00</pre></div></li><li class="listitem "><p>
     Login to first master node and set up cluster access environment
     variables.
    </p><div class="verbatim-wrap"><pre class="screen">$ ssh fedora@172.31.0.7
[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ export DOCKER_TLS_VERIFY=1
[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ export DOCKER_HOST=tcp://172.31.0.7:2376</pre></div></li><li class="listitem "><p>
     Verfy that the swarm container is up and running.
    </p><div class="verbatim-wrap"><pre class="screen">[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ docker ps -a
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
fcbfab53148c        swarm:1.0.0         "/swarm join --addr 1"   24 minutes ago      Up 24 minutes       2375/tcp            my-xggjts5zbgr-0-d4qhxhdujh4q-swarm-node-vieanhwdonon.novalocal/swarm-agent</pre></div></li><li class="listitem "><p>
     Deploy a sample docker application (nginx) and verify that Nginx is
     serving requests at port 8080 on worker node(s), on both floating and
     private IPs:
    </p><div class="verbatim-wrap"><pre class="screen">[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ docker run -itd -p 8080:80 nginx
192030325fef0450b7b917af38da986edd48ac5a6d9ecb1e077b017883d18802

[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ docker port 192030325fef
80/tcp -&gt; 10.0.0.11:8080

[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ curl http://10.0.0.11:8080
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
...
[fedora@my-6zxz5ukdu-0-bvqbsn2z2uwo-swarm-master-n6wfplu7jcwo ~]$ curl http://172.31.0.5:8080
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
...</pre></div></li><li class="listitem "><p>
     If LBaaS v2 is enabled in your <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> environment, a new load balancer
     can be created to perform request rotation between several masters. For
     more information about LBaaS v2 support, see
     <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 31 “Configuring Load Balancer as a Service”</span>.
    </p></li></ol></div></div></div><div class="sect1" id="deploying-apache-mesos-ubuntu"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying an Apache Mesos Cluster on Ubuntu</span> <a title="Permalink" class="permalink" href="#deploying-apache-mesos-ubuntu">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_apache_mesos_ubuntu.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_apache_mesos_ubuntu.xml</li><li><span class="ds-label">ID: </span>deploying-apache-mesos-ubuntu</li></ul></div></div></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-apache-mesos-ubuntu-xml-6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-apache-mesos-ubuntu-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_apache_mesos_ubuntu.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_apache_mesos_ubuntu.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-apache-mesos-ubuntu-xml-6</li></ul></div></div></div></div><p>
   These steps assume the following have been completed:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     The Magnum service has been installed. For more information, see
     <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 14 “Magnum Overview”, Section 14.2 “Install the Magnum Service”</span>.
    </p></li><li class="listitem "><p>
     Deploying an Apache Mesos Cluster requires the Fedora Atomic image
     that is compatible for the OpenStack release. You can download
     the <span class="bold"><strong>ubuntu-mesos-latest.qcow2</strong></span>
     image from
     <a class="link" href="https://fedorapeople.org/groups/magnum/" target="_blank">https://fedorapeople.org/groups/magnum/</a>
    </p></li></ul></div></div><div class="sect2" id="idg-all-userguide-container-service-deploying-apache-mesos-ubuntu-xml-7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating the Cluster</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-deploying-apache-mesos-ubuntu-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-deploying_apache_mesos_ubuntu.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-deploying_apache_mesos_ubuntu.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-deploying-apache-mesos-ubuntu-xml-7</li></ul></div></div></div></div><p>
   The following example is created using Kubernetes Container Orchestration
   Engine (COE) running on Fedora Atomic guest OS on <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> VMs.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     As <span class="bold"><strong>stack</strong></span> user, login to the lifecycle
     manager.
    </p></li><li class="step "><p>
     Source openstack admin credentials.
    </p><div class="verbatim-wrap"><pre class="screen">$ source service.osrc</pre></div></li><li class="step "><p>
     If you haven't already, download Fedora Atomic image that is compatible for the
     OpenStack release.
    </p><div id="id-1.7.4.2.6.3.3.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      The <code class="literal">https_proxy</code> is only needed if your environment
      requires a proxy.
     </p></div><div class="verbatim-wrap"><pre class="screen">$ https_proxy=http://proxy.yourcompany.net:8080 wget https://fedorapeople.org/groups/magnum/ubuntu-mesos-latest.qcow2</pre></div></li><li class="step "><p>
     Create a Glance image.
    </p><div class="verbatim-wrap"><pre class="screen">$ glance image-create --name ubuntu-mesos-latest --visibility public --disk-format qcow2 --os-distro ubuntu --container-format bare --file ubuntu-mesos-latest.qcow2 --progress
[=============================&gt;] 100%
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 97cc1fdb9ca80bf80dbd6842aab7dab5     |
| container_format | bare                                 |
| created_at       | 2017-04-21T19:40:20Z                 |
| disk_format      | qcow2                                |
| id               | d6a4e6f9-9e34-4816-99fe-227e0131244f |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | ubuntu-mesos-latest                  |
| os_distro        | ubuntu                               |
| owner            | 2f5b83ab49d54aaea4b39f5082301d09     |
| protected        | False                                |
| size             | 753616384                            |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2017-04-21T19:40:32Z                 |
| virtual_size     | None                                 |
| visibility       | public                               |
+------------------+--------------------------------------+</pre></div></li><li class="step "><p>
     Create a Nova keypair.
    </p><div class="verbatim-wrap"><pre class="screen">$ test -f ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa
$ nova keypair-add --pub-key ~/.ssh/id_rsa.pub testkey</pre></div></li><li class="step "><p>
     Create a Magnum cluster template.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-template-create --name my-mesos-template \
  --image-id d6a4e6f9-9e34-4816-99fe-227e0131244f \
  --keypair-id testkey \
  --external-network-id ext-net \
  --dns-nameserver 8.8.8.8 \
  --flavor-id m1.small \
  --docker-volume-size 5 \
  --network-driver docker \
  --coe mesos \
  --http-proxy http://proxy.yourcompany.net:8080/ \
  --https-proxy http://proxy.yourcompany.net:8080/</pre></div><div id="id-1.7.4.2.6.3.3.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
        Use the <span class="emphasis"><em>image_id</em></span> from <code class="literal">glance
        image-create</code> command output in the previous step.
       </p></li><li class="listitem "><p>
        Use your organization's DNS server. If the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> public endpoint is
        configured with the hostname, this server should provide resolution for
        this hostname.
       </p></li><li class="listitem "><p>
        The proxy is only needed if public internet (for example,
        <code class="literal">https://discovery.etcd.io/</code> or
        <code class="literal">https://gcr.io/</code>) is not accessible
        without proxy.
       </p></li></ol></div></div></li><li class="step "><p>
     Create cluster. The command below will create a minimalistic cluster
     consisting of a single Kubernetes Master (kubemaster) and single
     Kubernetes Node (worker, kubeminion).
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-create --name my-mesos-cluster --cluster-template my-mesos-template --node-count 1 --master-count 1</pre></div></li><li class="step "><p>
     Immediately after issuing <code class="literal">cluster-create</code> command,
     cluster status should turn to
     <span class="bold"><strong>CREATE_IN_PROGRESS</strong></span> and stack_id assigned.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-show my-mesos-cluster
+---------------------+--------------------------------------+
| Property            | Value                                |
+---------------------+--------------------------------------+
| status              | CREATE_IN_PROGRESS                   |
| cluster_template_id | be354919-fa6c-4db8-9fd1-69792040f095 |
| uuid                | b1493402-8571-4683-b81e-ddc129ff8937 |
| stack_id            | 50aa20a6-bf29-4663-9181-cf7ba3070a25 |
| status_reason       | -                                    |
| created_at          | 2017-04-21T19:50:34+00:00            |
| name                | my-mesos-cluster                     |
| updated_at          | -                                    |
| discovery_url       | -                                    |
| api_address         | -                                    |
| coe_version         | -                                    |
| master_addresses    | []                                   |
| create_timeout      | 60                                   |
| node_addresses      | []                                   |
| master_count        | 1                                    |
| container_version   | -                                    |
| node_count          | 1                                    |
+---------------------+--------------------------------------+</pre></div></li><li class="step "><p>
     You can monitor cluster creation progress by listing the resources of the
     Heat stack. Use the <code class="literal">stack_id</code> value from the
     <code class="literal">magnum cluster-status</code> output above in the following
     command:
    </p><div class="verbatim-wrap"><pre class="screen">$ heat resource-list -n2 50aa20a6-bf29-4663-9181-cf7ba3070a25
WARNING (shell) "heat resource-list" is deprecated, please use "openstack stack resource list" instead
+------------------------------+--------------------------------------+-----------------------------------+-----------------+----------------------+-------------------------------+
| resource_name                | physical_resource_id                 | resource_type                     | resource_status | updated_time         | stack_name                    |
+------------------------------+--------------------------------------+-----------------------------------+-----------------+----------------------+-------------------------------+
| add_proxy_master             | 10394a74-1503-44b4-969a-44258c9a7be1 | OS::Heat::SoftwareConfig          | CREATE_COMPLETE | 2017-04-21T19:50:33Z | my-mesos-cluster-w2trq7m46qus |
| add_proxy_master_deployment  |                                      | OS::Heat::SoftwareDeploymentGroup | INIT_COMPLETE   | 2017-04-21T19:50:33Z | my-mesos-cluster-w2trq7m46qus |
...</pre></div></li><li class="step "><p>
     The cluster is complete when all resources show
     <span class="bold"><strong>CREATE_COMPLETE</strong></span>.
    </p><div class="verbatim-wrap"><pre class="screen">$ magnum cluster-show my-mesos-cluster
+---------------------+--------------------------------------+
| Property            | Value                                |
+---------------------+--------------------------------------+
| status              | CREATE_COMPLETE                      |
| cluster_template_id | 9e942bfa-2c78-4837-82f5-6bea88ba1bf9 |
| uuid                | 9d7bb502-8865-4cbd-96fa-3cd75f0f6945 |
| stack_id            | 339a72b4-a131-47c6-8d10-365e6f6a18cf |
| status_reason       | Stack CREATE completed successfully  |
| created_at          | 2017-04-24T20:54:31+00:00            |
| name                | my-mesos-cluster                     |
| updated_at          | 2017-04-24T20:59:18+00:00            |
| discovery_url       | -                                    |
| api_address         | 172.31.0.10                          |
| coe_version         | -                                    |
| master_addresses    | ['172.31.0.10']                      |
| create_timeout      | 60                                   |
| node_addresses      | ['172.31.0.5']                       |
| master_count        | 1                                    |
| container_version   | 1.9.1                                |
| node_count          | 1                                    |
+---------------------+--------------------------------------+</pre></div></li><li class="step "><p>
     Verify that
     <a class="link" href="https://mesosphere.github.io/marathon/" target="_blank">Marathon</a>
     web console is available at http://${MASTER_IP}:8080/, and
     <a class="link" href="http://mesos.apache.org/documentation/latest/" target="_blank">Mesos</a>
     UI is available at http://${MASTER_IP}:5050/
    </p><div class="verbatim-wrap"><pre class="screen">$ https_proxy=http://proxy.yourcompany.net:8080 curl -LO \
  https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
$ chmod +x ./kubectl
$ sudo mv ./kubectl /usr/local/bin/kubectl</pre></div></li><li class="step "><p>
     Create an example Mesos application.
    </p><div class="verbatim-wrap"><pre class="screen">$ mkdir my_mesos_cluster
$ cd my_mesos_cluster/
$ cat &gt; sample.json &lt;&lt;-EOFc
{
  "id": "sample",
  "cmd": "python3 -m http.server 8080",
  "cpus": 0.5,
  "mem": 32.0,
  "container": {
    "type": "DOCKER",
    "docker": {
      "image": "python:3",
      "network": "BRIDGE",
      "portMappings": [
        { "containerPort": 8080, "hostPort": 0 }
      ]
    }
  }
}
EOF</pre></div><div class="verbatim-wrap"><pre class="screen">$ curl -s -X POST -H "Content-Type: application/json" \
  http://172.31.0.10:8080/v2/apps -d@sample.json | json_pp
{
   "dependencies" : [],
   "healthChecks" : [],
   "user" : null,
   "mem" : 32,
   "requirePorts" : false,
   "tasks" : [],
   "cpus" : 0.5,
   "upgradeStrategy" : {
      "minimumHealthCapacity" : 1,
      "maximumOverCapacity" : 1
   },
   "maxLaunchDelaySeconds" : 3600,
   "disk" : 0,
   "constraints" : [],
   "executor" : "",
   "cmd" : "python3 -m http.server 8080",
   "id" : "/sample",
   "labels" : {},
   "ports" : [
      0
   ],
   "storeUrls" : [],
   "instances" : 1,
   "tasksRunning" : 0,
   "tasksHealthy" : 0,
   "acceptedResourceRoles" : null,
   "env" : {},
   "tasksStaged" : 0,
   "tasksUnhealthy" : 0,
   "backoffFactor" : 1.15,
   "version" : "2017-04-25T16:37:40.657Z",
   "uris" : [],
   "args" : null,
   "container" : {
      "volumes" : [],
      "docker" : {
         "portMappings" : [
            {
               "containerPort" : 8080,
               "hostPort" : 0,
               "servicePort" : 0,
               "protocol" : "tcp"
            }
         ],
         "parameters" : [],
         "image" : "python:3",
         "forcePullImage" : false,
         "network" : "BRIDGE",
         "privileged" : false
      },
      "type" : "DOCKER"
   },
   "deployments" : [
      {
         "id" : "6fbe48f0-6a3c-44b7-922e-b172bcae1be8"
      }
   ],
   "backoffSeconds" : 1
}</pre></div></li><li class="step "><p>
     Wait for sample application to start. Use REST API or Marathon web console
     to monitor status:
    </p><div class="verbatim-wrap"><pre class="screen">$ curl -s http://172.31.0.10:8080/v2/apps/sample | json_pp
{
   "app" : {
      "deployments" : [],
      "instances" : 1,
      "tasks" : [
         {
            "id" : "sample.7fdd1ee4-29d5-11e7-9ee0-02427da4ced1",
            "stagedAt" : "2017-04-25T16:37:40.807Z",
            "version" : "2017-04-25T16:37:40.657Z",
            "ports" : [
               31827
            ],
            "appId" : "/sample",
            "slaveId" : "21444bc5-3eb8-49cd-b020-77041e0c88d0-S0",
            "host" : "10.0.0.9",
            "startedAt" : "2017-04-25T16:37:42.003Z"
         }
      ],
      "upgradeStrategy" : {
         "maximumOverCapacity" : 1,
         "minimumHealthCapacity" : 1
      },
      "storeUrls" : [],
      "requirePorts" : false,
      "user" : null,
      "id" : "/sample",
      "acceptedResourceRoles" : null,
      "tasksRunning" : 1,
      "cpus" : 0.5,
      "executor" : "",
      "dependencies" : [],
      "args" : null,
      "backoffFactor" : 1.15,
      "ports" : [
         10000
      ],
      "version" : "2017-04-25T16:37:40.657Z",
      "container" : {
         "volumes" : [],
         "docker" : {
            "portMappings" : [
               {
                  "servicePort" : 10000,
                  "protocol" : "tcp",
                  "hostPort" : 0,
                  "containerPort" : 8080
               }
            ],
            "forcePullImage" : false,
            "parameters" : [],
            "image" : "python:3",
            "privileged" : false,
            "network" : "BRIDGE"
         },
         "type" : "DOCKER"
      },
      "constraints" : [],
      "tasksStaged" : 0,
      "env" : {},
      "mem" : 32,
      "disk" : 0,
      "labels" : {},
      "tasksHealthy" : 0,
      "healthChecks" : [],
      "cmd" : "python3 -m http.server 8080",
      "backoffSeconds" : 1,
      "maxLaunchDelaySeconds" : 3600,
      "versionInfo" : {
         "lastConfigChangeAt" : "2017-04-25T16:37:40.657Z",
         "lastScalingAt" : "2017-04-25T16:37:40.657Z"
      },
      "uris" : [],
      "tasksUnhealthy" : 0
   }
}</pre></div></li><li class="step "><p>
     Verify that deployed application is responding on automatically assigned
     port on floating IP address of worker node.
    </p><div class="verbatim-wrap"><pre class="screen">$ curl http://172.31.0.5:31827
&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd"&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;
&lt;title&gt;Directory listing for /&lt;/title&gt;
...</pre></div></li><li class="step "><p>
     If LBaaS v2 is enabled in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> environment, a new load balancer can be
     created to perform request rotation between several masters. For more
     information about LBaaS v2 support, see <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 31 “Configuring Load Balancer as a Service”</span>.
    </p></li></ol></div></div></div></div><div class="sect1" id="create-magnum-cluster"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Magnum Cluster with the Dashboard</span> <a title="Permalink" class="permalink" href="#create-magnum-cluster">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-create_magnum_cluster_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-create_magnum_cluster_dashboard.xml</li><li><span class="ds-label">ID: </span>create-magnum-cluster</li></ul></div></div></div></div><p>
  You can alternatively create a cluster template and cluster with the Magnum
  UI in Horizon. The example instructions below demonstrate how to deploy a
  Kubernetes Cluster using the Fedora Atomic image. Other deployments such as
  Kubernetes on CoreOS, Docker Swarm on Fedora, and Mesos on Ubuntu all follow
  the same set of instructions mentioned below with slight variations to their
  parameters. You can determine those parameters by looking at the previous
  set of CLI instructions in the
  <code class="command">magnum cluster-template-create</code> and
  <code class="command">magnum cluster-create</code> commands.
 </p><div class="sect2" id="idg-all-userguide-container-service-create-magnum-cluster-dashboard-xml-7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-container-service-create-magnum-cluster-dashboard-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-create_magnum_cluster_dashboard.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-create_magnum_cluster_dashboard.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-container-service-create-magnum-cluster-dashboard-xml-7</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Magnum must be installed before proceeding. For more information, see
     <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 14 “Magnum Overview”, Section 14.2 “Install the Magnum Service”</span>.
    </p><div id="id-1.7.4.2.7.3.2.1.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      Pay particular attention to <code class="literal">external-name:</code> in
      <code class="literal">data/network_groups.yml</code>. This cannot be set to the
      default <code class="literal">myardana.test</code> and must be a valid
      DNS-resolvable FQDN. If you do not have a DNS-resolvable FQDN, remove or
      comment out the <code class="literal">external-name</code> entry and the public
      endpoint will use an IP address instead of a name.
     </p></div></li><li class="listitem "><p>
     The image for which you want to base your cluster on must already have
     been uploaded into glance. See the previous CLI instructions regarding
     deploying a cluster on how this is done.
    </p></li></ul></div></div><div class="sect2" id="cluster-template"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating the Cluster Template</span> <a title="Permalink" class="permalink" href="#cluster-template">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-create_magnum_cluster_dashboard.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-create_magnum_cluster_dashboard.xml</li><li><span class="ds-label">ID: </span>cluster-template</li></ul></div></div></div></div><p>
   You will need access to the Dashboard to create the cluster
   template. If you have not accessed the Horizon Dashboard before or you are
   unfamiliar with it, see <a class="xref" href="#user-dashboard-overview" title="Chapter 2. Using the Dashboard">Chapter 2, <em>Using the Dashboard</em></a>
   and <a class="xref" href="#cloudadmin-gui" title="Chapter 3. Cloud Admin Actions with the Dashboard">Chapter 3, <em>Cloud Admin Actions with the Dashboard</em></a> for more
   information.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Open a web browser that has both JavaScript and cookies enabled. In the
     address bar, enter the host name or IP address for the dashboard.
    </p></li><li class="step "><p>
     On the <span class="guimenu ">Log In</span> page, enter your user name
     and password and then click <span class="guimenu ">Connect</span>.
    </p></li><li class="step "><p>
     Make sure you are in the appropriate domain and project in the left pane.
     Below is an example image of the drop-down box:
    </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-domain_selector.png" target="_blank"><img src="images/media-horizon-domain_selector.png" width="" /></a></div></div></li><li class="step "><p>
     A key pair is required for cluster template creation. It is applied to VMs
     created during the cluster creation process. This allows SSH access to your
     cluster's VMs. If you would like to create a new key pair, do so by going
     to <span class="guimenu ">Project</span> › <span class="guimenu ">Compute</span> › <span class="guimenu ">Access &amp; Security</span> › <span class="guimenu ">Key Pairs</span>.
    </p></li><li class="step "><p>
     Go to <span class="guimenu ">Project</span> › <span class="guimenu ">Container Infra</span> › <span class="guimenu ">Cluster Templates</span>.
     Insert
     <em class="replaceable ">CLUSTER_NAME</em> and click on
     <span class="guimenu ">+ Create Cluster Template</span> with the following options:
    </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-create_cluster_template.png" target="_blank"><img src="images/media-horizon-create_cluster_template.png" width="" /></a></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       <span class="guimenu ">Public</span> - makes the template available
       for others to use.
      </p></li><li class="listitem "><p>
       <span class="guimenu ">Enable Registry</span> - creates and uses a
       private docker registry backed by OpenStack Swift in addition to using
       the public docker registry.
      </p></li><li class="listitem "><p>
       <span class="guimenu ">Disable TLS</span> - turns off TLS encryption.
       For Kubernetes clusters which use client certificate authentication,
       disabling TLS also involves disabling authentication.
      </p></li></ul></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-create_cluster_template2.png" target="_blank"><img src="images/media-horizon-create_cluster_template2.png" width="" /></a></div></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-create_cluster_template3.png" target="_blank"><img src="images/media-horizon-create_cluster_template3.png" width="" /></a></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       Proxies are only needed if the created VMs require a proxy to connect
       externally.
      </p></li><li class="listitem "><p>
       <span class="guimenu ">Master LB</span> – This should be turned on
       if LbaaS v2 (Octavia) is configured in your environment. This option
       will create load balancers in front of the cluster's master nodes and
       distribute the requests to the Kubernetes API and etcd across the master
       nodes.
      </p></li><li class="listitem "><p>
       <span class="guimenu ">Floating IP</span> – This assigns floating
       IPs to the cluster nodes when the cluster is being created. This should
       be selected if you wish to ssh into the cluster nodes, perform
       diagnostics and additional tuning to Kubernetes.
      </p></li></ul></div></li><li class="step "><p>
     Click the <span class="guimenu ">Submit</span> button to create the cluster template
     and you should see <span class="emphasis"><em>my-template</em></span> in the list of
     templates.
    </p></li></ol></div></div></div><div class="sect2" id="creating-the-cluster"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating the Cluster</span> <a title="Permalink" class="permalink" href="#creating-the-cluster">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-container_service-create_magnum_cluster_dashboard.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-container_service-create_magnum_cluster_dashboard.xml</li><li><span class="ds-label">ID: </span>creating-the-cluster</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Click <span class="guimenu ">Create Cluster</span> for
     <span class="emphasis"><em>my-template</em></span> or go to
     <span class="guimenu ">Project</span> › <span class="guimenu ">Container Infra</span> › <span class="guimenu ">Clusters</span> and click <span class="guimenu ">+ Create
     Cluster</span> with the following options.
    </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-create_cluster_img1.png" target="_blank"><img src="images/media-horizon-create_cluster_img1.png" width="" /></a></div></div></li><li class="step "><p>
     Click <span class="guimenu ">Create</span> to start the cluster
     creation process.
    </p></li><li class="step "><p>
     Click <span class="guimenu ">Clusters</span> in the left pane to see
     the list of clusters. You will see
     <span class="emphasis"><em>my-cluster</em></span> in this list. If you select
     <span class="emphasis"><em>my-cluster</em></span>, you will see additional
     information regarding your cluster.
    </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-create_cluster_img3.png" target="_blank"><img src="images/media-horizon-create_cluster_img3.png" width="" /></a></div></div></li></ol></div></div></div></div></div><div class="chapter " id="idg-all-userguide-create-network-xml-1"><div class="titlepage"><div><div><h2 class="title"><span class="number">8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Private Network</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-network-xml-1">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_network.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_network.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-network-xml-1</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-userguide-create-network-xml-6"><span class="number">8.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="section"><a href="#create-router"><span class="number">8.2 </span><span class="name">Creating a Router</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-create-network-xml-8"><span class="number">8.3 </span><span class="name">Creating a Network and Subnet</span></a></span></dt></dl></div></div><div class="sect1" id="idg-all-userguide-create-network-xml-6"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-network-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_network.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_network.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-network-xml-6</li></ul></div></div></div></div><p>
   These steps assume the following have been completed:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Your Administrator has created a valid external network for your
     environment. See <span class="intraxref">Book “<em class="citetitle ">Installing with Cloud Lifecycle Manager</em>”, Chapter 27 “UI Verification”, Section 27.4 “Creating an External Network”</span>
     for more details.
    </p></li><li class="listitem "><p>
     Your Administrator has provided you with the IP address or hostname for
     the Horizon Dashboard. See <a class="xref" href="#cloudadmin-gui" title="Chapter 3. Cloud Admin Actions with the Dashboard">Chapter 3, <em>Cloud Admin Actions with the Dashboard</em></a> for more
     details.
    </p></li></ul></div><p>
   You will want to use the user credentials that your Administrator has
   provided to you when you access the dashboard.
  </p></div><div class="sect1" id="create-router"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Router</span> <a title="Permalink" class="permalink" href="#create-router">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_network.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_network.xml</li><li><span class="ds-label">ID: </span>create-router</li></ul></div></div></div></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Access Horizon and log in with your credentials. Contact your
     Administrator if you do not know your login credentials.
    </p></li><li class="listitem "><p>
     Open the Create Router wizard by following these steps:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Navigate to <span class="bold"><strong>Routers</strong></span>
       under the Network menu.
      </p></li><li class="listitem "><p>
       Press the <span class="bold"><strong>Create Router</strong></span> button.
      </p></li></ol></div></li><li class="listitem "><p>
     Give your router a name and then click the Create Router button again:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Select a <span class="bold"><strong>Router Name</strong></span>.
      </p></li><li class="listitem "><p>
       Select an <span class="bold"><strong>External Network</strong></span> from the
       drop down menu.
      </p></li><li class="listitem "><p>
       Press the <span class="bold"><strong>Create Router</strong></span> button.
      </p></li></ol></div></li></ol></div></div><div class="sect1" id="idg-all-userguide-create-network-xml-8"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Network and Subnet</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-network-xml-8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_network.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_network.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-network-xml-8</li></ul></div></div></div></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Access Horizon and log in with your credentials. Contact your
     Administrator if you do not know your login credentials.
    </p></li><li class="listitem "><p>
     Open the Create Network wizard by following these steps:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Navigate to
       <span class="bold"><strong>Networks</strong></span>
       under the Network menu.
      </p></li><li class="listitem "><p>
       Press the <span class="bold"><strong>Create Network</strong></span> button.
      </p></li></ol></div></li><li class="listitem "><p>
     On the first window of the create network wizard:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Choose a <span class="bold"><strong>Network Name</strong></span>.
      </p></li><li class="listitem "><p>
       Select the
       <span class="bold"><strong>Next</strong></span>
       button.
      </p></li></ol></div></li><li class="listitem "><p>
     On the second window of the create network wizard:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Choose a <span class="bold"><strong>Subnet Name</strong></span>.
      </p></li><li class="listitem "><p>
       Enter a <span class="bold"><strong>Network Address</strong></span> (CIDR) for your
       subnet.
      </p></li><li class="listitem "><p>
       Select the
       <span class="bold"><strong>Next</strong></span>
       button.
      </p></li></ol></div></li><li class="listitem "><p>
     On the final window of the Create Network wizard:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Ensure that <span class="bold"><strong>Enable DHCP</strong></span> is checked.
      </p></li><li class="listitem "><p>
       For a basic network setup, leave the <span class="bold"><strong>Allocation
       Pools</strong></span>, <span class="bold"><strong>DNS Name Servers</strong></span>, and
       <span class="bold"><strong>Host Routes</strong></span> fields blank.
      </p></li><li class="listitem "><p>
       Select <span class="guimenu ">Create</span> when finished.
      </p></li></ol></div></li><li class="listitem "><p>
     The next step is to attach your subnet to your router.
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Navigate to <span class="guimenu ">Routers</span> under the
       <code class="literal">Network</code> menu.
      </p></li><li class="listitem "><p>
       Click on your router name to bring up its settings.
      </p></li></ol></div></li><li class="listitem "><p>
     Create the interface:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Select the <span class="bold"><strong>Interfaces</strong></span> tab.
      </p></li><li class="listitem "><p>
       Click the <span class="bold"><strong>Add Interface</strong></span> button.
      </p></li></ol></div></li><li class="listitem "><p>
     Complete the interface creation:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Select your subnet from the drop down menu.
      </p></li><li class="listitem "><p>
       select the <span class="bold"><strong>Add Interface</strong></span> button.
      </p></li></ol></div><div id="id-1.7.4.3.4.2.8.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
      Do not enter a value for the <code class="literal">IP Address (Optional)</code>
      field as this can cause other issues.
     </p></div></li><li class="listitem "><p>
     To confirm your router is setup properly you can:
    </p><div class="orderedlist "><ol class="orderedlist" type="a"><li class="listitem "><p>
       Click on the <span class="bold"><strong>Network Topology</strong></span> menu
       option:
      </p></li><li class="listitem "><p>
       Ensure it looks correct.
      </p></li></ol></div></li></ol></div></div></div><div class="chapter " id="create-keypair"><div class="titlepage"><div><div><h2 class="title"><span class="number">9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Key Pair</span> <a title="Permalink" class="permalink" href="#create-keypair">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_keypair.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_keypair.xml</li><li><span class="ds-label">ID: </span>create-keypair</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-userguide-create-keypair-xml-5"><span class="number">9.1 </span><span class="name">Creating a Key Pair using Horizon</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-create-keypair-xml-6"><span class="number">9.2 </span><span class="name">Creating a Key Pair using the Command Line</span></a></span></dt></dl></div></div><p>
  Key pairs are used to provide SSH access to Nova compute instances. These
  steps will show you how to create them with either the Horizon dashboard UI
  or the command-line tools.
 </p><p>
  For more details about access and security for Nova, see
  <a class="link" href="http://docs.openstack.org/user-guide/cli_nova_configure_access_security_for_instances.html" target="_blank">Configure
  access and security for instances</a>.
 </p><div class="sect1" id="idg-all-userguide-create-keypair-xml-5"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Key Pair using Horizon</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-keypair-xml-5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_keypair.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_keypair.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-keypair-xml-5</li></ul></div></div></div></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Log in to your Horizon dashboard.
    </p></li><li class="listitem "><p>
     Under the <span class="bold"><strong>Project</strong></span> menu, navigate to
     <span class="bold"><strong>Access and Security</strong></span>.
    </p></li><li class="listitem "><p>
     Navigate to the <span class="bold"><strong>Key Pairs</strong></span> tab and select
     the <span class="bold"><strong>Create Key Pair</strong></span> button.
    </p></li><li class="listitem "><p>
     Enter in a unique name for your key pair and then select the
     <span class="bold"><strong>Create Key Pair</strong></span> button.
    </p></li><li class="listitem "><p>
     Your key pair will be created and the public key portion of the key
     (<code class="literal">.pem</code>) will be automatically downloaded to your local
     computer. You will then have the option to select this key pair when
     creating new Nova compute instances.
    </p></li></ol></div></div><div class="sect1" id="idg-all-userguide-create-keypair-xml-6"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Key Pair using the Command Line</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-keypair-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_keypair.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_keypair.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-keypair-xml-6</li></ul></div></div></div></div><p>
   You can utilize either the OpenStack unified command-line tool or the
   NovaClient command-line tool to create a keypair. These steps assume you
   have the tool installed and that you have credentials to request an
   authentication token.
  </p><p>
   For full details on these command-line clients and installation
   instructions, see
   <a class="link" href="http://docs.openstack.org/cli-reference/content/" target="_blank">OpenStack
   Command-Line Interface Reference</a>
  </p><p>
   <span class="bold"><strong>Using the OpenStack CLI</strong></span>
  </p><p>
   The format of the command-line call for this is:
  </p><div class="verbatim-wrap"><pre class="screen">openstack keypair create --public-key &lt;file&gt; &lt;name&gt;</pre></div><p>
   where:
  </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>Value</th><th>Description</th></tr></thead><tbody><tr><td>--public-key &lt;file&gt;</td><td>
       <p>
        This is an optional field. If used, this will be the path to your
        public key which will be used when creating the key pair.
       </p>
      </td></tr><tr><td>&lt;name&gt;</td><td>
       <p>
        This will be the unique name for your key pair.
       </p>
      </td></tr></tbody></table></div><p>
   <span class="bold"><strong>Using the Nova CLI</strong></span>
  </p><p>
   The format of the command-line call for this is:
  </p><div class="verbatim-wrap"><pre class="screen">nova keypair-add --public-key &lt;file&gt; &lt;name&gt;</pre></div><p>
   where:
  </p><div id="id-1.7.4.4.5.13" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    You can use <code class="literal">nova help keypair-add</code> to get the syntax
    for this command.
   </p></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>Value</th><th>Description</th></tr></thead><tbody><tr><td>--public-key &lt;file&gt;</td><td>
       <p>
        This is an optional field. If used, this will be the path to your
        public key which will be used when creating the key pair.
       </p>
      </td></tr><tr><td>&lt;name&gt;</td><td>
       <p>
        This will be the unique name for your key pair.
       </p>
      </td></tr></tbody></table></div></div></div><div class="chapter " id="user-image-upload"><div class="titlepage"><div><div><h2 class="title"><span class="number">10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating and Uploading a Glance Image</span> <a title="Permalink" class="permalink" href="#user-image-upload">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_image.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_image.xml</li><li><span class="ds-label">ID: </span>user-image-upload</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-userguide-create-image-xml-7"><span class="number">10.1 </span><span class="name">How to Curate Your Own Images</span></a></span></dt><dt><span class="section"><a href="#upload-cirros-img"><span class="number">10.2 </span><span class="name">Example: Uploading a Cirros Linux Image for Use</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-create-image-xml-11"><span class="number">10.3 </span><span class="name">Using Horizon to Upload an Image</span></a></span></dt></dl></div></div><p>
  This guide will assist you in obtaining, creating, or modifying cloud images
  for your Image (Glance) repository and uploading them for use.
 </p><div class="sect1" id="idg-all-userguide-create-image-xml-7"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How to Curate Your Own Images</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-image-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_image.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_image.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-image-xml-7</li></ul></div></div></div></div><p>
   OpenStack has created a guide to show you how to obtain, create, and modify
   images that will be compatible with your <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> cloud:
  </p><p>
   <a class="link" href="http://docs.openstack.org/image-guide/content/" target="_blank">OpenStack
   Virtual Machine Image Guide</a>
  </p></div><div class="sect1" id="upload-cirros-img"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example: Uploading a Cirros Linux Image for Use</span> <a title="Permalink" class="permalink" href="#upload-cirros-img">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_image.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_image.xml</li><li><span class="ds-label">ID: </span>upload-cirros-img</li></ul></div></div></div></div><p>
   These steps assume you have a user account setup within Keystone that has
   access to upload images to the Glance repository. Contact your Administrator
   if you do not have these permissions or if you are unsure.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Download the Cirros image from the internet:
    </p><div class="verbatim-wrap"><pre class="screen">wget http://download.cirros-cloud.net/0.4.0/cirros-0.4.0-x86_64-disk.img</pre></div></li><li class="step "><p>
     Upload that file to Glance using the GlanceClient CLI:
    </p><div class="verbatim-wrap"><pre class="screen">glance \
  --os-username &lt;username&gt; \
  --os-password &lt;password&gt; \
  --os-tenant-name &lt;project name&gt; \
  --os-auth-url &lt;identity endpoint&gt; \
  --os-endpoint-type internalURL \
  image-create
     --name cirros-0.3.3-x86_64 \
     --container-format bare \
     --disk-format qcow2 \
     --visibility public \
     --file &lt;path to Cirros image file&gt;</pre></div></li></ol></div></div></div><div class="sect1" id="idg-all-userguide-create-image-xml-11"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Horizon to Upload an Image</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-create-image-xml-11">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-create_image.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-create_image.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-create-image-xml-11</li></ul></div></div></div></div><p>
   It is possible to use the Horizon UI to create images for use in your cloud.
   These steps will show you how.
  </p><p>
   To successfully create large images, select the image format first, then add
   image name, image source and visibility.
  </p><p>
   Performing the steps out of this order will cause OS image creation to fail.
  </p><div id="id-1.7.4.5.5.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    By default, the HTTP upload option will not work when uploading images. To
    utilize this option you will need your cloud administrator to enable this
    option. See <span class="intraxref">Book “Operations Guide”, Chapter 15 “Troubleshooting Issues”, Section 15.5 “Troubleshooting the Image (Glance) Service”</span> for more
    details.
   </p></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Log in to the Horizon UI.
    </p></li><li class="listitem "><p>
     In the menu, select
     <span class="guimenu ">Project</span> › <span class="guimenu ">Compute</span> › <span class="guimenu ">Images</span>
     and click the <span class="guimenu ">Create Image</span> button:
    </p></li><li class="listitem "><p>
     Fill in the details for your new image and then click the
     <span class="bold"><strong>Create Image</strong></span> button:
    </p></li></ol></div></div></div><div class="chapter " id="lbaas-dashboard"><div class="titlepage"><div><div><h2 class="title"><span class="number">11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Load Balancer with the Dashboard</span> <a title="Permalink" class="permalink" href="#lbaas-dashboard">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas_dashboard.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas_dashboard.xml</li><li><span class="ds-label">ID: </span>lbaas-dashboard</li></ul></div></div></div></div><div class="line"></div><p>
  In <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> you can create a Load Balancer with the Load Balancer
  Panel in the Dashboard.
 </p><p>
  Follow the steps below to create the load balancer, listener, pool, add
  members to the pool and create the health monitor.
 </p><div id="id-1.7.4.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
   Optionally, you may add members to the load balancer pool after the load
   balancer has been created.
  </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    <span class="bold"><strong>Login to the Dashboard</strong></span>
   </p><p>
    Login into the Dashboard using your domain, user account and password.
   </p></li><li class="step "><p>
    <span class="bold"><strong>Navigate and Create Load Balancer</strong></span>
   </p><p>
    Once logged into the Dashboard, navigate to the <span class="guimenu ">Load
    Balancers</span> panel by selecting
    <span class="guimenu ">Project</span> › <span class="guimenu ">Network</span> › <span class="guimenu ">Load
    Balancers</span> in the navigation menu, then select
    <span class="guimenu ">Create Load Balancer</span> from the Load
    Balancers page.
   </p></li><li class="step "><p>
    <span class="bold"><strong>Create Load Balancer</strong></span>
   </p><p>
    Provide the Load Balancer details, Load Balancer Name, Description
    (optional), IP Address and Subnet. When complete, select Next.
   </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers2.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers2.png" width="" /></a></div></div></li><li class="step "><p>
    <span class="bold"><strong>Create Listener</strong></span>
   </p><p>
    Provide a Name, Description, Protocol (HTTP, TCP, TERMINATED_HTTPS) and
    Port for the Load Balancer Listener.
   </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers3.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers3.png" width="" /></a></div></div></li><li class="step "><p>
    <span class="bold"><strong>Create Pool</strong></span>
   </p><p>
    Provide the Name, Description and Method (LEAST_CONNECTIONS, ROUND_ROBIN,
    SOURCE_IP) for the Load Balancer Pool.
   </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers4.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers4.png" width="" /></a></div></div></li><li class="step "><p>
    <span class="bold"><strong>Add Pool Members</strong></span>
   </p><p>
    Add members to the Load Balancer Pool.
   </p><div id="id-1.7.4.6.5.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
     Optionally, you may add members to the load balancer pool after the load
     balancer has been created.
    </p></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers5.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers5.png" width="" /></a></div></div></li><li class="step "><p>
    <span class="bold"><strong>Create Health Monitor</strong></span>
   </p><p>
    Create Health Monitor by providing the Monitor type (HTTP, PING, TCP), the
    Health check interval, Retry count, timeout, HTTP Method, Expected HTTP
    status code and the URL path. Once all fields are filled, select
    <span class="bold"><strong>Create Load Balancer</strong></span>.
   </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers6.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers6.png" width="" /></a></div></div></li><li class="step "><p>
    <span class="bold"><strong>Load Balancer Provisioning Status</strong></span>
   </p><p>
    Clicking on the Load Balancers tab again will provide the status of the
    Load Balancer. The Load Balancer will be in
    <span class="bold"><strong>Pending Create</strong></span> until the Load Balancer
    is created, at which point the Load Balancer will change to an
    <span class="bold"><strong>Active</strong></span> state.
   </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers8.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers8.png" width="" /></a></div></div></li><li class="step "><p>
    <span class="bold"><strong>Load Balancer Overview</strong></span>
   </p><p>
    Once <span class="bold"><strong>Load Balancer 1</strong></span> has been created, it
    will appear in the Load Balancers list. Click the Load Balancer 1, it will show
    the Overview. In this view, you can see the Load  Balancer Provider type,
    the Admin State, Floating IP, Load Balancer, Subnet and Port ID's.
   </p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/media-horizon-lbaas_panel-LoadBalancers7.png" target="_blank"><img src="images/media-horizon-lbaas_panel-LoadBalancers7.png" width="" /></a></div></div></li></ol></div></div></div><div class="chapter " id="HP2-0LBaaS"><div class="titlepage"><div><div><h2 class="title"><span class="number">12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Load Balancing as a Service (LBaaS)</span> <a title="Permalink" class="permalink" href="#HP2-0LBaaS">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas.xml</li><li><span class="ds-label">ID: </span>HP2-0LBaaS</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-userguide-lbaas-xml-6"><span class="number">12.1 </span><span class="name">Configuration</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-lbaas-xml-15"><span class="number">12.2 </span><span class="name">For More Information</span></a></span></dt></dl></div></div><p>
  Load Balancing as a Service (LBaaS) is an advanced networking service that
  allows load balancing of multi-node environments. It provides the ability to
  spread requests across multiple servers thereby reducing the load on any
  single server. The following examples depict usage of the various OpenStack
  command-line interfaces. The Load Balancer v1 API is also accessible
  via the Horizon web interface if the v1 API is enabled. The Load Balancer v2
  API does not currently have a representative Horizon web interface. The v2
  API is targeted to have a Horizon web interface in a future <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> release.
  This document describes the configuration for LBaaS v1 and v2.
 </p><p>
  You can create TLS enabled Load Balancers in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> by following the
  steps labeled for TLS Load Balancers. You cannot enable TLS with v1 Load
  Balancers, only v2 Load Balancers can be enabled with TLS.
 </p><div id="id-1.7.4.7.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   When Barbican is not installed by default, you have to manually install
   Barbican and redeploy neutron.
  </p></div><p>
  <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> can support either LBaaS v1 or LBaaS v2 to allow for wide
  ranging customer requirements. Check with your administrator for the version
  that is installed before starting your configuration.
 </p><div class="sect1" id="idg-all-userguide-lbaas-xml-6"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-lbaas-xml-6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-lbaas-xml-6</li></ul></div></div></div></div><p>
   <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> LBaaS Configuration
  </p><p>
   <span class="bold"><strong>Create Private Network for LBaaS</strong></span>
  </p><p>
   You can create the new network and router by executing the following command
   from the Cloud Lifecycle Manager or a shell with access to the API nodes.
  </p><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>
     As a cloud admin, run the following commands to create a private network
     and a router.
    </p><div class="verbatim-wrap"><pre class="screen">neutron net-create private
neutron subnet-create --name sub private 10.1.0.0/24 --gateway 10.1.0.1
neutron router-create --distributed false router
neutron router-interface-add router sub
neutron router-gateway-set router ext-net</pre></div></li></ul></div></div><p>
   <span class="bold"><strong>Start Virtual Machines</strong></span>
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Add security group rules.
    </p><div id="id-1.7.4.7.6.7.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      In the example below the load balancer is tested on port 80. If you
      need to test the load balancer on a different port you will need to
      create a security group rule for your port number.
     </p></div><div class="verbatim-wrap"><pre class="screen">neutron security-group-rule-create default --protocol icmp
neutron security-group-rule-create default --protocol tcp --port-range-min 22 --port-range-max 22
neutron security-group-rule-create default --protocol tcp --port-range-min 80 --port-range-max 80</pre></div></li><li class="step "><p>
     Start two VMs on the private network.
    </p><div class="verbatim-wrap"><pre class="screen">## Start vm1
nova boot --flavor 1 --image &lt;image&gt; --nic net-id=$(neutron net-list | awk '/private/ {print $2}') vm1

## start vm2
nova boot --flavor 1 --image &lt;image&gt; --nic net-id=$(neutron net-list | awk '/private/ {print $2}') vm2</pre></div></li><li class="step "><p>
     Check if the VMs are active.
    </p><div class="verbatim-wrap"><pre class="screen">nova list</pre></div></li></ol></div></div><p>
   <span class="bold"><strong>For TLS Load Balancers - Create Certificate Chain and
   Key</strong></span>
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     From a computer with access to the Barbican and labs API, run the
     following sequence of commands
    </p><div class="verbatim-wrap"><pre class="screen">openssl genrsa -des3 -out ca.key 1024
openssl req -new -x509 -days 3650 -key ca.key -out ca.crt
openssl x509  -in  ca.crt -out ca.pem
openssl genrsa -des3 -out ca-int_encrypted.key 1024
openssl rsa -in ca-int_encrypted.key -out ca-int.key
openssl req -new -key ca-int.key -out ca-int.csr -subj "/CN=ca-int@acme.com"
openssl x509 -req -days 3650 -in ca-int.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out ca-int.crt
openssl genrsa -des3 -out server_encrypted.key 1024
openssl rsa -in server_encrypted.key -out server.key
openssl req -new -key server.key -out server.csr -subj "/CN=server@acme.com"
openssl x509 -req -days 3650 -in server.csr -CA ca-int.crt -CAkey ca-int.key -set_serial 01 -out server.crt</pre></div></li><li class="step "><p>
     For SNI, create another chain with a different CN
    </p><div class="verbatim-wrap"><pre class="screen">openssl genrsa -des3 -out ca2.key 1024
openssl req -new -x509 -days 3650 -key ca2.key -out ca2.crt
openssl x509  -in  ca2.crt -out ca2.pem
openssl genrsa -des3 -out ca-int_encrypted2.key 1024
openssl rsa -in ca-int_encrypted2.key -out ca-int2.key
openssl req -new -key ca-int2.key -out ca-int2.csr -subj "/CN=ca-int-test2@stacme.com"
openssl x509 -req -days 3650 -in ca-int2.csr -CA ca2.crt -CAkey ca2.key -set_serial 01 -out ca-int2.crt
openssl genrsa -des3 -out server_encrypted2.key 1024
openssl rsa -in server_encrypted2.key -out server2.key
openssl req -new -key server2.key -out server2.csr -subj "/CN=test2@stacme.com"
openssl x509 -req -days 3650 -in server2.csr -CA ca-int2.crt -CAkey ca-int2.key -set_serial 01 -out server2.crt</pre></div></li></ol></div></div><p>
   <span class="bold"><strong>For TLS Load Balancers - Barbican Secrets and
   Containers</strong></span>
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Source the <code class="literal">barbican.osrc</code> file from the lifecycle
     manager node. If you need to perform this operation on a different
     computer make sure that the OpenStack user account uploading the certs has
     the keymanager-admin role and is in the admin tenant (see
     <span class="intraxref">Book “Operations Guide”, Chapter 4 “Managing Identity”, Section 4.5 “Configuring the Identity Service”</span> 
     for a list of roles and tenants). LBaaS will only be able to access
     certificates stored in the admin tenant.
    </p><div class="verbatim-wrap"><pre class="screen">barbican secret store --payload-content-type='text/plain' --name='certificate' --payload="$(cat server.crt)"
barbican secret store --payload-content-type='text/plain' --name='private_key' --payload="$(cat server.key)"
barbican secret container create --name='tls_container' --type='certificate' --secret="certificate=$(barbican secret list | awk '/ certificate / {print $2}')" --secret="private_key=$(barbican secret list | awk '/ private_key / {print $2}')"</pre></div><div id="id-1.7.4.7.6.11.1.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
      Do not delete the certificate container associated with your Load
      Balancer listeners before deleting the Load Balancers themselves. If you
      delete the certificate first, future operations on your Load Balancers
      and failover will cease to function.
     </p></div></li><li class="step "><p>
     Add the second certificate chain to test SNI
    </p><div class="verbatim-wrap"><pre class="screen">barbican secret store --payload-content-type='text/plain' --name='certificate2' --payload="$(cat server2.crt)"
barbican secret store --payload-content-type='text/plain' --name='private_key2' --payload="$(cat server2.key)"
barbican secret container create --name='tls_container2' --type='certificate' --secret="certificate=$(barbican secret list | awk '/ certificate2 / {print $2}')" --secret="private_key=$(barbican secret list | awk '/ private_key2 / {print $2}')"</pre></div></li><li class="step "><p>
     Find the Octavia user id. You will add the id as a barbican acl user for
     the containers and keys.
    </p><div class="verbatim-wrap"><pre class="screen">source keystone.osrc
openstack user list</pre></div></li><li class="step "><p>
     Get the container and secret hrefs.
    </p><div class="verbatim-wrap"><pre class="screen">source barbican.osrc
barbican secret list
barbican secret container list</pre></div></li><li class="step "><p>
     Add the acl user obtained in step 3 to the hrefs obtained in step 4 by
     executing <code class="literal">barbican acl user add --user &lt;user id of Octavia&gt;
     &lt;href&gt;</code>. In the example below, the Octavia user,
     <code class="literal">66649a0863b64275bc3bffb50e3d76c8</code> is being added as the
     Barbican acl user for the containers and keys:
    </p><div class="verbatim-wrap"><pre class="screen">barbican acl user add --user 66649a0863b64275bc3bffb50e3d76c8 https://10.242.124.130:9311/v1/containers/7ebcd4fa-e96a-493d-b1ee-260914d3cbeb
barbican acl user add --user 66649a0863b64275bc3bffb50e3d76c8 https://10.242.124.130:9311/v1/secrets/d3c9584c-a43c-4fc1-bfa9-ebcafee57059
barbican acl user add --user 66649a0863b64275bc3bffb50e3d76c8 https://10.242.124.130:9311/v1/secrets/0b958aa8-49d2-40aa-82dd-5660e012b3a3</pre></div></li></ol></div></div><p>
   <span class="bold"><strong>Create Load Balancer v2</strong></span>
  </p><div id="id-1.7.4.7.6.13" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    The creation of the Load Balancer requires a tenant network and not an
    external network.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Create the new load balancer using the
     <code class="literal">lbaas-loadbalancer-create</code> command and giving the load
     balancer a name and subnet.
    </p><div class="verbatim-wrap"><pre class="screen">source barbican.osrc
neutron lbaas-loadbalancer-create --name lb sub</pre></div></li><li class="step "><p>
     Create a new listener. If you are enabling TLS, use the second example, if
     you are enabling TLS and SNI, use the third example.
    </p><div id="id-1.7.4.7.6.14.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      Use unique port numbers for each listener. This example uses 80, 443
      and 444.
     </p></div><ol type="a" class="substeps "><li class="step "><p>
       Create a new listener for the load balancer without TLS using the
       <code class="literal">lbaas-listener-create</code> command and giving the listener
       the name of the load balancer, the protocol, the protocol port and a
       name for the listener.
      </p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-listener-create --loadbalancer lb --protocol HTTP --protocol-port 80 --name listener</pre></div></li><li class="step "><p>
       Create a new listener for the load balancer with TLS and no SNI using
       the <code class="literal">lbaas-listener-create</code> command and giving the
       listener the name of the load balancer, the protocol, the protocol port,
       the name for the listener and the default TLS container.
      </p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-listener-create --loadbalancer lb --protocol-port 443 --protocol TERMINATED_HTTPS --name tls_listener --default-tls-container-ref=$(barbican secret container list | awk '/ tls_container / {print $2}')</pre></div></li><li class="step "><p>
       Create a new listener for the load balancer with TLS and SNI using the
       <code class="literal">lbaas-listener-create</code> command and giving the listener
       the name of the load balancer, the protocol, the protocol port, the name
       for the listener, the default TLS container and the SNI container.
      </p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-listener-create --loadbalancer lb --protocol-port 444 --protocol TERMINATED_HTTPS --name sni_listener --default-tls-container-ref=$(barbican secret container list | awk '/ tls_container / {print $2}') --sni-container-refs $(barbican secret container list | awk '/ tls_container2 / {print $2}’</pre></div></li><li class="step "><p>
       For each listener, create a new pool for the load balancer using the
       <code class="literal">lbaas-pool-create</code> command. Creating a new pool
       requires the load balancing algorithm, the name of the listener, the
       protocol and a name for the pool. In the example below we show the
       command for the listener named <code class="literal">listener</code>. You need to
       repeat that for the tls_listener and sni_listener as well. Make sure to
       specify different names for each pool.
      </p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-pool-create --lb-algorithm ROUND_ROBIN --listener listener --protocol HTTP --name &lt;pool name&gt;</pre></div></li><li class="step "><p>
       You can add members to the load balancer pool by running the
       <code class="literal">lbaas-member-create</code> command. The command requires the
       subnet, IP address, protocol port and the name of the pool for each
       virtual machine you would like to include into the load balancer pool. It is
       important to note that this will need to be repeated for each pool
       created above.
      </p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-member-create --subnet sub --address &lt;ip address vm1&gt; --protocol-port &lt;port&gt; &lt;pool name&gt;
neutron lbaas-member-create --subnet sub --address &lt;ip address vm2&gt; --protocol-port &lt;port&gt; &lt;pool name&gt;</pre></div></li><li class="step "><p>
       Display the current state of the load balancer and values with
       <code class="literal">lbaas-loadbalancer-show</code>.
      </p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-loadbalancer-show lb</pre></div></li><li class="step "><p>
       You need to assign the floating IP to lbaas VIP so it can be accessed
       from the external network.
      </p><div class="verbatim-wrap"><pre class="screen">fixedip_vip=$(neutron lbaas-loadbalancer-list | awk '/lb/ {print $6}')
portuuid_vip=$(neutron port-list | grep $fixedip_vip | awk '{print $2}')</pre></div></li><li class="step "><p>
       Create and associate the floating IP address to lbaas VIP address.
      </p><div class="verbatim-wrap"><pre class="screen">neutron floatingip-create ext-net --port-id $portuuid_vip</pre></div></li></ol></li></ol></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     A complete list of the Load Balancer v2 API commands can be found at:
     <a class="link" href="https://wiki.openstack.org/wiki/Neutron/LBaaS/API_2.0" target="_blank">https://wiki.openstack.org/wiki/Neutron/LBaaS/API_2.0</a>
    </p></li><li class="listitem "><p>
     Additional Load Balancer v2 API examples can be found at:
     <a class="link" href="http://docs.openstack.org/mitaka/networking-guide/adv-config-lbaas.html" target="_blank">http://docs.openstack.org/mitaka/networking-guide/adv-config-lbaas.html</a>
    </p></li><li class="listitem "><p>
     Instructions on how to terminate TLS certificates on a deployed Load
     Balancer can be found at:
     <a class="link" href="https://wiki.openstack.org/wiki/Neutron/LBaaS/API_2.0#Create_a_Listener" target="_blank">https://wiki.openstack.org/wiki/Neutron/LBaaS/API_2.0#Create_a_Listener</a>
    </p></li></ul></div><p>
   <span class="bold"><strong>Create Load Balancer v1</strong></span>
  </p><div id="id-1.7.4.7.6.17" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    v1 Load Balancers cannot be enabled with TLS.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Create the load balancer pool with <code class="literal">lb-pool-create</code>
     giving it a method, name, protocol and subnet.
    </p><div class="verbatim-wrap"><pre class="screen">neutron lb-pool-create --lb-method ROUND_ROBIN --name pool --protocol HTTP --subnet-id $(neutron subnet-list | awk '/sub/ {print $2}')</pre></div></li><li class="step "><p>
     Create load balancing members with <code class="literal">lb-member-create</code>
     providing the IP address, protocol and load balancing pool name to each
     member.
    </p><div class="verbatim-wrap"><pre class="screen">neutron lb-member-create --address &lt;ip address vm1&gt; --protocol-port &lt;port&gt; pool
neutron lb-member-create --address &lt;ip address vm2&gt; --protocol-port &lt;port&gt; pool</pre></div></li><li class="step "><p>
     Create the vip with <code class="literal">lb-vip-create</code> giving it a name,
     protocol, protocol port and a subnet.
    </p><div class="verbatim-wrap"><pre class="screen">neutron lb-vip-create --name vip --protocol-port &lt;port&gt; --protocol HTTP --subnet-id $(neutron subnet-list | awk '/sub/ {print $2}') pool</pre></div></li><li class="step "><p>
     You can check to see if the load balancer is active with
     <code class="literal">lb-vip-show</code>
    </p><div class="verbatim-wrap"><pre class="screen">neutron lb-vip-show vip</pre></div></li></ol></div></div><p>
   <span class="bold"><strong>Validate LBaaS Functionality</strong></span>
  </p><div id="id-1.7.4.7.6.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    You should perform the following steps from a node that has a route to
    the private network. Using the examples from above, 10.1.0.0/24 should be
    reachable.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     SSH into both vm1 and vm2 in two separate windows and make them listen on
     your configured port.
    </p></li><li class="step "><p>
     From one window.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@&lt;ip address vm1&gt;
pass: &lt;password&gt;</pre></div></li><li class="step "><p>
     From another window.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@&lt;ip address vm2&gt;
pass: &lt;password&gt;</pre></div></li><li class="step "><p>
     Start running web servers on both of the virtual machines.
    </p></li><li class="step "><p>
     Create a webserv.sh script with below contents. Use the &lt;port&gt; from
     the member creation step.
    </p><div class="verbatim-wrap"><pre class="screen">$ vi webserv.sh

#!/bin/bash

MYIP=$(/sbin/ifconfig eth0|grep 'inet addr'|awk -F: '{print $2}'| awk '{print $1}');
while true; do
    echo -e "HTTP/1.0 200 OK

Welcome to $MYIP" | sudo nc -l -p &lt;port&gt;
done

## Give it Exec rights
$ chmod 755 webserv.sh

## Start webserver
$ ./webserv.sh</pre></div></li><li class="step "><p>
     Open a separate window. From the respective source node in external
     network (in case of accessing LBaaS VIP thorough its FIP) or in private
     network (in case of no FIP), add the respective IP address to the no_proxy
     env variable, if required. You can get the <span class="emphasis"><em>VIP</em></span> from
     the <code class="literal">neutron lbaas-loadbalancer-list</code> for LBaaS v2 and
     <code class="literal">neutron lb-vip-list</code> for LBaaS v1.
    </p></li><li class="step "><p>
     Run the following commands to test load balancing. In this example, the
     VIP IP address is 10.1.0.7 and when executing curl against the VIP, the
     responses are returned from the load balanced services.
    </p><div class="verbatim-wrap"><pre class="screen">$ export no_proxy=$no_proxy,10.1.0.7

## Curl the VIP
$ curl 10.1.0.7
Welcome to 10.1.0.4

$ curl 10.1.0.7
Welcome to 10.1.0.5

$ curl 10.1.0.7
Welcome to 10.1.0.4</pre></div></li></ol></div></div><p>
   <span class="bold"><strong>Verify SNI</strong></span>
  </p><p>
   You can verify SNI by running the following command from a node with access
   to the private network. You can get the VIP from the neutron
   <code class="literal">lbaas-loadbalancer-list</code> for LBaaS v2.
  </p><div class="verbatim-wrap"><pre class="screen">openssl s_client -servername test2@stacme.com -connect &lt;vip of lb&gt;:444</pre></div><p>
   Certificate information will print to the screen. You should verify that the
   CN matches the CN you passed to <code class="literal">-servername</code>. In the
   example below the CN matches the servername passed from above.
  </p><div class="verbatim-wrap"><pre class="screen">subject=/CN=test2@stacme.com
issuer=/CN=ca-int-test2@stacme.com</pre></div></div><div class="sect1" id="idg-all-userguide-lbaas-xml-15"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">For More Information</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-lbaas-xml-15">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-lbaas-xml-15</li></ul></div></div></div></div><p>
   For more information on the neutron command-line interface (CLI) and load
   balancing, see the OpenStack networking command-line client reference:
   <a class="link" href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html" target="_blank">http://docs.openstack.org/cli-reference/content/neutronclient_commands.html</a>
  </p></div></div><div class="chapter " id="LBaaSHeat"><div class="titlepage"><div><div><h2 class="title"><span class="number">13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Load Balancing as a Service with Orchestration Service</span> <a title="Permalink" class="permalink" href="#LBaaSHeat">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas_heat.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas_heat.xml</li><li><span class="ds-label">ID: </span>LBaaSHeat</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#Intro"><span class="number">13.1 </span><span class="name">Orchestration Service</span></a></span></dt><dt><span class="section"><a href="#HeatSupport"><span class="number">13.2 </span><span class="name">Orchestration Service support for LBaaS v2</span></a></span></dt><dt><span class="section"><a href="#loadbalancer-limitations"><span class="number">13.3 </span><span class="name">Limitations</span></a></span></dt><dt><span class="section"><a href="#idg-all-userguide-lbaas-heat-xml-8"><span class="number">13.4 </span><span class="name">More Information</span></a></span></dt></dl></div></div><div class="sect1" id="Intro"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration Service</span> <a title="Permalink" class="permalink" href="#Intro">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas_heat.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas_heat.xml</li><li><span class="ds-label">ID: </span>Intro</li></ul></div></div></div></div><p>
   HPE Orchestration service, based on OpenStack Heat, enables the design and
   coordination of multiple composite cloud applications using templates.
  </p><p>
   You can use the Orchestration Service templates to describe and execute
   OpenStack API calls to create running cloud applications. The templates can
   be used to describe relationships and resources to help manage your cloud
   infrastructure and can also help you with the creation of resource types.
  </p></div><div class="sect1" id="HeatSupport"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration Service support for LBaaS v2</span> <a title="Permalink" class="permalink" href="#HeatSupport">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas_heat.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas_heat.xml</li><li><span class="ds-label">ID: </span>HeatSupport</li></ul></div></div></div></div><p>
   In <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span>, the Orchestration Service provides support for LBaaS
   v2, which means users can create LBaaS v2 resources using Orchestration.
  </p><p>
   The OpenStack documentation for LBaaSv2 resource plugins is available at
   following locations.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Neutron LBaaS v2 LoadBalancer:
     <a class="link" href="http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::LoadBalancer" target="_blank">http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::LoadBalancer</a>
    </p></li><li class="listitem "><p>
     Neutron LBaaS v2 Listener:
     <a class="link" href="http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::Listener" target="_blank">http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::Listener</a>
    </p></li><li class="listitem "><p>
     Neutron LBaaS v2 Pool:
     <a class="link" href="http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::Pool" target="_blank">http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::Pool</a>
    </p></li><li class="listitem "><p>
     Neutron LBaaS v2 Pool Member:
     <a class="link" href="http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::PoolMember" target="_blank">http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::PoolMember</a>
    </p></li><li class="listitem "><p>
     Neutron LBaaS v2 Health Monitor:
     <a class="link" href="http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::HealthMonitor" target="_blank">http://docs.openstack.org/developer/heat/template_guide/openstack.html#OS::Neutron::LBaaS::HealthMonitor</a>
    </p></li></ul></div></div><div class="sect1" id="loadbalancer-limitations"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Limitations</span> <a title="Permalink" class="permalink" href="#loadbalancer-limitations">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas_heat.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas_heat.xml</li><li><span class="ds-label">ID: </span>loadbalancer-limitations</li></ul></div></div></div></div><p>
   In order to avoid stack-create timeouts when using load balancers, it is
   recommended that no more than 100 load balancers be created at a time using
   stack-create loops. Larger numbers of load balancers could reach quotas
   and/or exhaust resources resulting in the stack create-timeout.
  </p></div><div class="sect1" id="idg-all-userguide-lbaas-heat-xml-8"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">More Information</span> <a title="Permalink" class="permalink" href="#idg-all-userguide-lbaas-heat-xml-8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/userguide-lbaas_heat.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>userguide-lbaas_heat.xml</li><li><span class="ds-label">ID: </span>idg-all-userguide-lbaas-heat-xml-8</li></ul></div></div></div></div><p>
   For more information on configuring and using the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Load Balancing as
   a Service, see: <span class="intraxref">Book “Operations Guide”, Chapter 9 “Managing Networking”, Section 9.3 “Networking Service Overview”, Section 9.3.8 “Configuring Load Balancing as a Service (LBaaS)”</span> and
   <a class="xref" href="#HP2-0LBaaS" title="Chapter 12. Using Load Balancing as a Service (LBaaS)">Chapter 12, <em>Using Load Balancing as a Service (LBaaS)</em></a>.
  </p><p>
   For more information on the neutron command-line interface (CLI) and load
   balancing, see the OpenStack networking command-line client reference:
   <a class="link" href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html" target="_blank">http://docs.openstack.org/cli-reference/content/neutronclient_commands.html</a>
  </p><p>
   For more information on Heat see:
   <a class="link" href="http://docs.openstack.org/developer/heat" target="_blank">http://docs.openstack.org/developer/heat</a>
  </p></div></div><div class="chapter " id="HP2-0FWaaS"><div class="titlepage"><div><div><h2 class="title"><span class="number">14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Firewall as a Service (FWaaS)</span> <a title="Permalink" class="permalink" href="#HP2-0FWaaS">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-fwaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-fwaas.xml</li><li><span class="ds-label">ID: </span>HP2-0FWaaS</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-networking-fwaas-xml-8"><span class="number">14.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="section"><a href="#idg-all-networking-fwaas-xml-9"><span class="number">14.2 </span><span class="name"><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> FWaaS Configuration</span></a></span></dt><dt><span class="section"><a href="#sec-hp20fwaas-more"><span class="number">14.3 </span><span class="name">More Information</span></a></span></dt></dl></div></div><p>
  The Firewall as a Service (FWaaS) provides the ability to assign
  network-level, port security for all traffic entering and existing a tenant
  network. More information on this service can be found via the public
  OpenStack documentation located at
  <a class="link" href="http://specs.openstack.org/openstack/neutron-specs/specs/api/firewall_as_a_service__fwaas_.html" target="_blank">http://specs.openstack.org/openstack/neutron-specs/specs/api/firewall_as_a_service__fwaas_.html</a>.
  The following documentation provides command-line interface example
  instructions for configuring and testing a firewall. The Firewall as a
  Service can also be configured and managed by the Horizon web interface.
 </p><p>
  FWaaS is implemented directly in the L3 agent
  (<span class="emphasis"><em>neutron-l3-agent</em></span>), however if VPNaaS is enabled, FWaaS
  is implemented in the VPNaaS agent (<span class="emphasis"><em>neutron-vpn-agent</em></span>).
  Because FWaaS does not use a separate agent process or start a specific
  service, there currently are no Monasca alarms for it.
 </p><p>
  If DVR is enabled, the firewall service currently does not filter traffic
  between OpenStack private networks, also known as <span class="emphasis"><em>east-west
  traffic</em></span> and will only filter traffic from external networks, also
  known as <span class="emphasis"><em>north-south traffic</em></span>.
 </p><div class="sect1" id="idg-all-networking-fwaas-xml-8"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-networking-fwaas-xml-8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-fwaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-fwaas.xml</li><li><span class="ds-label">ID: </span>idg-all-networking-fwaas-xml-8</li></ul></div></div></div></div><p>
   <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> must be installed.
  </p></div><div class="sect1" id="idg-all-networking-fwaas-xml-9"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name"><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> FWaaS Configuration</span> <a title="Permalink" class="permalink" href="#idg-all-networking-fwaas-xml-9">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-fwaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-fwaas.xml</li><li><span class="ds-label">ID: </span>idg-all-networking-fwaas-xml-9</li></ul></div></div></div></div><p>
   <span class="bold"><strong>Check for an enabled firewall.</strong></span>
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     You should check to determine if the firewall is enabled. The output of
     the <span class="emphasis"><em>neutron ext-list</em></span> should contain a firewall entry.
    </p><div class="verbatim-wrap"><pre class="screen">neutron ext-list</pre></div></li><li class="listitem "><p>
     Assuming the external network is already created by the admin, this
     command will show the external network.
    </p><div class="verbatim-wrap"><pre class="screen">neutron net-list</pre></div></li></ol></div><p>
   <span class="bold"><strong>Create required assets.</strong></span>
  </p><p>
   Before creating firewalls, you will need to create a network, subnet,
   router, security group rules, start an instance and assign it a floating IP
   address.
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Create the network, subnet and router.
    </p><div class="verbatim-wrap"><pre class="screen">neutron net-create private
neutron subnet-create --name sub private 10.0.0.0/24 --gateway 10.0.0.1
neutron router-create router
neutron router-interface-add router sub
neutron router-gateway-set router ext-net</pre></div></li><li class="listitem "><p>
     Create security group rules. Security group rules filter traffic at VM
     level.
    </p><div class="verbatim-wrap"><pre class="screen">neutron security-group-rule-create default --protocol icmp
neutron security-group-rule-create default --protocol tcp --port-range-min 22 --port-range-max 22
neutron security-group-rule-create default --protocol tcp --port-range-min 80 --port-range-max 80</pre></div></li><li class="listitem "><p>
     Boot a VM.
    </p><div class="verbatim-wrap"><pre class="screen">NET=$(neutron net-list | awk '/private/ {print $2}')
nova boot --flavor 1 --image &lt;image&gt; --nic net-id=$NET vm1 --poll</pre></div></li><li class="listitem "><p>
     Verify if the instance is ACTIVE and is assigned an IP address.
    </p><div class="verbatim-wrap"><pre class="screen">nova list</pre></div></li><li class="listitem "><p>
     Get the port id of the vm1 instance.
    </p><div class="verbatim-wrap"><pre class="screen">fixedip=$(nova list | awk '/vm1/ {print $12}' | awk -F '=' '{print $2}' | awk -F ',' '{print $1}')
vmportuuid=$(neutron port-list | grep $fixedip | awk '{print $2}')</pre></div></li><li class="listitem "><p>
     Create and associate a floating IP address to the vm1 instance.
    </p><div class="verbatim-wrap"><pre class="screen">neutron floatingip-create ext-net --port-id $vmportuuid</pre></div></li><li class="listitem "><p>
     Verify if the floating IP is assigned to the instance. The following
     command should show an assigned floating IP address from the external
     network range.
    </p><div class="verbatim-wrap"><pre class="screen">nova show vm1</pre></div></li><li class="listitem "><p>
     Verify if the instance is reachable from the external network. SSH into
     the instance from a node in (or has route to) the external network.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@FIP-VM1
password: &lt;password&gt;</pre></div></li></ol></div><p>
   <span class="bold"><strong>Create and attach the firewall.</strong></span>
  </p><div id="id-1.7.4.9.6.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    By default, an internal "drop all" rule is enabled in IP tables if none of
    the defined rules match the real-time data packets.
   </p></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Create new firewall rules using <code class="literal">firewall-rule-create</code>
     command and providing the protocol, action (allow, deny, reject) and name
     for the new rule.
    </p><p>
     Firewall actions provide rules in which data traffic can be handled. An
     <span class="bold"><strong>allow</strong></span> rule will allow traffic to pass
     through the firewall,
     <span class="bold"><strong>deny</strong></span>
     will stop and prevent data traffic from passing through the firewall and
     <span class="bold"><strong>reject</strong></span>
     will reject the data traffic and return a
     <span class="emphasis"><em>destination-unreachable</em></span> response. Using
     <span class="bold"><strong>reject</strong></span> will speed up failure detection
     time dramatically for legitimate users, since they will not be required to
     wait for retransmission timeouts or submit retries. Some customers should
     stick with <span class="bold"><strong>deny</strong></span> where prevention of port
     scanners and similar methods may be attempted by hostile attackers. Using
     <span class="bold"><strong>deny</strong></span>
     will drop all of the packets, making it more difficult for malicious
     intent. The firewall action, <span class="bold"><strong>deny</strong></span> is the
     default behavior.
    </p><p>
     The example below demonstrates how to allow icmp and ssh while denying
     access to http. See the <code class="literal">neutron</code> command-line reference
     at <a class="link" href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html" target="_blank">http://docs.openstack.org/cli-reference/content/neutronclient_commands.html</a>
     on additional options such as source IP, destination IP, source port and
     destination port.
    </p><div id="id-1.7.4.9.6.9.1.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      You can create a firewall rule with an identical name and each instance
      will have a unique id associated with the created rule, however for
      clarity purposes this is not recommended.
     </p></div><div class="verbatim-wrap"><pre class="screen">neutron firewall-rule-create --protocol icmp --action allow --name allow-icmp
neutron firewall-rule-create --protocol tcp --destination-port 80 --action deny --name deny-http
neutron firewall-rule-create --protocol tcp --destination-port 22 --action allow --name allow-ssh</pre></div></li><li class="listitem "><p>
     Once the rules are created, create the firewall policy by using the
     <code class="literal">firewall-policy-create</code> command with the
     <code class="literal">--firewall-rules</code> option and rules to include in quotes,
     followed by the name of the new policy. The order of the rules is
     important.
    </p><div class="verbatim-wrap"><pre class="screen">neutron firewall-policy-create --firewall-rules "allow-icmp deny-http allow-ssh" policy-fw</pre></div></li><li class="listitem "><p>
     Finish the firewall creation by using the
     <code class="literal">firewall-create</code> command, the policy name and the new
     name you want to give to your new firewall.
    </p><div class="verbatim-wrap"><pre class="screen">neutron firewall-create policy-fw --name user-fw</pre></div></li><li class="listitem "><p>
     You can view the details of your new firewall by using the
     <code class="literal">firewall-show</code> command and the name of your firewall.
     This will verify that the status of the firewall is ACTIVE.
    </p><div class="verbatim-wrap"><pre class="screen">neutron firewall-show user-fw</pre></div></li></ol></div><p>
   <span class="bold"><strong>Verify the FWaaS is functional.</strong></span>
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     Since allow-icmp firewall rule is set you can ping the floating IP address
     of the instance from the external network.
    </p><div class="verbatim-wrap"><pre class="screen">ping &lt;FIP-VM1&gt;</pre></div></li><li class="listitem "><p>
     Similarly, you can connect via ssh to the instance due to the allow-ssh
     firewall rule.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@&lt;FIP-VM1&gt;
password: &lt;password&gt;</pre></div></li><li class="listitem "><p>
     Run a web server on vm1 instance that listens over port 80, accepts
     requests and sends a WELCOME response.
    </p><div class="verbatim-wrap"><pre class="screen">$ vi webserv.sh

#!/bin/bash

MYIP=$(/sbin/ifconfig eth0|grep 'inet addr'|awk -F: '{print $2}'| awk '{print $1}');
while true; do
  echo -e "HTTP/1.0 200 OK

Welcome to $MYIP" | sudo nc -l -p 80
done

# Give it Exec rights
$ chmod 755 webserv.sh

# Execute the script
$ ./webserv.sh</pre></div></li><li class="listitem "><p>
     You should expect to see curl fail over port 80 because of the deny-http
     firewall rule. If curl succeeds, the firewall is not blocking incoming
     http requests.
    </p><div class="verbatim-wrap"><pre class="screen">curl -vvv &lt;FIP-VM1&gt;</pre></div></li></ol></div><div id="id-1.7.4.9.6.12" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
    When using reference implementation, new networks, FIPs and routers created
    after the Firewall creation will not be automatically updated with firewall
    rules. Thus, execute the firewall-update command by passing the current and
    new router Ids such that the rules are reconfigured across all the routers
    (both current and new).
   </p><p>
    For example if router-1 is created before and router-2 is created after the
    firewall creation
   </p><div class="verbatim-wrap"><pre class="screen">$ neutron firewall-update —router &lt;router-1-id&gt; —router &lt;router-2-id&gt; &lt;firewall-name&gt;</pre></div></div></div><div class="sect1" id="sec-hp20fwaas-more"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">More Information</span> <a title="Permalink" class="permalink" href="#sec-hp20fwaas-more">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-fwaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-fwaas.xml</li><li><span class="ds-label">ID: </span>sec-hp20fwaas-more</li></ul></div></div></div></div><p>
   Firewalls are based in IPtable settings.
  </p><p>
   Each firewall that is created is known as an instance.
  </p><p>
   A firewall instance can be deployed on selected project routers. If no
   specific project router is selected, a firewall instance is automatically
   applied to all project routers.
  </p><p>
   Only 1 firewall instance can be applied to a project router.
  </p><p>
   Only 1 firewall policy can be applied to a firewall instance.
  </p><p>
   Multiple firewall rules can be added and applied to a firewall policy.
  </p><p>
   Firewall rules can be shared across different projects via the Share API
   flag.
  </p><p>
   Firewall rules supersede the Security Group rules that are applied at the
   Instance level for all traffic entering or leaving a private, project
   network.
  </p><p>
   For more information on the neutron command-line interface (CLI) and
   firewalls, see the OpenStack networking command-line client reference:
   <a class="link" href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html" target="_blank">http://docs.openstack.org/cli-reference/content/neutronclient_commands.html</a>
  </p></div></div><div class="chapter " id="UsingVPNaaS"><div class="titlepage"><div><div><h2 class="title"><span class="number">15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using VPN as a Service (VPNaaS)</span> <a title="Permalink" class="permalink" href="#UsingVPNaaS">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-vpnaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-vpnaas.xml</li><li><span class="ds-label">ID: </span>UsingVPNaaS</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#idg-all-networking-vpnaas-xml-7"><span class="number">15.1 </span><span class="name">Prerequisites</span></a></span></dt><dt><span class="section"><a href="#Considerations"><span class="number">15.2 </span><span class="name">Considerations</span></a></span></dt><dt><span class="section"><a href="#idg-all-networking-vpnaas-xml-9"><span class="number">15.3 </span><span class="name">Configuration</span></a></span></dt><dt><span class="section"><a href="#sec-vpnaas-more"><span class="number">15.4 </span><span class="name">More Information</span></a></span></dt></dl></div></div><p>
  <span class="bold"><strong><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> VPNaaS Configuration</strong></span>
 </p><p>
  This document describes the configuration process and requirements for the
  <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> <span class="phrase"><span class="phrase">8</span></span> Virtual Private Network (VPN) as a Service module.
 </p><div class="sect1" id="idg-all-networking-vpnaas-xml-7"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prerequisites</span> <a title="Permalink" class="permalink" href="#idg-all-networking-vpnaas-xml-7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-vpnaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-vpnaas.xml</li><li><span class="ds-label">ID: </span>idg-all-networking-vpnaas-xml-7</li></ul></div></div></div></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> must be installed.
    </p></li><li class="listitem "><p>
     Before setting up VPNaaS, you will need to have created an external
     network and a subnet with access to the internet. Information on how to
     create the external network and subnet can be found in
     <a class="xref" href="#sec-vpnaas-more" title="15.4. More Information">Section 15.4, “More Information”</a>.
    </p></li><li class="listitem "><p>
     You should assume 172.16.0.0/16 as the ext-net CIDR in this document.
    </p></li></ol></div></div><div class="sect1" id="Considerations"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Considerations</span> <a title="Permalink" class="permalink" href="#Considerations">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-vpnaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-vpnaas.xml</li><li><span class="ds-label">ID: </span>Considerations</li></ul></div></div></div></div><p>
   Using the Neutron plugin-based VPNaaS causes additional processes to be run
   on the Network Service Nodes. One of these processes, the ipsec charon
   process from StrongSwan, runs as root and listens on an external network. A
   vulnerability in that process can lead to remote root compromise of the
   Network Service Nodes. If this is a concern customers should consider using
   a VPN solution other than the Neutron plugin-based VPNaaS and/or deploying
   additional protection mechanisms.
  </p></div><div class="sect1" id="idg-all-networking-vpnaas-xml-9"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#idg-all-networking-vpnaas-xml-9">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-vpnaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-vpnaas.xml</li><li><span class="ds-label">ID: </span>idg-all-networking-vpnaas-xml-9</li></ul></div></div></div></div><p>
   <span class="bold"><strong>Setup Networks</strong></span> You can setup VPN as a
   Service (VPNaaS) by first creating networks, subnets and routers using the
   <code class="literal">neutron</code> command line. The VPNaaS module enables the
   ability to extend access between private networks across two different
   <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> clouds or between a <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> cloud and a non-cloud network. VPNaaS
   is based on the open source software application called StrongSwan.
   StrongSwan (more information available
   at <a class="link" href="http://www.strongswan.org/" target="_blank">http://www.strongswan.org/</a>)
   is an IPsec implementation and provides basic VPN gateway functionality.
  </p><div id="id-1.7.4.10.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    You can execute the included commands from any shell with access to the
    service APIs. In the included examples, the commands are executed from the
    lifecycle manager, however you could execute the commands from the
    controller node or any other shell with aforementioned service API access.
   </p></div><div id="id-1.7.4.10.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    The use of floating IP's is not possible with the current version of
    VPNaaS when DVR is enabled. Ensure that no floating IP is associated to
    instances that will be using VPNaaS when using a DVR router. Floating IP
    associated to instances are ok when using CVR router.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     From the Cloud Lifecycle Manager, create first private network, subnet and
     router assuming that <span class="emphasis"><em>ext-net</em></span> is created by admin.
    </p><div class="verbatim-wrap"><pre class="screen">neutron net-create privateA
neutron subnet-create --name subA privateA 10.1.0.0/24 --gateway 10.1.0.1
neutron router-create router1
neutron router-interface-add router1 subA
neutron router-gateway-set router1 ext-net</pre></div></li><li class="step "><p>
     Create second private network, subnet and router.
    </p><div class="verbatim-wrap"><pre class="screen">neutron net-create privateB
neutron subnet-create --name subB privateB 10.2.0.0/24 --gateway 10.2.0.1
neutron router-create router2
neutron router-interface-add router2 subB
neutron router-gateway-set router2 ext-net</pre></div></li></ol></div></div><div class="procedure " id="pro-vpnaas-start"><div class="procedure-title-wrap"><h6 class="procedure-title"><span class="number">Procedure 15.1: </span><span class="name">Starting Virtual Machines </span><a title="Permalink" class="permalink" href="#pro-vpnaas-start">#</a></h6></div><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     From the Cloud Lifecycle Manager run the following to start the virtual
     machines. Begin with adding secgroup rules for SSH and ICMP.
    </p><div class="verbatim-wrap"><pre class="screen">neutron security-group-rule-create default --protocol icmp
neutron security-group-rule-create default --protocol tcp --port-range-min 22 --port-range-max 22</pre></div></li><li class="step "><p>
     Start the virtual machine in the privateA subnet. Using <span class="emphasis"><em>nova
     images-list</em></span>, use the image id to boot image instead of the
     image name. After executing this step, it is recommended that you wait
     approximately 10 seconds to allow the virtual machine to become active.
    </p><div class="verbatim-wrap"><pre class="screen">NETA=$(neutron net-list | awk '/privateA/ {print $2}')
nova boot --flavor 1 --image &lt;id&gt; --nic net-id=$NETA vm1</pre></div></li><li class="step "><p>
     Start the virtual machine in the privateB subnet.
    </p><div class="verbatim-wrap"><pre class="screen">NETB=$(neutron net-list | awk '/privateB/ {print $2}')
nova boot --flavor 1 --image &lt;id&gt; --nic net-id=$NETB vm2</pre></div></li><li class="step " id="st-vpnaas-obtain-ip"><p>
     Verify private IP's are allocated to the respective vms. Take note of IP's
     for later use.
    </p><div class="verbatim-wrap"><pre class="screen">nova show vm1
nova show vm2</pre></div></li></ol></div></div><div class="procedure " id="id-1.7.4.10.6.7"><div class="procedure-title-wrap"><h6 class="procedure-title"><span class="number">Procedure 15.2: </span><span class="name">Create VPN </span><a title="Permalink" class="permalink" href="#id-1.7.4.10.6.7">#</a></h6></div><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     You can set up the VPN by executing the below commands from the lifecycle
     manager or any shell with access to the service APIs. Begin with creating
     the policies with <code class="literal">vpn-ikepolicy-create</code> and
     <code class="literal">vpn-ipsecpolicy-create </code>.
    </p><div class="verbatim-wrap"><pre class="screen">neutron vpn-ikepolicy-create ikepolicy
neutron vpn-ipsecpolicy-create ipsecpolicy</pre></div></li><li class="step "><p>
     Create the VPN service at router1.
    </p><div class="verbatim-wrap"><pre class="screen">neutron vpn-service-create --name myvpnA --description "My vpn service" router1 subA</pre></div></li><li class="step "><p>
     Wait at least 5 seconds and then run
     <code class="literal">ipsec-site-connection-create</code> to create a ipsec-site
     connection. Note that <code class="literal">--peer-address</code> is the assign
     ext-net IP from router2 and <code class="literal">--peer-cidr</code> is subB cidr.
    </p><div class="verbatim-wrap"><pre class="screen">neutron ipsec-site-connection-create --name vpnconnection1 --vpnservice-id myvpnA \
--ikepolicy-id ikepolicy --ipsecpolicy-id ipsecpolicy --peer-address 172.16.0.3 \
--peer-id 172.16.0.3 --peer-cidr 10.2.0.0/24 --psk secret</pre></div></li><li class="step "><p>
     Create the VPN service at router2.
    </p><div class="verbatim-wrap"><pre class="screen">neutron vpn-service-create --name myvpnB --description "My vpn serviceB" router2 subB</pre></div></li><li class="step "><p>
     Wait at least 5 seconds and then run
     <code class="literal">ipsec-site-connection-create</code> to create a ipsec-site
     connection. Note that <code class="literal">--peer-address</code> is the assigned
     ext-net IP from router1 and <code class="literal">--peer-cidr</code> is subA cidr.
    </p><div class="verbatim-wrap"><pre class="screen">neutron ipsec-site-connection-create --name vpnconnection2 --vpnservice-id myvpnB \
--ikepolicy-id ikepolicy --ipsecpolicy-id ipsecpolicy --peer-address 172.16.0.2 \
--peer-id 172.16.0.2 --peer-cidr 10.1.0.0/24 --psk secret</pre></div></li><li class="step "><p>
     On the Cloud Lifecycle Manager, run the
     <code class="literal">ipsec-site-connection-list</code> command to see the active
     connections. Be sure to check that the vpn_services are ACTIVE. You can
     check this by running <code class="literal">vpn-service-list</code> and then
     checking ipsec-site-connections status. You should expect that the time
     for both vpn-services and ipsec-site-connections to become ACTIVE could
     take as long as 1 to 3 minutes.
    </p><div class="verbatim-wrap"><pre class="screen">neutron ipsec-site-connection-list
+--------------------------------------+----------------+--------------+---------------+------------+-----------+--------+
| id                                   | name           | peer_address | peer_cidrs    | route_mode | auth_mode | status |
+--------------------------------------+----------------+--------------+---------------+------------+-----------+--------+
| 1e8763e3-fc6a-444c-a00e-426a4e5b737c | vpnconnection2 | 172.16.0.2   | "10.1.0.0/24" | static     | psk       | ACTIVE |
| 4a97118e-6d1d-4d8c-b449-b63b41e1eb23 | vpnconnection1 | 172.16.0.3   | "10.2.0.0/24" | static     | psk       | ACTIVE |
+--------------------------------------+----------------+--------------+---------------+------------+-----------+--------+</pre></div></li></ol></div></div><p>
   <span class="bold"><strong>Verify VPN</strong></span> In the case of non-admin users,
   you can verify the VPN connection by pinging the virtual machines.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Check the VPN connections.
    </p><div id="id-1.7.4.10.6.9.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      vm1-ip and vm2-ip denotes private IP's for vm1 and vm2 respectively.
      The private IPs are obtained, as described in of
      <a class="xref" href="#st-vpnaas-obtain-ip" title="Step 4">Step 4</a>. If you are unable to SSH to the
      private network due to a lack
      of direct access, the VM console can be accessed through Horizon.
     </p></div><div class="verbatim-wrap"><pre class="screen">ssh cirros@vm1-ip
password: &lt;password&gt;

# ping the private IP address of vm2
ping ###.###.###.###</pre></div></li><li class="step "><p>
     In another terminal.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@vm2-ip
password: &lt;password&gt;

# ping the private IP address of vm1
ping ###.###.###.###</pre></div></li><li class="step "><p>
     You should see ping responses from both virtual machines.
    </p></li></ol></div></div><p>
   As the admin user, you should check to make sure that a route exists between
   the router gateways. Once the gateways have been checked, packet encryption
   can be verified by using traffic analyzer (tcpdump) by tapping on the
   respective namespace (qrouter-* in case of non-DVR and snat-* in case of
   DVR) and tapping the right interface (qg-***).
  </p><div id="id-1.7.4.10.6.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    When using DVR namespaces, all the occurrences of qrouter-xxxxxx in the
    following commands should be replaced with respective snat-xxxxxx.
   </p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Check the if the route exists between two router gateways. You can get the
     right qrouter namespace id by executing <span class="emphasis"><em>sudo ip
     netns</em></span>. Once you have the qrouter namespace id, you can get the
     interface by executing <span class="emphasis"><em>sudo ip netns qrouter-xxxxxxxx ip
     addr</em></span> and from the result the interface can be found.
    </p><div class="verbatim-wrap"><pre class="screen">sudo ip netns
sudo ip netns exec qrouter-&lt;router1 UUID&gt; ping &lt;router2 gateway&gt;
sudo ip netns exec qrouter-&lt;router2 UUID&gt; ping &lt;router1 gateway&gt;</pre></div></li><li class="step "><p>
     Initiate a tcpdump on the interface.
    </p><div class="verbatim-wrap"><pre class="screen">sudo ip netns exec qrouter-xxxxxxxx tcpdump -i qg-xxxxxx</pre></div></li><li class="step "><p>
     Check the VPN connection.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@vm1-ip
password: &lt;password&gt;

# ping the private IP address of vm2
ping ###.###.###.###</pre></div></li><li class="step "><p>
     Repeat for other namespace and right tap interface.
    </p><div class="verbatim-wrap"><pre class="screen">sudo ip netns exec qrouter-xxxxxxxx tcpdump -i qg-xxxxxx</pre></div></li><li class="step "><p>
     In another terminal.
    </p><div class="verbatim-wrap"><pre class="screen">ssh cirros@vm2-ip
password: &lt;password&gt;

# ping the private IP address of vm1
ping ###.###.###.###</pre></div></li><li class="step "><p>
     You will find encrypted packets containing ‘ESP’ in the tcpdump trace.
    </p></li></ol></div></div></div><div class="sect1" id="sec-vpnaas-more"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">More Information</span> <a title="Permalink" class="permalink" href="#sec-vpnaas-more">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/develop/xml/networking-vpnaas.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>networking-vpnaas.xml</li><li><span class="ds-label">ID: </span>sec-vpnaas-more</li></ul></div></div></div></div><p>
   VPNaaS currently only supports Pre-shared Keys (PSK) security between VPN
   gateways. A different VPN gateway solution should be considered if stronger,
   certificate-based security is required.
  </p><p>
   For more information on the neutron command-line interface (CLI) and VPN as
   a Service (VPNaaS), see the OpenStack networking command-line client
   reference:
   <a class="link" href="http://docs.openstack.org/cli-reference/content/neutronclient_commands.html" target="_blank">http://docs.openstack.org/cli-reference/content/neutronclient_commands.html</a>
  </p><p>
   For information on how to create an external network and subnet, see the
   OpenStack manual:
   <a class="link" href="http://docs.openstack.org/user-guide/dashboard_create_networks.html" target="_blank">http://docs.openstack.org/user-guide/dashboard_create_networks.html</a>
  </p></div></div></div></div></div><div class="page-bottom"><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2021 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>