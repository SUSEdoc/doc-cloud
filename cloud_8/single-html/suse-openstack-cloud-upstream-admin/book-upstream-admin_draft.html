<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>OpenStack Administrator Guide | SUSE OpenStack Cloud 8</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.0.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.0.17 (based on DocBook XSL Stylesheets 1.79.2)" /><meta name="product-name" content="SUSE OpenStack Cloud" /><meta name="product-number" content="8" /><meta name="book-title" content="OpenStack Administrator Guide" /><meta name="description" content="Abstract" /><meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi" /><meta name="tracker-type" content="bsc" /><meta name="tracker-bsc-component" content="Documentation" /><meta name="tracker-bsc-product" content="SUSE OpenStack Cloud 8" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css"></link>');
}
else {
  document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft single offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #FABEBE;"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs inactive"><a class="single-crumb" href="#book-upstream-admin" accesskey="c"><span class="single-contents-icon"></span>OpenStack Administrator Guide</a><div class="bubble-corner active-contents"></div></div><div class="clearme"></div></div></div><div id="_fixed-header-wrap" style="background-color: #FABEBE;" class="inactive"><div id="_fixed-header"><div class="crumbs inactive"><a class="single-crumb" href="#book-upstream-admin" accesskey="c"><span class="single-contents-icon"></span>Show Contents: OpenStack Administrator Guide</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="clearme"></div></div><div class="clearme"></div></div><div class="active-contents bubble"><div class="bubble-container"><div id="_bubble-toc"><ol><li class="inactive"><a href="#id-1.4.3"><span class="number">1 </span><span class="name">Documentation Conventions</span></a></li><li class="inactive"><a href="#id-1.4.4"><span class="number">2 </span><span class="name">Get started with OpenStack</span></a></li><li class="inactive"><a href="#cha-identity"><span class="number">3 </span><span class="name">Identity management</span></a></li><li class="inactive"><a href="#id-1.4.6"><span class="number">4 </span><span class="name">Dashboard</span></a></li><li class="inactive"><a href="#id-1.4.7"><span class="number">5 </span><span class="name">Compute</span></a></li><li class="inactive"><a href="#id-1.4.8"><span class="number">6 </span><span class="name">Object Storage</span></a></li><li class="inactive"><a href="#id-1.4.9"><span class="number">7 </span><span class="name">Block Storage</span></a></li><li class="inactive"><a href="#id-1.4.10"><span class="number">8 </span><span class="name">Shared File Systems</span></a></li><li class="inactive"><a href="#networking"><span class="number">9 </span><span class="name">Networking</span></a></li><li class="inactive"><a href="#id-1.4.12"><span class="number">10 </span><span class="name">Telemetry</span></a></li><li class="inactive"><a href="#id-1.4.13"><span class="number">11 </span><span class="name">Database</span></a></li><li class="inactive"><a href="#id-1.4.14"><span class="number">12 </span><span class="name">Bare Metal</span></a></li><li class="inactive"><a href="#id-1.4.15"><span class="number">13 </span><span class="name">Orchestration</span></a></li><li class="inactive"><a href="#osadm-os-cli"><span class="number">14 </span><span class="name">OpenStack command-line clients</span></a></li><li class="inactive"><a href="#id-1.4.17"><span class="number">15 </span><span class="name">Cross-project features</span></a></li><li class="inactive"><a href="#id-1.4.18"><span class="number">16 </span><span class="name">Appendix</span></a></li><li class="inactive"><a href="#id-1.4.19"><span class="number"> </span><span class="name">Glossary</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_toc-bubble-wrap"></div><div id="_content" class="draft "><div class="documentation"><div xml:lang="en" class="book" id="book-upstream-admin" lang="en"><div class="titlepage"><div><h6 class="version-info"><span class="productname ">SUSE OpenStack Cloud</span> <span class="productnumber ">8</span></h6><div><h1 class="title">OpenStack Administrator Guide <a title="Permalink" class="permalink" href="#book-upstream-admin">#</a></h1></div><div class="abstract "><div class="abstract-title-wrap"><h6 class="abstract-title">Abstract<a title="Permalink" class="permalink" href="#id-1.4.2.1">#</a></h6></div><p>OpenStack offers open source software for OpenStack administrators to
manage and troubleshoot an OpenStack cloud.</p><p>This guide documents OpenStack Newton and Mitaka releases.</p></div><div class="date"><span class="imprint-label">Publication Date: </span>10/21/2020</div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#id-1.4.3"><span class="number">1 </span><span class="name">Documentation Conventions</span></a></span></dt><dt><span class="chapter"><a href="#id-1.4.4"><span class="number">2 </span><span class="name">Get started with OpenStack</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#get-started-conceptual-architecture"><span class="number">2.1 </span><span class="name">Conceptual architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.4.8"><span class="number">2.2 </span><span class="name">Logical architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.4.9"><span class="number">2.3 </span><span class="name">OpenStack services</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.4.10"><span class="number">2.4 </span><span class="name">Feedback</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#cha-identity"><span class="number">3 </span><span class="name">Identity management</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.5.4"><span class="number">3.1 </span><span class="name">Identity concepts</span></a></span></dt><dt><span class="sect1"><a href="#cha-certificates-pki"><span class="number">3.2 </span><span class="name">Certificates for PKI</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.6"><span class="number">3.3 </span><span class="name">Domain-specific configuration</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.7"><span class="number">3.4 </span><span class="name">External authentication with Identity</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.8"><span class="number">3.5 </span><span class="name">Integrate Identity with LDAP</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.9"><span class="number">3.6 </span><span class="name">Keystone tokens</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.10"><span class="number">3.7 </span><span class="name">Configure Identity service for token binding</span></a></span></dt><dt><span class="sect1"><a href="#cha-fernet-faq"><span class="number">3.8 </span><span class="name">Fernet - Frequently Asked Questions</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.12"><span class="number">3.9 </span><span class="name">Use trusts</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.13"><span class="number">3.10 </span><span class="name">Caching layer</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.14"><span class="number">3.11 </span><span class="name">Security compliance and PCI-DSS</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.15"><span class="number">3.12 </span><span class="name">Example usage and Identity features</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.16"><span class="number">3.13 </span><span class="name">Authentication middleware with user name and password</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.17"><span class="number">3.14 </span><span class="name">Identity API protection with role-based access control (RBAC)</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.18"><span class="number">3.15 </span><span class="name">Troubleshoot the Identity service</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.6"><span class="number">4 </span><span class="name">Dashboard</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.6.5"><span class="number">4.1 </span><span class="name">Customize and configure the Dashboard</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.6"><span class="number">4.2 </span><span class="name">Set up session storage for the Dashboard</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.7"><span class="number">4.3 </span><span class="name">Create and manage images</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.8"><span class="number">4.4 </span><span class="name">Create and manage roles</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.9"><span class="number">4.5 </span><span class="name">Manage instances</span></a></span></dt><dt><span class="sect1"><a href="#osadm-manage-flavor"><span class="number">4.6 </span><span class="name">Manage flavors</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.11"><span class="number">4.7 </span><span class="name">Manage volumes and volume types</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.12"><span class="number">4.8 </span><span class="name">Manage shares and share types</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.13"><span class="number">4.9 </span><span class="name">View and manage quotas</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.14"><span class="number">4.10 </span><span class="name">View cloud resources</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.15"><span class="number">4.11 </span><span class="name">Create and manage host aggregates</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.16"><span class="number">4.12 </span><span class="name">Launch and manage stacks using the Dashboard</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.7"><span class="number">5 </span><span class="name">Compute</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.7.5"><span class="number">5.1 </span><span class="name">System architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.6"><span class="number">5.2 </span><span class="name">Images and instances</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.7"><span class="number">5.3 </span><span class="name">Networking with nova-network</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.8"><span class="number">5.4 </span><span class="name">System administration</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.9"><span class="number">5.5 </span><span class="name">Troubleshoot Compute</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.8"><span class="number">6 </span><span class="name">Object Storage</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.8.3"><span class="number">6.1 </span><span class="name">Introduction to Object Storage</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.4"><span class="number">6.2 </span><span class="name">Features and benefits</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.5"><span class="number">6.3 </span><span class="name">Object Storage characteristics</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.6"><span class="number">6.4 </span><span class="name">Components</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.7"><span class="number">6.5 </span><span class="name">Ring-builder</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.8"><span class="number">6.6 </span><span class="name">Cluster architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.9"><span class="number">6.7 </span><span class="name">Replication</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.10"><span class="number">6.8 </span><span class="name">Large object support</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.11"><span class="number">6.9 </span><span class="name">Object Auditor</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.12"><span class="number">6.10 </span><span class="name">Erasure coding</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.13"><span class="number">6.11 </span><span class="name">Account reaper</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.14"><span class="number">6.12 </span><span class="name">Configure project-specific image locations with Object Storage</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.15"><span class="number">6.13 </span><span class="name">Object Storage monitoring</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.16"><span class="number">6.14 </span><span class="name">System administration for Object Storage</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.17"><span class="number">6.15 </span><span class="name">Troubleshoot Object Storage</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.9"><span class="number">7 </span><span class="name">Block Storage</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.9.6"><span class="number">7.1 </span><span class="name">Increase Block Storage API service throughput</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.9.7"><span class="number">7.2 </span><span class="name">Manage volumes</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.9.8"><span class="number">7.3 </span><span class="name">Troubleshoot your installation</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.10"><span class="number">8 </span><span class="name">Shared File Systems</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.10.5"><span class="number">8.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.6"><span class="number">8.2 </span><span class="name">Key concepts</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.7"><span class="number">8.3 </span><span class="name">Share management</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.8"><span class="number">8.4 </span><span class="name">Migrate shares</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-share-types"><span class="number">8.5 </span><span class="name">Share types</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-snapshots"><span class="number">8.6 </span><span class="name">Share snapshots</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-security-services"><span class="number">8.7 </span><span class="name">Security services</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-cgroups"><span class="number">8.8 </span><span class="name">Consistency groups</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.13"><span class="number">8.9 </span><span class="name">Share replication</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-multi-backend"><span class="number">8.10 </span><span class="name">Multi-storage configuration</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.15"><span class="number">8.11 </span><span class="name">Networking</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.16"><span class="number">8.12 </span><span class="name">Troubleshoot Shared File Systems service</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#networking"><span class="number">9 </span><span class="name">Networking</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.11.4"><span class="number">9.1 </span><span class="name">Introduction to Networking</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.5"><span class="number">9.2 </span><span class="name">Networking architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.6"><span class="number">9.3 </span><span class="name">Plug-in configurations</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.7"><span class="number">9.4 </span><span class="name">Configure neutron agents</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.8"><span class="number">9.5 </span><span class="name">Configure Identity service for Networking</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.9"><span class="number">9.6 </span><span class="name">Advanced configuration options</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.10"><span class="number">9.7 </span><span class="name">Scalable and highly available DHCP agents</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.11"><span class="number">9.8 </span><span class="name">Use Networking</span></a></span></dt><dt><span class="sect1"><a href="#networking-adv-features"><span class="number">9.9 </span><span class="name">Advanced features through API extensions</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.13"><span class="number">9.10 </span><span class="name">Advanced operational features</span></a></span></dt><dt><span class="sect1"><a href="#authentication-and-authorization"><span class="number">9.11 </span><span class="name">Authentication and authorization</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.12"><span class="number">10 </span><span class="name">Telemetry</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#telemetry-system-architecture"><span class="number">10.1 </span><span class="name">System architecture</span></a></span></dt><dt><span class="sect1"><a href="#telemetry-data-collection"><span class="number">10.2 </span><span class="name">Data collection</span></a></span></dt><dt><span class="sect1"><a href="#data-collection-and-processing"><span class="number">10.3 </span><span class="name">Data collection, processing, and pipelines</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.12"><span class="number">10.4 </span><span class="name">Data retrieval</span></a></span></dt><dt><span class="sect1"><a href="#telemetry-alarms"><span class="number">10.5 </span><span class="name">Alarms</span></a></span></dt><dt><span class="sect1"><a href="#telemetry-measurements"><span class="number">10.6 </span><span class="name">Measurements</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.15"><span class="number">10.7 </span><span class="name">Events</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.16"><span class="number">10.8 </span><span class="name">Troubleshoot Telemetry</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.17"><span class="number">10.9 </span><span class="name">Telemetry best practices</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.13"><span class="number">11 </span><span class="name">Database</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.13.4"><span class="number">11.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.13.5"><span class="number">11.2 </span><span class="name">Create a data store</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.13.6"><span class="number">11.3 </span><span class="name">Configure a cluster</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.14"><span class="number">12 </span><span class="name">Bare Metal</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.14.4"><span class="number">12.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.5"><span class="number">12.2 </span><span class="name">System architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.6"><span class="number">12.3 </span><span class="name">Bare Metal deployment</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.7"><span class="number">12.4 </span><span class="name">Use Bare Metal</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.8"><span class="number">12.5 </span><span class="name">Troubleshooting</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.15"><span class="number">13 </span><span class="name">Orchestration</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.15.4"><span class="number">13.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.15.5"><span class="number">13.2 </span><span class="name">Orchestration authorization model</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.15.6"><span class="number">13.3 </span><span class="name">Stack domain users</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#osadm-os-cli"><span class="number">14 </span><span class="name">OpenStack command-line clients</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.16.3"><span class="number">14.1 </span><span class="name">Command-line client overview</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.4"><span class="number">14.2 </span><span class="name">Install the OpenStack command-line clients</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.5"><span class="number">14.3 </span><span class="name">Discover the version number for a client</span></a></span></dt><dt><span class="sect1"><a href="#sec-rcfile"><span class="number">14.4 </span><span class="name">Set environment variables using the OpenStack RC file</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.7"><span class="number">14.5 </span><span class="name">Manage projects, users, and roles</span></a></span></dt><dt><span class="sect1"><a href="#osadm-security-group"><span class="number">14.6 </span><span class="name">Manage project security</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.9"><span class="number">14.7 </span><span class="name">Manage services</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.10"><span class="number">14.8 </span><span class="name">Manage images</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.11"><span class="number">14.9 </span><span class="name">Manage volumes</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.12"><span class="number">14.10 </span><span class="name">Manage shares</span></a></span></dt><dt><span class="sect1"><a href="#osadm-manage-flavors-cmd"><span class="number">14.11 </span><span class="name">Manage flavors</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.14"><span class="number">14.12 </span><span class="name">Manage the OpenStack environment</span></a></span></dt><dt><span class="sect1"><a href="#manage-quotas"><span class="number">14.13 </span><span class="name">Manage quotas</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.16"><span class="number">14.14 </span><span class="name">Analyze log files</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.17"><span class="number">14.15 </span><span class="name">Manage Block Storage scheduling</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.17"><span class="number">15 </span><span class="name">Cross-project features</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.17.4"><span class="number">15.1 </span><span class="name">Cross-origin resource sharing</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#id-1.4.18"><span class="number">16 </span><span class="name">Appendix</span></a></span></dt><dd><dl><dt><span class="sect1"><a href="#id-1.4.18.3"><span class="number">16.1 </span><span class="name">Community support</span></a></span></dt></dl></dd><dt><span class="glossary"><a href="#id-1.4.19"><span class="name">Glossary</span></a></span></dt></dl></div><div class="list-of-figures"><div class="toc-title">List of Figures</div><dl><dt><span class="figure"><a href="#id-1.4.6.7.5.3.3.2"><span class="number">4.1 </span><span class="name">Figure Dashboard — Create Image</span></a></span></dt><dt><span class="figure"><a href="#id-1.4.6.9.5.3"><span class="number">4.2 </span><span class="name">Figure Dashboard — Instance Actions</span></a></span></dt><dt><span class="figure"><a href="#id-1.4.6.10.5.2.4.2"><span class="number">4.3 </span><span class="name">Dashboard — Create Flavor</span></a></span></dt><dt><span class="figure"><a href="#id-1.4.6.11.5.3"><span class="number">4.4 </span><span class="name">Encryption Options</span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.6.9"><span class="number">5.1 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.6.10.4"><span class="number">5.2 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.6.10.10"><span class="number">5.3 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.7.11.5"><span class="number">5.4 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.7.11.6"><span class="number">5.5 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.7.11.7"><span class="number">5.6 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.8.17.5.8"><span class="number">5.7 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.8.19.3.7"><span class="number">5.8 </span><span class="name">Configuring Compute to use trusted compute pools</span></a></span></dt><dt><span class="figure"><a href="#id-1.4.7.8.19.3.12"><span class="number">5.9 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.5.5"><span class="number">6.1 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.5"><span class="number">6.2 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.7.9"><span class="number">6.3 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.8.4"><span class="number">6.4 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.9.4"><span class="number">6.5 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.10.7"><span class="number">6.6 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.11.7"><span class="number">6.7 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.6.12.3.7"><span class="number">6.8 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.8.2.5"><span class="number">6.9 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.8.8.3.4"><span class="number">6.10 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.11.5.4.4"><span class="number">9.1 </span><span class="name"></span></a></span></dt><dt><span class="figure"><a href="#id-1.4.11.5.4.5"><span class="number">9.2 </span><span class="name"></span></a></span></dt></dl></div><div class="list-of-tables"><div class="toc-title">List of Tables</div><dl><dt><span class="table"><a href="#id-1.4.4.6"><span class="number">2.1 </span><span class="name">OpenStack Services</span></a></span></dt><dt><span class="table"><a href="#id-1.4.4.9.4.3"><span class="number">2.2 </span><span class="name">Storage types</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.7.6.10"><span class="number">5.1 </span><span class="name">Description of IPv6 configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.7.7.28"><span class="number">5.2 </span><span class="name">Description of metadata configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.8.3"><span class="number">5.3 </span><span class="name">openstack volume commands</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.14.8.4"><span class="number">5.4 </span><span class="name">rootwrap.conf configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.14.8.10"><span class="number">5.5 </span><span class="name">Filters configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.16.6.3.2"><span class="number">5.6 </span><span class="name">openstack compute service list</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.17.4.6"><span class="number">5.7 </span><span class="name">Description of SPICE configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.17.5.9.4"><span class="number">5.8 </span><span class="name">Description of VNC configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.7.8.19.3.10"><span class="number">5.9 </span><span class="name">Description of trusted computing configuration options</span></a></span></dt><dt><span class="table"><a href="#id-1.4.8.17.5.3.3"><span class="number">6.1 </span><span class="name">Description of configuration options for [drive-audit] in drive-audit.conf</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.8.6.3"><span class="number">9.1 </span><span class="name">nova.conf API and credential settings prior to Mitaka</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.8.6.4"><span class="number">9.2 </span><span class="name">nova.conf API and credential settings in Newton</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.3.7.3"><span class="number">9.3 </span><span class="name">Provider network attributes</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.4.4.4"><span class="number">9.4 </span><span class="name">Basic L3 Operations</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.5.6.3"><span class="number">9.5 </span><span class="name">Basic security group operations</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.7.3.3.4.3"><span class="number">9.6 </span><span class="name">Basic VMware NSX QoS operations</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.7.3.6.6"><span class="number">9.7 </span><span class="name">Configuration options for tuning operational status synchronization in the NSX plug-in</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.7.4.3.3.3"><span class="number">9.8 </span><span class="name">Big Switch Router rule attributes</span></a></span></dt><dt><span class="table"><a href="#id-1.4.11.12.8.4.4"><span class="number">9.9 </span><span class="name">Basic L3 operations</span></a></span></dt><dt><span class="table"><a href="#id-1.4.14.7.3.2.4"><span class="number">12.1 </span><span class="name">local_link_connection fields</span></a></span></dt><dt><span class="table"><a href="#id-1.4.16.3.8.3"><span class="number">14.1 </span><span class="name">OpenStack services and clients</span></a></span></dt><dt><span class="table"><a href="#id-1.4.16.4.3.4"><span class="number">14.2 </span><span class="name">OpenStack command-line clients prerequisites</span></a></span></dt><dt><span class="table"><a href="#disk-and-cd-rom-bus-model-values-table"><span class="number">14.3 </span><span class="name">Disk and CD-ROM bus model values</span></a></span></dt><dt><span class="table"><a href="#vif-model-values-table"><span class="number">14.4 </span><span class="name">VIF model values</span></a></span></dt></dl></div><div><div class="legalnotice" id="id-1.4.2.4"><p>Except where otherwise noted, this document is licensed under
  <span class="bold"><strong>Creative Commons Attribution 3.0 License </strong></span>:
  <a class="link" href="http://creativecommons.org/licenses/by/3.0/legalcode" target="_blank">http://creativecommons.org/licenses/by/3.0/legalcode</a>
 </p></div></div><div class="chapter " id="id-1.4.3"><div class="titlepage"><div><div><h1 class="title"><span class="number">1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Documentation Conventions</span> <a title="Permalink" class="permalink" href="#id-1.4.3">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"></div><p>
  The following notices and typographical conventions are used
  in this documentation:
 </p><div id="id-1.4.3.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
    Vital information you must be aware of before proceeding. Warns you about
    security issues, potential loss of data, damage to hardware, or physical
    hazards.
   </p></div><div id="id-1.4.3.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
    Important information you should be aware of before proceeding.
   </p></div><div id="id-1.4.3.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    Additional information, for example about differences in software
    versions.
   </p></div><div id="id-1.4.3.7" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>
    Helpful information, like a guideline or a piece of practical advice.
   </p></div><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code><code class="command">command</code></pre></div><p>
    Commands than can be run by any user, including the <code class="systemitem">root</code> user.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt root">root # </code><code class="command">command</code></pre></div><p>
    Commands that must be run with <code class="systemitem">root</code> privileges. In often you
    can also prefix these commands with the <code class="command">sudo</code> command to
    run them.
   </p></div><div class="chapter " id="id-1.4.4"><div class="titlepage"><div><div><h1 class="title"><span class="number">2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Get started with OpenStack</span> <a title="Permalink" class="permalink" href="#id-1.4.4">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#get-started-conceptual-architecture"><span class="number">2.1 </span><span class="name">Conceptual architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.4.8"><span class="number">2.2 </span><span class="name">Logical architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.4.9"><span class="number">2.3 </span><span class="name">OpenStack services</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.4.10"><span class="number">2.4 </span><span class="name">Feedback</span></a></span></dt></dl></div></div><p>The OpenStack project is an open source cloud computing platform for all
types of clouds, which aims to be simple to implement, massively
scalable, and feature rich. Developers and cloud computing technologists
from around the world create the OpenStack project.</p><p>OpenStack provides an <a class="xref" href="#term-infrastructure-as-a-service-iaas" title="Infrastructure-as-a-Service (IaaS)">Infrastructure-as-a-Service (IaaS)</a> solution
through a set of interrelated services. Each service offers an
<a class="xref" href="#term-application-programming-interface-api" title="Application Programming Interface (API)">Application Programming Interface (API)</a> that facilitates this
integration. Depending on your needs, you can install some or all
services.</p><p>The following table describes the OpenStack services that make up the
OpenStack architecture:</p><div class="table" id="id-1.4.4.6"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 2.1: </span><span class="name">OpenStack Services </span><a title="Permalink" class="permalink" href="#id-1.4.4.6">#</a></h6></div><div class="table-contents"><table class="table" summary="OpenStack Services" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
              <p>Service</p>
            </th><th>
              <p>Project name</p>
            </th><th>
              <p>Description</p>
            </th></tr></thead><tbody><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/horizon" target="_blank">Dashboard</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/horizon/" target="_blank">Horizon</a>
              </p>
            </td><td>
              <p>Provides a web-based self-service portal to interact with underlying
OpenStack services, such as launching an instance, assigning IP
addresses and configuring access controls.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/nova" target="_blank">Compute</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/nova/" target="_blank">Nova</a>
              </p>
            </td><td>
              <p>Manages the lifecycle of compute instances in an OpenStack environment.
Responsibilities include spawning, scheduling and decommissioning of
virtual machines on demand.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/neutron" target="_blank">Networking</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/neutron/" target="_blank">Neutron</a>
              </p>
            </td><td>
              <p>Enables Network-Connectivity-as-a-Service for other OpenStack services,
such as OpenStack Compute. Provides an API for users to define networks
and the attachments into them. Has a pluggable architecture that
supports many popular networking vendors and technologies.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/swift" target="_blank">Object Storage</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/swift/" target="_blank">Swift</a>
              </p>
            </td><td>
              <p>Stores and retrieves arbitrary unstructured data objects via a RESTful,
HTTP based API. It is highly fault tolerant with its data replication
and scale-out architecture. Its implementation is not like a file server
with mountable directories. In this case, it writes objects and files to
multiple drives, ensuring the data is replicated across a server
cluster.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/cinder" target="_blank">Block Storage</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/cinder/" target="_blank">Cinder</a>
              </p>
            </td><td>
              <p>Provides persistent block storage to running instances. Its pluggable
driver architecture facilitates the creation and management of block
storage devices.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/keystone" target="_blank">Identity service</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/keystone/" target="_blank">Keystone</a>
              </p>
            </td><td>
              <p>Provides an authentication and authorization service for other
OpenStack services. Provides a catalog of endpoints for all
OpenStack services.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/glance" target="_blank">Image service</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/glance/" target="_blank">Glance</a>
              </p>
            </td><td>
              <p>Stores and retrieves virtual machine disk images. OpenStack Compute
makes use of this during instance provisioning.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/ceilometer" target="_blank">Telemetry</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/ceilometer/" target="_blank">Ceilometer</a>
              </p>
            </td><td>
              <p>Monitors and meters the OpenStack cloud for billing, benchmarking,
scalability, and statistical purposes.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/heat" target="_blank">Orchestration</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/heat/" target="_blank">Heat</a>
              </p>
            </td><td>
              <p>Orchestrates multiple composite cloud applications by using either the
native HOT template format or the AWS CloudFormation template format,
through both an OpenStack-native REST API and a
CloudFormation-compatible Query API.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/trove" target="_blank">Database service</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/trove/" target="_blank">Trove</a>
              </p>
            </td><td>
              <p>Provides scalable and reliable Cloud Database-as-a-Service functionality
for both relational and non-relational database engines.</p>
            </td></tr><tr><td>
              <p>
                <a class="link" href="http://www.openstack.org/software/releases/newton/components/sahara" target="_blank">Data processing service</a>
              </p>
            </td><td>
              <p>
                <a class="link" href="http://docs.openstack.org/developer/sahara/" target="_blank">Sahara</a>
              </p>
            </td><td>
              <p>Provides capabilities to provision and scale Hadoop clusters in OpenStack
by specifying parameters like Hadoop version, cluster topology and nodes
hardware details.</p>
            </td></tr></tbody></table></div></div><div class="sect1 " id="get-started-conceptual-architecture"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Conceptual architecture</span> <a title="Permalink" class="permalink" href="#get-started-conceptual-architecture">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>get-started-conceptual-architecture</li></ul></div></div></div></div><p>The following diagram shows the relationships among the OpenStack
services:</p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/openstack_kilo_conceptual_arch.png" target="_blank"><img src="images/openstack_kilo_conceptual_arch.png" width="" /></a></div></div></div><div class="sect1 " id="id-1.4.4.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logical architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.4.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To design, deploy, and configure OpenStack, administrators must
understand the logical architecture.</p><p>As shown in <a class="xref" href="#get-started-conceptual-architecture" title="2.1. Conceptual architecture">Section 2.1, “Conceptual architecture”</a>, OpenStack consists of
several independent parts, named the OpenStack services. All services
authenticate through a common Identity service. Individual services interact
with each other through public APIs, except where privileged administrator
commands are necessary.</p><p>Internally, OpenStack services are composed of several processes. All
services have at least one API process, which listens for API requests,
preprocesses them and passes them on to other parts of the service. With
the exception of the Identity service, the actual work is done by
distinct processes.</p><p>For communication between the processes of one service, an AMQP message
broker is used. The service's state is stored in a database. When
deploying and configuring your OpenStack cloud, you can choose among
several message broker and database solutions, such as RabbitMQ,
MySQL, MariaDB, and SQLite.</p><p>Users can access OpenStack via the web-based user interface implemented
by <a class="xref" href="#sec-dashboard" title="2.3.7. Dashboard overview">Section 2.3.7, “Dashboard overview”</a>, via <a class="link" href="http://docs.openstack.org/cli-reference/" target="_blank">command-line
clients</a> and by
issuing API requests through tools like browser plug-ins or <code class="command">curl</code>.
For applications, <a class="link" href="http://developer.openstack.org/#sdk" target="_blank">several SDKs</a>
are available. Ultimately, all these access methods issue REST API calls
to the various OpenStack services.</p><p>The following diagram shows the most common, but not the only possible,
architecture for an OpenStack cloud:</p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/openstack-arch-kilo-logical-v1.png" target="_blank"><img src="images/openstack-arch-kilo-logical-v1.png" width="" /></a></div></div></div><div class="sect1 " id="id-1.4.4.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack services</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section describes OpenStack services in detail.</p><div class="sect2 " id="id-1.4.4.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use OpenStack Compute to host and manage cloud computing systems.
OpenStack Compute is a major part of an <a class="xref" href="#term-infrastructure-as-a-service-iaas" title="Infrastructure-as-a-Service (IaaS)">Infrastructure-as-a-Service (IaaS)</a> system. The main modules are implemented in Python.</p><p>OpenStack Compute interacts with OpenStack Identity for authentication;
OpenStack Image service for disk and server images; and OpenStack
Dashboard for the user and administrative interface. Image access is
limited by projects, and by users; quotas are limited per project (the
number of instances, for example). OpenStack Compute can scale
horizontally on standard hardware, and download images to launch
instances.</p><p>OpenStack Compute consists of the following areas and their components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.3.5.1"><span class="term "><code class="literal">nova-api</code> service</span></dt><dd><p>Accepts and responds to end user compute API calls. The service
supports the OpenStack Compute API, the Amazon EC2 API, and a
special Admin API for privileged users to perform administrative
actions. It enforces some policies and initiates most orchestration
activities, such as running an instance.</p></dd><dt id="id-1.4.4.9.3.5.2"><span class="term "><code class="literal">nova-api-metadata</code> service</span></dt><dd><p>Accepts metadata requests from instances. The <code class="literal">nova-api-metadata</code>
service is generally used when you run in multi-host mode with
<code class="literal">nova-network</code> installations. For details, see <a class="link" href="http://docs.openstack.org/admin-guide/compute-networking-nova.html#metadata-service" target="_blank">Metadata
service</a>
in the OpenStack Administrator Guide.</p></dd><dt id="id-1.4.4.9.3.5.3"><span class="term "><code class="literal">nova-compute</code> service</span></dt><dd><p>A worker daemon that creates and terminates virtual machine
instances through hypervisor APIs. For example:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>XenAPI for XenServer/XCP</p></li><li class="listitem "><p>libvirt for KVM or QEMU</p></li><li class="listitem "><p>VMwareAPI for VMware</p></li></ul></div><p>Processing is fairly complex. Basically, the daemon accepts actions
from the queue and performs a series of system commands such as
launching a KVM instance and updating its state in the database.</p></dd><dt id="id-1.4.4.9.3.5.4"><span class="term "><code class="literal">nova-scheduler</code> service</span></dt><dd><p>Takes a virtual machine instance request from the queue and
determines on which compute server host it runs.</p></dd><dt id="id-1.4.4.9.3.5.5"><span class="term "><code class="literal">nova-conductor</code> module</span></dt><dd><p>Mediates interactions between the <code class="literal">nova-compute</code> service and the
database. It eliminates direct accesses to the cloud database made
by the <code class="literal">nova-compute</code> service. The <code class="literal">nova-conductor</code> module scales
horizontally. However, do not deploy it on nodes where the
<code class="literal">nova-compute</code> service runs. For more information, see <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/conductor.html" target="_blank">Configuration
Reference Guide</a>.</p></dd><dt id="id-1.4.4.9.3.5.6"><span class="term "><code class="literal">nova-cert</code> module</span></dt><dd><p>A server daemon that serves the Nova Cert service for X509
certificates. Used to generate certificates for
<code class="literal">euca-bundle-image</code>. Only needed for the EC2 API.</p></dd><dt id="id-1.4.4.9.3.5.7"><span class="term "><code class="literal">nova-consoleauth</code> daemon</span></dt><dd><p>Authorizes tokens for users that console proxies provide. See
<code class="literal">nova-novncproxy</code>. This service must be running
for console proxies to work. You can run proxies of either type
against a single nova-consoleauth service in a cluster
configuration. For information, see <a class="link" href="http://docs.openstack.org/admin-guide/compute-remote-console-access.html#about-nova-consoleauth" target="_blank">About
nova-consoleauth</a>.</p></dd><dt id="id-1.4.4.9.3.5.8"><span class="term "><code class="literal">nova-novncproxy</code> daemon</span></dt><dd><p>Provides a proxy for accessing running instances through a VNC
connection. Supports browser-based novnc clients.</p></dd><dt id="id-1.4.4.9.3.5.9"><span class="term "><code class="literal">nova-spicehtml5proxy</code> daemon</span></dt><dd><p>Provides a proxy for accessing running instances through a SPICE
connection. Supports browser-based HTML5 client.</p></dd><dt id="id-1.4.4.9.3.5.10"><span class="term ">The queue</span></dt><dd><p>A central hub for passing messages between daemons. Usually
implemented with <a class="link" href="http://www.rabbitmq.com/" target="_blank">RabbitMQ</a>, also can be
implemented with another AMQP message queue, such as <a class="link" href="http://www.zeromq.org/" target="_blank">ZeroMQ</a>.</p></dd><dt id="id-1.4.4.9.3.5.11"><span class="term ">SQL database</span></dt><dd><p>Stores most build-time and run-time states for a cloud
infrastructure, including:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Available instance types</p></li><li class="listitem "><p>Instances in use</p></li><li class="listitem "><p>Available networks</p></li><li class="listitem "><p>Projects</p></li></ul></div><p>Theoretically, OpenStack Compute can support any database that
SQLAlchemy supports. Common databases are SQLite3 for test and
development work, MySQL, MariaDB, and PostgreSQL.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storage concepts</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack stack uses the following storage types:</p><div class="table" id="id-1.4.4.9.4.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 2.2: </span><span class="name">Storage types </span><a title="Permalink" class="permalink" href="#id-1.4.4.9.4.3">#</a></h6></div><div class="table-contents"><table class="table" summary="Storage types" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                  <p>On-instance / ephemeral</p>
                </th><th>
                  <p>Block storage (cinder)</p>
                </th><th>
                  <p>Object Storage (swift)</p>
                </th><th>
                  <p>File Storage (manila)</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Runs operating systems and provides scratch space</p>
                </td><td>
                  <p>Used for adding additional persistent storage to a virtual machine (VM)</p>
                </td><td>
                  <p>Used for storing virtual machine images and data</p>
                </td><td>
                  <p>Used for providing file shares to a virtual machine</p>
                </td></tr><tr><td>
                  <p>Persists until VM is terminated</p>
                </td><td>
                  <p>Persists until deleted</p>
                </td><td>
                  <p>Persists until deleted</p>
                </td><td>
                  <p>Persists until deleted</p>
                </td></tr><tr><td>
                  <p>Access associated with a VM</p>
                </td><td>
                  <p>Access associated with a VM</p>
                </td><td>
                  <p>Available from anywhere</p>
                </td><td>
                  <p>Access can be provided to a VM</p>
                </td></tr><tr><td>
                  <p>Implemented as a filesystem underlying OpenStack Compute</p>
                </td><td>
                  <p>Mounted via OpenStack Block Storage controlled protocol (for example, iSCSI)</p>
                </td><td>
                  <p>REST API</p>
                </td><td>
                  <p>Provides Shared File System service via nfs, cifs, glusterfs, or hdfs protocol</p>
                </td></tr><tr><td>
                  <p>Encryption is available</p>
                </td><td>
                  <p>Encryption is available</p>
                </td><td>
                  <p>Work in progress - expected for the Mitaka release</p>
                </td><td>
                  <p>Encryption is not available yet</p>
                </td></tr><tr><td>
                  <p>Administrator configures size setting, based on flavors</p>
                </td><td>
                  <p>Sizings based on need</p>
                </td><td>
                  <p>Easily scalable for future growth</p>
                </td><td>
                  <p>Sizing based on need</p>
                </td></tr><tr><td>
                  <p>Example: 10 GB first disk, 30 GB/core second disk</p>
                </td><td>
                  <p>Example: 1 TB "extra hard drive"</p>
                </td><td>
                  <p>Example: 10s of TBs of data set storage</p>
                </td><td>
                  <p>Example: 1 TB of file share</p>
                </td></tr></tbody></table></div></div><div id="id-1.4.4.9.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="emphasis"><em>You cannot use OpenStack Object Storage like a traditional hard
drive.</em></span> The Object Storage relaxes some of the constraints of a
POSIX-style file system to get other gains. You can access the
objects through an API which uses HTTP. Subsequently you don't have
to provide atomic operations (that is, relying on eventual
consistency), you can scale a storage system easily and avoid a
central point of failure.</p></li><li class="listitem "><p><span class="emphasis"><em>The OpenStack Image service is used to manage the virtual machine
images in an OpenStack cluster, not store them.</em></span> It provides an
abstraction to different methods for storage - a bridge to the
storage, not the storage itself.</p></li><li class="listitem "><p><span class="emphasis"><em>The OpenStack Object Storage can function on its own.</em></span> The Object
Storage (swift) product can be used independently of the Compute
(nova) product.</p></li></ul></div></div></div><div class="sect2 " id="id-1.4.4.9.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object Storage service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Object Storage is a multi-tenant object storage system. It
is highly scalable and can manage large amounts of unstructured data at
low cost through a RESTful HTTP API.</p><p>It includes the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.5.4.1"><span class="term ">Proxy servers (swift-proxy-server)</span></dt><dd><p>Accepts OpenStack Object Storage API and raw HTTP requests to upload
files, modify metadata, and create containers. It also serves file
or container listings to web browsers. To improve performance, the
proxy server can use an optional cache that is usually deployed with
memcache.</p></dd><dt id="id-1.4.4.9.5.4.2"><span class="term ">Account servers (swift-account-server)</span></dt><dd><p>Manages accounts defined with Object Storage.</p></dd><dt id="id-1.4.4.9.5.4.3"><span class="term ">Container servers (swift-container-server)</span></dt><dd><p>Manages the mapping of containers or folders, within Object Storage.</p></dd><dt id="id-1.4.4.9.5.4.4"><span class="term ">Object servers (swift-object-server)</span></dt><dd><p>Manages actual objects, such as files, on the storage nodes.</p></dd><dt id="id-1.4.4.9.5.4.5"><span class="term ">Various periodic processes</span></dt><dd><p>Performs housekeeping tasks on the large data store. The replication
services ensure consistency and availability through the cluster.
Other periodic processes include auditors, updaters, and reapers.</p></dd><dt id="id-1.4.4.9.5.4.6"><span class="term ">WSGI middleware</span></dt><dd><p>Handles authentication and is usually OpenStack Identity.</p></dd><dt id="id-1.4.4.9.5.4.7"><span class="term ">swift client</span></dt><dd><p>Enables users to submit commands to the REST API through a
command-line client authorized as either a admin user, reseller
user, or swift user.</p></dd><dt id="id-1.4.4.9.5.4.8"><span class="term ">swift-init</span></dt><dd><p>Script that initializes the building of the ring file, takes daemon
names as parameter and offers commands. Documented in
<a class="link" href="http://docs.openstack.org/developer/swift/admin_guide.html#managing-services" target="_blank">Managing Services</a>.</p></dd><dt id="id-1.4.4.9.5.4.9"><span class="term ">swift-recon</span></dt><dd><p>A cli tool used to retrieve various metrics and telemetry information
about a cluster that has been collected by the swift-recon middleware.</p></dd><dt id="id-1.4.4.9.5.4.10"><span class="term ">swift-ring-builder</span></dt><dd><p>Storage ring build and rebalance utility. Documented in
<a class="link" href="http://docs.openstack.org/developer/swift/admin_guide.html#managing-the-rings" target="_blank">Managing the Rings</a>.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block Storage service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Block Storage service (cinder) adds persistent storage
to a virtual machine. Block Storage provides an infrastructure for managing
volumes, and interacts with OpenStack Compute to provide volumes for
instances. The service also enables management of volume snapshots, and
volume types.</p><p>The Block Storage service consists of the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.6.4.1"><span class="term ">cinder-api</span></dt><dd><p>Accepts API requests, and routes them to the <code class="literal">cinder-volume</code> for
action.</p></dd><dt id="id-1.4.4.9.6.4.2"><span class="term ">cinder-volume</span></dt><dd><p>Interacts directly with the Block Storage service, and processes
such as the <code class="literal">cinder-scheduler</code>. It also interacts with these processes
through a message queue. The <code class="literal">cinder-volume</code> service responds to read
and write requests sent to the Block Storage service to maintain
state. It can interact with a variety of storage providers through a
driver architecture.</p></dd><dt id="id-1.4.4.9.6.4.3"><span class="term ">cinder-scheduler daemon</span></dt><dd><p>Selects the optimal storage provider node on which to create the
volume. A similar component to the <code class="literal">nova-scheduler</code>.</p></dd><dt id="id-1.4.4.9.6.4.4"><span class="term ">cinder-backup daemon</span></dt><dd><p>The <code class="literal">cinder-backup</code> service provides backing up volumes of any type to
a backup storage provider. Like the <code class="literal">cinder-volume</code> service, it can
interact with a variety of storage providers through a driver
architecture.</p></dd><dt id="id-1.4.4.9.6.4.5"><span class="term ">Messaging queue</span></dt><dd><p>Routes information between the Block Storage processes.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Shared File Systems service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Shared File Systems service (manila) provides file storage to a
virtual machine. The Shared File Systems service provides an infrastructure
for managing and provisioning of file shares. The service also enables
management of share types as well as share snapshots if a driver supports
them.</p><p>The Shared File Systems service consists of the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.7.4.1"><span class="term ">manila-api</span></dt><dd><p>A WSGI app that authenticates and routes requests throughout the Shared File
Systems service. It supports the OpenStack APIs.</p></dd><dt id="id-1.4.4.9.7.4.2"><span class="term ">manila-data</span></dt><dd><p>A standalone service whose purpose is to receive requests, process data
operations such as copying, share migration or backup, and send back a
response after an operation has been completed.</p></dd><dt id="id-1.4.4.9.7.4.3"><span class="term ">manila-scheduler</span></dt><dd><p>Schedules and routes requests to the appropriate share service. The
scheduler uses configurable filters and weighers to route requests. The
Filter Scheduler is the default and enables filters on things like Capacity,
Availability Zone, Share Types, and Capabilities as well as custom filters.</p></dd><dt id="id-1.4.4.9.7.4.4"><span class="term ">manila-share</span></dt><dd><p>Manages back-end devices that provide shared file systems. A manila-share
process can run in one of two modes, with or without handling of share
servers. Share servers export file shares via share networks. When share
servers are not used, the networking requirements are handled outside of
Manila.</p></dd><dt id="id-1.4.4.9.7.4.5"><span class="term ">Messaging queue</span></dt><dd><p>Routes information between the Shared File Systems processes.</p></dd></dl></div><p>For more information, see <a class="link" href="http://docs.openstack.org/newton/config-reference/shared-file-systems/overview.html" target="_blank">OpenStack Configuration Reference</a>.</p></div><div class="sect2 " id="id-1.4.4.9.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Networking (neutron) allows you to create and attach interface
devices managed by other OpenStack services to networks. Plug-ins can be
implemented to accommodate different networking equipment and software,
providing flexibility to OpenStack architecture and deployment.</p><p>It includes the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.8.4.1"><span class="term ">neutron-server</span></dt><dd><p>Accepts and routes API requests to the appropriate OpenStack
Networking plug-in for action.</p></dd><dt id="id-1.4.4.9.8.4.2"><span class="term ">OpenStack Networking plug-ins and agents</span></dt><dd><p>Plug and unplug ports, create networks or subnets, and provide
IP addressing. These plug-ins and agents differ depending on the
vendor and technologies used in the particular cloud. OpenStack
Networking ships with plug-ins and agents for Cisco virtual and
physical switches, NEC OpenFlow products, Open vSwitch, Linux
bridging, and the VMware NSX product.</p><p>The common agents are L3 (layer 3), DHCP (dynamic host IP
addressing), and a plug-in agent.</p></dd><dt id="id-1.4.4.9.8.4.3"><span class="term ">Messaging queue</span></dt><dd><p>Used by most OpenStack Networking installations to route information
between the neutron-server and various agents. Also acts as a database
to store networking state for particular plug-ins.</p></dd></dl></div><p>OpenStack Networking mainly interacts with OpenStack Compute to provide
networks and connectivity for its instances.</p></div><div class="sect2 " id="sec-dashboard"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dashboard overview</span> <a title="Permalink" class="permalink" href="#sec-dashboard">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>sec-dashboard</li></ul></div></div></div></div><p>The OpenStack Dashboard is a modular <a class="link" href="https://www.djangoproject.com/" target="_blank">Django web
application</a> that provides a
graphical interface to OpenStack services.</p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/horizon-screenshot.png" target="_blank"><img src="images/horizon-screenshot.png" width="" /></a></div></div><p>The dashboard is usually deployed through
<a class="link" href="http://code.google.com/p/modwsgi/" target="_blank">mod_wsgi</a> in Apache. You can
modify the dashboard code to make it suitable for different sites.</p><p>From a network architecture point of view, this service must be
accessible to customers and the public API for each OpenStack service.
To use the administrator functionality for other services, it must also
connect to Admin API endpoints, which should not be accessible by
customers.</p></div><div class="sect2 " id="id-1.4.4.9.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Identity service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack <a class="xref" href="#term-identity-service-keystone" title="Identity service (keystone)">Identity service (keystone)</a>
        provides a single point of integration for managing authentication,
        authorization, and a catalog of services.</p><p>
         The Identity service is typically the first service a user interacts
         with. Once authenticated, an end user can use their identity to access
         other OpenStack services. Likewise, other OpenStack services leverage
         the Identity service to ensure users are who they say they are and
         discover where other services are within the deployment. The Identity
         service can also integrate with some external user management systems
         (such as LDAP).</p><p>Users and services can locate other services by using the service
        catalog, which is managed by the Identity service. As the name implies,
        a service catalog is a collection of available services in an OpenStack
        deployment. Each service can have one or many endpoints and each
        endpoint can be one of three types: admin, internal, or public. In a
        production environment, different endpoint types might reside on
        separate networks exposed to different types of users for security
        reasons. For instance, the public API network might be visible from the
        Internet so customers can manage their clouds. The admin API network
        might be restricted to operators within the organization that manages
        cloud infrastructure. The internal API network might be restricted to
        the hosts that contain OpenStack services. OpenStack supports multiple
        regions for scalability. However Cloud 8 does not support multiple
        regions, so this guide uses the default <code class="literal">RegionOne</code>
        region. In addition, for simplicity this guide uses the management
        network for all endpoint types. Together, regions, services, and
        endpoints created within the Identity service comprise the service
        catalog for a deployment. Each OpenStack service in your deployment
        needs a service entry with corresponding endpoints stored in the
        Identity service. This can all be done after the Identity service has
        been installed and configured.</p><p>The Identity service contains these components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.10.6.1"><span class="term ">Server</span></dt><dd><p>A centralized server provides authentication and authorization
services using a RESTful interface.</p></dd><dt id="id-1.4.4.9.10.6.2"><span class="term ">Drivers</span></dt><dd><p>Drivers or a service back end are integrated to the centralized
server. They are used for accessing identity information in
repositories external to OpenStack, and may already exist in
the infrastructure where OpenStack is deployed (for example, SQL
databases or LDAP servers).</p></dd><dt id="id-1.4.4.9.10.6.3"><span class="term ">Modules</span></dt><dd><p>Middleware modules run in the address space of the OpenStack
component that is using the Identity service. These modules
intercept service requests, extract user credentials, and send them
to the centralized server for authorization. The integration between
the middleware modules and OpenStack components uses the Python Web
Server Gateway Interface.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Image service is central to Infrastructure-as-a-Service
(IaaS) as shown in <a class="xref" href="#get-started-conceptual-architecture" title="2.1. Conceptual architecture">Section 2.1, “Conceptual architecture”</a>. It accepts API
requests for disk or server images, and metadata definitions from end users or
OpenStack Compute components. It also supports the storage of disk or server
images on various repository types, including OpenStack Object Storage.</p><p>A number of periodic processes run on the OpenStack Image service to
support caching. Replication services ensure consistency and
availability through the cluster. Other periodic processes include
auditors, updaters, and reapers.</p><p>The OpenStack Image service includes the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.11.5.1"><span class="term ">glance-api</span></dt><dd><p>Accepts Image API calls for image discovery, retrieval, and storage.</p></dd><dt id="id-1.4.4.9.11.5.2"><span class="term ">glance-registry</span></dt><dd><p>Stores, processes, and retrieves metadata about images. Metadata
includes items such as size and type.</p><div id="id-1.4.4.9.11.5.2.2.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>The registry is a private internal service meant for use by
OpenStack Image service. Do not expose this service to users.</p></div></dd><dt id="id-1.4.4.9.11.5.3"><span class="term ">Database</span></dt><dd><p>Stores image metadata and you can choose your database depending on
your preference. Most deployments use MySQL or SQLite.</p></dd><dt id="id-1.4.4.9.11.5.4"><span class="term ">Storage repository for image files</span></dt><dd><p>Various repository types are supported including normal file
systems (or any filesystem mounted on the glance-api controller
node), Object Storage, RADOS block devices, VMware datastore,
and HTTP. Note that some repositories will only support read-only
usage.</p></dd><dt id="id-1.4.4.9.11.5.5"><span class="term ">Metadata definition service</span></dt><dd><p>A common API for vendors, admins, services, and users to meaningfully
define their own custom metadata. This metadata can be used on
different types of resources like images, artifacts, volumes,
flavors, and aggregates. A definition includes the new property's key,
description, constraints, and the resource types which it can be
associated with.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.4.9.12.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">2.3.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry Data Collection service</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.12.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry Data Collection services provide the following functions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Efficiently polls metering data related to OpenStack services.</p></li><li class="listitem "><p>Collects event and metering data by monitoring notifications sent
from services.</p></li><li class="listitem "><p>Publishes collected data to various targets including data stores and
message queues.</p></li></ul></div><p>The Telemetry service consists of the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.12.2.5.1"><span class="term ">A compute agent (<code class="literal">ceilometer-agent-compute</code>)</span></dt><dd><p>Runs on each compute node and polls for resource utilization
statistics. There may be other types of agents in the future, but
for now our focus is creating the compute agent.</p></dd><dt id="id-1.4.4.9.12.2.5.2"><span class="term ">A central agent (<code class="literal">ceilometer-agent-central</code>)</span></dt><dd><p>Runs on a central management server to poll for resource utilization
statistics for resources not tied to instances or compute nodes.
Multiple agents can be started to scale service horizontally.</p></dd><dt id="id-1.4.4.9.12.2.5.3"><span class="term ">A notification agent (<code class="literal">ceilometer-agent-notification</code>)</span></dt><dd><p>Runs on a central management server(s) and consumes messages from
the message queue(s) to build event and metering data.</p></dd><dt id="id-1.4.4.9.12.2.5.4"><span class="term ">A collector (<code class="literal">ceilometer-collector</code>)</span></dt><dd><p>Runs on central management server(s) and dispatches collected
telemetry data to a data store or external consumer without
modification.</p></dd><dt id="id-1.4.4.9.12.2.5.5"><span class="term ">An API server (<code class="literal">ceilometer-api</code>)</span></dt><dd><p>Runs on one or more central management servers to provide data
access from the data store.</p></dd></dl></div></div><div class="sect3 " id="id-1.4.4.9.12.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">2.3.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry Alarming service</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.12.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry Alarming services trigger alarms when the collected metering
or event data break the defined rules.</p><p>The Telemetry Alarming service consists of the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.12.3.4.1"><span class="term ">An API server (<code class="literal">aodh-api</code>)</span></dt><dd><p>Runs on one or more central management servers to provide access
to the alarm information stored in the data store.</p></dd><dt id="id-1.4.4.9.12.3.4.2"><span class="term ">An alarm evaluator (<code class="literal">aodh-evaluator</code>)</span></dt><dd><p>Runs on one or more central management servers to determine when
alarms fire due to the associated statistic trend crossing a
threshold over a sliding time window.</p></dd><dt id="id-1.4.4.9.12.3.4.3"><span class="term ">A notification listener (<code class="literal">aodh-listener</code>)</span></dt><dd><p>Runs on a central management server and determines when to fire alarms.
The alarms are generated based on defined rules against events, which are
captured by the Telemetry Data Collection service's notification agents.</p></dd><dt id="id-1.4.4.9.12.3.4.4"><span class="term ">An alarm notifier (<code class="literal">aodh-notifier</code>)</span></dt><dd><p>Runs on one or more central management servers to allow alarms to be
set based on the threshold evaluation for a collection of samples.</p></dd></dl></div><p>These services communicate by using the OpenStack messaging bus. Only
the collector and API server have access to the data store.</p></div></div><div class="sect2 " id="id-1.4.4.9.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Orchestration service provides a template-based orchestration for
describing a cloud application by running OpenStack API calls to
generate running cloud applications. The software integrates other core
components of OpenStack into a one-file template system. The templates
allow you to create most OpenStack resource types such as instances,
floating IPs, volumes, security groups, and users. It also provides
advanced functionality such as instance high availability, instance
auto-scaling, and nested stacks. This enables OpenStack core projects to
receive a larger user base.</p><p>The service enables deployers to integrate with the Orchestration service
directly or through custom plug-ins.</p><p>The Orchestration service consists of the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.13.5.1"><span class="term "><code class="literal">heat</code> command-line client</span></dt><dd><p>A CLI that communicates with the <code class="literal">heat-api</code> to run AWS
CloudFormation APIs. End developers can directly use the Orchestration
REST API.</p></dd><dt id="id-1.4.4.9.13.5.2"><span class="term "><code class="literal">heat-api</code> component</span></dt><dd><p>An OpenStack-native REST API that processes API requests by sending
them to the <code class="literal">heat-engine</code> over <a class="xref" href="#term-remote-procedure-call-rpc" title="Remote Procedure Call (RPC)">Remote Procedure Call (RPC)</a>.</p></dd><dt id="id-1.4.4.9.13.5.3"><span class="term "><code class="literal">heat-api-cfn</code> component</span></dt><dd><p>An AWS Query API that is compatible with AWS CloudFormation. It
processes API requests by sending them to the <code class="literal">heat-engine</code> over RPC.</p></dd><dt id="id-1.4.4.9.13.5.4"><span class="term ">
              <code class="literal">heat-engine</code>
            </span></dt><dd><p>Orchestrates the launching of templates and provides events back to
the API consumer.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Database service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Database service provides scalable and reliable cloud provisioning
functionality for both relational and non-relational database engines.
Users can quickly and easily use database features without the burden of
handling complex administrative tasks. Cloud users and database
administrators can provision and manage multiple database instances as
needed.</p><p>The Database service provides resource isolation at high performance
levels and automates complex administrative tasks such as deployment,
configuration, patching, backups, restores, and monitoring.</p><p>
          <span class="bold"><strong>Process flow example</strong></span>
        </p><p>This example is a high-level process flow for using Database services:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The OpenStack Administrator configures the basic infrastructure using
the following steps:</p><ol type="a" class="substeps "><li class="step "><p>Install the Database service.</p></li><li class="step "><p>Create an image for each type of database. For example, one for MySQL
and one for MongoDB.</p></li><li class="step "><p>Use the <code class="command">trove-manage</code> command to import images and offer them
to tenants.</p></li></ol></li><li class="step "><p>The OpenStack end user deploys the Database service using the following
steps:</p><ol type="a" class="substeps "><li class="step "><p>Create a Database service instance using the <code class="command">trove create</code>
command.</p></li><li class="step "><p>Use the <code class="command">trove list</code> command to get the ID of the instance,
followed by the <code class="command">trove show</code> command to get the IP address of
it.</p></li><li class="step "><p>Access the Database service instance using typical database access
commands. For example, with MySQL:</p><div class="verbatim-wrap"><pre class="screen">$ mysql -u myuser -p -h TROVE_IP_ADDRESS mydb</pre></div></li></ol></li></ol></div></div><p>
          <span class="bold"><strong>Components</strong></span>
        </p><p>The Database service includes the following components:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.4.9.14.9.1"><span class="term "><code class="literal">python-troveclient</code> command-line client</span></dt><dd><p>A CLI that communicates with the <code class="literal">trove-api</code> component.</p></dd><dt id="id-1.4.4.9.14.9.2"><span class="term "><code class="literal">trove-api</code> component</span></dt><dd><p>Provides an OpenStack-native RESTful API that supports JSON to
provision and manage Trove instances.</p></dd><dt id="id-1.4.4.9.14.9.3"><span class="term "><code class="literal">trove-conductor</code> service</span></dt><dd><p>Runs on the host, and receives messages from guest instances that
want to update information on the host.</p></dd><dt id="id-1.4.4.9.14.9.4"><span class="term "><code class="literal">trove-taskmanager</code> service</span></dt><dd><p>Instruments the complex system flows that support provisioning
instances, managing the lifecycle of instances, and performing
operations on instances.</p></dd><dt id="id-1.4.4.9.14.9.5"><span class="term "><code class="literal">trove-guestagent</code> service</span></dt><dd><p>Runs within the guest instance. Manages and performs operations on
the database itself.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.4.9.15"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.3.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data Processing service overview</span> <a title="Permalink" class="permalink" href="#id-1.4.4.9.15">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Data processing service for OpenStack (sahara) aims to provide users
with a simple means to provision data processing (Hadoop, Spark)
clusters by specifying several parameters like Hadoop version, cluster
topology, node hardware details and a few more. After a user fills in
all the parameters, the Data processing service deploys the cluster in a
few minutes. Sahara also provides a means to scale already provisioned
clusters by adding or removing worker nodes on demand.</p><p>The solution addresses the following use cases:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Fast provisioning of Hadoop clusters on OpenStack for development and
QA.</p></li><li class="listitem "><p>Utilization of unused compute power from general purpose OpenStack
IaaS cloud.</p></li><li class="listitem "><p>Analytics-as-a-Service for ad-hoc or bursty analytic workloads.</p></li></ul></div><p>Key features are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Designed as an OpenStack component.</p></li><li class="listitem "><p>Managed through REST API with UI available as part of OpenStack
Dashboard.</p></li><li class="listitem "><p>Support for different Hadoop distributions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Pluggable system of Hadoop installation engines.</p></li><li class="listitem "><p>Integration with vendor specific management tools, such as Apache
Ambari or Cloudera Management Console.</p></li></ul></div></li><li class="listitem "><p>Predefined templates of Hadoop configurations with the ability to
modify parameters.</p></li><li class="listitem "><p>User-friendly UI for ad-hoc analytics queries based on Hive or Pig.</p></li></ul></div></div></div><div class="sect1 " id="id-1.4.4.10"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Feedback</span> <a title="Permalink" class="permalink" href="#id-1.4.4.10">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To provide feedback on documentation, join and use the
<a class="link" href="mailto:openstack-docs@lists.openstack.org" target="_blank">openstack-docs@lists.openstack.org</a> mailing list at <a class="link" href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs" target="_blank">OpenStack
Documentation Mailing
List</a>,
or <a class="link" href="https://bugs.launchpad.net/openstack-manuals/+filebug" target="_blank">report a
bug</a>.</p></div></div><div class="chapter " id="cha-identity"><div class="titlepage"><div><div><h1 class="title"><span class="number">3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Identity management</span> <a title="Permalink" class="permalink" href="#cha-identity">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>cha-identity</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.5.4"><span class="number">3.1 </span><span class="name">Identity concepts</span></a></span></dt><dt><span class="sect1"><a href="#cha-certificates-pki"><span class="number">3.2 </span><span class="name">Certificates for PKI</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.6"><span class="number">3.3 </span><span class="name">Domain-specific configuration</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.7"><span class="number">3.4 </span><span class="name">External authentication with Identity</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.8"><span class="number">3.5 </span><span class="name">Integrate Identity with LDAP</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.9"><span class="number">3.6 </span><span class="name">Keystone tokens</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.10"><span class="number">3.7 </span><span class="name">Configure Identity service for token binding</span></a></span></dt><dt><span class="sect1"><a href="#cha-fernet-faq"><span class="number">3.8 </span><span class="name">Fernet - Frequently Asked Questions</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.12"><span class="number">3.9 </span><span class="name">Use trusts</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.13"><span class="number">3.10 </span><span class="name">Caching layer</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.14"><span class="number">3.11 </span><span class="name">Security compliance and PCI-DSS</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.15"><span class="number">3.12 </span><span class="name">Example usage and Identity features</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.16"><span class="number">3.13 </span><span class="name">Authentication middleware with user name and password</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.17"><span class="number">3.14 </span><span class="name">Identity API protection with role-based access control (RBAC)</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.5.18"><span class="number">3.15 </span><span class="name">Troubleshoot the Identity service</span></a></span></dt></dl></div></div><p>OpenStack Identity, code-named keystone, is the default Identity
management system for OpenStack. After you install Identity, you
configure it through the <code class="literal">/etc/keystone/keystone.conf</code>
configuration file and, possibly, a separate logging configuration
file. You initialize data into Identity by using the <code class="literal">keystone</code>
command-line client.</p><div class="sect1 " id="id-1.4.5.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Identity concepts</span> <a title="Permalink" class="permalink" href="#id-1.4.5.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.4.2.1"><span class="term ">Authentication</span></dt><dd><p>The process of confirming the identity of a user. To confirm an incoming
request, OpenStack Identity validates a set of credentials users
supply. Initially, these credentials are a user name and password, or a
user name and API key. When OpenStack Identity validates user credentials,
it issues an authentication token. Users provide the token in
subsequent requests.</p></dd><dt id="id-1.4.5.4.2.2"><span class="term ">Credentials</span></dt><dd><p>Data that confirms the identity of the user. For example, user
name and password, user name and API key, or an authentication
token that the Identity service provides.</p></dd><dt id="id-1.4.5.4.2.3"><span class="term ">Domain</span></dt><dd><p>An Identity service API v3 entity. Domains are a collection of
projects and users that define administrative boundaries for
managing Identity entities. Domains can represent an
individual, company, or operator-owned space. They expose
administrative activities directly to system users. Users can be
granted the administrator role for a domain. A domain
administrator can create projects, users, and groups in a domain
and assign roles to users and groups in a domain.</p></dd><dt id="id-1.4.5.4.2.4"><span class="term ">Endpoint</span></dt><dd><p>A network-accessible address, usually a URL, through which you can
access a service. If you are using an extension for templates, you
can create an endpoint template that represents the templates of
all consumable services that are available across the regions.</p></dd><dt id="id-1.4.5.4.2.5"><span class="term ">Group</span></dt><dd><p>An Identity service API v3 entity. Groups are a collection of
users owned by a domain. A group role, granted to a domain
or project, applies to all users in the group. Adding or removing
users to or from a group grants or revokes their role and
authentication to the associated domain or project.</p></dd><dt id="id-1.4.5.4.2.6"><span class="term ">OpenStackClient</span></dt><dd><p>A command-line interface for several OpenStack services including
the Identity API. For example, a user can run the
<code class="command">openstack service create</code> and
<code class="command">openstack endpoint create</code> commands to register services
in their OpenStack installation.</p></dd><dt id="id-1.4.5.4.2.7"><span class="term ">Project</span></dt><dd><p>A container that groups or isolates resources or identity objects.
Depending on the service operator, a project might map to a
customer, account, organization, or tenant.</p></dd><dt id="id-1.4.5.4.2.8"><span class="term ">Region</span></dt><dd><p>An Identity service API v3 entity. Represents a general
            division in an OpenStack deployment. Zero or more sub-regions can be
            associated with a region to make a tree-like structured hierarchy.
            However Cloud 8 does not support multiple regions, so this
            guide uses the default <code class="literal">RegionOne</code> region. </p></dd><dt id="id-1.4.5.4.2.9"><span class="term ">Role</span></dt><dd><p>A personality with a defined set of user rights and privileges to
perform a specific set of operations. The Identity service issues
a token to a user that includes a list of roles. When a user calls
a service, that service interprets the user role set, and
determines to which operations or resources each role grants
access.</p></dd><dt id="id-1.4.5.4.2.10"><span class="term ">Service</span></dt><dd><p>An OpenStack service, such as Compute (nova), Object Storage
(swift), or Image service (glance), that provides one or more
endpoints through which users can access resources and perform
operations.</p></dd><dt id="id-1.4.5.4.2.11"><span class="term ">Token</span></dt><dd><p>An alpha-numeric text string that enables access to OpenStack APIs
and resources. A token may be revoked at any time and is valid for
a finite duration. While OpenStack Identity supports token-based
authentication in this release, it intends to support additional
protocols in the future. OpenStack Identity is an integration
service that does not aspire to be a full-fledged identity store
and management solution.</p></dd><dt id="id-1.4.5.4.2.12"><span class="term ">User</span></dt><dd><p>A digital representation of a person, system, or service that uses
OpenStack cloud services. The Identity service validates that
incoming requests are made by the user who claims to be making the
call. Users have a login and can access resources by using
assigned tokens. Users can be directly assigned to a particular
project and behave as if they are contained in that project.</p></dd></dl></div><div class="sect2 " id="id-1.4.5.4.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">User management</span> <a title="Permalink" class="permalink" href="#id-1.4.5.4.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Identity user management examples:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a user named <code class="literal">alice</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user create --password-prompt --email alice@example.com alice</pre></div></li><li class="listitem "><p>Create a project named <code class="literal">acme</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project create acme --domain default</pre></div></li><li class="listitem "><p>Create a domain named <code class="literal">emea</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-identity-api-version=3 domain create emea</pre></div></li><li class="listitem "><p>Create a role named <code class="literal">compute-user</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role create compute-user</pre></div><div id="id-1.4.5.4.3.3.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Individual services assign meaning to roles, typically through
limiting or granting access to users with the role to the
operations that the service supports. Role access is typically
configured in the service's <code class="literal">policy.json</code> file. For example,
to limit Compute access to the <code class="literal">compute-user</code> role, edit the
Compute service's <code class="literal">policy.json</code> file to require this role for
Compute operations.</p></div></li></ul></div><p>The Identity service assigns a project and a role to a user. You might
assign the <code class="literal">compute-user</code> role to the <code class="literal">alice</code> user in the <code class="literal">acme</code>
project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role add --project acme --user alice compute-user</pre></div><p>A user can have different roles in different projects. For example, Alice
might also have the <code class="literal">admin</code> role in the <code class="literal">Cyberdyne</code> project. A user
can also have multiple roles in the same project.</p><p>The <code class="literal">/etc/[SERVICE_CODENAME]/policy.json</code> file controls the
tasks that users can perform for a given service. For example, the
<code class="literal">/etc/nova/policy.json</code> file specifies the access policy for the
Compute service, the <code class="literal">/etc/glance/policy.json</code> file specifies
the access policy for the Image service, and the
<code class="literal">/etc/keystone/policy.json</code> file specifies the access policy for
the Identity service.</p><p>The default <code class="literal">policy.json</code> files in the Compute, Identity, and
Image services recognize only the <code class="literal">admin</code> role. Any user with
any role in a project can access all operations that do not require the
<code class="literal">admin</code> role.</p><p>To restrict users from performing operations in, for example, the
Compute service, you must create a role in the Identity service and
then modify the <code class="literal">/etc/nova/policy.json</code> file so that this role
is required for Compute operations.</p><p>For example, the following line in the <code class="literal">/etc/cinder/policy.json</code>
file does not restrict which users can create volumes:</p><div class="verbatim-wrap highlight json"><pre class="screen">"volume:create": "",</pre></div><p>If the user has any role in a project, he can create volumes in that
project.</p><p>To restrict the creation of volumes to users who have the
<code class="literal">compute-user</code> role in a particular project, you add <code class="literal">"role:compute-user"</code>:</p><div class="verbatim-wrap highlight json"><pre class="screen">"volume:create": "role:compute-user",</pre></div><p>To restrict all Compute service requests to require this role, the
resulting file looks like:</p><div class="verbatim-wrap highlight json"><pre class="screen">{
   "admin_or_owner": "role:admin or project_id:%(project_id)s",
   "default": "rule:admin_or_owner",
   "compute:create": "role:compute-user",
   "compute:create:attach_network": "role:compute-user",
   "compute:create:attach_volume": "role:compute-user",
   "compute:get_all": "role:compute-user",
   "compute:unlock_override": "rule:admin_api",
   "admin_api": "role:admin",
   "compute_extension:accounts": "rule:admin_api",
   "compute_extension:admin_actions": "rule:admin_api",
   "compute_extension:admin_actions:pause": "rule:admin_or_owner",
   "compute_extension:admin_actions:unpause": "rule:admin_or_owner",
   "compute_extension:admin_actions:suspend": "rule:admin_or_owner",
   "compute_extension:admin_actions:resume": "rule:admin_or_owner",
   "compute_extension:admin_actions:lock": "rule:admin_or_owner",
   "compute_extension:admin_actions:unlock": "rule:admin_or_owner",
   "compute_extension:admin_actions:resetNetwork": "rule:admin_api",
   "compute_extension:admin_actions:injectNetworkInfo": "rule:admin_api",
   "compute_extension:admin_actions:createBackup": "rule:admin_or_owner",
   "compute_extension:admin_actions:migrateLive": "rule:admin_api",
   "compute_extension:admin_actions:migrate": "rule:admin_api",
   "compute_extension:aggregates": "rule:admin_api",
   "compute_extension:certificates": "role:compute-user",
   "compute_extension:cloudpipe": "rule:admin_api",
   "compute_extension:console_output": "role:compute-user",
   "compute_extension:consoles": "role:compute-user",
   "compute_extension:createserverext": "role:compute-user",
   "compute_extension:deferred_delete": "role:compute-user",
   "compute_extension:disk_config": "role:compute-user",
   "compute_extension:evacuate": "rule:admin_api",
   "compute_extension:extended_server_attributes": "rule:admin_api",
   "compute_extension:extended_status": "role:compute-user",
   "compute_extension:flavorextradata": "role:compute-user",
   "compute_extension:flavorextraspecs": "role:compute-user",
   "compute_extension:flavormanage": "rule:admin_api",
   "compute_extension:floating_ip_dns": "role:compute-user",
   "compute_extension:floating_ip_pools": "role:compute-user",
   "compute_extension:floating_ips": "role:compute-user",
   "compute_extension:hosts": "rule:admin_api",
   "compute_extension:keypairs": "role:compute-user",
   "compute_extension:multinic": "role:compute-user",
   "compute_extension:networks": "rule:admin_api",
   "compute_extension:quotas": "role:compute-user",
   "compute_extension:rescue": "role:compute-user",
   "compute_extension:security_groups": "role:compute-user",
   "compute_extension:server_action_list": "rule:admin_api",
   "compute_extension:server_diagnostics": "rule:admin_api",
   "compute_extension:simple_tenant_usage:show": "rule:admin_or_owner",
   "compute_extension:simple_tenant_usage:list": "rule:admin_api",
   "compute_extension:users": "rule:admin_api",
   "compute_extension:virtual_interfaces": "role:compute-user",
   "compute_extension:virtual_storage_arrays": "role:compute-user",
   "compute_extension:volumes": "role:compute-user",
   "compute_extension:volume_attachments:index": "role:compute-user",
   "compute_extension:volume_attachments:show": "role:compute-user",
   "compute_extension:volume_attachments:create": "role:compute-user",
   "compute_extension:volume_attachments:delete": "role:compute-user",
   "compute_extension:volumetypes": "role:compute-user",
   "volume:create": "role:compute-user",
   "volume:get_all": "role:compute-user",
   "volume:get_volume_metadata": "role:compute-user",
   "volume:get_snapshot": "role:compute-user",
   "volume:get_all_snapshots": "role:compute-user",
   "network:get_all_networks": "role:compute-user",
   "network:get_network": "role:compute-user",
   "network:delete_network": "role:compute-user",
   "network:disassociate_network": "role:compute-user",
   "network:get_vifs_by_instance": "role:compute-user",
   "network:allocate_for_instance": "role:compute-user",
   "network:deallocate_for_instance": "role:compute-user",
   "network:validate_networks": "role:compute-user",
   "network:get_instance_uuids_by_ip_filter": "role:compute-user",
   "network:get_floating_ip": "role:compute-user",
   "network:get_floating_ip_pools": "role:compute-user",
   "network:get_floating_ip_by_address": "role:compute-user",
   "network:get_floating_ips_by_project": "role:compute-user",
   "network:get_floating_ips_by_fixed_address": "role:compute-user",
   "network:allocate_floating_ip": "role:compute-user",
   "network:deallocate_floating_ip": "role:compute-user",
   "network:associate_floating_ip": "role:compute-user",
   "network:disassociate_floating_ip": "role:compute-user",
   "network:get_fixed_ip": "role:compute-user",
   "network:add_fixed_ip_to_instance": "role:compute-user",
   "network:remove_fixed_ip_from_instance": "role:compute-user",
   "network:add_network_to_project": "role:compute-user",
   "network:get_instance_nw_info": "role:compute-user",
   "network:get_dns_domains": "role:compute-user",
   "network:add_dns_entry": "role:compute-user",
   "network:modify_dns_entry": "role:compute-user",
   "network:delete_dns_entry": "role:compute-user",
   "network:get_dns_entries_by_address": "role:compute-user",
   "network:get_dns_entries_by_name": "role:compute-user",
   "network:create_private_dns_domain": "role:compute-user",
   "network:create_public_dns_domain": "role:compute-user",
   "network:delete_dns_domain": "role:compute-user"
}</pre></div></div><div class="sect2 " id="id-1.4.5.4.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Service management</span> <a title="Permalink" class="permalink" href="#id-1.4.5.4.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Identity service provides identity, token, catalog, and policy
services. It consists of:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.4.4.3.1.1.1"><span class="term ">keystone Web Server Gateway Interface (WSGI) service</span></dt><dd><p>Can be run in a WSGI-capable web server such as Apache httpd to provide
the Identity service. The service and administrative APIs are run as
separate instances of the WSGI service.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.4.4.3.2.1.1"><span class="term ">Identity service functions</span></dt><dd><p>Each has a pluggable back end that allow different ways to use the
particular service. Most support standard back ends like LDAP or SQL.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.4.4.3.3.1.1"><span class="term ">keystone-all</span></dt><dd><p>Starts both the service and administrative APIs in a single process.
Using federation with keystone-all is not supported. keystone-all is
deprecated in favor of the WSGI service. Also, this will be removed
in Newton.</p></dd></dl></div></li></ul></div><p>The Identity service also maintains a user that corresponds to each
service, such as, a user named <code class="literal">nova</code> for the Compute service, and a
special service project called <code class="literal">service</code>.</p><p>For information about how to create services and endpoints, see the
<a class="link" href="http://docs.openstack.org/admin-guide/cli-manage-services.html" target="_blank">OpenStack Administrator Guide</a>.</p></div><div class="sect2 " id="id-1.4.5.4.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Groups</span> <a title="Permalink" class="permalink" href="#id-1.4.5.4.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A group is a collection of users in a domain. Administrators can
create groups and add users to them. A role can then be assigned to
the group, rather than individual users. Groups were introduced with
the Identity API v3.</p><p>Identity API V3 provides the following group-related operations:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a group</p></li><li class="listitem "><p>Delete a group</p></li><li class="listitem "><p>Update a group (change its name or description)</p></li><li class="listitem "><p>Add a user to a group</p></li><li class="listitem "><p>Remove a user from a group</p></li><li class="listitem "><p>List group members</p></li><li class="listitem "><p>List groups for a user</p></li><li class="listitem "><p>Assign a role on a project to a group</p></li><li class="listitem "><p>Assign a role on a domain to a group</p></li><li class="listitem "><p>Query role assignments to groups</p></li></ul></div><div id="id-1.4.5.4.5.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The Identity service server might not allow all operations. For
example, if you use the Identity server with the LDAP Identity
back end and group updates are disabled, a request to create,
delete, or update a group fails.</p></div><p>Here are a couple of examples:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Group A is granted Role A on Project A. If User A is a member of Group
A, when User A gets a token scoped to Project A, the token also
includes Role A.</p></li><li class="listitem "><p>Group B is granted Role B on Domain B. If User B is a member of
Group B, when User B gets a token scoped to Domain B, the token also
includes Role B.</p></li></ul></div></div></div><div class="sect1 " id="cha-certificates-pki"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Certificates for PKI</span> <a title="Permalink" class="permalink" href="#cha-certificates-pki">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>cha-certificates-pki</li></ul></div></div></div></div><p>PKI stands for Public Key Infrastructure. Tokens are documents,
cryptographically signed using the X509 standard. In order to work
correctly token generation requires a public/private key pair. The
public key must be signed in an X509 certificate, and the certificate
used to sign it must be available as a <a class="xref" href="#term-certificate-authority-ca" title="certificate authority (CA)">certificate authority (CA)</a>
certificate. These files can be generated either using the
<code class="command">keystone-manage</code> utility, or externally generated. The files need to
be in the locations specified by the top level Identity service
configuration file <code class="literal">/etc/keystone/keystone.conf</code> as specified in the
above section. Additionally, the private key should only be readable by
the system user that will run the Identity service.</p><div id="id-1.4.5.5.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>The certificates can be world readable, but the private key cannot
be. The private key should only be readable by the account that is
going to sign tokens. When generating files with the
<code class="command">keystone-manage pki_setup</code> command, your best option is to run
as the pki user. If you run <code class="command">keystone-manage</code> as root, you can
append <code class="literal">--keystone-user</code> and <code class="literal">--keystone-group</code> parameters
to set the user name and group keystone is going to run under.</p></div><p>The values that specify where to read the certificates are under the
<code class="literal">[signing]</code> section of the configuration file. The configuration
values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.1.1.1"><span class="term ">
                <code class="literal">certfile</code>
              </span></dt><dd><p>Location of certificate used to verify tokens. Default is
<code class="literal">/etc/keystone/ssl/certs/signing_cert.pem</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.2.1.1"><span class="term ">
                <code class="literal">keyfile</code>
              </span></dt><dd><p>Location of private key used to sign tokens. Default is
<code class="literal">/etc/keystone/ssl/private/signing_key.pem</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.3.1.1"><span class="term ">
                <code class="literal">ca_certs</code>
              </span></dt><dd><p>Location of certificate for the authority that issued
the above certificate. Default is
<code class="literal">/etc/keystone/ssl/certs/ca.pem</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.4.1.1"><span class="term ">
                <code class="literal">ca_key</code>
              </span></dt><dd><p>Location of the private key used by the CA. Default is
<code class="literal">/etc/keystone/ssl/private/cakey.pem</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.5.1.1"><span class="term ">
                <code class="literal">key_size</code>
              </span></dt><dd><p>Default is <code class="literal">2048</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.6.1.1"><span class="term ">
                <code class="literal">valid_days</code>
              </span></dt><dd><p>Default is <code class="literal">3650</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.5.7.1.1"><span class="term ">
                <code class="literal">cert_subject</code>
              </span></dt><dd><p>Certificate subject (auto generated certificate) for token signing.
Default is <code class="literal">/C=US/ST=Unset/L=Unset/O=Unset/CN=www.example.com</code>.</p></dd></dl></div></li></ul></div><p>When generating certificates with the <code class="command">keystone-manage pki_setup</code>
command, the <code class="literal">ca_key</code>, <code class="literal">key_size</code>, and <code class="literal">valid_days</code> configuration
options are used.</p><p>If the <code class="command">keystone-manage pki_setup</code> command is not used to generate
certificates, or you are providing your own certificates, these values
do not need to be set.</p><p>If <code class="literal">provider=keystone.token.providers.uuid.Provider</code> in the
<code class="literal">[token]</code> section of the keystone configuration file, a typical token
looks like <code class="literal">53f7f6ef0cc344b5be706bcc8b1479e1</code>. If
<code class="literal">provider=keystone.token.providers.pki.Provider</code>, a typical token is a
much longer string, such as:</p><div class="verbatim-wrap"><pre class="screen">MIIKtgYJKoZIhvcNAQcCoIIKpzCCCqMCAQExCTAHBgUrDgMCGjCCCY8GCSqGSIb3DQEHAaCCCYAEggl8eyJhY2Nlc3MiOiB7InRva2VuIjogeyJpc3N1ZWRfYXQiOiAiMjAxMy0wNS0z
MFQxNTo1MjowNi43MzMxOTgiLCAiZXhwaXJlcyI6ICIyMDEzLTA1LTMxVDE1OjUyOjA2WiIsICJpZCI6ICJwbGFjZWhvbGRlciIsICJ0ZW5hbnQiOiB7ImRlc2NyaXB0aW9uIjogbnVs
bCwgImVuYWJsZWQiOiB0cnVlLCAiaWQiOiAiYzJjNTliNGQzZDI4NGQ4ZmEwOWYxNjljYjE4MDBlMDYiLCAibmFtZSI6ICJkZW1vIn19LCAic2VydmljZUNhdGFsb2ciOiBbeyJlbmRw
b2ludHMiOiBbeyJhZG1pblVSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4xMDA6ODc3NC92Mi9jMmM1OWI0ZDNkMjg0ZDhmYTA5ZjE2OWNiMTgwMGUwNiIsICJyZWdpb24iOiAiUmVnaW9u
T25lIiwgImludGVybmFsVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4Nzc0L3YyL2MyYzU5YjRkM2QyODRkOGZhMDlmMTY5Y2IxODAwZTA2IiwgImlkIjogIjFmYjMzYmM5M2Y5
ODRhNGNhZTk3MmViNzcwOTgzZTJlIiwgInB1YmxpY1VSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4xMDA6ODc3NC92Mi9jMmM1OWI0ZDNkMjg0ZDhmYTA5ZjE2OWNiMTgwMGUwNiJ9XSwg
ImVuZHBvaW50c19saW5rcyI6IFtdLCAidHlwZSI6ICJjb21wdXRlIiwgIm5hbWUiOiAibm92YSJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3
LjEwMDozMzMzIiwgInJlZ2lvbiI6ICJSZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjMzMzMiLCAiaWQiOiAiN2JjMThjYzk1NWFiNDNkYjhm
MGU2YWNlNDU4NjZmMzAiLCAicHVibGljVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDozMzMzIn1dLCAiZW5kcG9pbnRzX2xpbmtzIjogW10sICJ0eXBlIjogInMzIiwgIm5hbWUi
OiAiczMifSwgeyJlbmRwb2ludHMiOiBbeyJhZG1pblVSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4xMDA6OTI5MiIsICJyZWdpb24iOiAiUmVnaW9uT25lIiwgImludGVybmFsVVJMIjog
Imh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo5MjkyIiwgImlkIjogIjczODQzNTJhNTQ0MjQ1NzVhM2NkOTVkN2E0YzNjZGY1IiwgInB1YmxpY1VSTCI6ICJodHRwOi8vMTkyLjE2OC4yNy4x
MDA6OTI5MiJ9XSwgImVuZHBvaW50c19saW5rcyI6IFtdLCAidHlwZSI6ICJpbWFnZSIsICJuYW1lIjogImdsYW5jZSJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6
Ly8xOTIuMTY4LjI3LjEwMDo4Nzc2L3YxL2MyYzU5YjRkM2QyODRkOGZhMDlmMTY5Y2IxODAwZTA2IiwgInJlZ2lvbiI6ICJSZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDov
LzE5Mi4xNjguMjcuMTAwOjg3NzYvdjEvYzJjNTliNGQzZDI4NGQ4ZmEwOWYxNjljYjE4MDBlMDYiLCAiaWQiOiAiMzQ3ZWQ2ZThjMjkxNGU1MGFlMmJiNjA2YWQxNDdjNTQiLCAicHVi
bGljVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4Nzc2L3YxL2MyYzU5YjRkM2QyODRkOGZhMDlmMTY5Y2IxODAwZTA2In1dLCAiZW5kcG9pbnRzX2xpbmtzIjogW10sICJ0eXBl
IjogInZvbHVtZSIsICJuYW1lIjogImNpbmRlciJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4NzczL3NlcnZpY2VzL0FkbWluIiwg
InJlZ2lvbiI6ICJSZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjg3NzMvc2VydmljZXMvQ2xvdWQiLCAiaWQiOiAiMmIwZGMyYjNlY2U4NGJj
YWE1NDAzMDMzNzI5YzY3MjIiLCAicHVibGljVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDo4NzczL3NlcnZpY2VzL0Nsb3VkIn1dLCAiZW5kcG9pbnRzX2xpbmtzIjogW10sICJ0
eXBlIjogImVjMiIsICJuYW1lIjogImVjMiJ9LCB7ImVuZHBvaW50cyI6IFt7ImFkbWluVVJMIjogImh0dHA6Ly8xOTIuMTY4LjI3LjEwMDozNTM1Ny92Mi4wIiwgInJlZ2lvbiI6ICJS
ZWdpb25PbmUiLCAiaW50ZXJuYWxVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjUwMDAvdjIuMCIsICJpZCI6ICJiNTY2Y2JlZjA2NjQ0ZmY2OWMyOTMxNzY2Yjc5MTIyOSIsICJw
dWJsaWNVUkwiOiAiaHR0cDovLzE5Mi4xNjguMjcuMTAwOjUwMDAvdjIuMCJ9XSwgImVuZHBvaW50c19saW5rcyI6IFtdLCAidHlwZSI6ICJpZGVudGl0eSIsICJuYW1lIjogImtleXN0
b25lIn1dLCAidXNlciI6IHsidXNlcm5hbWUiOiAiZGVtbyIsICJyb2xlc19saW5rcyI6IFtdLCAiaWQiOiAiZTVhMTM3NGE4YTRmNDI4NWIzYWQ3MzQ1MWU2MDY4YjEiLCAicm9sZXMi
OiBbeyJuYW1lIjogImFub3RoZXJyb2xlIn0sIHsibmFtZSI6ICJNZW1iZXIifV0sICJuYW1lIjogImRlbW8ifSwgIm1ldGFkYXRhIjogeyJpc19hZG1pbiI6IDAsICJyb2xlcyI6IFsi
YWRiODM3NDVkYzQzNGJhMzk5ODllNjBjOTIzYWZhMjgiLCAiMzM2ZTFiNjE1N2Y3NGFmZGJhNWUwYTYwMWUwNjM5MmYiXX19fTGB-zCB-AIBATBcMFcxCzAJBgNVBAYTAlVTMQ4wDAYD
VQQIEwVVbnNldDEOMAwGA1UEBxMFVW5zZXQxDjAMBgNVBAoTBVVuc2V0MRgwFgYDVQQDEw93d3cuZXhhbXBsZS5jb20CAQEwBwYFKw4DAhowDQYJKoZIhvcNAQEBBQAEgYCAHLpsEs2R
nouriuiCgFayIqCssK3SVdhOMINiuJtqv0sE-wBDFiEj-Prcudqlz-n+6q7VgV4mwMPszz39-rwp+P5l4AjrJasUm7FrO-4l02tPLaaZXU1gBQ1jUG5e5aL5jPDP08HbCWuX6wr-QQQB
SrWY8lF3HrTcJT23sZIleg==</pre></div><div class="sect2 " id="id-1.4.5.5.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Sign certificate issued by external CA</span> <a title="Permalink" class="permalink" href="#id-1.4.5.5.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can use a signing certificate issued by an external CA instead of
generated by <code class="command">keystone-manage</code>. However, a certificate issued by an
external CA must satisfy the following conditions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>All certificate and key files must be in Privacy Enhanced Mail (PEM)
format</p></li><li class="listitem "><p>Private key files must not be protected by a password</p></li></ul></div><p>When using a signing certificate issued by an external CA, you do not
need to specify <code class="literal">key_size</code>, <code class="literal">valid_days</code>, and <code class="literal">ca_password</code> as
they will be ignored.</p><p>The basic workflow for using a signing certificate issued by an external
CA involves:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Request Signing Certificate from External CA</p></li><li class="step "><p>Convert certificate and private key to PEM if needed</p></li><li class="step "><p>Install External Signing Certificate</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.5.5.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Request a signing certificate from an external CA</span> <a title="Permalink" class="permalink" href="#id-1.4.5.5.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>One way to request a signing certificate from an external CA is to first
generate a PKCS #10 Certificate Request Syntax (CRS) using OpenSSL CLI.</p><p>Create a certificate request configuration file. For example, create the
<code class="literal">cert_req.conf</code> file, as follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ req ]
default_bits            = 4096
default_keyfile         = keystonekey.pem
default_md              = sha256

prompt                  = no
distinguished_name      = distinguished_name

[ distinguished_name ]
countryName             = US
stateOrProvinceName     = CA
localityName            = Sunnyvale
organizationName        = OpenStack
organizationalUnitName  = Keystone
commonName              = Keystone Signing
emailAddress            = keystone@openstack.org</pre></div><p>Then generate a CRS with OpenSSL CLI. <span class="bold"><strong>Do not encrypt the generated
private key. You must use the -nodes option.</strong></span></p><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openssl req -newkey rsa:1024 -keyout signing_key.pem -keyform PEM \
  -out signing_cert_req.pem -outform PEM -config cert_req.conf -nodes</pre></div><p>If everything is successful, you should end up with
<code class="literal">signing_cert_req.pem</code> and <code class="literal">signing_key.pem</code>. Send
<code class="literal">signing_cert_req.pem</code> to your CA to request a token signing certificate
and make sure to ask the certificate to be in PEM format. Also, make sure your
trusted CA certificate chain is also in PEM format.</p></div><div class="sect2 " id="id-1.4.5.5.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install an external signing certificate</span> <a title="Permalink" class="permalink" href="#id-1.4.5.5.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Assuming you have the following already:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.12.3.1.1.1"><span class="term ">
                  <code class="literal">signing_cert.pem</code>
                </span></dt><dd><p>(Keystone token) signing certificate in PEM format</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.12.3.2.1.1"><span class="term ">
                  <code class="literal">signing_key.pem</code>
                </span></dt><dd><p>Corresponding (non-encrypted) private key in PEM format</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.5.12.3.3.1.1"><span class="term ">
                  <code class="literal">cacert.pem</code>
                </span></dt><dd><p>Trust CA certificate chain in PEM format</p></dd></dl></div></li></ul></div><p>Copy the above to your certificate directory. For example:</p><div class="verbatim-wrap"><pre class="screen"># mkdir -p /etc/keystone/ssl/certs
# cp signing_cert.pem /etc/keystone/ssl/certs/
# cp signing_key.pem /etc/keystone/ssl/certs/
# cp cacert.pem /etc/keystone/ssl/certs/
# chmod -R 700 /etc/keystone/ssl/certs</pre></div><div id="id-1.4.5.5.12.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Make sure the certificate directory is only accessible by root.</p></div><div id="id-1.4.5.5.12.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The procedure of copying the key and cert files may be improved if
done after first running <code class="command">keystone-manage pki_setup</code> since this
command also creates other needed files, such as the <code class="literal">index.txt</code>
and <code class="literal">serial</code> files.</p><p>Also, when copying the necessary files to a different server for
replicating the functionality, the entire directory of files is
needed, not just the key and cert files.</p></div><p>If your certificate directory path is different from the default
<code class="literal">/etc/keystone/ssl/certs</code>, make sure it is reflected in the
<code class="literal">[signing]</code> section of the configuration file.</p></div><div class="sect2 " id="id-1.4.5.5.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Switching out expired signing certificates</span> <a title="Permalink" class="permalink" href="#id-1.4.5.5.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following procedure details how to switch out expired signing
certificates with no cloud outages.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Generate a new signing key.</p></li><li class="step "><p>Generate a new certificate request.</p></li><li class="step "><p>Sign the new certificate with the existing CA to generate a new
<code class="literal">signing_cert</code>.</p></li><li class="step "><p>Append the new <code class="literal">signing_cert</code> to the old <code class="literal">signing_cert</code>. Ensure the
old certificate is in the file first.</p></li><li class="step "><p>Remove all signing certificates from all your hosts to force OpenStack
Compute to download the new <code class="literal">signing_cert</code>.</p></li><li class="step "><p>Replace the old signing key with the new signing key. Move the new
signing certificate above the old certificate in the <code class="literal">signing_cert</code>
file.</p></li><li class="step "><p>After the old certificate reads as expired, you can safely remove the
old signing certificate from the file.</p></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.5.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Domain-specific configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.5.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Identity service supports domain-specific Identity drivers.
The drivers allow a domain to have its own LDAP or SQL back end.
By default, domain-specific drivers are disabled.</p><p>Domain-specific Identity configuration options can be stored in
domain-specific configuration files, or in the Identity SQL
database using API REST calls.</p><div id="id-1.4.5.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Storing and managing configuration options in an SQL database is
experimental in Kilo, and added to the Identity service in the
Liberty release.</p></div><div class="sect2 " id="id-1.4.5.6.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable drivers for domain-specific configuration files</span> <a title="Permalink" class="permalink" href="#id-1.4.5.6.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable domain-specific drivers, set these options in the
<code class="literal">/etc/keystone/keystone.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[identity]
domain_specific_drivers_enabled = True
domain_config_dir = /etc/keystone/domains</pre></div><p>When you enable domain-specific drivers, Identity looks in the
<code class="literal">domain_config_dir</code> directory for configuration files that are named as
<code class="literal">keystone.DOMAIN_NAME.conf</code>. A domain without a domain-specific
configuration file uses options in the primary configuration file.</p></div><div class="sect2 " id="id-1.4.5.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable drivers for storing configuration options in SQL database</span> <a title="Permalink" class="permalink" href="#id-1.4.5.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable domain-specific drivers, set these options in the
<code class="literal">/etc/keystone/keystone.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[identity]
domain_specific_drivers_enabled = True
domain_configurations_from_database = True</pre></div><p>Any domain-specific configuration options specified through the
Identity v3 API will override domain-specific configuration files in the
<code class="literal">/etc/keystone/domains</code> directory.</p></div><div class="sect2 " id="id-1.4.5.6.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate domain-specific configuration files to the SQL database</span> <a title="Permalink" class="permalink" href="#id-1.4.5.6.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can use the <code class="literal">keystone-manage</code> command to migrate configuration
options in domain-specific configuration files to the SQL database:</p><div class="verbatim-wrap"><pre class="screen"># keystone-manage domain_config_upload --all</pre></div><p>To upload options from a specific domain-configuration file, specify the
domain name:</p><div class="verbatim-wrap"><pre class="screen"># keystone-manage domain_config_upload --domain-name DOMAIN_NAME</pre></div></div></div><div class="sect1 " id="id-1.4.5.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">External authentication with Identity</span> <a title="Permalink" class="permalink" href="#id-1.4.5.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When Identity runs in <code class="literal">apache-httpd</code>, you can use external
authentication methods that differ from the authentication provided by
the identity store back end. For example, you can use an SQL identity
back end together with X.509 authentication and Kerberos, instead of
using the user name and password combination.</p><div class="sect2 " id="id-1.4.5.7.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use HTTPD authentication</span> <a title="Permalink" class="permalink" href="#id-1.4.5.7.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Web servers, like Apache HTTP, support many methods of authentication.
Identity can allow the web server to perform the authentication. The web
server then passes the authenticated user to Identity by using the
<code class="literal">REMOTE_USER</code> environment variable. This user must already exist in
the Identity back end to get a token from the controller. To use this
method, Identity should run on <code class="literal">apache-httpd</code>.</p></div><div class="sect2 " id="id-1.4.5.7.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use X.509</span> <a title="Permalink" class="permalink" href="#id-1.4.5.7.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following Apache configuration snippet authenticates the user based
on a valid X.509 certificate from a known CA:</p><div class="verbatim-wrap"><pre class="screen">&lt;VirtualHost _default_:5000&gt;
    SSLEngine on
    SSLCertificateFile    /etc/ssl/certs/ssl.cert
    SSLCertificateKeyFile /etc/ssl/private/ssl.key

    SSLCACertificatePath /etc/ssl/allowed_cas
    SSLCARevocationPath  /etc/ssl/allowed_cas
    SSLUserName          SSL_CLIENT_S_DN_CN
    SSLVerifyClient      require
    SSLVerifyDepth       10

    (...)
&lt;/VirtualHost&gt;</pre></div></div></div><div class="sect1 " id="id-1.4.5.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Integrate Identity with LDAP</span> <a title="Permalink" class="permalink" href="#id-1.4.5.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Identity service supports integration with existing LDAP
directories for authentication and authorization services. LDAP back
ends require initialization before configuring the OpenStack Identity
service to work with it. For more information, see <a class="link" href="https://wiki.openstack.org/wiki/OpenLDAP" target="_blank">Setting up LDAP
for use with Keystone</a>.</p><p>When the OpenStack Identity service is configured to use LDAP back ends,
you can split authentication (using the <span class="emphasis"><em>identity</em></span> feature) and
authorization (using the <span class="emphasis"><em>assignment</em></span> feature).</p><p>The <span class="emphasis"><em>identity</em></span> feature enables administrators to manage users and groups
by each domain or the OpenStack Identity service entirely.</p><p>The <span class="emphasis"><em>assignment</em></span> feature enables administrators to manage project role
authorization using the OpenStack Identity service SQL database, while
providing user authentication through the LDAP directory.</p><div class="sect2 " id="identity-ldap-server-setup"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Identity LDAP server set up</span> <a title="Permalink" class="permalink" href="#identity-ldap-server-setup">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>identity-ldap-server-setup</li></ul></div></div></div></div><div id="id-1.4.5.8.6.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>For the OpenStack Identity service to access LDAP servers, you must
enable the <code class="literal">authlogin_nsswitch_use_ldap</code> boolean value for SELinux
on the server running the OpenStack Identity service. To enable and
make the option persistent across reboots, set the following boolean
value as the root user:</p><div class="verbatim-wrap"><pre class="screen"># setsebool -P authlogin_nsswitch_use_ldap on</pre></div></div><p>The Identity configuration is split into two separate back ends; identity
(back end for users and groups), and assignments (back end for domains,
projects, roles, role assignments). To configure Identity, set options
in the <code class="literal">/etc/keystone/keystone.conf</code> file. See
<a class="xref" href="#integrate-identity-backend-ldap" title="3.5.2. Integrate Identity back end with LDAP">Section 3.5.2, “Integrate Identity back end with LDAP”</a> for Identity back end configuration
examples. Modify these examples as needed.</p><p>
          <span class="bold"><strong>To define the destination LDAP server</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>Define the destination LDAP server in the
<code class="literal">/etc/keystone/keystone.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
url = ldap://localhost
user = dc=Manager,dc=example,dc=org
password = samplepassword
suffix = dc=example,dc=org</pre></div></li></ul></div></div><p>
          <span class="bold"><strong>Additional LDAP integration settings</strong></span>
        </p><p>Set these options in the <code class="literal">/etc/keystone/keystone.conf</code> file for a
single LDAP server, or <code class="literal">/etc/keystone/domains/keystone.DOMAIN_NAME.conf</code>
files for multiple back ends. Example configurations appear below each
setting summary:</p><p>
          <span class="bold"><strong>Query option</strong></span>
        </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Use <code class="literal">query_scope</code> to control the scope level of data presented
(search only the first level or search an entire sub-tree)
through LDAP.</p></li><li class="listitem "><p>Use <code class="literal">page_size</code> to control the maximum results per page. A value
of zero disables paging.</p></li><li class="listitem "><p>Use <code class="literal">alias_dereferencing</code> to control the LDAP dereferencing
option for queries.</p></li></ul></div><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
query_scope = sub
page_size = 0
alias_dereferencing = default
chase_referrals =</pre></div><p>
          <span class="bold"><strong>Debug</strong></span>
        </p><p>Use <code class="literal">debug_level</code> to set the LDAP debugging level for LDAP calls.
A value of zero means that debugging is not enabled.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
debug_level = 0</pre></div><div id="id-1.4.5.8.6.14" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>This value is a bitmask, consult your LDAP documentation for
possible values.</p></div><p>
          <span class="bold"><strong>Connection pooling</strong></span>
        </p><p>Use <code class="literal">use_pool</code> to enable LDAP connection pooling. Configure the
connection pool size, maximum retry, reconnect trials, timeout (-1
indicates indefinite wait) and lifetime in seconds.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
use_pool = true
pool_size = 10
pool_retry_max = 3
pool_retry_delay = 0.1
pool_connection_timeout = -1
pool_connection_lifetime = 600</pre></div><p>
          <span class="bold"><strong>Connection pooling for end user authentication</strong></span>
        </p><p>Use <code class="literal">use_auth_pool</code> to enable LDAP connection pooling for end user
authentication. Configure the connection pool size and lifetime in
seconds.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
use_auth_pool = false
auth_pool_size = 100
auth_pool_connection_lifetime = 60</pre></div><p>When you have finished the configuration, restart the OpenStack Identity
service.</p><div id="id-1.4.5.8.6.22" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>During the service restart, authentication and authorization are
unavailable.</p></div></div><div class="sect2 " id="integrate-identity-backend-ldap"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Integrate Identity back end with LDAP</span> <a title="Permalink" class="permalink" href="#integrate-identity-backend-ldap">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>integrate-identity-backend-ldap</li></ul></div></div></div></div><p>The Identity back end contains information for users, groups, and group
member lists. Integrating the Identity back end with LDAP allows
administrators to use users and groups in LDAP.</p><div id="id-1.4.5.8.7.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>For OpenStack Identity service to access LDAP servers, you must
define the destination LDAP server in the
<code class="literal">/etc/keystone/keystone.conf</code> file. For more information,
see <a class="xref" href="#identity-ldap-server-setup" title="3.5.1. Identity LDAP server set up">Section 3.5.1, “Identity LDAP server set up”</a>.</p></div><p>
          <span class="bold"><strong>To integrate one Identity back end with LDAP</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Enable the LDAP Identity driver in the <code class="literal">/etc/keystone/keystone.conf</code>
file. This allows LDAP as an identity back end:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[identity]
#driver = sql
driver = ldap</pre></div></li><li class="step "><p>Create the organizational units (OU) in the LDAP directory, and define
the corresponding location in the <code class="literal">/etc/keystone/keystone.conf</code>
file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
user_tree_dn = ou=Users,dc=example,dc=org
user_objectclass = inetOrgPerson

group_tree_dn = ou=Groups,dc=example,dc=org
group_objectclass = groupOfNames</pre></div><div id="id-1.4.5.8.7.5.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>These schema attributes are extensible for compatibility with
various schemas. For example, this entry maps to the person
attribute in Active Directory:</p><div class="verbatim-wrap highlight ini"><pre class="screen">user_objectclass = person</pre></div></div></li><li class="step "><p>Restart the OpenStack Identity service.</p><div id="id-1.4.5.8.7.5.3.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>During service restart, authentication and authorization are
unavailable.</p></div></li></ol></div></div><p>
          <span class="bold"><strong>To integrate multiple Identity back ends with LDAP</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Set the following options in the <code class="literal">/etc/keystone/keystone.conf</code>
file:</p><ol type="a" class="substeps "><li class="step "><p>Enable the LDAP driver:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[identity]
#driver = sql
driver = ldap</pre></div></li><li class="step "><p>Enable domain-specific drivers:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[identity]
domain_specific_drivers_enabled = True
domain_config_dir = /etc/keystone/domains</pre></div></li></ol></li><li class="step "><p>Restart the OpenStack Identity service.</p><div id="id-1.4.5.8.7.7.2.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>During service restart, authentication and authorization are
unavailable.</p></div></li><li class="step "><p>List the domains using the dashboard, or the OpenStackClient CLI. Refer
to the <a class="link" href="http://docs.openstack.org/developer/python-openstackclient/command-list.html" target="_blank">Command List</a>
for a list of OpenStackClient commands.</p></li><li class="step "><p>Create domains using OpenStack dashboard, or the OpenStackClient CLI.</p></li><li class="step "><p>For each domain, create a domain-specific configuration file in the
<code class="literal">/etc/keystone/domains</code> directory. Use the file naming convention
<code class="literal">keystone.DOMAIN_NAME.conf</code>, where DOMAIN_NAME is the domain name
assigned in the previous step.</p><div id="id-1.4.5.8.7.7.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The options set in the
<code class="literal">/etc/keystone/domains/keystone.DOMAIN_NAME.conf</code> file will
override options in the <code class="literal">/etc/keystone/keystone.conf</code> file.</p></div></li><li class="step "><p>Define the destination LDAP server in the
<code class="literal">/etc/keystone/domains/keystone.DOMAIN_NAME.conf</code> file. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
url = ldap://localhost
user = dc=Manager,dc=example,dc=org
password = samplepassword
suffix = dc=example,dc=org</pre></div></li><li class="step "><p>Create the organizational units (OU) in the LDAP directories, and define
their corresponding locations in the
<code class="literal">/etc/keystone/domains/keystone.DOMAIN_NAME.conf</code> file. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
user_tree_dn = ou=Users,dc=example,dc=org
user_objectclass = inetOrgPerson

group_tree_dn = ou=Groups,dc=example,dc=org
group_objectclass = groupOfNames</pre></div><div id="id-1.4.5.8.7.7.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>These schema attributes are extensible for compatibility with
various schemas. For example, this entry maps to the person
attribute in Active Directory:</p><div class="verbatim-wrap highlight ini"><pre class="screen">user_objectclass = person</pre></div></div></li><li class="step "><p>A read-only implementation is recommended for LDAP integration. These
permissions are applied to object types in the
<code class="literal">/etc/keystone/domains/keystone.DOMAIN_NAME.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
user_allow_create = False
user_allow_update = False
user_allow_delete = False

group_allow_create = False
group_allow_update = False
group_allow_delete = False</pre></div></li><li class="step "><p>Restart the OpenStack Identity service.</p><div id="id-1.4.5.8.7.7.9.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>During service restart, authentication and authorization are
unavailable.</p></div></li></ol></div></div><p>
          <span class="bold"><strong>Additional LDAP integration settings</strong></span>
        </p><p>Set these options in the <code class="literal">/etc/keystone/keystone.conf</code> file for a
single LDAP server, or <code class="literal">/etc/keystone/domains/keystone.DOMAIN_NAME.conf</code>
files for multiple back ends. Example configurations appear below each
setting summary:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.8.7.10.1"><span class="term ">Filters</span></dt><dd><p>Use filters to control the scope of data presented through LDAP.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
user_filter = (memberof=cn=openstack-users,ou=workgroups,dc=example,dc=org)
group_filter =</pre></div></dd><dt id="id-1.4.5.8.7.10.2"><span class="term ">Identity attribute mapping</span></dt><dd><p>Mask account status values (include any additional attribute
mappings) for compatibility with various directory services.
Superfluous accounts are filtered with <code class="literal">user_filter</code>.</p><p>Setting attribute ignore to list of attributes stripped off on
update.</p><p>For example, you can mask Active Directory account status attributes
in the <code class="literal">/etc/keystone/keystone.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
user_id_attribute      = cn
user_name_attribute    = sn
user_mail_attribute    = mail
user_pass_attribute    = userPassword
user_enabled_attribute = userAccountControl
user_enabled_mask      = 2
user_enabled_invert    = false
user_enabled_default   = 512
user_default_project_id_attribute =
user_additional_attribute_mapping =

group_id_attribute     = cn
group_name_attribute   = ou
group_member_attribute = member
group_desc_attribute   = description
group_additional_attribute_mapping =</pre></div></dd><dt id="id-1.4.5.8.7.10.3"><span class="term ">Enabled emulation</span></dt><dd><p>An alternative method to determine if a user is enabled or not is by
checking if that user is a member of the emulation group.</p><p>Use DN of the group entry to hold enabled user when using enabled
emulation.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ldap]
user_enabled_emulation = false
user_enabled_emulation_dn = false</pre></div></dd></dl></div><p>When you have finished configuration, restart the OpenStack Identity
service.</p><div id="id-1.4.5.8.7.12" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>During service restart, authentication and authorization are
unavailable.</p></div></div><div class="sect2 " id="id-1.4.5.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Secure the OpenStack Identity service connection to an LDAP back end</span> <a title="Permalink" class="permalink" href="#id-1.4.5.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Identity service supports the use of TLS to encrypt LDAP traffic.
Before configuring this, you must first verify where your certificate
authority file is located. For more information, see the
<a class="link" href="http://docs.openstack.org/security-guide/secure-communication/introduction-to-ssl-and-tls.html" target="_blank">OpenStack Security Guide SSL introduction</a>.</p><p>Once you verify the location of your certificate authority file:</p><p>
          <span class="bold"><strong>To configure TLS encryption on LDAP traffic</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Open the <code class="literal">/etc/keystone/keystone.conf</code> configuration file.</p></li><li class="step "><p>Find the <code class="literal">[ldap]</code> section.</p></li><li class="step "><p>In the <code class="literal">[ldap]</code> section, set the <code class="literal">use_tls</code> configuration key to
<code class="literal">True</code>. Doing so will enable TLS.</p></li><li class="step "><p>Configure the Identity service to use your certificate authorities file.
To do so, set the <code class="literal">tls_cacertfile</code> configuration key in the <code class="literal">ldap</code>
section to the certificate authorities file's path.</p><div id="id-1.4.5.8.8.5.4.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You can also set the <code class="literal">tls_cacertdir</code> (also in the <code class="literal">ldap</code>
section) to the directory where all certificate authorities files
are kept. If both <code class="literal">tls_cacertfile</code> and <code class="literal">tls_cacertdir</code> are set,
then the latter will be ignored.</p></div></li><li class="step "><p>Specify what client certificate checks to perform on incoming TLS
sessions from the LDAP server. To do so, set the <code class="literal">tls_req_cert</code>
configuration key in the <code class="literal">[ldap]</code> section to <code class="literal">demand</code>, <code class="literal">allow</code>, or
<code class="literal">never</code>:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">demand</code> - The LDAP server always receives certificate
requests. The session terminates if no certificate
is provided, or if the certificate provided cannot be verified
against the existing certificate authorities file.</p></li><li class="listitem "><p><code class="literal">allow</code> - The LDAP server always receives certificate
requests. The session will proceed as normal even if a certificate
is not provided. If a certificate is provided but it cannot be
verified against the existing certificate authorities file, the
certificate will be ignored and the session will proceed as
normal.</p></li><li class="listitem "><p><code class="literal">never</code> - A certificate will never be requested.</p></li></ul></div></li></ol></div></div><p>On distributions that include openstack-config, you can configure TLS
encryption on LDAP traffic by running the following commands instead.</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/keystone/keystone.conf \
  ldap use_tls True
# openstack-config --set /etc/keystone/keystone.conf \
  ldap tls_cacertfile ``CA_FILE``
# openstack-config --set /etc/keystone/keystone.conf \
  ldap tls_req_cert ``CERT_BEHAVIOR``</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">CA_FILE</code> is the absolute path to the certificate authorities file
that should be used to encrypt LDAP traffic.</p></li><li class="listitem "><p><code class="literal">CERT_BEHAVIOR</code> specifies what client certificate checks to perform
on an incoming TLS session from the LDAP server (<code class="literal">demand</code>,
<code class="literal">allow</code>, or <code class="literal">never</code>).</p></li></ul></div></div></div><div class="sect1 " id="id-1.4.5.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Keystone tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Tokens are used to authenticate and authorize your interactions with the
various OpenStack APIs. Tokens come in many flavors, representing various
authorization scopes and sources of identity. There are also several different
"token providers", each with their own user experience, performance, and
deployment characteristics.</p><div class="sect2 " id="id-1.4.5.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Authorization scopes</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Tokens can express your authorization in different scopes. You likely have
different sets of roles, in different projects, and in different domains.
While tokens always express your identity, they may only ever express one set
of roles in one authorization scope at a time.</p><p>Each level of authorization scope is useful for certain types of operations in
certain OpenStack services, and are not interchangeable.</p><div class="sect3 " id="id-1.4.5.9.3.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.6.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Unscoped tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.3.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An unscoped token contains neither a service catalog, any roles, a project
scope, nor a domain scope. Their primary use case is simply to prove your
identity to keystone at a later time (usually to generate scoped tokens),
without repeatedly presenting your original credentials.</p><p>The following conditions must be met to receive an unscoped token:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>You must not specify an authorization scope in your authentication request
(for example, on the command line with arguments such as
<code class="literal">--os-project-name</code> or <code class="literal">--os-domain-id</code>),</p></li><li class="listitem "><p>Your identity must not have a "default project" associated with it that you
also have role assignments, and thus authorization, upon.</p></li></ul></div></div><div class="sect3 " id="id-1.4.5.9.3.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.6.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Project-scoped tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.3.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Project-scoped tokens are the bread and butter of OpenStack. They express your
authorization to operate in a specific tenancy of the cloud and are useful to
authenticate yourself when working with most other services.</p><p>They contain a service catalog, a set of roles, and details of the project upon
which you have authorization.</p></div><div class="sect3 " id="id-1.4.5.9.3.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.6.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Domain-scoped tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.3.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Domain-scoped tokens also have limited use cases in OpenStack. They express
your authorization to operate a domain-level, above that of the user and
projects contained therein (typically as a domain-level administrator).
Depending on Keystone's configuration, they are useful for working with a
single domain in Keystone.</p><p>They contain a limited service catalog (only those services which do not
explicitly require per-project endpoints), a set of roles, and details of the
project upon which you have authorization.</p><p>They can also be used to work with domain-level concerns in other services,
such as to configure domain-wide quotas that apply to all users or projects in
a specific domain.</p></div></div><div class="sect2 " id="id-1.4.5.9.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Token providers</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The token type issued by keystone is configurable through the
<code class="literal">/etc/keystone/keystone.conf</code> file. Currently, there are four supported
token types and they include <code class="literal">UUID</code>, <code class="literal">fernet</code>, <code class="literal">PKI</code>, and <code class="literal">PKIZ</code>.</p><div class="sect3 " id="id-1.4.5.9.4.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.6.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">UUID tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.4.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>UUID was the first token type supported and is currently the default token
provider. UUID tokens are 32 bytes in length and must be persisted in a back
end. Clients must pass their UUID token to the Identity service in order to
validate it.</p></div><div class="sect3 " id="id-1.4.5.9.4.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.6.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Fernet tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.4.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The fernet token format was introduced in the OpenStack Kilo release. Unlike
the other token types mentioned in this document, fernet tokens do not need to
be persisted in a back end. <code class="literal">AES256</code> encryption is used to protect the
information stored in the token and integrity is verified with a <code class="literal">SHA256
HMAC</code> signature. Only the Identity service should have access to the keys used
to encrypt and decrypt fernet tokens. Like UUID tokens, fernet tokens must be
passed back to the Identity service in order to validate them. For more
information on the fernet token type, see the <a class="xref" href="#cha-fernet-faq" title="3.8. Fernet - Frequently Asked Questions">Section 3.8, “Fernet - Frequently Asked Questions”</a>.</p></div><div class="sect3 " id="id-1.4.5.9.4.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.6.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">PKI and PKIZ tokens</span> <a title="Permalink" class="permalink" href="#id-1.4.5.9.4.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>PKI tokens are signed documents that contain the authentication context, as
well as the service catalog. Depending on the size of the OpenStack deployment,
these tokens can be very long. The Identity service uses public/private key
pairs and certificates in order to create and validate PKI tokens.</p><p>The same concepts from PKI tokens apply to PKIZ tokens. The only difference
between the two is PKIZ tokens are compressed to help mitigate the size issues
of PKI. For more information on the certificate setup for PKI and PKIZ tokens,
see the <a class="xref" href="#cha-certificates-pki" title="3.2. Certificates for PKI">Section 3.2, “Certificates for PKI”</a>.</p></div></div></div><div class="sect1 " id="id-1.4.5.10"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Identity service for token binding</span> <a title="Permalink" class="permalink" href="#id-1.4.5.10">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Token binding embeds information from an external authentication
mechanism, such as a Kerberos server or X.509 certificate, inside a
token. By using token binding, a client can enforce the use of a
specified external authentication mechanism with the token. This
additional security mechanism ensures that if a token is stolen, for
example, it is not usable without external authentication.</p><p>You configure the authentication types for a token binding in the
<code class="literal">/etc/keystone/keystone.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[token]
bind = kerberos</pre></div><p>or</p><div class="verbatim-wrap highlight ini"><pre class="screen">[token]
bind = x509</pre></div><p>Currently <code class="literal">kerberos</code> and <code class="literal">x509</code> are supported.</p><p>To enforce checking of token binding, set the <code class="literal">enforce_token_bind</code>
option to one of these modes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.10.9.1.1.1"><span class="term ">
                <code class="literal">disabled</code>
              </span></dt><dd><p>Disables token bind checking.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.10.9.2.1.1"><span class="term ">
                <code class="literal">permissive</code>
              </span></dt><dd><p>Enables bind checking. If a token is bound to an unknown
authentication mechanism, the server ignores it. The default is this
mode.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.10.9.3.1.1"><span class="term ">
                <code class="literal">strict</code>
              </span></dt><dd><p>Enables bind checking. If a token is bound to an unknown
authentication mechanism, the server rejects it.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.10.9.4.1.1"><span class="term ">
                <code class="literal">required</code>
              </span></dt><dd><p>Enables bind checking. Requires use of at least authentication
mechanism for tokens.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.10.9.5.1.1"><span class="term ">
                <code class="literal">kerberos</code>
              </span></dt><dd><p>Enables bind checking. Requires use of kerberos as the authentication
mechanism for tokens:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[token]
enforce_token_bind = kerberos</pre></div></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.10.9.6.1.1"><span class="term ">
                <code class="literal">x509</code>
              </span></dt><dd><p>Enables bind checking. Requires use of X.509 as the authentication
mechanism for tokens:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[token]
enforce_token_bind = x509</pre></div></dd></dl></div></li></ul></div></div><div class="sect1 " id="cha-fernet-faq"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Fernet - Frequently Asked Questions</span> <a title="Permalink" class="permalink" href="#cha-fernet-faq">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>cha-fernet-faq</li></ul></div></div></div></div><p>The following questions have been asked periodically since the initial release
of the fernet token format in Kilo.</p><div class="sect2 " id="id-1.4.5.11.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What are the different types of keys?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A key repository is required by keystone in order to create fernet tokens.
These keys are used to encrypt and decrypt the information that makes up the
payload of the token. Each key in the repository can have one of three states.
The state of the key determines how keystone uses a key with fernet tokens. The
different types are as follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.11.3.3.1"><span class="term ">Primary key:</span></dt><dd><p>There is only ever one primary key in a key repository. The primary key is
allowed to encrypt and decrypt tokens. This key is always named as the
highest index in the repository.</p></dd><dt id="id-1.4.5.11.3.3.2"><span class="term ">Secondary key:</span></dt><dd><p>A secondary key was at one point a primary key, but has been demoted in place
of another primary key. It is only allowed to decrypt tokens. Since it was
the primary at some point in time, its existence in the key repository is
justified. Keystone needs to be able to decrypt tokens that were created with
old primary keys.</p></dd><dt id="id-1.4.5.11.3.3.3"><span class="term ">Staged key:</span></dt><dd><p>The staged key is a special key that shares some similarities with secondary
keys. There can only ever be one staged key in a repository and it must
exist. Just like secondary keys, staged keys have the ability to decrypt
tokens. Unlike secondary keys, staged keys have never been a primary key. In
fact, they are opposites since the staged key will always be the next primary
key. This helps clarify the name because they are the next key staged to be
the primary key. This key is always named as <code class="literal">0</code> in the key repository.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.5.11.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">So, how does a staged key help me and why do I care about it?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The fernet keys have a natural lifecycle. Each key starts as a staged key, is
promoted to be the primary key, and then demoted to be a secondary key. New
tokens can only be encrypted with a primary key. Secondary and staged keys are
never used to encrypt token. The staged key is a special key given the order of
events and the attributes of each type of key. The staged key is the only key
in the repository that has not had a chance to encrypt any tokens yet, but it
is still allowed to decrypt tokens. As an operator, this gives you the chance
to perform a key rotation on one keystone node, and distribute the new key set
over a span of time. This does not require the distribution to take place in an
ultra short period of time. Tokens encrypted with a primary key can be
decrypted, and validated, on other nodes where that key is still staged.</p></div><div class="sect2 " id="id-1.4.5.11.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Where do I put my key repository?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The key repository is specified using the <code class="literal">key_repository</code> option in the
keystone configuration file. The keystone process should be able to read and
write to this location but it should be kept secret otherwise. Currently,
keystone only supports file-backed key repositories.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[fernet_tokens]
key_repository = /etc/keystone/fernet-keys/</pre></div></div><div class="sect2 " id="id-1.4.5.11.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What is the recommended way to rotate and distribute keys?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="command">keystone-manage</code> command line utility includes a key rotation
mechanism. This mechanism will initialize and rotate keys but does not make
an effort to distribute keys across keystone nodes. The distribution of keys
across a keystone deployment is best handled through configuration management
tooling. Use <code class="command">keystone-manage fernet_rotate</code> to rotate the key
repository.</p></div><div class="sect2 " id="id-1.4.5.11.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Do fernet tokens still expire?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Yes, fernet tokens can expire just like any other keystone token formats.</p></div><div class="sect2 " id="id-1.4.5.11.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Why should I choose fernet tokens over UUID tokens?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Even though fernet tokens operate very similarly to UUID tokens, they do not
require persistence. The keystone token database no longer suffers bloat as a
side effect of authentication. Pruning expired tokens from the token database
is no longer required when using fernet tokens. Because fernet tokens do not
require persistence, they do not have to be replicated. As long as each
keystone node shares the same key repository, fernet tokens can be created and
validated instantly across nodes.</p></div><div class="sect2 " id="id-1.4.5.11.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Why should I choose fernet tokens over PKI or PKIZ tokens?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The arguments for using fernet over PKI and PKIZ remain the same as UUID, in
addition to the fact that fernet tokens are much smaller than PKI and PKIZ
tokens. PKI and PKIZ tokens still require persistent storage and can sometimes
cause issues due to their size. This issue is mitigated when switching to
fernet because fernet tokens are kept under a 250 byte limit. PKI and PKIZ
tokens typically exceed 1600 bytes in length. The length of a PKI or PKIZ token
is dependent on the size of the deployment. Bigger service catalogs will result
in longer token lengths. This pattern does not exist with fernet tokens because
the contents of the encrypted payload is kept to a minimum.</p></div><div class="sect2 " id="id-1.4.5.11.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Should I rotate and distribute keys from the same keystone node every rotation?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>No, but the relationship between rotation and distribution should be lock-step.
Once you rotate keys on one keystone node, the key repository from that node
should be distributed to the rest of the cluster. Once you confirm that each
node has the same key repository state, you could rotate and distribute from
any other node in the cluster.</p><p>If the rotation and distribution are not lock-step, a single keystone node in
the deployment will create tokens with a primary key that no other node has as
a staged key. This will cause tokens generated from one keystone node to fail
validation on other keystone nodes.</p></div><div class="sect2 " id="id-1.4.5.11.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How do I add new keystone nodes to a deployment?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The keys used to create fernet tokens should be treated like super secret
configuration files, similar to an SSL secret key. Before a node is allowed to
join an existing cluster, issuing and validating tokens, it should have the
same key repository as the rest of the nodes in the cluster.</p></div><div class="sect2 " id="id-1.4.5.11.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How should I approach key distribution?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Remember that key distribution is only required in multi-node keystone
deployments. If you only have one keystone node serving requests in your
deployment, key distribution is unnecessary.</p><p>Key distribution is a problem best approached from the deployment's current
configuration management system. Since not all deployments use the same
configuration management systems, it makes sense to explore options around what
is already available for managing keys, while keeping the secrecy of the keys
in mind. Many configuration management tools can leverage something like
<code class="literal">rsync</code> to manage key distribution.</p><p>Key rotation is a single operation that promotes the current staged key to
primary, creates a new staged key, and prunes old secondary keys. It is easiest
to do this on a single node and verify the rotation took place properly before
distributing the key repository to the rest of the cluster. The concept behind
the staged key breaks the expectation that key rotation and key distribution
have to be done in a single step. With the staged key, we have time to inspect
the new key repository before syncing state with the rest of the cluster. Key
distribution should be an operation that can run in succession until it
succeeds. The following might help illustrate the isolation between key
rotation and key distribution.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Ensure all keystone nodes in the deployment have the same key repository.</p></li><li class="step "><p>Pick a keystone node in the cluster to rotate from.</p></li><li class="step "><p>Rotate keys.</p><ol type="a" class="substeps "><li class="step "><p>Was it successful?</p><ol type="i" class="substeps "><li class="step "><p>If no, investigate issues with the particular keystone node you
rotated keys on. Fernet keys are small and the operation for
rotation is trivial. There should not be much room for error in key
rotation. It is possible that the user does not have the ability to
write new keys to the key repository. Log output from
<code class="literal">keystone-manage fernet_rotate</code> should give more information into
specific failures.</p></li><li class="step "><p>If yes, you should see a new staged key. The old staged key should
be the new primary. Depending on the <code class="literal">max_active_keys</code> limit you
might have secondary keys that were pruned. At this point, the node
that you rotated on will be creating fernet tokens with a primary
key that all other nodes should have as the staged key. This is why
we checked the state of all key repositories in Step one. All other
nodes in the cluster should be able to decrypt tokens created with
the new primary key. At this point, we are ready to distribute the
new key set.</p></li></ol></li></ol></li><li class="step "><p>Distribute the new key repository.</p><ol type="a" class="substeps "><li class="step "><p>Was it successful?</p><ol type="i" class="substeps "><li class="step "><p>If yes, you should be able to confirm that all nodes in the cluster
have the same key repository that was introduced in Step 3.  All
nodes in the cluster will be creating tokens with the primary key
that was promoted in Step 3. No further action is required until the
next schedule key rotation.</p></li><li class="step "><p>If no, try distributing again. Remember that we already rotated the
repository and performing another rotation at this point will
result in tokens that cannot be validated across certain hosts.
Specifically, the hosts that did not get the latest key set. You
should be able to distribute keys until it is successful. If certain
nodes have issues syncing, it could be permission or network issues
and those should be resolved before subsequent rotations.</p></li></ol></li></ol></li></ol></div></div></div><div class="sect2 " id="id-1.4.5.11.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How long should I keep my keys around?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The fernet tokens that keystone creates are only secure as the keys creating
them. With staged keys the penalty of key rotation is low, allowing you to err
on the side of security and rotate weekly, daily, or even hourly.  Ultimately,
this should be less time than it takes an attacker to break a <code class="literal">AES256</code> key
and a <code class="literal">SHA256 HMAC</code>.</p></div><div class="sect2 " id="id-1.4.5.11.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Is a fernet token still a bearer token?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Yes, and they follow exactly the same validation path as UUID tokens, with the
exception of being written to, and read from, a back end. If someone
compromises your fernet token, they have the power to do all the operations you
are allowed to do.</p></div><div class="sect2 " id="id-1.4.5.11.15"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What if I need to revoke all my tokens?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.15">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To invalidate every token issued from keystone and start fresh, remove the
current key repository, create a new key set, and redistribute it to all nodes
in the cluster. This will render every token issued from keystone as invalid
regardless if the token has actually expired. When a client goes to
re-authenticate, the new token will have been created with a new fernet key.</p></div><div class="sect2 " id="id-1.4.5.11.16"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What can an attacker do if they compromise a fernet key in my deployment?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.16">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If any key used in the key repository is compromised, an attacker will be able
to build their own tokens. If they know the ID of an administrator on a
project, they could generate administrator tokens for the project. They will be
able to generate their own tokens until the compromised key has been removed
from from the repository.</p></div><div class="sect2 " id="id-1.4.5.11.17"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.8.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">I rotated keys and now tokens are invalidating early, what did I do?</span> <a title="Permalink" class="permalink" href="#id-1.4.5.11.17">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Using fernet tokens requires some awareness around token expiration and the key
lifecycle. You do not want to rotate so often that secondary keys are removed
that might still be needed to decrypt unexpired tokens. If this happens, you
will not be able to decrypt the token because the key the was used to encrypt
it is now gone. Only remove keys that you know are not being used to encrypt or
decrypt tokens.</p><p>For example, your token is valid for 24 hours and we want to rotate keys every
six hours. We will need to make sure tokens that were created at 08:00 AM on
Monday are still valid at 07:00 AM on Tuesday, assuming they were not
prematurely revoked. To accomplish this, we will want to make sure we set
<code class="literal">max_active_keys=6</code> in our keystone configuration file. This will allow us to
hold all keys that might still be required to validate a previous token, but
keeps the key repository limited to only the keys that are needed.</p><p>The number of <code class="literal">max_active_keys</code> for a deployment can be determined by
dividing the token lifetime, in hours, by the frequency of rotation in hours
and adding two. Better illustrated as:</p><div class="verbatim-wrap"><pre class="screen">token_expiration = 24
rotation_frequency = 6
max_active_keys = (token_expiration / rotation_frequency) + 2</pre></div><p>The reason for adding two additional keys to the count is to include the staged
key and a buffer key. This can be shown based on the previous example. We
initially setup the key repository at 6:00 AM on Monday, and the initial state
looks like:</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (primary key)</pre></div><p>All tokens created after 6:00 AM are encrypted with key <code class="literal">1</code>. At 12:00 PM we
will rotate keys again, resulting in,</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (primary key)</pre></div><p>We are still able to validate tokens created between 6:00 - 11:59 AM because
the <code class="literal">1</code> key still exists as a secondary key. All tokens issued after 12:00 PM
will be encrypted with key <code class="literal">2</code>. At 6:00 PM we do our next rotation, resulting
in:</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (primary key)</pre></div><p>It is still possible to validate tokens issued from 6:00 AM - 5:59 PM because
keys <code class="literal">1</code> and <code class="literal">2</code> exist as secondary keys. Every token issued until 11:59 PM
will be encrypted with key <code class="literal">3</code>, and at 12:00 AM we do our next rotation:</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (secondary key)
-rw------- 1 keystone keystone   44 4    (primary key)</pre></div><p>Just like before, we can still validate tokens issued from 6:00 AM the previous
day until 5:59 AM today because keys <code class="literal">1</code> - <code class="literal">4</code> are present. At 6:00 AM,
tokens issued from the previous day will start to expire and we do our next
scheduled rotation:</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 1    (secondary key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (secondary key)
-rw------- 1 keystone keystone   44 4    (secondary key)
-rw------- 1 keystone keystone   44 5    (primary key)</pre></div><p>Tokens will naturally expire after 6:00 AM, but we will not be able to remove
key <code class="literal">1</code> until the next rotation because it encrypted all tokens from 6:00 AM
to 12:00 PM the day before. Once we do our next rotation, which is at 12:00 PM,
the <code class="literal">1</code> key will be pruned from the repository:</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /etc/keystone/fernet-keys/
drwx------ 2 keystone keystone 4096 .
drwxr-xr-x 3 keystone keystone 4096 ..
-rw------- 1 keystone keystone   44 0    (staged key)
-rw------- 1 keystone keystone   44 2    (secondary key)
-rw------- 1 keystone keystone   44 3    (secondary key)
-rw------- 1 keystone keystone   44 4    (secondary key)
-rw------- 1 keystone keystone   44 5    (secondary key)
-rw------- 1 keystone keystone   44 6    (primary key)</pre></div><p>If keystone were to receive a token that was created between 6:00 AM and 12:00
PM the day before, encrypted with the <code class="literal">1</code> key, it would not be valid because
it was already expired. This makes it possible for us to remove the <code class="literal">1</code> key
from the repository without negative validation side-effects.</p></div></div><div class="sect1 " id="id-1.4.5.12"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use trusts</span> <a title="Permalink" class="permalink" href="#id-1.4.5.12">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Identity manages authentication and authorization. A trust is
an OpenStack Identity extension that enables delegation and, optionally,
impersonation through <code class="literal">keystone</code>. A trust extension defines a
relationship between:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.12.3.1"><span class="term ">
            <span class="bold"><strong>Trustor</strong></span>
          </span></dt><dd><p>The user delegating a limited set of their own rights to another user.</p></dd><dt id="id-1.4.5.12.3.2"><span class="term ">
            <span class="bold"><strong>Trustee</strong></span>
          </span></dt><dd><p>The user trust is being delegated to, for a limited time.</p><p>The trust can eventually allow the trustee to impersonate the trustor.
For security reasons, some safeties are added. For example, if a trustor
loses a given role, any trusts the user issued with that role, and the
related tokens, are automatically revoked.</p></dd></dl></div><p>The delegation parameters are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.5.12.5.1"><span class="term ">
            <span class="bold"><strong>User ID</strong></span>
          </span></dt><dd><p>The user IDs for the trustor and trustee.</p></dd><dt id="id-1.4.5.12.5.2"><span class="term ">
            <span class="bold"><strong>Privileges</strong></span>
          </span></dt><dd><p>The delegated privileges are a combination of a project ID and a
number of roles that must be a subset of the roles assigned to the
trustor.</p><p>If you omit all privileges, nothing is delegated. You cannot
delegate everything.</p></dd><dt id="id-1.4.5.12.5.3"><span class="term ">
            <span class="bold"><strong>Delegation depth</strong></span>
          </span></dt><dd><p>Defines whether or not the delegation is recursive. If it is
recursive, defines the delegation chain length.</p><p>Specify one of the following values:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">0</code>. The delegate cannot delegate these permissions further.</p></li><li class="listitem "><p><code class="literal">1</code>. The delegate can delegate the permissions to any set of
delegates but the latter cannot delegate further.</p></li><li class="listitem "><p><code class="literal">inf</code>. The delegation is infinitely recursive.</p></li></ul></div></dd><dt id="id-1.4.5.12.5.4"><span class="term ">
            <span class="bold"><strong>Endpoints</strong></span>
          </span></dt><dd><p>A list of endpoints associated with the delegation.</p><p>This parameter further restricts the delegation to the specified
endpoints only. If you omit the endpoints, the delegation is
useless. A special value of <code class="literal">all_endpoints</code> allows the trust to be
used by all endpoints associated with the delegated project.</p></dd><dt id="id-1.4.5.12.5.5"><span class="term ">
            <span class="bold"><strong>Duration</strong></span>
          </span></dt><dd><p>(Optional) Comprised of the start time and end time for the trust.</p></dd></dl></div></div><div class="sect1 " id="id-1.4.5.13"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Caching layer</span> <a title="Permalink" class="permalink" href="#id-1.4.5.13">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Identity supports a caching layer that is above the
configurable subsystems (for example, token). OpenStack Identity uses the
<a class="link" href="http://docs.openstack.org/developer/oslo.cache/" target="_blank">oslo.cache</a>
library which allows flexible cache back ends. The majority of the
caching configuration options are set in the <code class="literal">[cache]</code> section of the
<code class="literal">/etc/keystone/keystone.conf</code> file. However, each section that has
the capability to be cached usually has a caching boolean value that
toggles caching.</p><p>So to enable only the token back end caching, set the values as follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[cache]
enabled=true

[catalog]
caching=false

[domain_config]
caching=false

[federation]
caching=false

[resource]
caching=false

[revoke]
caching=false

[role]
caching=false

[token]
caching=true</pre></div><div id="id-1.4.5.13.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Since the Newton release, the default setting is enabled for subsystem
caching and the global toggle. As a result, all subsystems that support
caching are doing this by default.</p></div><div class="sect2 " id="id-1.4.5.13.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Caching for tokens and tokens validation</span> <a title="Permalink" class="permalink" href="#id-1.4.5.13.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The token system has a separate <code class="literal">cache_time</code> configuration option,
that can be set to a value above or below the global <code class="literal">expiration_time</code>
default, allowing for different caching behavior from the other systems
in OpenStack Identity. This option is set in the <code class="literal">[token]</code> section of
the configuration file. Fernet tokens do not need to be persisted in a
back end and therefore must not be cached.</p><p>The token revocation list cache time is handled by the configuration
option <code class="literal">revocation_cache_time</code> in the <code class="literal">[token]</code> section. The
revocation list is refreshed whenever a token is revoked. It typically
sees significantly more requests than specific token retrievals or token
validation calls.</p><p>Here is a list of actions that are affected by the cached time: getting
a new token, revoking tokens, validating tokens, checking v2 tokens, and
checking v3 tokens.</p><p>The delete token API calls invalidate the cache for the tokens being
acted upon, as well as invalidating the cache for the revoked token list
and the validate/check token calls.</p><p>Token caching is configurable independently of the <code class="literal">revocation_list</code>
caching. Lifted expiration checks from the token drivers to the token
manager. This ensures that cached tokens will still raise a
<code class="literal">TokenNotFound</code> flag when expired.</p><p>For cache consistency, all token IDs are transformed into the short
token hash at the provider and token driver level. Some methods have
access to the full ID (PKI Tokens), and some methods do not. Cache
invalidation is inconsistent without token ID normalization.</p></div><div class="sect2 " id="id-1.4.5.13.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Caching for non-token resources</span> <a title="Permalink" class="permalink" href="#id-1.4.5.13.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Various other keystone components have a separate <code class="literal">cache_time</code> configuration
option, that can be set to a value above or below the global
<code class="literal">expiration_time</code> default, allowing for different caching behavior
from the other systems in Identity service. This option can be set in various
sections (for example, <code class="literal">[role]</code> and <code class="literal">[resource]</code>) of the configuration
file.
The create, update, and delete actions for domains, projects and roles
will perform proper invalidations of the cached methods listed above.</p><p>For more information about the different back ends (and configuration
options), see:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://dogpilecache.readthedocs.io/en/latest/api.html#memory-backend" target="_blank">dogpile.cache.memory</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://dogpilecache.readthedocs.io/en/latest/api.html#memcached-backends" target="_blank">dogpile.cache.memcached</a>
            </p><div id="id-1.4.5.13.7.4.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The memory back end is not suitable for use in a production
environment.</p></div></li><li class="listitem "><p>
              <a class="link" href="http://dogpilecache.readthedocs.io/en/latest/api.html#redis-backends" target="_blank">dogpile.cache.redis</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://dogpilecache.readthedocs.io/en/latest/api.html#file-backends" target="_blank">dogpile.cache.dbm</a>
            </p></li></ul></div></div><div class="sect2 " id="id-1.4.5.13.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.10.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Memcached back end example</span> <a title="Permalink" class="permalink" href="#id-1.4.5.13.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following example shows how to configure the memcached back end:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[cache]

enabled = true
backend = dogpile.cache.memcached
backend_argument = url:127.0.0.1:11211</pre></div><p>You need to specify the URL to reach the <code class="literal">memcached</code> instance with the
<code class="literal">backend_argument</code> parameter.</p></div></div><div class="sect1 " id="id-1.4.5.14"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Security compliance and PCI-DSS</span> <a title="Permalink" class="permalink" href="#id-1.4.5.14">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As of the Newton release, the Identity service contains additional security
compliance features, specifically to satisfy Payment Card Industry -
Data Security Standard (PCI-DSS) v3.1 requirements. See
<a class="link" href="http://specs.openstack.org/openstack/keystone-specs/specs/keystone/newton/pci-dss.html" target="_blank">Security Hardening PCI-DSS</a> for more information on PCI-DSS.</p><p>Security compliance features are disabled by default and most of the features
only apply to the SQL backend for the identity driver. Other identity backends,
such as LDAP, should implement their own security controls.</p><p>Enable these features by changing the configuration settings under the
<code class="literal">[security_compliance]</code> section in <code class="literal">keystone.conf</code>.</p><div class="sect2 " id="id-1.4.5.14.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting the account lockout threshold</span> <a title="Permalink" class="permalink" href="#id-1.4.5.14.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The account lockout feature limits the number of incorrect password attempts.
If a user fails to authenticate after the maximum number of attempts, the
service disables the user. Re-enable the user by explicitly setting the
enable user attribute with the update user API call, either
<a class="link" href="http://developer.openstack.org/api-ref/identity/v2-admin/index.html?expanded=update-user-admin-endpoint-detail#update-user-admin-endpoint" target="_blank">v2.0</a> or <a class="link" href="http://developer.openstack.org/api-ref/identity/v3/index.html#update-user" target="_blank">v3</a>.</p><p>You set the maximum number of failed authentication attempts by setting
the <code class="literal">lockout_failure_attempts</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
lockout_failure_attempts = 6</pre></div><p>You set the number of minutes a user would be locked out by setting
the <code class="literal">lockout_duration</code> in seconds:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
lockout_duration = 1800</pre></div><p>If you do not set the <code class="literal">lockout_duration</code>, users may be locked out
indefinitely until the user is explicitly enabled via the API.</p></div><div class="sect2 " id="id-1.4.5.14.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disabling inactive users</span> <a title="Permalink" class="permalink" href="#id-1.4.5.14.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>PCI-DSS 8.1.4 requires that inactive user accounts be removed or disabled
within 90 days. You can achieve this by setting the
<code class="literal">disable_user_account_days_inactive</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
disable_user_account_days_inactive = 90</pre></div><p>This above example means that users that have not authenticated (inactive) for
the past 90 days are automatically disabled. Users can be re-enabled by
explicitly setting the enable user attribute via the API.</p></div><div class="sect2 " id="id-1.4.5.14.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuring password expiration</span> <a title="Permalink" class="permalink" href="#id-1.4.5.14.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Passwords can be configured to expire within a certain number of days by
setting the <code class="literal">password_expires_days</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
password_expires_days = 90</pre></div><p>Once set, any new password changes have an expiration date based on the
date/time of the password change plus the number of days defined here. Existing
passwords will not be impacted. If you want existing passwords to have an
expiration date, you would need to run a SQL script against the password table
in the database to update the expires_at column.</p><p>In addition, you can set it so that passwords never expire for some users by
adding their user ID to <code class="literal">password_expires_ignore_user_ids</code> list:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
password_expires_ignore_user_ids = [3a54353c9dcc44f690975ea768512f6a]</pre></div><p>In this example, the password for user ID <code class="literal">3a54353c9dcc44f690975ea768512f6a</code>
would never expire.</p></div><div class="sect2 " id="id-1.4.5.14.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.11.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Indicating password strength requirements</span> <a title="Permalink" class="permalink" href="#id-1.4.5.14.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You set password strength requirements, such as requiring numbers in passwords
or setting a minimum password length, by adding a regular expression to the
<code class="literal">password_regex</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
password_regex = ^(?=.*\d)(?=.*[a-zA-Z]).{7,}$</pre></div><p>The above example is a regular expression that requires a password to have
one letter, one digit, and a minimum length of seven characters.</p><p>If you do set the <code class="literal">password_regex</code>, you should provide text that
describes your password strength requirements. You can do this by setting the
<code class="literal">password_regex_description</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
password_regex_description = Passwords must contain at least 1 letter, 1
                             digit, and be a minimum length of 7
                             characters.</pre></div><p>The service returns that description to users to explain why their requested
password did not meet requirements.</p><div id="id-1.4.5.14.8.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You must ensure the <code class="literal">password_regex_description</code> accurately and
completely describes the <code class="literal">password_regex</code>. If the two options are out of
sync, the help text could inaccurately describe the password requirements
being applied to the password. This would lead to poor user experience.</p></div></div><div class="sect2 " id="id-1.4.5.14.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.11.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Requiring a unique password history</span> <a title="Permalink" class="permalink" href="#id-1.4.5.14.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The password history requirements controls the number of passwords for a user
that must be unique before an old password can be reused. You can enforce this
by setting the <code class="literal">unique_last_password_count</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
unique_last_password_count= 5</pre></div><p>The above example does not allow a user to create a new password that is the
same as any of their last four previous passwords.</p><p>Similarly, you can set the number of days that a password must be used before
the user can change it by setting the <code class="literal">minimum_password_age</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[security_compliance]
minimum_password_age = 1</pre></div><p>In the above example, once a user changes their password, they would not be
able to change it again for one day. This prevents users from changing their
passwords immediately in order to wipe out their password history and reuse an
old password.</p><div id="id-1.4.5.14.9.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When you set <code class="literal">password_expires_days</code>, the value for the
<code class="literal">minimum_password_age</code> should be less than the <code class="literal">password_expires_days</code>.
Otherwise, users would not be able to change their passwords before they
expire.</p></div></div></div><div class="sect1 " id="id-1.4.5.15"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example usage and Identity features</span> <a title="Permalink" class="permalink" href="#id-1.4.5.15">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">openstack</code> CLI is used to interact with the Identity service.
It is set up to expect commands in the general
form of <code class="literal">openstack command argument</code>, followed by flag-like keyword
arguments to provide additional (often optional) information. For
example, the <code class="command">user list</code> and <code class="command">project create</code>
commands can be invoked as follows:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># Using token auth env variables
export OS_SERVICE_ENDPOINT=http://127.0.0.1:5000/v2.0/
export OS_SERVICE_TOKEN=secrete_token
openstack user list
openstack project create demo --domain default

# Using token auth flags
openstack --os-token secrete --os-endpoint http://127.0.0.1:5000/v2.0/ user list
openstack --os-token secrete --os-endpoint http://127.0.0.1:5000/v2.0/ project create demo

# Using user + password + project_name env variables
export OS_USERNAME=admin
export OS_PASSWORD=secrete
export OS_PROJECT_NAME=admin
openstack user list
openstack project create demo --domain default

# Using user + password + project-name flags
openstack --os-username admin --os-password secrete --os-project-name admin user list
openstack --os-username admin --os-password secrete --os-project-name admin project create demo</pre></div><div class="sect2 " id="id-1.4.5.15.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging</span> <a title="Permalink" class="permalink" href="#id-1.4.5.15.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You configure logging externally to the rest of Identity. The name of
the file specifying the logging configuration is set using the
<code class="literal">log_config</code> option in the <code class="literal">[DEFAULT]</code> section of the
<code class="literal">/etc/keystone/keystone.conf</code> file. To route logging through syslog,
set <code class="literal">use_syslog=true</code> in the <code class="literal">[DEFAULT]</code> section.</p><p>A sample logging configuration file is available with the project in
<code class="literal">etc/logging.conf.sample</code>. Like other OpenStack projects, Identity
uses the Python logging module, which provides extensive configuration
options that let you define the output levels and formats.</p></div><div class="sect2 " id="id-1.4.5.15.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">User CRUD</span> <a title="Permalink" class="permalink" href="#id-1.4.5.15.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Identity provides a user CRUD (Create, Read, Update, and Delete) filter that
Administrators can add to the <code class="literal">public_api</code> pipeline. The user CRUD filter
enables users to use a HTTP PATCH to change their own password. To enable
this extension you should define a <code class="literal">user_crud_extension</code> filter, insert
it after the <code class="literal">*_body</code> middleware and before the <code class="literal">public_service</code>
application in the <code class="literal">public_api</code> WSGI pipeline in
<code class="literal">keystone-paste.ini</code>. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[filter:user_crud_extension]
paste.filter_factory = keystone.contrib.user_crud:CrudExtension.factory

[pipeline:public_api]
pipeline = sizelimit url_normalize request_id build_auth_context token_auth admin_token_auth json_body ec2_extension user_crud_extension public_service</pre></div><p>Each user can then change their own password with a HTTP PATCH.</p><div class="verbatim-wrap"><pre class="screen">$ curl -X PATCH http://localhost:5000/v2.0/OS-KSCRUD/users/USERID -H "Content-type: application/json"  \
  -H "X_Auth_Token: AUTHTOKENID" -d '{"user": {"password": "ABCD", "original_password": "DCBA"}}'</pre></div><p>In addition to changing their password, all current tokens for the user
are invalidated.</p><div id="id-1.4.5.15.5.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only use a KVS back end for tokens when testing.</p></div></div></div><div class="sect1 " id="id-1.4.5.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Authentication middleware with user name and password</span> <a title="Permalink" class="permalink" href="#id-1.4.5.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can also configure Identity authentication middleware using the
<code class="literal">admin_user</code> and <code class="literal">admin_password</code> options.</p><div id="id-1.4.5.16.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">admin_token</code> option is deprecated and no longer used for
configuring auth_token middleware.</p></div><p>For services that have a separate paste-deploy <code class="literal">.ini</code> file, you can
configure the authentication middleware in the <code class="literal">[keystone_authtoken]</code>
section of the main configuration file, such as <code class="literal">nova.conf</code>. In
Compute, for example, you can remove the middleware parameters from
<code class="literal">api-paste.ini</code>, as follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory</pre></div><p>And set the following values in <code class="literal">nova.conf</code> as follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
...
auth_strategy=keystone

[keystone_authtoken]
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_user = admin
admin_password = SuperSekretPassword
admin_tenant_name = service</pre></div><div id="id-1.4.5.16.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The middleware parameters in the paste config take priority. You
must remove them to use the values in the <code class="literal">[keystone_authtoken]</code>
section.</p></div><div id="id-1.4.5.16.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Comment out any <code class="literal">auth_host</code>, <code class="literal">auth_port</code>, and
<code class="literal">auth_protocol</code> options because the <code class="literal">identity_uri</code> option
replaces them.</p></div><p>This sample paste config filter makes use of the <code class="literal">admin_user</code> and
<code class="literal">admin_password</code> options:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
auth_token = 012345SECRET99TOKEN012345
admin_user = admin
admin_password = keystone123</pre></div><div id="id-1.4.5.16.12" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Using this option requires an admin project/role relationship. The
admin user is granted access to the admin role on the admin project.</p></div><div id="id-1.4.5.16.13" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Comment out any <code class="literal">auth_host</code>, <code class="literal">auth_port</code>, and
<code class="literal">auth_protocol</code> options because the <code class="literal">identity_uri</code> option
replaces them.</p></div></div><div class="sect1 " id="id-1.4.5.17"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Identity API protection with role-based access control (RBAC)</span> <a title="Permalink" class="permalink" href="#id-1.4.5.17">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Like most OpenStack projects, Identity supports the protection of its
APIs by defining policy rules based on an RBAC approach. Identity stores
a reference to a policy JSON file in the main Identity configuration
file, <code class="literal">/etc/keystone/keystone.conf</code>. Typically this file is named
<code class="literal">policy.json</code>, and contains the rules for which roles have access to
certain actions in defined services.</p><p>Each Identity API v3 call has a line in the policy file that dictates
which level of governance of access applies.</p><div class="verbatim-wrap highlight ini"><pre class="screen">API_NAME: RULE_STATEMENT or MATCH_STATEMENT</pre></div><p>Where:</p><p><code class="literal">RULE_STATEMENT</code> can contain <code class="literal">RULE_STATEMENT</code> or
<code class="literal">MATCH_STATEMENT</code>.</p><p><code class="literal">MATCH_STATEMENT</code> is a set of identifiers that must match between the
token provided by the caller of the API and the parameters or target
entities of the API call in question. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">"identity:create_user": "role:admin and domain_id:%(user.domain_id)s"</pre></div><p>Indicates that to create a user, you must have the admin role in your
token. The <code class="literal">domain_id</code> in your token must match the
<code class="literal">domain_id</code> in the user object that you are trying
to create, which implies this must be a domain-scoped token.
In other words, you must have the admin role on the domain
in which you are creating the user, and the token that you use
must be scoped to that domain.</p><p>Each component of a match statement uses this format:</p><div class="verbatim-wrap highlight ini"><pre class="screen">ATTRIB_FROM_TOKEN:CONSTANT or ATTRIB_RELATED_TO_API_CALL</pre></div><p>The Identity service expects these attributes:</p><p>Attributes from token:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
            <code class="literal">user_id</code>
          </p></li><li class="listitem "><p>
            <code class="literal">domain_id</code>
          </p></li><li class="listitem "><p>
            <code class="literal">project_id</code>
          </p></li></ul></div><p>The <code class="literal">project_id</code> attribute requirement depends on the scope, and the
list of roles you have within that scope.</p><p>Attributes related to API call:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
            <code class="literal">user.domain_id</code>
          </p></li><li class="listitem "><p>Any parameters passed into the API call</p></li><li class="listitem "><p>Any filters specified in the query string</p></li></ul></div><p>You reference attributes of objects passed with an object.attribute
syntax (such as, <code class="literal">user.domain_id</code>). The target objects of an API are
also available using a target.object.attribute syntax. For instance:</p><div class="verbatim-wrap highlight ini"><pre class="screen">"identity:delete_user": "role:admin and domain_id:%(target.user.domain_id)s"</pre></div><p>would ensure that Identity only deletes the user object in the same
domain as the provided token.</p><p>Every target object has an <code class="literal">id</code> and a <code class="literal">name</code> available as
<code class="literal">target.OBJECT.id</code> and <code class="literal">target.OBJECT.name</code>. Identity retrieves
other attributes from the database, and the attributes vary between
object types. The Identity service filters out some database fields,
such as user passwords.</p><p>List of object attributes:</p><div class="verbatim-wrap highlight ini"><pre class="screen">role:
     target.role.id
     target.role.name

user:
     target.user.default_project_id
     target.user.description
     target.user.domain_id
     target.user.enabled
     target.user.id
     target.user.name

group:
     target.group.description
     target.group.domain_id
     target.group.id
     target.group.name

domain:
     target.domain.enabled
     target.domain.id
     target.domain.name

project:
     target.project.description
     target.project.domain_id
     target.project.enabled
     target.project.id
     target.project.name</pre></div><p>The default <code class="literal">policy.json</code> file supplied provides a somewhat
basic example of API protection, and does not assume any particular
use of domains. Refer to <code class="literal">policy.v3cloudsample.json</code> as an
example of multi-domain configuration installations where a cloud
provider wants to delegate administration of the contents of a domain
to a particular <code class="literal">admin domain</code>. This example policy file also
shows the use of an <code class="literal">admin_domain</code> to allow a cloud provider to
enable administrators to have wider access across the APIs.</p><p>A clean installation could start with the standard policy file, to
allow creation of the <code class="literal">admin_domain</code> with the first users within
it. You could then obtain the <code class="literal">domain_id</code> of the admin domain,
paste the ID into a modified version of
<code class="literal">policy.v3cloudsample.json</code>, and then enable it as the main
<code class="literal">policy file</code>.</p></div><div class="sect1 " id="id-1.4.5.18"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot the Identity service</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To troubleshoot the Identity service, review the logs in the
<code class="literal">/var/log/keystone/keystone.log</code> file.</p><p>Use the <code class="literal">/etc/keystone/logging.conf</code> file to configure the
location of log files.</p><div id="id-1.4.5.18.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">insecure_debug</code> flag is unique to the Identity service.
If you enable <code class="literal">insecure_debug</code>, error messages from the API change
to return security-sensitive information. For example, the error message
on failed authentication includes information on why your authentication
failed.</p></div><p>The logs show the components that have come in to the WSGI request, and
ideally show an error that explains why an authorization request failed.
If you do not see the request in the logs, run keystone with the
<code class="literal">--debug</code> parameter. Pass the <code class="literal">--debug</code> parameter before the
command parameters.</p><div class="sect2 " id="id-1.4.5.18.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Debug PKI middleware</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.5.18.6.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.15.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.6.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you receive an <code class="literal">Invalid OpenStack Identity Credentials</code> message when
you accessing and reaching an OpenStack service, it might be caused by
the changeover from UUID tokens to PKI tokens in the Grizzly release.</p><p>The PKI-based token validation scheme relies on certificates from
Identity that are fetched through HTTP and stored in a local directory.
The location for this directory is specified by the <code class="literal">signing_dir</code>
configuration option.</p></div><div class="sect3 " id="id-1.4.5.18.6.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.15.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.6.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In your services configuration file, look for a section like this:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[keystone_authtoken]
signing_dir = /var/cache/glance/api
auth_uri = http://controller:5000/v2.0
identity_uri = http://controller:35357
admin_tenant_name = service
admin_user = glance</pre></div><p>The first thing to check is that the <code class="literal">signing_dir</code> does, in fact,
exist. If it does, check for certificate files:</p><div class="verbatim-wrap"><pre class="screen">$ ls -la /var/cache/glance/api/

total 24
drwx------. 2 ayoung root 4096 Jul 22 10:58 .
drwxr-xr-x. 4 root root 4096 Nov 7 2012 ..
-rw-r-----. 1 ayoung ayoung 1424 Jul 22 10:58 cacert.pem
-rw-r-----. 1 ayoung ayoung 15 Jul 22 10:58 revoked.pem
-rw-r-----. 1 ayoung ayoung 4518 Jul 22 10:58 signing_cert.pem</pre></div><p>This directory contains two certificates and the token revocation list.
If these files are not present, your service cannot fetch them from
Identity. To troubleshoot, try to talk to Identity to make sure it
correctly serves files, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://localhost:35357/v2.0/certificates/signing</pre></div><p>This command fetches the signing certificate:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 1 (0x1)
    Signature Algorithm: sha1WithRSAEncryption
        Issuer: C=US, ST=Unset, L=Unset, O=Unset, CN=www.example.com
        Validity
            Not Before: Jul 22 14:57:31 2013 GMT
            Not After : Jul 20 14:57:31 2023 GMT
        Subject: C=US, ST=Unset, O=Unset, CN=www.example.com</pre></div><p>Note the expiration dates of the certificate:</p><div class="verbatim-wrap"><pre class="screen">Not Before: Jul 22 14:57:31 2013 GMT
Not After : Jul 20 14:57:31 2023 GMT</pre></div><p>The token revocation list is updated once a minute, but the certificates
are not. One possible problem is that the certificates are the wrong
files or garbage. You can remove these files and run another command
against your server; they are fetched on demand.</p><p>The Identity service log should show the access of the certificate files. You
might have to turn up your logging levels. Set <code class="literal">debug = True</code> in your
Identity configuration file and restart the Identity server.</p><div class="verbatim-wrap"><pre class="screen">(keystone.common.wsgi): 2013-07-24 12:18:11,461 DEBUG wsgi __call__
arg_dict: {}
(access): 2013-07-24 12:18:11,462 INFO core __call__ 127.0.0.1 - - [24/Jul/2013:16:18:11 +0000]
"GET http://localhost:35357/v2.0/certificates/signing HTTP/1.0" 200 4518</pre></div><p>If the files do not appear in your directory after this, it is likely
one of the following issues:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Your service is configured incorrectly and cannot talk to Identity.
Check the <code class="literal">auth_port</code> and <code class="literal">auth_host</code> values and make sure that
you can talk to that service through cURL, as shown previously.</p></li><li class="listitem "><p>Your signing directory is not writable. Use the <code class="literal">chmod</code> command to
change its permissions so that the service (POSIX) user can write to
it. Verify the change through <code class="literal">su</code> and <code class="literal">touch</code> commands.</p></li><li class="listitem "><p>The SELinux policy is denying access to the directory.</p></li></ul></div><p>SELinux troubles often occur when you use Fedora or RHEL-based packages and
you choose configuration options that do not match the standard policy.
Run the <code class="literal">setenforce permissive</code> command. If that makes a difference,
you should relabel the directory. If you are using a sub-directory of
the <code class="literal">/var/cache/</code> directory, run the following command:</p><div class="verbatim-wrap"><pre class="screen"># restorecon /var/cache/</pre></div><p>If you are not using a <code class="literal">/var/cache</code> sub-directory, you should. Modify
the <code class="literal">signing_dir</code> configuration option for your service and restart.</p><p>Set back to <code class="literal">setenforce enforcing</code> to confirm that your changes solve
the problem.</p><p>If your certificates are fetched on demand, the PKI validation is
working properly. Most likely, the token from Identity is not valid for
the operation you are attempting to perform, and your user needs a
different role for the operation.</p></div></div><div class="sect2 " id="id-1.4.5.18.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Debug signing key file errors</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.5.18.7.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.15.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.7.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If an error occurs when the signing key file opens, it is possible that
the person who ran the <code class="command">keystone-manage pki_setup</code> command to
generate certificates and keys did not use the correct user.</p></div><div class="sect3 " id="id-1.4.5.18.7.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.15.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.7.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you run the <code class="command">keystone-manage pki_setup</code> command, Identity
generates a set of certificates and keys in <code class="literal">/etc/keystone/ssl*</code>, which
is owned by <code class="literal">root:root</code>. This can present a problem when you run the
Identity daemon under the keystone user account (nologin) when you try
to run PKI. Unless you run the <code class="command">chown</code> command against the
files <code class="literal">keystone:keystone</code>, or run the <code class="command">keystone-manage pki_setup</code>
command with the <code class="literal">--keystone-user</code> and
<code class="literal">--keystone-group</code> parameters, you will get an error.
For example:</p><div class="verbatim-wrap"><pre class="screen">2012-07-31 11:10:53 ERROR [keystone.common.cms] Error opening signing key file
/etc/keystone/ssl/private/signing_key.pem
140380567730016:error:0200100D:system library:fopen:Permission
denied:bss_file.c:398:fopen('/etc/keystone/ssl/private/signing_key.pem','r')
140380567730016:error:20074002:BIO routines:FILE_CTRL:system lib:bss_file.c:400:
unable to load signing key file</pre></div></div></div><div class="sect2 " id="id-1.4.5.18.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.15.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Flush expired tokens from the token database table</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.5.18.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.15.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.8.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As you generate tokens, the token database table on the Identity server
grows.</p></div><div class="sect3 " id="id-1.4.5.18.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.15.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.5.18.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To clear the token table, an administrative user must run the
<code class="command">keystone-manage token_flush</code> command to flush the tokens. When you
flush tokens, expired tokens are deleted and traceability is eliminated.</p><p>Use <code class="literal">cron</code> to schedule this command to run frequently based on your
workload. For large workloads, running it every minute is recommended.</p></div></div></div></div><div class="chapter " id="id-1.4.6"><div class="titlepage"><div><div><h1 class="title"><span class="number">4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dashboard</span> <a title="Permalink" class="permalink" href="#id-1.4.6">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.6.5"><span class="number">4.1 </span><span class="name">Customize and configure the Dashboard</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.6"><span class="number">4.2 </span><span class="name">Set up session storage for the Dashboard</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.7"><span class="number">4.3 </span><span class="name">Create and manage images</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.8"><span class="number">4.4 </span><span class="name">Create and manage roles</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.9"><span class="number">4.5 </span><span class="name">Manage instances</span></a></span></dt><dt><span class="sect1"><a href="#osadm-manage-flavor"><span class="number">4.6 </span><span class="name">Manage flavors</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.11"><span class="number">4.7 </span><span class="name">Manage volumes and volume types</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.12"><span class="number">4.8 </span><span class="name">Manage shares and share types</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.13"><span class="number">4.9 </span><span class="name">View and manage quotas</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.14"><span class="number">4.10 </span><span class="name">View cloud resources</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.15"><span class="number">4.11 </span><span class="name">Create and manage host aggregates</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.6.16"><span class="number">4.12 </span><span class="name">Launch and manage stacks using the Dashboard</span></a></span></dt></dl></div></div><p>The OpenStack Dashboard is a web-based interface that allows you to
manage OpenStack resources and services. The Dashboard allows you to
interact with the OpenStack Compute cloud controller using the OpenStack
APIs. For more information about installing and configuring the
Dashboard, see the <a class="link" href="http://docs.openstack.org/project-install-guide/newton/" target="_blank">Installation Tutorials and Guides</a>
for your operating system.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To deploy the dashboard, see the <a class="link" href="http://docs.openstack.org/developer/horizon/topics/deployment.html" target="_blank">OpenStack dashboard documentation</a>.</p></li><li class="listitem "><p>To launch instances with the dashboard as an end user, see the
          <a class="link" href="http://docs.openstack.org/user-guide/dashboard-launch-instances.html" target="_blank">Launch and manage instances</a>.
          in the OpenStack End User Guide.</p></li><li class="listitem "><p>To create and manage ports, see the <a class="link" href="http://docs.openstack.org/user-guide/dashboard-create-networks.html#create-a-port" target="_blank">Create and manage networks</a>
          section of the OpenStack End User Guide.</p></li></ul></div><div class="sect1 " id="id-1.4.6.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Customize and configure the Dashboard</span> <a title="Permalink" class="permalink" href="#id-1.4.6.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
         For information on this topic, see the SUSE OpenStack Supplement Guide,
         available at <a class="link" href="https://documentation.suse.com/soc/8/single-html/suse-openstack-cloud-supplement" target="_blank">https://documentation.suse.com/soc/8/single-html/suse-openstack-cloud-supplement</a>.
       </p></div><div class="sect1 " id="id-1.4.6.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Set up session storage for the Dashboard</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Dashboard uses <a class="link" href="https://docs.djangoproject.com/en/dev/topics/http/sessions/" target="_blank">Django sessions
framework</a>
to handle user session data. However, you can use any available session
back end. You customize the session back end through the
<code class="literal">SESSION_ENGINE</code> setting in your <code class="literal">local_settings.py</code> file.</p><p>After architecting and implementing the core OpenStack
services and other required services, combined with the Dashboard
service steps below, users and administrators can use
the OpenStack dashboard. Refer to the <a class="link" href="http://docs.openstack.org/user-guide/dashboard.html" target="_blank">OpenStack Dashboard</a>
chapter of the OpenStack End User Guide for
further instructions on logging in to the Dashboard.</p><p>The following sections describe the pros and cons of each option as it
pertains to deploying the Dashboard.</p><div class="sect2 " id="id-1.4.6.6.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Local memory cache</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Local memory storage is the quickest and easiest session back end to set
up, as it has no external dependencies whatsoever. It has the following
significant drawbacks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>No shared storage across processes or workers.</p></li><li class="listitem "><p>No persistence after a process terminates.</p></li></ul></div><p>The local memory back end is enabled as the default for Horizon solely
because it has no dependencies. It is not recommended for production
use, or even for serious development work.</p><div class="verbatim-wrap highlight python"><pre class="screen">SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
  'default' : {
    'BACKEND': 'django.core.cache.backends.locmem.LocMemCache'
  }
}</pre></div><p>You can use applications such as <code class="literal">Memcached</code> or <code class="literal">Redis</code> for external
caching. These applications offer persistence and shared storage and are
useful for small-scale deployments and development.</p><div class="sect3 " id="id-1.4.6.6.5.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.2.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Memcached</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6.5.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Memcached is a high-performance and distributed memory object caching
system providing in-memory key-value store for small chunks of arbitrary
data.</p><p>Requirements:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Memcached service running and accessible.</p></li><li class="listitem "><p>Python module <code class="literal">python-memcached</code> installed.</p></li></ul></div><div class="verbatim-wrap highlight python"><pre class="screen">SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
  'default': {
    'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
    'LOCATION': 'my_memcached_host:11211',
  }
}</pre></div></div><div class="sect3 " id="id-1.4.6.6.5.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.2.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Redis</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6.5.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Redis is an open source, BSD licensed, advanced key-value store. It is
often referred to as a data structure server.</p><p>Requirements:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Redis service running and accessible.</p></li><li class="listitem "><p>Python modules <code class="literal">redis</code> and <code class="literal">django-redis</code> installed.</p></li></ul></div><div class="verbatim-wrap highlight python"><pre class="screen">SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
    "default": {
        "BACKEND": "redis_cache.cache.RedisCache",
        "LOCATION": "127.0.0.1:6379:1",
        "OPTIONS": {
            "CLIENT_CLASS": "redis_cache.client.DefaultClient",
        }
    }
}</pre></div></div><div class="sect3 " id="id-1.4.6.6.5.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.2.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Initialize and configure the database</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6.5.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Database-backed sessions are scalable, persistent, and can be made
high-concurrency and highly available.</p><p>However, database-backed sessions are one of the slower session storages
and incur a high overhead under heavy usage. Proper configuration of
your database deployment can also be a substantial undertaking and is
far beyond the scope of this documentation.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Start the MySQL command-line client.</p><div class="verbatim-wrap"><pre class="screen">$ mysql -u root -p</pre></div></li><li class="step "><p>Enter the MySQL root user's password when prompted.</p></li><li class="step "><p>To configure the MySQL database, create the dash database.</p><div class="verbatim-wrap"><pre class="screen">mysql&gt; CREATE DATABASE dash;</pre></div></li><li class="step "><p>Create a MySQL user for the newly created dash database that has full
control of the database. Replace DASH_DBPASS with a password for the
new user.</p><div class="verbatim-wrap"><pre class="screen">mysql&gt; GRANT ALL PRIVILEGES ON dash.* TO 'dash'@'%' IDENTIFIED BY 'DASH_DBPASS';
mysql&gt; GRANT ALL PRIVILEGES ON dash.* TO 'dash'@'localhost' IDENTIFIED BY 'DASH_DBPASS';</pre></div></li><li class="step "><p>Enter <code class="literal">quit</code> at the <code class="literal">mysql&gt;</code> prompt to exit MySQL.</p></li><li class="step "><p>In the <code class="literal">local_settings.py</code> file, change these options:</p><div class="verbatim-wrap highlight python"><pre class="screen">SESSION_ENGINE = 'django.contrib.sessions.backends.db'
DATABASES = {
    'default': {
        # Database configuration here
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'dash',
        'USER': 'dash',
        'PASSWORD': 'DASH_DBPASS',
        'HOST': 'localhost',
        'default-character-set': 'utf8'
    }
}</pre></div></li><li class="step "><p>After configuring the <code class="literal">local_settings.py</code> file as shown, you can run the
<code class="command">manage.py syncdb</code> command to populate this newly created
database.</p><div class="verbatim-wrap"><pre class="screen"># /usr/share/openstack-dashboard/manage.py syncdb</pre></div></li><li class="step "><p>The following output is returned:</p><div class="verbatim-wrap"><pre class="screen">Installing custom SQL ...
Installing indexes ...
DEBUG:django.db.backends:(0.008) CREATE INDEX `django_session_c25c2c28` ON `django_session` (`expire_date`);; args=()
No fixtures found.</pre></div></li><li class="step "><p>To avoid a warning when you restart Apache on Ubuntu, create a
<code class="literal">blackhole</code> directory in the Dashboard directory, as follows.</p><div class="verbatim-wrap"><pre class="screen"># mkdir -p /var/lib/dash/.blackhole</pre></div></li><li class="step "><p>Restart the Apache service.</p></li><li class="step "><p>On Ubuntu, restart the <code class="literal">nova-api</code> service to ensure that the API server
can connect to the Dashboard without error.</p><div class="verbatim-wrap"><pre class="screen"># service nova-api restart</pre></div></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.6.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cached database</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To mitigate the performance issues of database queries, you can use the
Django <code class="literal">cached_db</code> session back end, which utilizes both your database
and caching infrastructure to perform write-through caching and
efficient retrieval.</p><p>Enable this hybrid setting by configuring both your database and cache,
as discussed previously. Then, set the following value:</p><div class="verbatim-wrap highlight python"><pre class="screen">SESSION_ENGINE = "django.contrib.sessions.backends.cached_db"</pre></div></div><div class="sect2 " id="id-1.4.6.6.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cookies</span> <a title="Permalink" class="permalink" href="#id-1.4.6.6.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you use Django 1.4 or later, the <code class="literal">signed_cookies</code> back end avoids
server load and scaling problems.</p><p>This back end stores session data in a cookie, which is stored by the
user's browser. The back end uses a cryptographic signing technique to
ensure session data is not tampered with during transport. This is not
the same as encryption; session data is still readable by an attacker.</p><p>The pros of this engine are that it requires no additional dependencies
or infrastructure overhead, and it scales indefinitely as long as the
quantity of session data being stored fits into a normal cookie.</p><p>The biggest downside is that it places session data into storage on the
user's machine and transports it over the wire. It also limits the
quantity of session data that can be stored.</p><p>See the Django <a class="link" href="https://docs.djangoproject.com/en/dev/topics/http/sessions/#using-cookie-based-sessions" target="_blank">cookie-based
sessions</a>
documentation.</p></div></div><div class="sect1 " id="id-1.4.6.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage images</span> <a title="Permalink" class="permalink" href="#id-1.4.6.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrative user, you can create and manage images
for the projects to which you belong. You can also create
and manage images for users in all projects to which you have
access.</p><p>To create and manage images in specified projects as an end
user, see the <a class="link" href="http://docs.openstack.org/user-guide/dashboard-manage-images.html" target="_blank">upload and manage images with Dashboard in
OpenStack End User Guide</a>
and <a class="link" href="http://docs.openstack.org/user-guide/common/cli-manage-images.html" target="_blank">manage images with CLI in OpenStack End User Guide</a>.</p><p>To create and manage images as an administrator for other
users, use the following procedures.</p><div class="sect2 " id="id-1.4.6.7.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create images</span> <a title="Permalink" class="permalink" href="#id-1.4.6.7.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For details about image creation, see the <a class="link" href="http://docs.openstack.org/image-guide/" target="_blank">Virtual Machine Image
Guide</a>.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Images</span> category. The images that you
can administer for cloud users appear on this page.</p></li><li class="step "><p>Click <span class="guimenu ">Create Image</span>, which opens the
<span class="guimenu ">Create An Image</span> window.</p><div class="figure" id="id-1.4.6.7.5.3.3.2"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/create_image.png" target="_blank"><img src="images/create_image.png" width="" alt="Figure Dashboard — Create Image" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 4.1: </span><span class="name">Figure Dashboard — Create Image </span><a title="Permalink" class="permalink" href="#id-1.4.6.7.5.3.3.2">#</a></h6></div></div></li><li class="step "><p>In the <span class="guimenu ">Create An Image</span> window, enter or select the
following values:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                      <p>
                        <span class="guimenu ">Name</span>
                      </p>
                    </td><td>
                      <p>Enter a name for the image.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Description</span>
                      </p>
                    </td><td>
                      <p>Enter a brief description of
the image.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Image Source</span>
                      </p>
                    </td><td>
                      <p>Choose the image source from
the dropdown list. Your choices
are <span class="guimenu ">Image Location</span>
and <span class="guimenu ">Image File</span>.</p>
                    </td></tr><tr><td>
                      <p><span class="guimenu ">Image File</span> or
<span class="guimenu ">Image Location</span></p>
                    </td><td>
                      <p>Based on your selection, there
is an <span class="guimenu ">Image File</span> or
<span class="guimenu ">Image Location</span>
field. You can include the
location URL or browse for the
image file on your file system
and add it.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Format</span>
                      </p>
                    </td><td>
                      <p>Select the image format.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Architecture</span>
                      </p>
                    </td><td>
                      <p>Specify the architecture. For
example, <code class="literal">i386</code> for a 32-bit
architecture or <code class="literal">x86_64</code> for
a 64-bit architecture.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Minimum Disk (GB)</span>
                      </p>
                    </td><td>
                      <p>Leave this field empty.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Minimum RAM (MB)</span>
                      </p>
                    </td><td>
                      <p>Leave this field empty.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Copy Data</span>
                      </p>
                    </td><td>
                      <p>Specify this option to copy
image data to the Image service.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Public</span>
                      </p>
                    </td><td>
                      <p>Select this option to make the
image public to all users.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="guimenu ">Protected</span>
                      </p>
                    </td><td>
                      <p>Select this option to ensure
that only users with
permissions can delete it.</p>
                    </td></tr></tbody></table></div></li><li class="step "><p>Click <span class="guimenu ">Create Image</span>.</p><p>The image is queued to be uploaded. It might take several minutes
before the status changes from <code class="literal">Queued</code> to <code class="literal">Active</code>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.7.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update images</span> <a title="Permalink" class="permalink" href="#id-1.4.6.7.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Images</span> category.</p></li><li class="step "><p>Select the images that you want to edit. Click <span class="guimenu ">Edit Image</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Edit Image</span> window, you can change the image name.</p><p>Select the <span class="guimenu ">Public</span> check box to make the image public.
Clear this check box to make the image private. You cannot change
the <span class="guimenu ">Kernel ID</span>, <span class="guimenu ">Ramdisk ID</span>, or
<span class="guimenu ">Architecture</span> attributes for an image.</p></li><li class="step "><p>Click <span class="guimenu ">Edit Image</span>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.7.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete images</span> <a title="Permalink" class="permalink" href="#id-1.4.6.7.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin tab</span>, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Images</span> category.</p></li><li class="step "><p>Select the images that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Images</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Images</span> window, click <span class="guimenu ">Delete
Images</span> to confirm the deletion.</p><p>You cannot undo this action.</p></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.6.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage roles</span> <a title="Permalink" class="permalink" href="#id-1.4.6.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A role is a personality that a user assumes to perform a specific set
of operations. A role includes a set of rights and privileges. A user
assumes that role inherits those rights and privileges.</p><div id="id-1.4.6.8.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>OpenStack Identity service defines a user's role on a
project, but it is completely up to the individual service
to define what that role means. This is referred to as the
service's policy. To get details about what the privileges
for each role are, refer to the <code class="literal">policy.json</code> file
available for each service in the
<code class="literal">/etc/SERVICE/policy.json</code> file. For example, the
policy defined for OpenStack Identity service is defined
in the <code class="literal">/etc/keystone/policy.json</code> file.</p></div><div class="sect2 " id="id-1.4.6.8.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a role</span> <a title="Permalink" class="permalink" href="#id-1.4.6.8.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Identity</span> tab, click the <span class="guimenu ">Roles</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Create Role</span> button.</p><p>In the <span class="guimenu ">Create Role</span> window, enter a name for the role.</p></li><li class="step "><p>Click the <span class="guimenu ">Create Role</span> button to confirm your changes.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.8.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit a role</span> <a title="Permalink" class="permalink" href="#id-1.4.6.8.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">Identity</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Identity</span> tab, click the <span class="guimenu ">Roles</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Edit</span> button.</p><p>In the <span class="guimenu ">Update Role</span> window, enter a new name for the role.</p></li><li class="step "><p>Click the <span class="guimenu ">Update Role</span> button to confirm your changes.</p></li></ol></div></div><div id="id-1.4.6.8.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Using the dashboard, you can edit only the name assigned to
a role.</p></div></div><div class="sect2 " id="id-1.4.6.8.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a role</span> <a title="Permalink" class="permalink" href="#id-1.4.6.8.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">Identity</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Identity</span> tab, click the <span class="guimenu ">Roles</span> category.</p></li><li class="step "><p>Select the role you want to delete and click the <span class="guimenu ">Delete
Roles</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Roles</span> window, click <span class="guimenu ">Delete
Roles</span> to confirm the deletion.</p><p>You cannot undo this action.</p></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.6.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage instances</span> <a title="Permalink" class="permalink" href="#id-1.4.6.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrative user, you can manage instances for users in various
projects. You can view, terminate, edit, perform a soft or hard reboot,
create a snapshot from, and migrate instances. You can also view the
logs for instances or launch a VNC console for an instance.</p><p>For information about using the Dashboard to launch instances as an end
user, see the <a class="link" href="http://docs.openstack.org/user-guide/dashboard-launch-instances.html" target="_blank">OpenStack End User Guide</a>.</p><div class="sect2 " id="id-1.4.6.9.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create instance snapshots</span> <a title="Permalink" class="permalink" href="#id-1.4.6.9.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Instances</span> category.</p></li><li class="step "><p>Select an instance to create a snapshot from it. From the
Actions drop-down list, select <span class="guimenu ">Create Snapshot</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Snapshot</span> window, enter a name for the snapshot.</p></li><li class="step "><p>Click <span class="guimenu ">Create Snapshot</span>. The Dashboard shows the instance snapshot
in the <span class="guimenu ">Images</span> category.</p></li><li class="step "><p>To launch an instance from the snapshot, select the snapshot and
click <span class="guimenu ">Launch</span>. For information about launching
instances, see the
<a class="link" href="http://docs.openstack.org/user-guide/dashboard-launch-instances.html" target="_blank">OpenStack End User Guide</a>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.9.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Control the state of an instance</span> <a title="Permalink" class="permalink" href="#id-1.4.6.9.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Instances</span> category.</p></li><li class="step "><p>Select the instance for which you want to change the state.</p></li><li class="step "><p>From the drop-down list in the Actions column,
select the state.</p><p>Depending on the current state of the instance, you can perform various
actions on the instance. For example, pause, un-pause, suspend, resume,
soft or hard reboot, or terminate (actions in red are dangerous).</p></li></ol></div></div><div class="figure" id="id-1.4.6.9.5.3"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/change_instance_state.jpg" target="_blank"><img src="images/change_instance_state.jpg" width="" alt="Figure Dashboard — Instance Actions" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 4.2: </span><span class="name">Figure Dashboard — Instance Actions </span><a title="Permalink" class="permalink" href="#id-1.4.6.9.5.3">#</a></h6></div></div></div><div class="sect2 " id="id-1.4.6.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Track usage</span> <a title="Permalink" class="permalink" href="#id-1.4.6.9.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use the <span class="guimenu ">Overview</span> category to track usage of instances
for each project.</p><p>You can track costs per month by showing meters like number of VCPUs,
disks, RAM, and uptime of all your instances.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project from the
drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Overview</span> category.</p></li><li class="step "><p>Select a month and click <span class="guimenu ">Submit</span> to query the instance usage for
that month.</p></li><li class="step "><p>Click <span class="guimenu ">Download CSV Summary</span> to download a CSV summary.</p></li></ol></div></div></div></div><div class="sect1 " id="osadm-manage-flavor"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage flavors</span> <a title="Permalink" class="permalink" href="#osadm-manage-flavor">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>osadm-manage-flavor</li></ul></div></div></div></div><p>In OpenStack, a flavor defines the compute, memory, and storage
capacity of a virtual server, also known as an instance. As an
administrative user, you can create, edit, and delete flavors.</p><p>As of Newton, there are no default flavors.  The following table
lists the default flavors for Mitaka and earlier.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                <p>Flavor</p>
              </th><th>
                <p>VCPUs</p>
              </th><th>
                <p>Disk (in GB)</p>
              </th><th>
                <p>RAM (in MB)</p>
              </th></tr></thead><tbody><tr><td>
                <p>m1.tiny</p>
              </td><td>
                <p>1</p>
              </td><td>
                <p>1</p>
              </td><td>
                <p>512</p>
              </td></tr><tr><td>
                <p>m1.small</p>
              </td><td>
                <p>1</p>
              </td><td>
                <p>20</p>
              </td><td>
                <p>2048</p>
              </td></tr><tr><td>
                <p>m1.medium</p>
              </td><td>
                <p>2</p>
              </td><td>
                <p>40</p>
              </td><td>
                <p>4096</p>
              </td></tr><tr><td>
                <p>m1.large</p>
              </td><td>
                <p>4</p>
              </td><td>
                <p>80</p>
              </td><td>
                <p>8192</p>
              </td></tr><tr><td>
                <p>m1.xlarge</p>
              </td><td>
                <p>8</p>
              </td><td>
                <p>160</p>
              </td><td>
                <p>16384</p>
              </td></tr></tbody></table></div><div class="sect2 " id="id-1.4.6.10.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create flavors</span> <a title="Permalink" class="permalink" href="#id-1.4.6.10.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>In the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span>
tab and click the <span class="guimenu ">Flavors</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Create Flavor</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Flavor</span> window, enter or select the
parameters for the flavor in the <span class="guimenu ">Flavor Information</span>
            tab.</p><div class="figure" id="id-1.4.6.10.5.2.4.2"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/create_flavor.png" target="_blank"><img src="images/create_flavor.png" width="" alt="Dashboard — Create Flavor" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 4.3: </span><span class="name">Dashboard — Create Flavor </span><a title="Permalink" class="permalink" href="#id-1.4.6.10.5.2.4.2">#</a></h6></div></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                      <p>
                        <span class="bold"><strong>Name</strong></span>
                      </p>
                    </td><td>
                      <p>Enter the flavor name.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>ID</strong></span>
                      </p>
                    </td><td>
                      <p>Unique ID (integer or UUID) for the
new flavor. If specifying 'auto', a
UUID will be automatically generated.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>VCPUs</strong></span>
                      </p>
                    </td><td>
                      <p>Enter the number of virtual CPUs to
use.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>RAM (MB)</strong></span>
                      </p>
                    </td><td>
                      <p>Enter the amount of RAM to use, in
megabytes.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>Root Disk (GB)</strong></span>
                      </p>
                    </td><td>
                      <p>Enter the amount of disk space in
gigabytes to use for the root (/)
partition.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>Ephemeral Disk (GB)</strong></span>
                      </p>
                    </td><td>
                      <p>Enter the amount of disk space in
gigabytes to use for the ephemeral
partition. If unspecified, the value
is 0 by default.</p>
                      <p>Ephemeral disks offer machine local
disk storage linked to the lifecycle
of a VM instance. When a VM is
terminated, all data on the ephemeral
disk is lost. Ephemeral disks are not
included in any snapshots.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>Swap Disk (MB)</strong></span>
                      </p>
                    </td><td>
                      <p>Enter the amount of swap space (in
megabytes) to use. If unspecified,
the default is 0.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>RX/TX Factor</strong></span>
                      </p>
                    </td><td>
                      <p>Optional property allows servers with
a different bandwidth to be created
with the RX/TX Factor. The default
value is 1. That is, the new bandwidth
is the same as that of the attached
network.</p>
                    </td></tr></tbody></table></div></li><li class="step "><p>In the <span class="guimenu ">Flavor Access</span> tab, you can control access to
the flavor by moving projects from the <span class="guimenu ">All Projects</span>
column to the <span class="guimenu ">Selected Projects</span> column.</p><p>Only projects in the <span class="guimenu ">Selected Projects</span> column can
use the flavor. If there are no projects in the right column,
all projects can use the flavor.</p></li><li class="step "><p>Click <span class="guimenu ">Create Flavor</span>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.10.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update flavors</span> <a title="Permalink" class="permalink" href="#id-1.4.6.10.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>In the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Flavors</span> category.</p></li><li class="step "><p>Select the flavor that you want to edit. Click <span class="guimenu ">Edit
Flavor</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Edit Flavor</span> window, you can change the flavor
name, VCPUs, RAM, root disk, ephemeral disk, and swap disk values.</p></li><li class="step "><p>Click <span class="guimenu ">Save</span>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.10.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update Metadata</span> <a title="Permalink" class="permalink" href="#id-1.4.6.10.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>In the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Flavors</span> category.</p></li><li class="step "><p>Select the flavor that you want to update. In the drop-down
list, click <span class="guimenu ">Update Metadata</span> or click <span class="guimenu ">No</span> or
<span class="guimenu ">Yes</span> in the <span class="guimenu ">Metadata</span> column.</p></li><li class="step "><p>In the <span class="guimenu ">Update Flavor Metadata</span> window, you can customize
some metadata keys, then add it to this flavor and set them values.</p></li><li class="step "><p>Click <span class="guimenu ">Save</span>.</p><p>
              <span class="bold"><strong>Optional metadata keys</strong></span>
            </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td rowspan="5">
                      <p>
                        <span class="bold"><strong>CPU limits</strong></span>
                      </p>
                    </td><td>
                      <p>quota:cpu_shares</p>
                    </td></tr><tr><td>
                      <p>quota:cpu_period</p>
                    </td></tr><tr><td>
                      <p>quota:cpu_limit</p>
                    </td></tr><tr><td>
                      <p>quota:cpu_reservation</p>
                    </td></tr><tr><td>
                      <p>quota:cpu_quota</p>
                    </td></tr><tr><td rowspan="6">
                      <p>
                        <span class="bold"><strong>Disk tuning</strong></span>
                      </p>
                    </td><td>
                      <p>quota:disk_read_bytes_sec</p>
                    </td></tr><tr><td>
                      <p>quota:disk_read_iops_sec</p>
                    </td></tr><tr><td>
                      <p>quota:disk_write_bytes_sec</p>
                    </td></tr><tr><td>
                      <p>quota:disk_write_iops_sec</p>
                    </td></tr><tr><td>
                      <p>quota:disk_total_bytes_sec</p>
                    </td></tr><tr><td>
                      <p>quota:disk_total_iops_sec</p>
                    </td></tr><tr><td rowspan="6">
                      <p>
                        <span class="bold"><strong>Bandwidth I/O</strong></span>
                      </p>
                    </td><td>
                      <p>quota:vif_inbound_average</p>
                    </td></tr><tr><td>
                      <p>quota:vif_inbound_burst</p>
                    </td></tr><tr><td>
                      <p>quota:vif_inbound_peak</p>
                    </td></tr><tr><td>
                      <p>quota:vif_outbound_average</p>
                    </td></tr><tr><td>
                      <p>quota:vif_outbound_burst</p>
                    </td></tr><tr><td>
                      <p>quota:vif_outbound_peak</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>Watchdog behavior</strong></span>
                      </p>
                    </td><td>
                      <p>hw:watchdog_action</p>
                    </td></tr><tr><td rowspan="3">
                      <p>
                        <span class="bold"><strong>Random-number generator</strong></span>
                      </p>
                    </td><td>
                      <p>hw_rng:allowed</p>
                    </td></tr><tr><td>
                      <p>hw_rng:rate_bytes</p>
                    </td></tr><tr><td>
                      <p>hw_rng:rate_period</p>
                    </td></tr></tbody></table></div><p>For information about supporting metadata keys, see the
<a class="xref" href="#compute-flavors" title="5.4.3. Flavors">Section 5.4.3, “Flavors”</a>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.10.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete flavors</span> <a title="Permalink" class="permalink" href="#id-1.4.6.10.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>In the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Flavors</span> category.</p></li><li class="step "><p>Select the flavors that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Flavors</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Flavors</span> window, click
<span class="guimenu ">Delete Flavors</span> to confirm the deletion. You cannot
undo this action.</p></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.6.11"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage volumes and volume types</span> <a title="Permalink" class="permalink" href="#id-1.4.6.11">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Volumes are the Block Storage devices that you attach to instances to enable
persistent storage. Users can attach a volume to a running instance or detach
a volume and attach it to another instance at any time. For information about
using the dashboard to create and manage volumes as an end user, see the
<a class="link" href="http://docs.openstack.org/user-guide/dashboard-manage-volumes.html" target="_blank">OpenStack End User Guide</a>.</p><p>As an administrative user, you can manage volumes and volume types for users
in various projects. You can create and delete volume types, and you can view
and delete volumes. Note that a volume can be encrypted by using the steps
outlined below.</p><div class="sect2 " id="create-a-volume-type"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a volume type</span> <a title="Permalink" class="permalink" href="#create-a-volume-type">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>create-a-volume-type</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span>
project from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Volume Types</span> tab, and click
<span class="guimenu ">Create Volume Type</span> button. In the
<span class="guimenu ">Create Volume Type</span> window, enter a name for the volume type.</p></li><li class="step "><p>Click <span class="guimenu ">Create Volume Type</span> button to confirm your changes.</p></li></ol></div></div><div id="id-1.4.6.11.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.11.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create an encrypted volume type</span> <a title="Permalink" class="permalink" href="#id-1.4.6.11.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create a volume type using the steps above for <a class="xref" href="#create-a-volume-type" title="4.7.1. Create a volume type">Section 4.7.1, “Create a volume type”</a>.</p></li><li class="step "><p>Click <span class="guimenu ">Create Encryption</span> in the Actions column of the newly
created volume type.</p></li><li class="step "><p>Configure the encrypted volume by setting the parameters below from
available options (see table):</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.6.11.5.2.3.2.1"><span class="term ">Provider</span></dt><dd><p>Specifies the class responsible for configuring the encryption.</p></dd><dt id="id-1.4.6.11.5.2.3.2.2"><span class="term ">Control Location</span></dt><dd><p>Specifies whether the encryption is from the front end (nova) or the
back end (cinder).</p></dd><dt id="id-1.4.6.11.5.2.3.2.3"><span class="term ">Cipher</span></dt><dd><p>Specifies the encryption algorithm.</p></dd><dt id="id-1.4.6.11.5.2.3.2.4"><span class="term ">Key Size (bits)</span></dt><dd><p>Specifies the encryption key size.</p></dd></dl></div></li><li class="step "><p>Click <span class="guimenu ">Create Volume Type Encryption</span>.</p></li></ol></div></div><div class="figure" id="id-1.4.6.11.5.3"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/create_volume_type_encryption.png" target="_blank"><img src="images/create_volume_type_encryption.png" width="" alt="Encryption Options" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 4.4: </span><span class="name">Encryption Options </span><a title="Permalink" class="permalink" href="#id-1.4.6.11.5.3">#</a></h6></div></div><p>The table below provides a few alternatives available for creating encrypted
volumes.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                  <p>Encryption
parameters</p>
                </th><th>
                  <p>Parameter
options</p>
                </th><th>
                  <p>Comments</p>
                </th></tr></thead><tbody><tr><td rowspan="2">
                  <p>Provider</p>
                </td><td>
                  <p>nova.volume.encryptors.
luks.LuksEncryptor
(Recommended)</p>
                </td><td>
                  <p>Allows easier import and
migration of imported
encrypted volumes, and
allows access key to be
changed without
re-encrypting the volume</p>
                </td></tr><tr><td>
                  <p>nova.volume.encryptors.
cryptsetup.
CryptsetupEncryptor</p>
                </td><td>
                  <p>Less disk overhead than
LUKS</p>
                </td></tr><tr><td rowspan="2">
                  <p>Control Location</p>
                </td><td>
                  <p>front-end
(Recommended)</p>
                </td><td>
                  <p>The encryption occurs within
nova so that the data
transmitted over the network
is encrypted</p>
                </td></tr><tr><td>
                  <p>back-end</p>
                </td><td>
                  <p>This could be selected if a
cinder plug-in supporting
an encrypted back-end block
storage device becomes
available in the future.
TLS or other network
encryption would also be
needed to protect data as it
traverses the network</p>
                </td></tr><tr><td rowspan="2">
                  <p>Cipher</p>
                </td><td>
                  <p>aes-xts-plain64
(Recommended)</p>
                </td><td>
                  <p>See NIST reference below
to see advantages*</p>
                </td></tr><tr><td>
                  <p>aes-cbc-essiv</p>
                </td><td>
                  <p>Note: On the command line,
type 'cryptsetup benchmark'
for additional options</p>
                </td></tr><tr><td rowspan="2">
                  <p>Key Size (bits)</p>
                </td><td>
                  <p>512 (Recommended for
aes-xts-plain64. 256
should be used for
aes-cbc-essiv)</p>
                </td><td>
                  <p>Using this selection for
aes-xts, the underlying key
size would only be 256-bits*</p>
                </td></tr><tr><td>
                  <p>256</p>
                </td><td>
                  <p>Using this selection for
aes-xts, the underlying key
size would only be 128-bits*</p>
                </td></tr></tbody></table></div><p><code class="literal">*</code> Source <a class="link" href="http://csrc.nist.gov/publications/nistpubs/800-38E/nist-sp-800-38E.pdf" target="_blank">NIST SP 800-38E</a></p></div><div class="sect2 " id="id-1.4.6.11.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete volume types</span> <a title="Permalink" class="permalink" href="#id-1.4.6.11.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you delete a volume type, volumes of that type are not deleted.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span> project from
the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Volume Types</span> tab, select the volume type
or types that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Volume Types</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Volume Types</span> window, click the
<span class="guimenu ">Delete Volume Types</span> button to confirm the action.</p></li></ol></div></div><div id="id-1.4.6.11.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.11.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete volumes</span> <a title="Permalink" class="permalink" href="#id-1.4.6.11.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you delete an instance, the data of its attached volumes is not
destroyed.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Select the volume or volumes that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Volumes</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Volumes</span> window, click the
<span class="guimenu ">Delete Volumes</span> button to confirm the action.</p></li></ol></div></div><div id="id-1.4.6.11.7.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div></div><div class="sect1 " id="id-1.4.6.12"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage shares and share types</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Shares are file storage that instances can access. Users can
allow or deny a running instance to have access to a share at any time.
For information about using the Dashboard to create and manage shares as
an end user, see the
<a class="link" href="http://docs.openstack.org/user-guide/dashboard-manage-shares.html" target="_blank">OpenStack End User Guide</a>.</p><p>As an administrative user, you can manage shares and share types for users
in various projects. You can create and delete share types, and view
or delete shares.</p><div class="sect2 " id="id-1.4.6.12.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a share type</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and choose the <span class="guimenu ">admin</span>
project from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Shares</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Share Types</span> tab, and click
<span class="guimenu ">Create Share Type</span> button. In the
<span class="guimenu ">Create Share Type</span> window, enter or select the
following values.</p><p><span class="guimenu ">Name</span>: Enter a name for the share type.</p><p><span class="guimenu ">Driver handles share servers</span>: Choose True or False</p><p><span class="guimenu ">Extra specs</span>: To add extra specs, use key=value.</p></li><li class="step "><p>Click <span class="guimenu ">Create Share Type</span> button to confirm your changes.</p></li></ol></div></div><div id="id-1.4.6.12.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.12.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update share type</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and choose the <span class="guimenu ">admin</span> project from
the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Shares</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Share Types</span> tab, select the share type
that you want to update.</p></li><li class="step "><p>Select <span class="guimenu ">Update Share Type</span> from Actions.</p></li><li class="step "><p>In the <span class="guimenu ">Update Share Type</span> window, update extra specs.</p><p><span class="guimenu ">Extra specs</span>: To add extra specs, use key=value.
To unset extra specs, use key.</p></li><li class="step "><p>Click <span class="guimenu ">Update Share Type</span> button to confirm your changes.</p></li></ol></div></div><div id="id-1.4.6.12.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.12.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete share types</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you delete a share type, shares of that type are not deleted.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and choose the <span class="guimenu ">admin</span> project from
the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Shares</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Share Types</span> tab, select the share type
or types that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Share Types</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Share Types</span> window, click the
<span class="guimenu ">Delete Share Types</span> button to confirm the action.</p></li></ol></div></div><div id="id-1.4.6.12.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.12.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete shares</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and choose the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Shares</span> category.</p></li><li class="step "><p>Select the share or shares that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Shares</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Shares</span> window, click the
<span class="guimenu ">Delete Shares</span> button to confirm the action.</p></li></ol></div></div><div id="id-1.4.6.12.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.12.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete share server</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and choose the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Share Servers</span> category.</p></li><li class="step "><p>Select the share that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Share Server</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Share Server</span> window, click the
<span class="guimenu ">Delete Share Server</span> button to confirm the action.</p></li></ol></div></div><div id="id-1.4.6.12.8.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect2 " id="id-1.4.6.12.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.8.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete share networks</span> <a title="Permalink" class="permalink" href="#id-1.4.6.12.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and choose the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Share Networks</span> category.</p></li><li class="step "><p>Select the share network or share networks that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Share Networks</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Share Networks</span> window, click the
<span class="guimenu ">Delete Share Networks</span> button to confirm the action.</p></li></ol></div></div><div id="id-1.4.6.12.9.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div></div><div class="sect1 " id="id-1.4.6.13"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View and manage quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.6.13">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To prevent system capacities from being exhausted without notification,
you can set up quotas. Quotas are operational limits. For example, the
number of gigabytes allowed for each project can be controlled so that
cloud resources are optimized. Quotas can be enforced at both the project
and the project-user level.</p><p>Typically, you change quotas when a project needs more than ten
volumes or 1 TB on a compute node.</p><p>Using the Dashboard, you can view default Compute and Block Storage
quotas for new projects, as well as update quotas for existing projects.</p><div id="id-1.4.6.13.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Using the command-line interface, you can manage quotas for the
OpenStack Compute service, the OpenStack Block Storage service, and
the OpenStack Networking service (see <a class="link" href="http://docs.openstack.org/admin-guide/cli-set-quotas.html" target="_blank">OpenStack Administrator Guide</a>).
Additionally, you can update Compute service quotas for
project users.</p></div><p>The following table describes the Compute and Block Storage service quotas:</p><p>
        <span class="bold"><strong>Quota Descriptions</strong></span>
      </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                <p>Quota Name</p>
              </th><th>
                <p>Defines the number of</p>
              </th><th>
                <p>Service</p>
              </th></tr></thead><tbody><tr><td>
                <p>Gigabytes</p>
              </td><td>
                <p>Volume gigabytes allowed for
each project.</p>
              </td><td>
                <p>Block Storage</p>
              </td></tr><tr><td>
                <p>Instances</p>
              </td><td>
                <p>Instances allowed for each
project.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Injected Files</p>
              </td><td>
                <p>Injected files allowed for each
project.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Injected File
Content Bytes</p>
              </td><td>
                <p>Content bytes allowed for each
injected file.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Keypairs</p>
              </td><td>
                <p>Number of keypairs.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Metadata Items</p>
              </td><td>
                <p>Metadata items allowed for each
instance.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>RAM (MB)</p>
              </td><td>
                <p>RAM megabytes allowed for
each instance.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Security Groups</p>
              </td><td>
                <p>Security groups allowed for each
project.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Security Group
Rules</p>
              </td><td>
                <p>Rules allowed for each security
group.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Snapshots</p>
              </td><td>
                <p>Volume snapshots allowed for
each project.</p>
              </td><td>
                <p>Block Storage</p>
              </td></tr><tr><td>
                <p>VCPUs</p>
              </td><td>
                <p>Instance cores allowed for each
project.</p>
              </td><td>
                <p>Compute</p>
              </td></tr><tr><td>
                <p>Volumes</p>
              </td><td>
                <p>Volumes allowed for each
project.</p>
              </td><td>
                <p>Block Storage</p>
              </td></tr></tbody></table></div><div class="sect2 " id="id-1.4.6.13.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View default project quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.6.13.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Defaults</span> category.</p></li><li class="step "><p>The default quota values are displayed.</p></li></ol></div></div><div id="id-1.4.6.13.9.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You can sort the table by clicking on either the
<span class="guimenu ">Quota Name</span> or <span class="guimenu ">Limit</span> column headers.</p></div></div><div class="sect2 " id="id-1.4.6.13.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update project quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.6.13.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">Defaults</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Update Defaults</span> button.</p></li><li class="step "><p>In the <span class="guimenu ">Update Default Quotas</span> window,
you can edit the default quota values.</p></li><li class="step "><p>Click the <span class="guimenu ">Update Defaults</span> button.</p></li></ol></div></div><div id="id-1.4.6.13.10.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The dashboard does not show all possible project quotas.
To view and update the quotas for a service, use its
command-line client. See <a class="link" href="http://docs.openstack.org/admin-guide/cli-set-quotas.html" target="_blank">OpenStack Administrator Guide</a>.</p></div></div></div><div class="sect1 " id="id-1.4.6.14"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View cloud resources</span> <a title="Permalink" class="permalink" href="#id-1.4.6.14">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.6.14.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View services information</span> <a title="Permalink" class="permalink" href="#id-1.4.6.14.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrative user, you can view information for OpenStack services.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the
<span class="guimenu ">admin</span> project from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab
and click the <span class="guimenu ">System Information</span> category.</p><p>View the following information on these tabs:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Services</span>:
Displays the internal name and the public OpenStack name
for each service, the host on which the service runs,
and whether or not the service is enabled.</p></li><li class="listitem "><p><span class="guimenu ">Compute Services</span>:
Displays information specific to the Compute service. Both host
and zone are listed for each service, as well as its
activation status.</p></li><li class="listitem "><p><span class="guimenu ">Block Storage Services</span>:
Displays information specific to the Block Storage service. Both host
and zone are listed for each service, as well as its
activation status.</p></li><li class="listitem "><p><span class="guimenu ">Network Agents</span>:
Displays the network agents active within the cluster, such as L3 and
DHCP agents, and the status of each agent.</p></li><li class="listitem "><p><span class="guimenu ">Orchestration Services</span>:
Displays information specific to the Orchestration service. Name,
engine id, host and topic are listed for each service, as well as its
activation status.</p></li></ul></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.6.14.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View cloud usage statistics</span> <a title="Permalink" class="permalink" href="#id-1.4.6.14.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service provides user-level usage data for
OpenStack-based clouds, which can be used for customer billing, system
monitoring, or alerts. Data can be collected by notifications sent by
existing OpenStack components (for example, usage events emitted from
Compute) or by polling the infrastructure (for example, libvirt).</p><div id="id-1.4.6.14.3.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You can only view metering statistics on the dashboard (available
only to administrators).
The Telemetry service must be set up and administered through the
<code class="command">ceilometer</code> command-line interface (CLI).</p><p>For basic administration information, refer to the <a class="link" href="http://docs.openstack.org/user-guide/cli-ceilometer.html" target="_blank">Measure Cloud
Resources</a>
chapter in the OpenStack End User Guide.</p></div><div class="sect3 " id="id-1.4.6.14.3.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.10.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View resource statistics</span> <a title="Permalink" class="permalink" href="#id-1.4.6.14.3.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, click the <span class="guimenu ">Resource Usage</span> category.</p></li><li class="step "><p>Click the:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Usage Report</span> tab to view a usage report per project
by specifying the time period (or even use a calendar to define
a date range).</p></li><li class="listitem "><p><span class="guimenu ">Stats</span> tab to view a multi-series line chart with
user-defined meters. You group by project, define the value type
(min, max, avg, or sum), and specify the time period (or even use
a calendar to define a date range).</p></li></ul></div></li></ol></div></div></div></div></div><div class="sect1 " id="id-1.4.6.15"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage host aggregates</span> <a title="Permalink" class="permalink" href="#id-1.4.6.15">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Host aggregates enable administrative users to assign key-value pairs to
groups of machines.</p><p>Each node can have multiple aggregates and each aggregate can have
multiple key-value pairs. You can assign the same key-value pair to
multiple aggregates.</p><p>The scheduler uses this information to make scheduling decisions.
For information, see
<a class="link" href="http://docs.openstack.org/newton/config-reference/compute/scheduler.html" target="_blank">Scheduling</a>.</p><div class="sect2 " id="id-1.4.6.15.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To create a host aggregate</span> <a title="Permalink" class="permalink" href="#id-1.4.6.15.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the Dashboard and select the <span class="guimenu ">admin</span> project
from the drop-down list.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab and click
the <span class="guimenu ">Host Aggregates</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Create Host Aggregate</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Host Aggregate</span> dialog box, enter or select the
following values on the <span class="guimenu ">Host Aggregate Information</span> tab:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Name</span>: The host aggregate name.</p></li><li class="listitem "><p><span class="guimenu ">Availability Zone</span>: The cloud provider defines the default
availability zone, such as <code class="literal">us-west</code>, <code class="literal">apac-south</code>, or
<code class="literal">nova</code>. You can target the host aggregate, as follows:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>When the host aggregate is exposed as an availability zone,
select the availability zone when you launch an instance.</p></li><li class="listitem "><p>When the host aggregate is not exposed as an availability zone,
select a flavor and its extra specs to target the host
aggregate.</p></li></ul></div></li></ul></div></li><li class="step "><p>Assign hosts to the aggregate using the <span class="guimenu ">Manage Hosts within
Aggregate</span> tab in the same dialog box.</p><p>To assign a host to the aggregate, click <span class="bold"><strong>+</strong></span> for the host. The host
moves from the <span class="guimenu ">All available hosts</span> list to the
<span class="guimenu ">Selected hosts</span> list.</p></li></ol></div></div><p>You can add one host to one or more aggregates. To add a host to an
existing aggregate, edit the aggregate.</p></div><div class="sect2 " id="id-1.4.6.15.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To manage host aggregates</span> <a title="Permalink" class="permalink" href="#id-1.4.6.15.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Select the <span class="guimenu ">admin</span> project from the drop-down list at the top
of the page.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, open the <span class="guimenu ">System</span> tab and click
the <span class="guimenu ">Host Aggregates</span> category.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To edit host aggregates, select the host aggregate that you want
to edit. Click <span class="guimenu ">Edit Host Aggregate</span>.</p><p>In the <span class="guimenu ">Edit Host Aggregate</span> dialog box, you can change the
name and availability zone for the aggregate.</p></li><li class="listitem "><p>To manage hosts, locate the host aggregate that you want to edit
in the table. Click <span class="guimenu ">More</span> and select <span class="guimenu ">Manage Hosts</span>.</p><p>In the <span class="guimenu ">Add/Remove Hosts to Aggregate</span> dialog box,
click <span class="bold"><strong>+</strong></span> to assign a host to an aggregate. Click <span class="bold"><strong>-</strong></span> to
remove a host that is assigned to an aggregate.</p></li><li class="listitem "><p>To delete host aggregates, locate the host aggregate that you want
to edit in the table. Click <span class="guimenu ">More</span> and select
<span class="guimenu ">Delete Host Aggregate</span>.</p></li></ul></div></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.6.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch and manage stacks using the Dashboard</span> <a title="Permalink" class="permalink" href="#id-1.4.6.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Orchestration service provides a template-based
orchestration engine for the OpenStack cloud. Orchestration
services create and manage cloud infrastructure
resources such as storage, networking, instances, and
applications as a repeatable running environment.</p><p>Administrators use templates to create stacks, which are
collections of resources. For example, a stack might
include instances, floating IPs, volumes,
security groups, or users. The Orchestration service
offers access to all OpenStack
core services via a single modular template, with additional
orchestration capabilities such as auto-scaling and basic
high availability.</p><p>For information about:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>administrative tasks on the command-line, see
the <a class="link" href="http://docs.openstack.org/admin-guide/cli-admin-manage-stacks.html" target="_blank">OpenStack Administrator Guide</a>.</p><div id="id-1.4.6.16.5.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>There are no administration-specific tasks that can be done through
the Dashboard.</p></div></li><li class="listitem "><p>the basic creation and deletion of Orchestration stacks, refer to
the <a class="link" href="http://docs.openstack.org/user-guide/dashboard-stacks.html" target="_blank">OpenStack End User Guide</a>.</p></li></ul></div></div></div><div class="chapter " id="id-1.4.7"><div class="titlepage"><div><div><h1 class="title"><span class="number">5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute</span> <a title="Permalink" class="permalink" href="#id-1.4.7">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.7.5"><span class="number">5.1 </span><span class="name">System architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.6"><span class="number">5.2 </span><span class="name">Images and instances</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.7"><span class="number">5.3 </span><span class="name">Networking with nova-network</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.8"><span class="number">5.4 </span><span class="name">System administration</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.7.9"><span class="number">5.5 </span><span class="name">Troubleshoot Compute</span></a></span></dt></dl></div></div><p>The OpenStack Compute service allows you to control an
<a class="xref" href="#term-infrastructure-as-a-service-iaas" title="Infrastructure-as-a-Service (IaaS)">Infrastructure-as-a-Service (IaaS)</a> cloud computing platform.
It gives you control over instances and networks, and allows you to manage
access to the cloud through users and projects.</p><p>Compute does not include virtualization software. Instead, it defines
drivers that interact with underlying virtualization mechanisms that run
on your host operating system, and exposes functionality over a
web-based API.</p><div class="sect1 " id="id-1.4.7.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Compute contains several main components.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <a class="xref" href="#term-cloud-controller" title="cloud controller">cloud controller</a> represents the global state and interacts with
the other components. The <code class="literal">API server</code> acts as the web services
front end for the cloud controller. The <code class="literal">compute controller</code>
provides compute server resources and usually also contains the
Compute service.</p></li><li class="listitem "><p>The <code class="literal">object store</code> is an optional component that provides storage
services; you can also use OpenStack Object Storage instead.</p></li><li class="listitem "><p>An <code class="literal">auth manager</code> provides authentication and authorization
services when used with the Compute system; you can also use
OpenStack Identity as a separate authentication service instead.</p></li><li class="listitem "><p>A <code class="literal">volume controller</code> provides fast and permanent block-level
storage for the compute servers.</p></li><li class="listitem "><p>The <code class="literal">network controller</code> provides virtual networks to enable
compute servers to interact with each other and with the public
network. You can also use OpenStack Networking instead.</p></li><li class="listitem "><p>The <code class="literal">scheduler</code> is used to select the most suitable compute
controller to host an instance.</p></li></ul></div><p>Compute uses a messaging-based, <code class="literal">shared nothing</code> architecture. All
major components exist on multiple servers, including the compute,
volume, and network controllers, and the Object Storage or Image service.
The state of the entire system is stored in a database. The cloud
controller communicates with the internal object store using HTTP, but
it communicates with the scheduler, network controller, and volume
controller using Advanced Message Queuing Protocol (AMQP). To avoid
blocking a component while waiting for a response, Compute uses
asynchronous calls, with a callback that is triggered when a response is
received.</p><div class="sect2 " id="id-1.4.7.5.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Hypervisors</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Compute controls hypervisors through an API server. Selecting the best
hypervisor to use can be difficult, and you must take budget, resource
constraints, supported features, and required technical specifications
into account. However, the majority of OpenStack development is done on
systems using KVM and Xen-based hypervisors. For a detailed list of
features and support across different hypervisors, see the
<a class="link" href="http://docs.openstack.org/developer/nova/support-matrix.html" target="_blank">Feature Support Matrix</a>.</p><p>You can also orchestrate clouds using multiple hypervisors in different
availability zones. Compute supports the following hypervisors:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="https://wiki.openstack.org/wiki/Ironic" target="_blank">Baremetal</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://linuxcontainers.org/" target="_blank">Linux Containers (LXC)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://wiki.qemu.org/Manual" target="_blank">Quick Emulator (QEMU)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://user-mode-linux.sourceforge.net/" target="_blank">User Mode Linux (UML)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://www.vmware.com/products/vsphere-hypervisor/support.html" target="_blank">VMware
vSphere</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://www.xen.org/support/documentation.html" target="_blank">Xen</a>
            </p></li></ul></div><p>For more information about hypervisors, see the
<a class="link" href="http://docs.openstack.org/newton/config-reference/compute/hypervisors.html" target="_blank">Hypervisors</a>
section in the OpenStack Configuration Reference.</p></div><div class="sect2 " id="id-1.4.7.5.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Projects, users, and roles</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Compute system is designed to be used by different consumers in the
form of projects on a shared system, and role-based access assignments.
Roles control the actions that a user is allowed to perform.</p><p>Projects are isolated resource containers that form the principal
organizational structure within the Compute service. They consist of an
individual VLAN, and volumes, instances, images, keys, and users. A user
can specify the project by appending <code class="literal">project_id</code> to their access key.
If no project is specified in the API request, Compute attempts to use a
project with the same ID as the user.</p><p>For projects, you can use quota controls to limit the:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Number of volumes that can be launched.</p></li><li class="listitem "><p>Number of processor cores and the amount of RAM that can be
allocated.</p></li><li class="listitem "><p>Floating IP addresses assigned to any instance when it launches. This
allows instances to have the same publicly accessible IP addresses.</p></li><li class="listitem "><p>Fixed IP addresses assigned to the same instance when it launches.
This allows instances to have the same publicly or privately
accessible IP addresses.</p></li></ul></div><p>Roles control the actions a user is allowed to perform. By default, most
actions do not require a particular role, but you can configure them by
editing the <code class="literal">policy.json</code> file for user roles. For example, a rule can
be defined so that a user must have the <code class="literal">admin</code> role in order to be
able to allocate a public IP address.</p><p>A project limits users' access to particular images. Each user is
assigned a user name and password. Keypairs granting access to an
instance are enabled for each user, but quotas are set, so that each
project can control resource consumption across available hardware
resources.</p><div id="id-1.4.7.5.6.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Earlier versions of OpenStack used the term <code class="literal">tenant</code> instead of
<code class="literal">project</code>. Because of this legacy terminology, some command-line tools
use <code class="literal">--tenant_id</code> where you would normally expect to enter a
project ID.</p></div></div><div class="sect2 " id="id-1.4.7.5.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block storage</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack provides two classes of block storage: ephemeral storage
and persistent volume.</p><p>
          <span class="bold"><strong>Ephemeral storage</strong></span>
        </p><p>Ephemeral storage includes a root ephemeral volume and an additional
ephemeral volume.</p><p>The root disk is associated with an instance, and exists only for the
life of this very instance. Generally, it is used to store an
instance's root file system, persists across the guest operating system
reboots, and is removed on an instance deletion. The amount of the root
ephemeral volume is defined by the flavor of an instance.</p><p>In addition to the ephemeral root volume, all default types of flavors,
except <code class="literal">m1.tiny</code>, which is the smallest one, provide an additional
ephemeral block device sized between 20 and 160 GB (a configurable value
to suit an environment). It is represented as a raw block device with no
partition table or file system. A cloud-aware operating system can
discover, format, and mount such a storage device. OpenStack Compute
defines the default file system for different operating systems as Ext4
for Linux distributions, VFAT for non-Linux and non-Windows operating
systems, and NTFS for Windows. However, it is possible to specify any
other filesystem type by using <code class="literal">virt_mkfs</code> or
<code class="literal">default_ephemeral_format</code> configuration options.</p><div id="id-1.4.7.5.7.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For example, the <code class="literal">cloud-init</code> package included into an Ubuntu's stock
cloud image, by default, formats this space as an Ext4 file system
and mounts it on <code class="literal">/mnt</code>. This is a cloud-init feature, and is not
an OpenStack mechanism. OpenStack only provisions the raw storage.</p></div><p>
          <span class="bold"><strong>Persistent volume</strong></span>
        </p><p>A persistent volume is represented by a persistent virtualized block
device independent of any particular instance, and provided by OpenStack
Block Storage.</p><p>Only a single configured instance can access a persistent volume.
Multiple instances cannot access a persistent volume. This type of
configuration requires a traditional network file system to allow
multiple instances accessing the persistent volume. It also requires a
traditional network file system like NFS, CIFS, or a cluster file system
such as GlusterFS. These systems can be built within an OpenStack
cluster, or provisioned outside of it, but OpenStack software does not
provide these features.</p><p>You can configure a persistent volume as bootable and use it to provide
a persistent virtual instance similar to the traditional non-cloud-based
virtualization system. It is still possible for the resulting instance
to keep ephemeral storage, depending on the flavor selected. In this
case, the root file system can be on the persistent volume, and its
state is maintained, even if the instance is shut down. For more
information about this type of configuration, see <a class="link" href="http://docs.openstack.org/newton/config-reference/block-storage/block-storage-overview.html" target="_blank">Introduction to the
Block Storage service</a>
in the OpenStack Configuration Reference.</p><div id="id-1.4.7.5.7.12" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A persistent volume does not provide concurrent access from multiple
instances. That type of configuration requires a traditional network
file system like NFS, or CIFS, or a cluster file system such as
GlusterFS. These systems can be built within an OpenStack cluster,
or provisioned outside of it, but OpenStack software does not
provide these features.</p></div></div><div class="sect2 " id="id-1.4.7.5.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">EC2 compatibility API</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In addition to the native compute API, OpenStack provides an
EC2-compatible API. This API allows EC2 legacy workflows built for EC2
to work with OpenStack.</p><div id="id-1.4.7.5.8.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Nova in tree EC2-compatible API is deprecated.
The <a class="link" href="http://git.openstack.org/cgit/openstack/ec2-api/" target="_blank">ec2-api project</a>
is working to implement the EC2 API.</p></div><p>You can use numerous third-party tools and language-specific SDKs to
interact with OpenStack clouds. You can use both native and
compatibility APIs. Some of the more popular third-party tools are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.5.8.5.1"><span class="term ">Euca2ools</span></dt><dd><p>A popular open source command-line tool for interacting with the EC2
API. This is convenient for multi-cloud environments where EC2 is
the common API, or for transitioning from EC2-based clouds to
OpenStack. For more information, see the <a class="link" href="https://docs.eucalyptus.com/eucalyptus/" target="_blank">Eucalyptus
Documentation</a>.</p></dd><dt id="id-1.4.7.5.8.5.2"><span class="term ">Hybridfox</span></dt><dd><p>A Firefox browser add-on that provides a graphical interface to many
popular public and private cloud technologies, including OpenStack.
For more information, see the <a class="link" href="http://code.google.com/p/hybridfox/" target="_blank">hybridfox
site</a>.</p></dd><dt id="id-1.4.7.5.8.5.3"><span class="term ">boto</span></dt><dd><p>Python library for interacting with Amazon Web Services. You can use
this library to access OpenStack through the EC2 compatibility API.
For more     information, see the <a class="link" href="https://github.com/boto/boto" target="_blank">boto project page on
GitHub</a>.</p></dd><dt id="id-1.4.7.5.8.5.4"><span class="term ">fog</span></dt><dd><p>A Ruby cloud services library. It provides methods to interact
with a large number of cloud and virtualization platforms, including
OpenStack. For more information, see the <a class="link" href="https://rubygems.org/gems/fog" target="_blank">fog
site</a>.</p></dd><dt id="id-1.4.7.5.8.5.5"><span class="term ">php-opencloud</span></dt><dd><p>A PHP SDK designed to work with most OpenStack-based cloud
deployments, as well as Rackspace public cloud. For more
information, see the <a class="link" href="http://www.php-opencloud.com" target="_blank">php-opencloud
site</a>.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.7.5.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Building blocks</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In OpenStack the base operating system is usually copied from an image
stored in the OpenStack Image service. This is the most common case and
results in an ephemeral instance that starts from a known template state
and loses all accumulated states on virtual machine deletion. It is also
possible to put an operating system on a persistent volume in the
OpenStack Block Storage volume system. This gives a more traditional
persistent system that accumulates states which are preserved on the
OpenStack Block Storage volume across the deletion and re-creation of
the virtual machine. To get a list of available images on your system,
run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list
+--------------------------------------+-----------------------------+--------+
| ID                                   | Name                        | Status |
+--------------------------------------+-----------------------------+--------+
| aee1d242-730f-431f-88c1-87630c0f07ba | Ubuntu 14.04 cloudimg amd64 | active |
| 0b27baa1-0ca6-49a7-b3f4-48388e440245 | Ubuntu 14.10 cloudimg amd64 | active |
| df8d56fc-9cea-4dfd-a8d3-28764de3cb08 | jenkins                     | active |
+--------------------------------------+-----------------------------+--------+</pre></div><p>The displayed image attributes are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.5.9.5.1"><span class="term ">
              <code class="literal">ID</code>
            </span></dt><dd><p>Automatically generated UUID of the image</p></dd><dt id="id-1.4.7.5.9.5.2"><span class="term ">
              <code class="literal">Name</code>
            </span></dt><dd><p>Free form, human-readable name for image</p></dd><dt id="id-1.4.7.5.9.5.3"><span class="term ">
              <code class="literal">Status</code>
            </span></dt><dd><p>The status of the image. Images marked <code class="literal">ACTIVE</code> are available for
use.</p></dd><dt id="id-1.4.7.5.9.5.4"><span class="term ">
              <code class="literal">Server</code>
            </span></dt><dd><p>For images that are created as snapshots of running instances, this
is the UUID of the instance the snapshot derives from. For uploaded
images, this field is blank.</p></dd></dl></div><p>Virtual hardware templates are called <code class="literal">flavors</code>. The default
installation provides five flavors. By default, these are configurable
by admin users, however that behavior can be changed by redefining the
access controls for <code class="literal">compute_extension:flavormanage</code> in
<code class="literal">/etc/nova/policy.json</code> on the <code class="literal">compute-api</code> server.</p><p>For a list of flavors that are available on your system:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor list
+-----+-----------+-------+------+-----------+-------+-----------+
| ID  | Name      |   RAM | Disk | Ephemeral | VCPUs | Is_Public |
+-----+-----------+-------+------+-----------+-------+-----------+
| 1   | m1.tiny   |   512 |    1 |         0 |     1 | True      |
| 2   | m1.small  |  2048 |   20 |         0 |     1 | True      |
| 3   | m1.medium |  4096 |   40 |         0 |     2 | True      |
| 4   | m1.large  |  8192 |   80 |         0 |     4 | True      |
| 5   | m1.xlarge | 16384 |  160 |         0 |     8 | True      |
+-----+-----------+-------+------+-----------+-------+-----------+</pre></div></div><div class="sect2 " id="id-1.4.7.5.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute service architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.7.5.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These basic categories describe the service architecture and information
about the cloud controller.</p><p>
          <span class="bold"><strong>API server</strong></span>
        </p><p>At the heart of the cloud framework is an API server, which makes
command and control of the hypervisor, storage, and networking
programmatically available to users.</p><p>The API endpoints are basic HTTP web services which handle
authentication, authorization, and basic command and control functions
using various API interfaces under the Amazon, Rackspace, and related
models. This enables API compatibility with multiple existing tool sets
created for interaction with offerings from other vendors. This broad
compatibility prevents vendor lock-in.</p><p>
          <span class="bold"><strong>Message queue</strong></span>
        </p><p>A messaging queue brokers the interaction between compute nodes
(processing), the networking controllers (software which controls
network infrastructure), API endpoints, the scheduler (determines which
physical hardware to allocate to a virtual resource), and similar
components. Communication to and from the cloud controller is handled by
HTTP requests through multiple API endpoints.</p><p>A typical message passing event begins with the API server receiving a
request from a user. The API server authenticates the user and ensures
that they are permitted to issue the subject command. The availability
of objects implicated in the request is evaluated and, if available, the
request is routed to the queuing engine for the relevant workers.
Workers continually listen to the queue based on their role, and
occasionally their type host name. When an applicable work request
arrives on the queue, the worker takes assignment of the task and begins
executing it. Upon completion, a response is dispatched to the queue
which is received by the API server and relayed to the originating user.
Database entries are queried, added, or removed as necessary during the
process.</p><p>
          <span class="bold"><strong>Compute worker</strong></span>
        </p><p>Compute workers manage computing instances on host machines. The API
dispatches commands to compute workers to complete these tasks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Run instances</p></li><li class="listitem "><p>Delete instances (Terminate instances)</p></li><li class="listitem "><p>Reboot instances</p></li><li class="listitem "><p>Attach volumes</p></li><li class="listitem "><p>Detach volumes</p></li><li class="listitem "><p>Get console output</p></li></ul></div><p>
          <span class="bold"><strong>Network Controller</strong></span>
        </p><p>The Network Controller manages the networking resources on host
machines. The API server dispatches commands through the message queue,
which are subsequently processed by Network Controllers. Specific
operations include:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Allocating fixed IP addresses</p></li><li class="listitem "><p>Configuring VLANs for projects</p></li><li class="listitem "><p>Configuring networks for compute nodes</p></li></ul></div></div></div><div class="sect1 " id="id-1.4.7.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Images and instances</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Virtual machine images contain a virtual disk that holds a
bootable operating system on it. Disk images provide templates for
virtual machine file systems. The Image service controls image storage
and management.</p><p>Instances are the individual virtual machines that run on physical
compute nodes inside the cloud. Users can launch any number of instances
from the same image. Each launched instance runs from a copy of the
base image. Any changes made to the instance do not affect
the base image. Snapshots capture the state of an instances
running disk. Users can create a snapshot, and build a new image based
on these snapshots. The Compute service controls instance, image, and
snapshot storage and management.</p><p>When you launch an instance, you must choose a <code class="literal">flavor</code>, which
represents a set of virtual resources. Flavors define virtual
CPU number, RAM amount available, and ephemeral disks size. Users
must select from the set of available flavors
defined on their cloud. OpenStack provides a number of predefined
flavors that you can edit or add to.</p><div id="id-1.4.7.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>For more information about creating and troubleshooting images,
see the <a class="link" href="http://docs.openstack.org/image-guide/" target="_blank">OpenStack Virtual Machine Image
Guide</a>.</p></li><li class="listitem "><p>For more information about image configuration options, see the
<a class="link" href="http://docs.openstack.org/newton/config-reference/image.html" target="_blank">Image services</a>
section of the OpenStack Configuration Reference.</p></li><li class="listitem "><p>For more information about flavors, see <a class="xref" href="#compute-flavors" title="5.4.3. Flavors">Section 5.4.3, “Flavors”</a>.</p></li></ul></div></div><p>You can add and remove additional resources from running instances, such
as persistent volume storage, or public IP addresses. The example used
in this chapter is of a typical virtual system within an OpenStack
cloud. It uses the <code class="literal">cinder-volume</code> service, which provides persistent
block storage, instead of the ephemeral storage provided by the selected
instance flavor.</p><p>This diagram shows the system state prior to launching an instance. The
image store has a number of predefined images, supported by the Image
service. Inside the cloud, a compute node contains the
available vCPU, memory, and local disk resources. Additionally, the
<code class="literal">cinder-volume</code> service stores predefined volumes.</p><p>
        <span class="bold"><strong>The base image state with no running instances</strong></span>
      </p><div class="figure" id="id-1.4.7.6.9"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/instance-life-1.png" target="_blank"><img src="images/instance-life-1.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.1: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.6.9">#</a></h6></div></div><div class="sect2 " id="id-1.4.7.6.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Instance Launch</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To launch an instance, select an image, flavor, and any optional
attributes. The selected flavor provides a root volume, labeled <code class="literal">vda</code>
in this diagram, and additional ephemeral storage, labeled <code class="literal">vdb</code>. In
this example, the <code class="literal">cinder-volume</code> store is mapped to the third virtual
disk on this instance, <code class="literal">vdc</code>.</p><p>
          <span class="bold"><strong>Instance creation from an image</strong></span>
        </p><div class="figure" id="id-1.4.7.6.10.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/instance-life-2.png" target="_blank"><img src="images/instance-life-2.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.2: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.6.10.4">#</a></h6></div></div><p>The Image service copies the base image from the image store to the
local disk. The local disk is the first disk that the instance
accesses, which is the root volume labeled <code class="literal">vda</code>. Smaller
instances start faster. Less data needs to be copied across
the network.</p><p>The new empty ephemeral disk is also created, labeled <code class="literal">vdb</code>.
This disk is deleted when you delete the instance.</p><p>The compute node connects to the attached <code class="literal">cinder-volume</code> using iSCSI. The
<code class="literal">cinder-volume</code> is mapped to the third disk, labeled <code class="literal">vdc</code> in this
diagram. After the compute node provisions the vCPU and memory
resources, the instance boots up from root volume <code class="literal">vda</code>. The instance
runs and changes data on the disks (highlighted in red on the diagram).
If the volume store is located on a separate network, the
<code class="literal">my_block_storage_ip</code> option specified in the storage node
configuration file directs image traffic to the compute node.</p><div id="id-1.4.7.6.10.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Some details in this example scenario might be different in your
environment. For example, you might use a different type of back-end
storage, or different network protocols. One common variant is that
the ephemeral storage used for volumes <code class="literal">vda</code> and <code class="literal">vdb</code> could be
backed by network storage rather than a local disk.</p></div><p>When you delete an instance, the state is reclaimed with the exception
of the persistent volume. The ephemeral storage, whether encrypted or not,
is purged. Memory and vCPU resources are released. The image remains
unchanged throughout this process.</p><div class="figure" id="id-1.4.7.6.10.10"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/instance-life-3.png" target="_blank"><img src="images/instance-life-3.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.3: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.6.10.10">#</a></h6></div></div></div><div class="sect2 " id="id-1.4.7.6.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image properties and property protection</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An image property is a key and value pair that the administrator
or the image owner attaches to an OpenStack Image service image, as
follows:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The administrator defines core properties, such as the image
name.</p></li><li class="listitem "><p>The administrator and the image owner can define additional
properties, such as licensing and billing information.</p></li></ul></div><p>The administrator can configure any property as protected, which
limits which policies or user roles can perform CRUD operations on that
property. Protected properties are generally additional properties to
which only administrators have access.</p><p>For unprotected image properties, the administrator can manage
core properties and the image owner can manage additional properties.</p><p>
          <span class="bold"><strong>To configure property protection</strong></span>
        </p><p>To configure property protection, edit the <code class="literal">policy.json</code> file. This file
can also be used to set policies for Image service actions.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Define roles or policies in the <code class="literal">policy.json</code> file:</p><div class="verbatim-wrap highlight json"><pre class="screen">{
    "context_is_admin":  "role:admin",
    "default": "",

    "add_image": "",
    "delete_image": "",
    "get_image": "",
    "get_images": "",
    "modify_image": "",
    "publicize_image": "role:admin",
    "copy_from": "",

    "download_image": "",
    "upload_image": "",

    "delete_image_location": "",
    "get_image_location": "",
    "set_image_location": "",

    "add_member": "",
    "delete_member": "",
    "get_member": "",
    "get_members": "",
    "modify_member": "",

    "manage_image_cache": "role:admin",

    "get_task": "",
    "get_tasks": "",
    "add_task": "",
    "modify_task": "",

    "deactivate": "",
    "reactivate": "",

    "get_metadef_namespace": "",
    "get_metadef_namespaces":"",
    "modify_metadef_namespace":"",
    "add_metadef_namespace":"",
    "delete_metadef_namespace":"",

    "get_metadef_object":"",
    "get_metadef_objects":"",
    "modify_metadef_object":"",
    "add_metadef_object":"",

    "list_metadef_resource_types":"",
    "get_metadef_resource_type":"",
    "add_metadef_resource_type_association":"",

    "get_metadef_property":"",
    "get_metadef_properties":"",
    "modify_metadef_property":"",
    "add_metadef_property":"",

    "get_metadef_tag":"",
    "get_metadef_tags":"",
    "modify_metadef_tag":"",
    "add_metadef_tag":"",
    "add_metadef_tags":""
 }</pre></div><p>For each parameter, use <code class="literal">"rule:restricted"</code> to restrict access to all
users or <code class="literal">"role:admin"</code> to limit access to administrator roles.
For example:</p><div class="verbatim-wrap highlight json"><pre class="screen">"download_image":
"upload_image":</pre></div></li><li class="step "><p>Define which roles or policies can manage which properties in a property
protections configuration file. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[x_none_read]
create = context_is_admin
read = !
update = !
delete = !

[x_none_update]
create = context_is_admin
read = context_is_admin
update = !
delete = context_is_admin

[x_none_delete]
create = context_is_admin
read = context_is_admin
update = context_is_admin
delete = !</pre></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A value of <code class="literal">@</code> allows the corresponding operation for a property.</p></li><li class="listitem "><p>A value of <code class="literal">!</code> disallows the corresponding operation for a
property.</p></li></ul></div></li><li class="step "><p>In the <code class="literal">glance-api.conf</code> file, define the location of a property
protections configuration file.</p><div class="verbatim-wrap highlight ini"><pre class="screen">property_protection_file = {file_name}</pre></div><p>This file contains the rules for property protections and the roles and
policies associated with it.</p><p>By default, property protections are not enforced.</p><p>If you specify a file name value and the file is not found, the
<code class="literal">glance-api</code> service does not start.</p><p>To view a sample configuration file, see
<a class="link" href="http://docs.openstack.org/newton/config-reference/image/glance-api.conf.html" target="_blank">glance-api.conf</a>.</p></li><li class="step "><p>Optionally, in the <code class="literal">glance-api.conf</code> file, specify whether roles or
policies are used in the property protections configuration file</p><div class="verbatim-wrap highlight ini"><pre class="screen">property_protection_rule_format = roles</pre></div><p>The default is <code class="literal">roles</code>.</p><p>To view a sample configuration file, see
<a class="link" href="http://docs.openstack.org/newton/config-reference/image/glance-api.conf.html" target="_blank">glance-api.conf</a>.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.7.6.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image download: how it works</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Prior to starting a virtual machine, transfer the virtual machine image
to the compute node from the Image service. How this
works can change depending on the settings chosen for the compute node
and the Image service.</p><p>Typically, the Compute service will use the image identifier passed to
it by the scheduler service and request the image from the Image API.
Though images are not stored in glance—rather in a back end, which could
be Object Storage, a filesystem or any other supported method—the
connection is made from the compute node to the Image service and the
image is transferred over this connection. The Image service streams the
image from the back end to the compute node.</p><p>It is possible to set up the Object Storage node on a separate network,
and still allow image traffic to flow between the compute and object
storage nodes. Configure the <code class="literal">my_block_storage_ip</code> option in the
storage node configuration file to allow block storage traffic to reach
the compute node.</p><p>Certain back ends support a more direct method, where on request the
Image service will return a URL that links directly to the back-end store.
You can download the image using this approach. Currently, the only store
to support the direct download approach is the filesystem store.
Configured the approach using the <code class="literal">filesystems</code> option in
the <code class="literal">image_file_url</code> section of the <code class="literal">nova.conf</code> file on
compute nodes.</p><p>Compute nodes also implement caching of images, meaning that if an image
has been used before it won't necessarily be downloaded every time.
Information on the configuration options for caching on compute nodes
can be found in the <a class="link" href="http://docs.openstack.org/newton/config-reference/" target="_blank">Configuration
Reference</a>.</p></div><div class="sect2 " id="id-1.4.7.6.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Instance building blocks</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In OpenStack, the base operating system is usually copied from an image
stored in the OpenStack Image service. This results in an ephemeral
instance that starts from a known template state and loses all
accumulated states on shutdown.</p><p>You can also put an operating system on a persistent volume in Compute
or the Block Storage volume system. This gives a more traditional,
persistent system that accumulates states that are preserved across
restarts. To get a list of available images on your system, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list
+--------------------------------------+-----------------------------+--------+
| ID                                   | Name                        | Status |
+--------------------------------------+-----------------------------+--------+
| aee1d242-730f-431f-88c1-87630c0f07ba | Ubuntu 14.04 cloudimg amd64 | active |
+--------------------------------------+-----------------------------+--------+
| 0b27baa1-0ca6-49a7-b3f4-48388e440245 | Ubuntu 14.10 cloudimg amd64 | active |
+--------------------------------------+-----------------------------+--------+
| df8d56fc-9cea-4dfd-a8d3-28764de3cb08 | jenkins                     | active |
+--------------------------------------+-----------------------------+--------+</pre></div><p>The displayed image attributes are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.6.13.6.1"><span class="term ">
              <code class="literal">ID</code>
            </span></dt><dd><p>Automatically generated UUID of the image.</p></dd><dt id="id-1.4.7.6.13.6.2"><span class="term ">
              <code class="literal">Name</code>
            </span></dt><dd><p>Free form, human-readable name for the image.</p></dd><dt id="id-1.4.7.6.13.6.3"><span class="term ">
              <code class="literal">Status</code>
            </span></dt><dd><p>The status of the image. Images marked <code class="literal">ACTIVE</code> are available for
use.</p></dd><dt id="id-1.4.7.6.13.6.4"><span class="term ">
              <code class="literal">Server</code>
            </span></dt><dd><p>For images that are created as snapshots of running instances, this
is the UUID of the instance the snapshot derives from. For uploaded
images, this field is blank.</p></dd></dl></div><p>Virtual hardware templates are called <code class="literal">flavors</code>. The default
installation provides five predefined flavors.</p><p>For a list of flavors that are available on your system, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor list
+-----+-----------+-------+------+-----------+-------+-----------+
| ID  | Name      |   RAM | Disk | Ephemeral | VCPUs | Is_Public |
+-----+-----------+-------+------+-----------+-------+-----------+
| 1   | m1.tiny   |   512 |    1 |         0 |     1 | True      |
| 2   | m1.small  |  2048 |   20 |         0 |     1 | True      |
| 3   | m1.medium |  4096 |   40 |         0 |     2 | True      |
| 4   | m1.large  |  8192 |   80 |         0 |     4 | True      |
| 5   | m1.xlarge | 16384 |  160 |         0 |     8 | True      |
+-----+-----------+-------+------+-----------+-------+-----------+</pre></div><p>By default, administrative users can configure the flavors. You can
change this behavior by redefining the access controls for
<code class="literal">compute_extension:flavormanage</code> in <code class="literal">/etc/nova/policy.json</code> on the
<code class="literal">compute-api</code> server.</p></div><div class="sect2 " id="id-1.4.7.6.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Instance management tools</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack provides command-line, web interface, and API-based instance
management tools. Third-party management tools are also available, using
either the native API or the provided EC2-compatible API.</p><p>The OpenStack python-novaclient package provides a basic command-line
utility, which uses the <code class="command">nova</code> command. This is available as a native
package for most Linux distributions, or you can install the latest
version using the pip python package installer:</p><div class="verbatim-wrap"><pre class="screen"># pip install python-novaclient</pre></div><p>For more information about python-novaclient and other command-line
tools, see the <a class="link" href="http://docs.openstack.org/user-guide/cli.html" target="_blank">OpenStack End User
Guide</a>.</p></div><div class="sect2 " id="id-1.4.7.6.15"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Control where instances run</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.15">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/scheduler.html" target="_blank">Scheduling section</a>
of OpenStack Configuration Reference
provides detailed information on controlling where your instances run,
including ensuring a set of instances run on different compute nodes for
service resiliency or on the same node for high performance
inter-instance communications.</p><p>Administrative users can specify which compute node their instances
run on. To do this, specify the <code class="literal">--availability-zone
AVAILABILITY_ZONE:COMPUTE_HOST</code> parameter.</p></div><div class="sect2 " id="id-1.4.7.6.16"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.2.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch instances with UEFI</span> <a title="Permalink" class="permalink" href="#id-1.4.7.6.16">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Unified Extensible Firmware Interface (UEFI) is a standard firmware
designed to replace legacy BIOS. There is a slow but steady trend
for operating systems to move to the UEFI format and, in some cases,
make it their only format.</p><p>
          <span class="bold"><strong>To configure UEFI environment</strong></span>
        </p><p>To successfully launch an instance from an UEFI image in QEMU/KVM
environment, the administrator has to install the following
packages on compute node:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>OVMF, a port of Intel's tianocore firmware to QEMU virtual machine.</p></li><li class="listitem "><p>libvirt, which has been supporting UEFI boot since version 1.2.9.</p></li></ul></div><p>Because default UEFI loader path is <code class="literal">/usr/share/OVMF/OVMF_CODE.fd</code>, the
administrator must create one link to this location after UEFI package
is installed.</p><p>
          <span class="bold"><strong>To upload UEFI images</strong></span>
        </p><p>To launch instances from a UEFI image, the administrator first has to
upload one UEFI image. To do so, <code class="literal">hw_firmware_type</code> property must
be set to <code class="literal">uefi</code> when the image is created. For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --container-format bare --disk-format qcow2 \
  --property hw_firmware_type=uefi --file /tmp/cloud-uefi.qcow --name uefi</pre></div><p>After that, you can launch instances from this UEFI image.</p></div></div><div class="sect1 " id="id-1.4.7.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking with nova-network</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Understanding the networking configuration options helps you design the
best configuration for your Compute instances.</p><p>You can choose to either install and configure <code class="literal">nova-network</code> or use the
OpenStack Networking service (neutron). This section contains a brief
overview of <code class="literal">nova-network</code>. For more information about OpenStack
Networking, see <a class="xref" href="#networking" title="Chapter 9. Networking">Chapter 9, <em>Networking</em></a>.</p><div class="sect2 " id="id-1.4.7.7.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking concepts</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Compute assigns a private IP address to each VM instance. Compute makes
a distinction between fixed IPs and floating IP. Fixed IPs are IP
addresses that are assigned to an instance on creation and stay the same
until the instance is explicitly terminated. Floating IPs are addresses
that can be dynamically associated with an instance. A floating IP
address can be disassociated and associated with another instance at any
time. A user can reserve a floating IP for their project.</p><div id="id-1.4.7.7.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Currently, Compute with <code class="literal">nova-network</code> only supports Linux bridge
networking that allows virtual interfaces to connect to the outside
network through the physical interface.</p></div><p>The network controller with <code class="literal">nova-network</code> provides virtual networks to
enable compute servers to interact with each other and with the public
network. Compute with <code class="literal">nova-network</code> supports the following network modes,
which are implemented as Network Manager types:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.7.4.5.1"><span class="term ">Flat Network Manager</span></dt><dd><p>In this mode, a network administrator specifies a subnet. IP
addresses for VM instances are assigned from the subnet, and then
injected into the image on launch. Each instance receives a fixed IP
address from the pool of available addresses. A system administrator
must create the Linux networking bridge (typically named <code class="literal">br100</code>,
although this is configurable) on the systems running the
<code class="literal">nova-network</code> service. All instances of the system are attached to
the same bridge, which is configured manually by the network
administrator.</p></dd></dl></div><div id="id-1.4.7.7.4.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Configuration injection currently only works on Linux-style
systems that keep networking configuration in
<code class="literal">/etc/network/interfaces</code>.</p></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.7.4.7.1"><span class="term ">Flat DHCP Network Manager</span></dt><dd><p>In this mode, OpenStack starts a DHCP server (dnsmasq) to allocate
IP addresses to VM instances from the specified subnet, in addition
to manually configuring the networking bridge. IP addresses for VM
instances are assigned from a subnet specified by the network
administrator.</p><p>Like flat mode, all instances are attached to a single bridge on the
compute node. Additionally, a DHCP server configures instances
depending on single-/multi-host mode, alongside each <code class="literal">nova-network</code>.
In this mode, Compute does a bit more configuration. It attempts to
bridge into an Ethernet device (<code class="literal">flat_interface</code>, eth0 by
default). For every instance, Compute allocates a fixed IP address
and configures dnsmasq with the MAC ID and IP address for the VM.
Dnsmasq does not take part in the IP address allocation process, it
only hands out IPs according to the mapping done by Compute.
Instances receive their fixed IPs with the <code class="command">dhcpdiscover</code> command.
These IPs are not assigned to any of the host's network interfaces,
only to the guest-side interface for the VM.</p><p>In any setup with flat networking, the hosts providing the
<code class="literal">nova-network</code> service are responsible for forwarding traffic from the
private network. They also run and configure dnsmasq as a DHCP
server listening on this bridge, usually on IP address 10.0.0.1 (see
<a class="xref" href="#compute-dnsmasq" title="5.3.2. DHCP server: dnsmasq">Section 5.3.2, “DHCP server: dnsmasq”</a>). Compute can determine
the NAT entries for each network, although sometimes NAT is not
used, such as when the network has been configured with all public
IPs, or if a hardware router is used (which is a high availability
option). In this case, hosts need to have <code class="literal">br100</code> configured and
physically connected to any other nodes that are hosting VMs. You
must set the <code class="literal">flat_network_bridge</code> option or create networks with
the bridge parameter in order to avoid raising an error. Compute
nodes have iptables or ebtables entries created for each project and
instance to protect against MAC ID or IP address spoofing and ARP
poisoning.</p></dd></dl></div><div id="id-1.4.7.7.4.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>In single-host Flat DHCP mode you will be able to ping VMs
through their fixed IP from the <code class="literal">nova-network</code> node, but you
cannot ping them from the compute nodes. This is expected
behavior.</p></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.7.4.9.1"><span class="term ">VLAN Network Manager</span></dt><dd><p>This is the default mode for OpenStack Compute. In this mode,
Compute creates a VLAN and bridge for each project. For
multiple-machine installations, the VLAN Network Mode requires a
switch that supports VLAN tagging (IEEE 802.1Q). The project gets a
range of private IPs that are only accessible from inside the VLAN.
In order for a user to access the instances in their project, a
special VPN instance (code named <code class="literal">cloudpipe</code>) needs to be created.
Compute generates a certificate and key for the user to access the
VPN and starts the VPN automatically. It provides a private network
segment for each project's instances that can be accessed through a
dedicated VPN connection from the internet. In this mode, each
project gets its own VLAN, Linux networking bridge, and subnet.</p><p>The subnets are specified by the network administrator, and are
assigned dynamically to a project when required. A DHCP server is
started for each VLAN to pass out IP addresses to VM instances from
the subnet assigned to the project. All instances belonging to one
project are bridged into the same VLAN for that project. OpenStack
Compute creates the Linux networking bridges and VLANs when
required.</p></dd></dl></div><p>These network managers can co-exist in a cloud system. However, because
you cannot select the type of network for a given project, you cannot
configure multiple network types in a single Compute installation.</p><p>All network managers configure the network using network drivers. For
example, the Linux L3 driver (<code class="literal">l3.py</code> and <code class="literal">linux_net.py</code>), which
makes use of <code class="literal">iptables</code>, <code class="literal">route</code> and other network management
facilities, and the libvirt <a class="link" href="http://libvirt.org/formatnwfilter.html" target="_blank">network filtering
facilities</a>. The driver is
not tied to any particular network manager; all network managers use the
same driver. The driver usually initializes only when the first VM lands
on this host node.</p><p>All network managers operate in either single-host or multi-host mode.
This choice greatly influences the network configuration. In single-host
mode, a single <code class="literal">nova-network</code> service provides a default gateway for VMs
and hosts a single DHCP server (dnsmasq). In multi-host mode, each
compute node runs its own <code class="literal">nova-network</code> service. In both cases, all
traffic between VMs and the internet flows through <code class="literal">nova-network</code>. Each
mode has benefits and drawbacks. For more on this, see the Network
Topology section in the <a class="link" href="http://docs.openstack.org/ops-guide/arch-network-design.html#network-topology" target="_blank">OpenStack Operations Guide</a>.</p><p>All networking options require network connectivity to be already set up
between OpenStack physical nodes. OpenStack does not configure any
physical network interfaces. All network managers automatically create
VM virtual interfaces. Some network managers can also create network
bridges such as <code class="literal">br100</code>.</p><p>The internal network interface is used for communication with VMs. The
interface should not have an IP address attached to it before OpenStack
installation, it serves only as a fabric where the actual endpoints are
VMs and dnsmasq. Additionally, the internal network interface must be in
<code class="literal">promiscuous</code> mode, so that it can receive packets whose target MAC
address is the guest VM, not the host.</p><p>All machines must have a public and internal network interface
(controlled by these options: <code class="literal">public_interface</code> for the public
interface, and <code class="literal">flat_interface</code> and <code class="literal">vlan_interface</code> for the
internal interface with flat or VLAN managers). This guide refers to the
public network as the external network and the private network as the
internal or project network.</p><p>For flat and flat DHCP modes, use the <code class="command">nova network-create</code> command
to create a network:</p><div class="verbatim-wrap"><pre class="screen">$ nova network-create vmnet \
  --fixed-range-v4 10.0.0.0/16 --fixed-cidr 10.0.20.0/24 --bridge br100</pre></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.7.4.18.1"><span class="term ">This example uses the following parameters:</span></dt><dd><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.7.4.18.1.2.1.1"><span class="term ">
                    <code class="option">--fixed-range-v4</code>
                  </span></dt><dd><p>specifies the network subnet.</p></dd><dt id="id-1.4.7.7.4.18.1.2.1.2"><span class="term ">
                    <code class="option">--fixed-cidr</code>
                  </span></dt><dd><p>specifies a range of fixed IP addresses to allocate,
and can be a subset of the <code class="literal">--fixed-range-v4</code>
argument.</p></dd><dt id="id-1.4.7.7.4.18.1.2.1.3"><span class="term ">
                    <code class="option">--bridge</code>
                  </span></dt><dd><p>specifies the bridge device to which this network is
connected on every compute node.</p></dd></dl></div></dd></dl></div></div><div class="sect2 " id="compute-dnsmasq"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DHCP server: dnsmasq</span> <a title="Permalink" class="permalink" href="#compute-dnsmasq">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>compute-dnsmasq</li></ul></div></div></div></div><p>The Compute service uses
<a class="link" href="http://www.thekelleys.org.uk/dnsmasq/doc.html" target="_blank">dnsmasq</a> as the DHCP
server when using either Flat DHCP Network Manager or VLAN Network
Manager. For Compute to operate in IPv4/IPv6 dual-stack mode, use at
least dnsmasq v2.63. The <code class="literal">nova-network</code> service is responsible for
starting dnsmasq processes.</p><p>The behavior of dnsmasq can be customized by creating a dnsmasq
configuration file. Specify the configuration file using the
<code class="literal">dnsmasq_config_file</code> configuration option:</p><div class="verbatim-wrap highlight ini"><pre class="screen">dnsmasq_config_file=/etc/dnsmasq-nova.conf</pre></div><p>For more information about creating a dnsmasq configuration file, see
the <a class="link" href="http://docs.openstack.org/newton/config-reference/" target="_blank">OpenStack Configuration
Reference</a>,
and <a class="link" href="http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq.conf.example" target="_blank">the dnsmasq
documentation</a>.</p><p>Dnsmasq also acts as a caching DNS server for instances. You can specify
the DNS server that dnsmasq uses by setting the <code class="literal">dns_server</code>
configuration option in <code class="literal">/etc/nova/nova.conf</code>. This example configures
dnsmasq to use Google's public DNS server:</p><div class="verbatim-wrap highlight ini"><pre class="screen">dns_server=8.8.8.8</pre></div><p>Dnsmasq logs to syslog (typically <code class="literal">/var/log/syslog</code> or
<code class="literal">/var/log/messages</code>, depending on Linux distribution). Logs can be
useful for troubleshooting, especially in a situation where VM instances
boot successfully but are not reachable over the network.</p><p>Administrators can specify the starting point IP address to reserve with
the DHCP server (in the format n.n.n.n) with this command:</p><div class="verbatim-wrap"><pre class="screen">$ nova-manage fixed reserve --address IP_ADDRESS</pre></div><p>This reservation only affects which IP address the VMs start at, not the
fixed IP addresses that <code class="literal">nova-network</code> places on the bridges.</p></div><div class="sect2 " id="id-1.4.7.7.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Compute to use IPv6 addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you are using OpenStack Compute with <code class="literal">nova-network</code>, you can put
Compute into dual-stack mode, so that it uses both IPv4 and IPv6
addresses for communication. In dual-stack mode, instances can acquire
their IPv6 global unicast addresses by using a stateless address
auto-configuration mechanism [RFC 4862/2462]. IPv4/IPv6 dual-stack mode
works with both <code class="literal">VlanManager</code> and <code class="literal">FlatDHCPManager</code> networking
modes.</p><p>In <code class="literal">VlanManager</code> networking mode, each project uses a different 64-bit
global routing prefix. In <code class="literal">FlatDHCPManager</code> mode, all instances use
one 64-bit global routing prefix.</p><p>This configuration was tested with virtual machine images that have an
IPv6 stateless address auto-configuration capability. This capability is
required for any VM to run with an IPv6 address. You must use an EUI-64
address for stateless address auto-configuration. Each node that
executes a <code class="literal">nova-*</code> service must have <code class="literal">python-netaddr</code> and <code class="literal">radvd</code>
installed.</p><p>
          <span class="bold"><strong>Switch into IPv4/IPv6 dual-stack mode</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>For every node running a <code class="literal">nova-*</code> service, install python-netaddr:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install python-netaddr</pre></div></li><li class="step "><p>For every node running <code class="literal">nova-network</code>, install <code class="literal">radvd</code> and configure
IPv6 networking:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install radvd
# echo 1 &gt; /proc/sys/net/ipv6/conf/all/forwarding
# echo 0 &gt; /proc/sys/net/ipv6/conf/all/accept_ra</pre></div></li><li class="step "><p>On all nodes, edit the <code class="literal">nova.conf</code> file and specify
<code class="literal">use_ipv6 = True</code>.</p></li><li class="step "><p>Restart all <code class="literal">nova-*</code> services.</p></li></ol></div></div><p>
          <span class="bold"><strong>IPv6 configuration options</strong></span>
        </p><p>You can use the following options with the <code class="command">nova network-create</code>
command:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Add a fixed range for IPv6 addresses to the <code class="command">nova network-create</code>
command. Specify <code class="literal">public</code> or <code class="literal">private</code> after the <code class="literal">network-create</code>
parameter.</p><div class="verbatim-wrap"><pre class="screen">$ nova network-create public --fixed-range-v4 FIXED_RANGE_V4 \
  --vlan VLAN_ID --vpn VPN_START --fixed-range-v6 FIXED_RANGE_V6</pre></div></li><li class="listitem "><p>Set the IPv6 global routing prefix by using the
<code class="literal">--fixed_range_v6</code> parameter. The default value for the parameter
is <code class="literal">fd00::/48</code>.</p><p>When you use <code class="literal">FlatDHCPManager</code>, the command uses the original
<code class="literal">--fixed_range_v6</code> value. For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova network-create public  --fixed-range-v4 10.0.2.0/24 \
  --fixed-range-v6 fd00:1::/48</pre></div></li><li class="listitem "><p>When you use <code class="literal">VlanManager</code>, the command increments the subnet ID
to create subnet prefixes. Guest VMs use this prefix to generate
their IPv6 global unicast addresses. For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova network-create public --fixed-range-v4 10.0.1.0/24 --vlan 100 \
  --vpn 1000 --fixed-range-v6 fd00:1::/48</pre></div></li></ul></div><div class="table" id="id-1.4.7.7.6.10"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.1: </span><span class="name">Description of IPv6 configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.7.6.10">#</a></h6></div><div class="table-contents"><table class="table" summary="Description of IPv6 configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Configuration option = Default value</p>
                </th><th>
                  <p>Description</p>
                </th></tr><tr><th>
                  <p>[DEFAULT]</p>
                </th><th> </th></tr></thead><tbody><tr><td>
                  <p>fixed_range_v6 = fd00::/48</p>
                </td><td>
                  <p>(StrOpt) Fixed IPv6 address block</p>
                </td></tr><tr><td>
                  <p>gateway_v6 = None</p>
                </td><td>
                  <p>(StrOpt) Default IPv6 gateway</p>
                </td></tr><tr><td>
                  <p>ipv6_backend = rfc2462</p>
                </td><td>
                  <p>(StrOpt) Backend to use for IPv6 generation</p>
                </td></tr><tr><td>
                  <p>use_ipv6 = False</p>
                </td><td>
                  <p>(BoolOpt) Use IPv6</p>
                </td></tr></tbody></table></div></div></div><div class="sect2 " id="id-1.4.7.7.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Metadata service</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Compute uses a metadata service for virtual machine instances to
retrieve instance-specific data. Instances access the metadata service
at <code class="literal">http://169.254.169.254</code>. The metadata service supports two sets of
APIs: an OpenStack metadata API and an EC2-compatible API. Both APIs are
versioned by date.</p><p>To retrieve a list of supported versions for the OpenStack metadata API,
make a GET request to <code class="literal">http://169.254.169.254/openstack</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/openstack
2012-08-10
2013-04-04
2013-10-17
latest</pre></div><p>To list supported versions for the EC2-compatible metadata API, make a
GET request to <code class="literal">http://169.254.169.254</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254
1.0
2007-01-19
2007-03-01
2007-08-29
2007-10-10
2007-12-15
2008-02-01
2008-09-01
2009-04-04
latest</pre></div><p>If you write a consumer for one of these APIs, always attempt to access
the most recent API version supported by your consumer first, then fall
back to an earlier version if the most recent one is not available.</p><p>Metadata from the OpenStack API is distributed in JSON format. To
retrieve the metadata, make a GET request to
<code class="literal">http://169.254.169.254/openstack/2012-08-10/meta_data.json</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/openstack/2012-08-10/meta_data.json</pre></div><div class="verbatim-wrap highlight json"><pre class="screen">{
   "uuid": "d8e02d56-2648-49a3-bf97-6be8f1204f38",
   "availability_zone": "nova",
   "hostname": "test.novalocal",
   "launch_index": 0,
   "meta": {
      "priority": "low",
      "role": "webserver"
   },
   "project_id": "f7ac731cc11f40efbc03a9f9e1d1d21f",
   "public_keys": {
       "mykey": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDYVEprvtYJXVOBN0XNKV\
                 VRNCRX6BlnNbI+USLGais1sUWPwtSg7z9K9vhbYAPUZcq8c/s5S9dg5vTH\
                 bsiyPCIDOKyeHba4MUJq8Oh5b2i71/3BISpyxTBH/uZDHdslW2a+SrPDCe\
                 uMMoss9NFhBdKtDkdG9zyi0ibmCP6yMdEX8Q== Generated by Nova\n"
   },
   "name": "test"
}</pre></div><p>Instances also retrieve user data (passed as the <code class="literal">user_data</code> parameter
in the API call or by the <code class="literal">--user_data</code> flag in the
<code class="command">openstack server create</code> command) through the metadata service, by making a
GET request to <code class="literal">http://169.254.169.254/openstack/2012-08-10/user_data</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/openstack/2012-08-10/user_data
#!/bin/bash
echo 'Extra user data here'</pre></div><p>The metadata service has an API that is compatible with version
2009-04-04 of the <a class="link" href="http://docs.amazonwebservices.com/AWSEC2/2009-04-04/UserGuide/AESDG-chapter-instancedata.html" target="_blank">Amazon EC2 metadata
service</a>.
This means that virtual machine images designed for EC2 will work
properly with OpenStack.</p><p>The EC2 API exposes a separate URL for each metadata element. Retrieve a
listing of these elements by making a GET query to
<code class="literal">http://169.254.169.254/2009-04-04/meta-data/</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/2009-04-04/meta-data/
ami-id
ami-launch-index
ami-manifest-path
block-device-mapping/
hostname
instance-action
instance-id
instance-type
kernel-id
local-hostname
local-ipv4
placement/
public-hostname
public-ipv4
public-keys/
ramdisk-id
reservation-id
security-groups</pre></div><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/2009-04-04/meta-data/block-device-mapping/
ami</pre></div><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/2009-04-04/meta-data/placement/
availability-zone</pre></div><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/2009-04-04/meta-data/public-keys/
0=mykey</pre></div><p>Instances can retrieve the public SSH key (identified by keypair name
when a user requests a new instance) by making a GET request to
<code class="literal">http://169.254.169.254/2009-04-04/meta-data/public-keys/0/openssh-key</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/2009-04-04/meta-data/public-keys/0/openssh-key
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDYVEprvtYJXVOBN0XNKVVRNCRX6BlnNbI+US\
LGais1sUWPwtSg7z9K9vhbYAPUZcq8c/s5S9dg5vTHbsiyPCIDOKyeHba4MUJq8Oh5b2i71/3B\
ISpyxTBH/uZDHdslW2a+SrPDCeuMMoss9NFhBdKtDkdG9zyi0ibmCP6yMdEX8Q== Generated\
by Nova</pre></div><p>Instances can retrieve user data by making a GET request to
<code class="literal">http://169.254.169.254/2009-04-04/user-data</code>:</p><div class="verbatim-wrap"><pre class="screen">$ curl http://169.254.169.254/2009-04-04/user-data
#!/bin/bash
echo 'Extra user data here'</pre></div><p>The metadata service is implemented by either the <code class="literal">nova-api</code> service or
the <code class="literal">nova-api-metadata</code> service. Note that the <code class="literal">nova-api-metadata</code> service
is generally only used when running in multi-host mode, as it retrieves
instance-specific metadata. If you are running the <code class="literal">nova-api</code> service, you
must have <code class="literal">metadata</code> as one of the elements listed in the
<code class="literal">enabled_apis</code> configuration option in <code class="literal">/etc/nova/nova.conf</code>. The
default <code class="literal">enabled_apis</code> configuration setting includes the metadata
service, so you do not need to modify it.</p><p>Hosts access the service at <code class="literal">169.254.169.254:80</code>, and this is
translated to <code class="literal">metadata_host:metadata_port</code> by an iptables rule
established by the <code class="literal">nova-network</code> service. In multi-host mode, you can set
<code class="literal">metadata_host</code> to <code class="literal">127.0.0.1</code>.</p><p>For instances to reach the metadata service, the <code class="literal">nova-network</code> service
must configure iptables to NAT port <code class="literal">80</code> of the <code class="literal">169.254.169.254</code>
address to the IP address specified in <code class="literal">metadata_host</code> (this defaults
to <code class="literal">$my_ip</code>, which is the IP address of the <code class="literal">nova-network</code> service) and
port specified in <code class="literal">metadata_port</code> (which defaults to <code class="literal">8775</code>) in
<code class="literal">/etc/nova/nova.conf</code>.</p><div id="id-1.4.7.7.7.26" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">metadata_host</code> configuration option must be an IP address,
not a host name.</p></div><p>The default Compute service settings assume that <code class="literal">nova-network</code> and
<code class="literal">nova-api</code> are running on the same host. If this is not the case, in the
<code class="literal">/etc/nova/nova.conf</code> file on the host running <code class="literal">nova-network</code>, set the
<code class="literal">metadata_host</code> configuration option to the IP address of the host
where <code class="literal">nova-api</code> is running.</p><div class="table" id="id-1.4.7.7.7.28"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.2: </span><span class="name">Description of metadata configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.7.7.28">#</a></h6></div><div class="table-contents"><table class="table" summary="Description of metadata configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Configuration option = Default value</p>
                </th><th>
                  <p>Description</p>
                </th></tr><tr><th>
                  <p>[DEFAULT]</p>
                </th><th> </th></tr></thead><tbody><tr><td>
                  <p>metadata_cache_expiration = 15</p>
                </td><td>
                  <p>(IntOpt) Time in seconds to cache metadata; 0 to disable metadata
caching entirely (not recommended). Increasing this should improve
response times of the metadata API when under heavy load. Higher values
may increase memory usage and result in longer times for host metadata
changes to take effect.</p>
                </td></tr><tr><td>
                  <p>metadata_host = $my_ip</p>
                </td><td>
                  <p>(StrOpt) The IP address for the metadata API server</p>
                </td></tr><tr><td>
                  <p>metadata_listen = 0.0.0.0</p>
                </td><td>
                  <p>(StrOpt) The IP address on which the metadata API will listen.</p>
                </td></tr><tr><td>
                  <p>metadata_listen_port = 8775</p>
                </td><td>
                  <p>(IntOpt) The port on which the metadata API will listen.</p>
                </td></tr><tr><td>
                  <p>metadata_manager = nova.api.manager.MetadataManager</p>
                </td><td>
                  <p>(StrOpt) OpenStack metadata service manager</p>
                </td></tr><tr><td>
                  <p>metadata_port = 8775</p>
                </td><td>
                  <p>(IntOpt) The port for the metadata API port</p>
                </td></tr><tr><td>
                  <p>metadata_workers = None</p>
                </td><td>
                  <p>(IntOpt) Number of workers for metadata service. The default will be the number of CPUs available.</p>
                </td></tr><tr><td>
                  <p>vendordata_driver = nova.api.metadata.vendordata_json.JsonFileVendorData</p>
                </td><td>
                  <p>(StrOpt) Driver to use for vendor data</p>
                </td></tr><tr><td>
                  <p>vendordata_jsonfile_path = None</p>
                </td><td>
                  <p>(StrOpt) File to load JSON formatted vendor data from</p>
                </td></tr></tbody></table></div></div></div><div class="sect2 " id="id-1.4.7.7.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable ping and SSH on VMs</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You need to enable <code class="literal">ping</code> and <code class="literal">ssh</code> on your VMs for network access.
This can be done with either the <code class="command">nova</code> or <code class="command">euca2ools</code>
commands.</p><div id="id-1.4.7.7.8.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Run these commands as root only if the credentials used to interact
with <code class="literal">nova-api</code> are in <code class="literal">/root/.bashrc</code>. If the EC2 credentials in
the <code class="literal">.bashrc</code> file are for an unprivileged user, you must run
these commands as that user instead.</p></div><p>Enable ping and SSH with <code class="command">openstack security group rule create</code>
commands:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create default --protocol icmp --dst-port -1:-1 --remote-ip 0.0.0.0/0
$ openstack security group rule create default --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0</pre></div><p>Enable ping and SSH with <code class="literal">euca2ools</code>:</p><div class="verbatim-wrap"><pre class="screen">$ euca-authorize -P icmp -t -1:-1 -s 0.0.0.0/0 default
$ euca-authorize -P tcp -p 22 -s 0.0.0.0/0 default</pre></div><p>If you have run these commands and still cannot ping or SSH your
instances, check the number of running <code class="literal">dnsmasq</code> processes, there
should be two. If not, kill the processes and restart the service with
these commands:</p><div class="verbatim-wrap"><pre class="screen"># killall dnsmasq
# service nova-network restart</pre></div></div><div class="sect2 " id="id-1.4.7.7.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure public (floating) IP addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section describes how to configure floating IP addresses with
<code class="literal">nova-network</code>. For information about doing this with OpenStack
Networking, see <a class="xref" href="#l3-routing-and-nat" title="9.9.2. L3 routing and NAT">Section 9.9.2, “L3 routing and NAT”</a>.</p><div class="sect3 " id="id-1.4.7.7.9.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Private and public IP addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.9.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In this section, the term floating IP address is used to refer to an IP
address, usually public, that you can dynamically add to a running
virtual instance.</p><p>Every virtual instance is automatically assigned a private IP address.
You can choose to assign a public (or floating) IP address instead.
OpenStack Compute uses network address translation (NAT) to assign
floating IPs to virtual instances.</p><p>To be able to assign a floating IP address, edit the
<code class="literal">/etc/nova/nova.conf</code> file to specify which interface the
<code class="literal">nova-network</code> service should bind public IP addresses to:</p><div class="verbatim-wrap highlight ini"><pre class="screen">public_interface=VLAN100</pre></div><p>If you make changes to the <code class="literal">/etc/nova/nova.conf</code> file while the
<code class="literal">nova-network</code> service is running, you will need to restart the service to
pick up the changes.</p><div id="id-1.4.7.7.9.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Floating IPs are implemented by using a source NAT (SNAT rule in
iptables), so security groups can sometimes display inconsistent
behavior if VMs use their floating IP to communicate with other VMs,
particularly on the same physical host. Traffic from VM to VM across
the fixed network does not have this issue, and so this is the
recommended setup. To ensure that traffic does not get SNATed to the
floating range, explicitly set:</p><div class="verbatim-wrap highlight ini"><pre class="screen">dmz_cidr=x.x.x.x/y</pre></div><p>The <code class="literal">x.x.x.x/y</code> value specifies the range of floating IPs for each
pool of floating IPs that you define. This configuration is also
required if the VMs in the source group have floating IPs.</p></div></div><div class="sect3 " id="id-1.4.7.7.9.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable IP forwarding</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.9.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>IP forwarding is disabled by default on most Linux distributions. You
will need to enable it in order to use floating IPs.</p><div id="id-1.4.7.7.9.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>IP forwarding only needs to be enabled on the nodes that run
<code class="literal">nova-network</code>. However, you will need to enable it on all compute
nodes if you use <code class="literal">multi_host</code> mode.</p></div><p>To check if IP forwarding is enabled, run:</p><div class="verbatim-wrap"><pre class="screen">$ cat /proc/sys/net/ipv4/ip_forward
0</pre></div><p>Alternatively, run:</p><div class="verbatim-wrap"><pre class="screen">$ sysctl net.ipv4.ip_forward
net.ipv4.ip_forward = 0</pre></div><p>In these examples, IP forwarding is disabled.</p><p>To enable IP forwarding dynamically, run:</p><div class="verbatim-wrap"><pre class="screen"># sysctl -w net.ipv4.ip_forward=1</pre></div><p>Alternatively, run:</p><div class="verbatim-wrap"><pre class="screen"># echo 1 &gt; /proc/sys/net/ipv4/ip_forward</pre></div><p>To make the changes permanent, edit the <code class="literal">/etc/sysctl.conf</code> file and
update the IP forwarding setting:</p><div class="verbatim-wrap highlight ini"><pre class="screen">net.ipv4.ip_forward = 1</pre></div><p>Save the file and run this command to apply the changes:</p><div class="verbatim-wrap"><pre class="screen"># sysctl -p</pre></div><p>You can also apply the changes by restarting the network service:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>on Ubuntu, Debian:</p><div class="verbatim-wrap"><pre class="screen"># /etc/init.d/networking restart</pre></div></li><li class="listitem "><p>on RHEL, Fedora, CentOS, openSUSE and SLES:</p><div class="verbatim-wrap"><pre class="screen"># service network restart</pre></div></li></ul></div></div><div class="sect3 " id="id-1.4.7.7.9.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a list of available floating IP addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.9.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Compute maintains a list of floating IP addresses that are available for
assigning to instances. Use the <code class="command">nova-manage floating</code> commands
to perform floating IP operations:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Add entries to the list:</p><div class="verbatim-wrap"><pre class="screen"># nova-manage floating create --pool nova --ip_range 68.99.26.170/31</pre></div></li><li class="listitem "><p>List the floating IP addresses in the pool:</p><div class="verbatim-wrap"><pre class="screen"># openstack floating ip list</pre></div></li><li class="listitem "><p>Create specific floating IPs for either a single address or a
subnet:</p><div class="verbatim-wrap"><pre class="screen"># nova-manage floating create --pool POOL_NAME --ip_range CIDR</pre></div></li><li class="listitem "><p>Remove floating IP addresses using the same parameters as the create
command:</p><div class="verbatim-wrap"><pre class="screen"># openstack floating ip delete CIDR</pre></div></li></ul></div><p>For more information about how administrators can associate floating IPs
with instances, see <a class="link" href="http://docs.openstack.org/admin-guide/cli-admin-manage-ip-addresses.html" target="_blank">Manage IP
addresses</a>
in the OpenStack Administrator Guide.</p></div><div class="sect3 " id="id-1.4.7.7.9.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Automatically add floating IPs</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.9.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can configure <code class="literal">nova-network</code> to automatically allocate and assign a
floating IP address to virtual instances when they are launched. Add
this line to the <code class="literal">/etc/nova/nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">auto_assign_floating_ip=True</pre></div><p>Save the file, and restart <code class="literal">nova-network</code></p><div id="id-1.4.7.7.9.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If this option is enabled, but all floating IP addresses have
already been allocated, the <code class="command">openstack server create</code>
command will fail.</p></div></div></div><div class="sect2 " id="id-1.4.7.7.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Remove a network from a project</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You cannot delete a network that has been associated to a project. This
section describes the procedure for dissociating it so that it can be
deleted.</p><p>In order to disassociate the network, you will need the ID of the
project it has been associated to. To get the project ID, you will need
to be an administrator.</p><p>Disassociate the network from the project using the
<code class="command">nova-manage project scrub</code> command,
with the project ID as the final parameter:</p><div class="verbatim-wrap"><pre class="screen"># nova-manage project scrub --project ID</pre></div></div><div class="sect2 " id="id-1.4.7.7.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Multiple interfaces for instances (multinic)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The multinic feature allows you to use more than one interface with your
instances. This is useful in several scenarios:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>SSL Configurations (VIPs)</p></li><li class="listitem "><p>Services failover/HA</p></li><li class="listitem "><p>Bandwidth Allocation</p></li><li class="listitem "><p>Administrative/Public access to your instances</p></li></ul></div><p>Each VIP represents a separate network with its own IP block. Every
network mode has its own set of changes regarding multinic usage:</p><div class="figure" id="id-1.4.7.7.11.5"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-manager.jpg" target="_blank"><img src="images/SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-manager.jpg" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.4: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.7.11.5">#</a></h6></div></div><div class="figure" id="id-1.4.7.7.11.6"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-DHCP-manager.jpg" target="_blank"><img src="images/SCH_5007_V00_NUAC-multi_nic_OpenStack-Flat-DHCP-manager.jpg" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.5: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.7.11.6">#</a></h6></div></div><div class="figure" id="id-1.4.7.7.11.7"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/SCH_5007_V00_NUAC-multi_nic_OpenStack-VLAN-manager.jpg" target="_blank"><img src="images/SCH_5007_V00_NUAC-multi_nic_OpenStack-VLAN-manager.jpg" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.6: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.7.11.7">#</a></h6></div></div><div class="sect3 " id="id-1.4.7.7.11.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using multinic</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.11.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In order to use multinic, create two networks, and attach them to the
project (named <code class="literal">project</code> on the command line):</p><div class="verbatim-wrap"><pre class="screen">$ nova network-create first-net --fixed-range-v4 20.20.0.0/24 --project-id $your-project
$ nova network-create second-net --fixed-range-v4 20.20.10.0/24 --project-id $your-project</pre></div><p>Each new instance will now receive two IP addresses from their
respective DHCP servers:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server list
+---------+----------+--------+-----------------------------------------+------------+
|ID       | Name     | Status | Networks                                | Image Name |
+---------+----------+--------+-----------------------------------------+------------+
| 1234... | MyServer | ACTIVE | network2=20.20.0.3; private=20.20.10.14 | cirros     |
+---------+----------+--------+-----------------------------------------+------------+</pre></div><div id="id-1.4.7.7.11.8.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Make sure you start the second interface on the instance, or it
won't be reachable through the second IP.</p></div><p>This example demonstrates how to set up the interfaces within the
instance. This is the configuration that needs to be applied inside the
image.</p><p>Edit the <code class="literal">/etc/network/interfaces</code> file:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># The loopback network interface
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet dhcp

auto eth1
iface eth1 inet dhcp</pre></div><p>If the Virtual Network Service Neutron is installed, you can specify the
networks to attach to the interfaces by using the <code class="literal">--nic</code> flag with
the <code class="command">openstack server create</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server create --image ed8b2a37-5535-4a5f-a615-443513036d71 \
  --flavor 1 --nic net-id=NETWORK1_ID --nic net-id=NETWORK2_ID test-vm1</pre></div></div></div><div class="sect2 " id="id-1.4.7.7.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.7.12.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cannot reach floating IPs</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.12.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.2.3"><span class="name">Problem</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.2.3">#</a></h5></div><p>You cannot reach your instances through the floating IP address.</p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.2.5"><span class="name">Solution</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.2.5">#</a></h5></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Check that the default security group allows ICMP (ping) and SSH
(port 22), so that you can reach the instances:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule list default
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| ID                                   | IP Protocol | IP Range  | Port Range      | Remote Security Group |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| 63536865-e5b6-4df1-bac5-ca6d97d8f54d | tcp         | 0.0.0.0/0 | 22:22           | None                  |
| e9d3200f-647a-4293-a9fc-e65ceee189ae | icmp        | 0.0.0.0/0 | type=1:code=-1  | None                  |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+</pre></div></li><li class="listitem "><p>Check the NAT rules have been added to iptables on the node that is
running <code class="literal">nova-network</code>:</p><div class="verbatim-wrap"><pre class="screen"># iptables -L -nv -t nat
-A nova-network-PREROUTING -d 68.99.26.170/32 -j DNAT --to-destination 10.0.0.3
-A nova-network-floating-snat -s 10.0.0.3/32 -j SNAT --to-source 68.99.26.170</pre></div></li><li class="listitem "><p>Check that the public address (<code class="literal">68.99.26.170</code> in
this example), has been added to your public interface. You should
see the address in the listing when you use the <code class="command">ip addr</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ ip addr
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP qlen 1000
link/ether xx:xx:xx:17:4b:c2 brd ff:ff:ff:ff:ff:ff
inet 13.22.194.80/24 brd 13.22.194.255 scope global eth0
inet 68.99.26.170/32 scope global eth0
inet6 fe80::82b:2bf:fe1:4b2/64 scope link
valid_lft forever preferred_lft forever</pre></div><div id="id-1.4.7.7.12.2.6.3.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You cannot use <code class="literal">SSH</code> to access an instance with a public IP from within
the same server because the routing configuration does not allow
it.</p></div></li><li class="listitem "><p>Use <code class="literal">tcpdump</code> to identify if packets are being routed to the
inbound interface on the compute host. If the packets are reaching
the compute hosts but the connection is failing, the issue may be
that the packet is being dropped by reverse path filtering. Try
disabling reverse-path filtering on the inbound interface. For
example, if the inbound interface is <code class="literal">eth2</code>, run:</p><div class="verbatim-wrap"><pre class="screen"># sysctl -w net.ipv4.conf.ETH2.rp_filter=0</pre></div><p>If this solves the problem, add the following line to
<code class="literal">/etc/sysctl.conf</code> so that the reverse-path filter is persistent:</p><div class="verbatim-wrap highlight ini"><pre class="screen">net.ipv4.conf.rp_filter=0</pre></div></li></ul></div></div><div class="sect3 " id="id-1.4.7.7.12.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Temporarily disable firewall</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.12.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.3.3"><span class="name">Problem</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.3.3">#</a></h5></div><p>Networking issues prevent administrators accessing or reaching VM's
through various pathways.</p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.3.5"><span class="name">Solution</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.3.5">#</a></h5></div><p>You can disable the firewall by setting this option
in <code class="literal">/etc/nova/nova.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">firewall_driver=nova.virt.firewall.NoopFirewallDriver</pre></div></div><div class="sect3 " id="id-1.4.7.7.12.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Packet loss from instances to nova-network server (VLANManager mode)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.12.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.4.3"><span class="name">Problem</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.4.3">#</a></h5></div><p>If you can access your instances with <code class="literal">SSH</code> but the network to your instance
is slow, or if you find that running certain operations are slower than
they should be (for example, <code class="literal">sudo</code>), packet loss could be occurring
on the connection to the instance.</p><p>Packet loss can be caused by Linux networking configuration settings
related to bridges. Certain settings can cause packets to be dropped
between the VLAN interface (for example, <code class="literal">vlan100</code>) and the associated
bridge interface (for example, <code class="literal">br100</code>) on the host running
<code class="literal">nova-network</code>.</p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.4.6"><span class="name">Solution</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.4.6">#</a></h5></div><p>One way to check whether this is the problem is to open three terminals
and run the following commands:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>In the first terminal, on the host running <code class="literal">nova-network</code>, use
<code class="literal">tcpdump</code> on the VLAN interface to monitor DNS-related traffic
(UDP, port 53). As root, run:</p><div class="verbatim-wrap"><pre class="screen"># tcpdump -K -p -i vlan100 -v -vv udp port 53</pre></div></li><li class="step "><p>In the second terminal, also on the host running <code class="literal">nova-network</code>, use
<code class="literal">tcpdump</code> to monitor DNS-related traffic on the bridge interface.
As root, run:</p><div class="verbatim-wrap"><pre class="screen"># tcpdump -K -p -i br100 -v -vv udp port 53</pre></div></li><li class="step "><p>In the third terminal, use <code class="literal">SSH</code> to access the instance and generate DNS
requests by using the <code class="command">nslookup</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ nslookup www.google.com</pre></div><p>The symptoms may be intermittent, so try running <code class="command">nslookup</code>
multiple times. If the network configuration is correct, the command
should return immediately each time. If it is not correct, the
command hangs for several seconds before returning.</p></li><li class="step "><p>If the <code class="command">nslookup</code> command sometimes hangs, and there are packets
that appear in the first terminal but not the second, then the
problem may be due to filtering done on the bridges. Try disabling
filtering, and running these commands as root:</p><div class="verbatim-wrap"><pre class="screen"># sysctl -w net.bridge.bridge-nf-call-arptables=0
# sysctl -w net.bridge.bridge-nf-call-iptables=0
# sysctl -w net.bridge.bridge-nf-call-ip6tables=0</pre></div><p>If this solves your issue, add the following line to
<code class="literal">/etc/sysctl.conf</code> so that the changes are persistent:</p><div class="verbatim-wrap highlight ini"><pre class="screen">net.bridge.bridge-nf-call-arptables=0
net.bridge.bridge-nf-call-iptables=0
net.bridge.bridge-nf-call-ip6tables=0</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.7.7.12.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.3.9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">KVM: Network connectivity works initially, then fails</span> <a title="Permalink" class="permalink" href="#id-1.4.7.7.12.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.5.3"><span class="name">Problem</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.5.3">#</a></h5></div><p>With KVM hypervisors, instances running Ubuntu 12.04 sometimes lose
network connectivity after functioning properly for a period of time.</p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect4 bridgehead"><h5 class="title" id="id-1.4.7.7.12.5.5"><span class="name">Solution</span><a title="Permalink" class="permalink" href="#id-1.4.7.7.12.5.5">#</a></h5></div><p>Try loading the <code class="literal">vhost_net</code> kernel module as a workaround for this
issue (see <a class="link" href="https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/997978/" target="_blank">bug
#997978</a>)
. This kernel module may also <a class="link" href="http://www.linux-kvm.org/page/VhostNet" target="_blank">improve network
performance</a> on KVM. To load
the kernel module:</p><div class="verbatim-wrap"><pre class="screen"># modprobe vhost_net</pre></div><div id="id-1.4.7.7.12.5.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Loading the module has no effect on running instances.</p></div></div></div></div><div class="sect1 " id="id-1.4.7.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System administration</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To effectively administer compute, you must understand how the different
        installed nodes interact with each other. Compute can be installed in
        many different ways using multiple servers, but generally multiple
        compute nodes control the virtual servers and a cloud controller node
        contains the remaining Compute services.</p><p>The Compute cloud works using a series of daemon processes named <code class="literal">nova-*</code>
        that exist persistently on the host machine. These binaries can all run
        on the same machine or be spread out on multiple boxes in a large
        deployment. The responsibilities of services and drivers are:</p><p>
        <span class="bold"><strong>Services</strong></span>
      </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.8.5.1"><span class="term ">
            <code class="literal">nova-api</code>
          </span></dt><dd><p>receives XML requests and sends them to the rest of the
              system. A WSGI app routes and authenticates requests. Supports the
              EC2 and OpenStack APIs. A <code class="literal">nova.conf</code> configuration file is created
              when Compute is installed.</p></dd><dt id="id-1.4.7.8.5.2"><span class="term ">
            <code class="literal">nova-cert</code>
          </span></dt><dd><p>manages certificates.</p></dd><dt id="id-1.4.7.8.5.3"><span class="term ">
            <code class="literal">nova-compute</code>
          </span></dt><dd><p>manages virtual machines. Loads a Service object, and
              exposes the public methods on ComputeManager through a Remote
              Procedure Call (RPC).</p></dd><dt id="id-1.4.7.8.5.4"><span class="term ">
            <code class="literal">nova-conductor</code>
          </span></dt><dd><p>provides database-access support for compute nodes
              (thereby reducing security risks).</p></dd><dt id="id-1.4.7.8.5.5"><span class="term ">
            <code class="literal">nova-consoleauth</code>
          </span></dt><dd><p>manages console authentication.</p></dd><dt id="id-1.4.7.8.5.6"><span class="term ">
            <code class="literal">nova-objectstore</code>
          </span></dt><dd><p>a simple file-based storage system for images that
              replicates most of the S3 API. It can be replaced with OpenStack
              Image service and either a simple image manager or OpenStack Object
              Storage as the virtual machine image storage facility. It must exist
              on the same node as <code class="literal">nova-compute</code>.</p></dd><dt id="id-1.4.7.8.5.7"><span class="term ">
            <code class="literal">nova-network</code>
          </span></dt><dd><p>manages floating and fixed IPs, DHCP, bridging and
              VLANs. Loads a Service object which exposes the public methods on one
              of the subclasses of NetworkManager. Different networking strategies
              are available by changing the <code class="literal">network_manager</code> configuration
              option to <code class="literal">FlatManager</code>, <code class="literal">FlatDHCPManager</code>, or <code class="literal">VLANManager</code>
              (defaults to <code class="literal">VLANManager</code> if nothing is specified).</p></dd><dt id="id-1.4.7.8.5.8"><span class="term ">
            <code class="literal">nova-scheduler</code>
          </span></dt><dd><p>dispatches requests for new virtual machines to the
              correct node.</p></dd><dt id="id-1.4.7.8.5.9"><span class="term ">
            <code class="literal">nova-novncproxy</code>
          </span></dt><dd><p>provides a VNC proxy for browsers, allowing VNC
              consoles to access virtual machines.</p></dd></dl></div><div id="id-1.4.7.8.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Some services have drivers that change how the service implements
          its core functionality. For example, the <code class="literal">nova-compute</code> service
          supports drivers that let you choose which hypervisor type it can
          use. <code class="literal">nova-network</code> and <code class="literal">nova-scheduler</code> also have drivers.</p></div><div class="sect2 " id="id-1.4.7.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage Compute users</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Access to the Euca2ools (ec2) API is controlled by an access key and a
secret key. The user's access key needs to be included in the request,
and the request must be signed with the secret key. Upon receipt of API
requests, Compute verifies the signature and runs commands on behalf of
the user.</p><p>To begin using Compute, you must create a user with the Identity
service.</p></div><div class="sect2 " id="id-1.4.7.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage volumes</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Depending on the setup of your cloud provider, they may give you an
endpoint to use to manage volumes, or there may be an extension under
the covers. In either case, you can use the <code class="literal">openstack</code> CLI to manage
volumes.</p><div class="table" id="id-1.4.7.8.8.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.3: </span><span class="name">openstack volume commands </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.8.3">#</a></h6></div><div class="table-contents"><table class="table" summary="openstack volume commands" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Command</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>server add volume</p>
                </td><td>
                  <p>Attach a volume to a server.</p>
                </td></tr><tr><td>
                  <p>volume create</p>
                </td><td>
                  <p>Add a new volume.</p>
                </td></tr><tr><td>
                  <p>volume delete</p>
                </td><td>
                  <p>Remove or delete a volume.</p>
                </td></tr><tr><td>
                  <p>server remove volume</p>
                </td><td>
                  <p>Detach or remove a volume from a server.</p>
                </td></tr><tr><td>
                  <p>volume list</p>
                </td><td>
                  <p>List all the volumes.</p>
                </td></tr><tr><td>
                  <p>volume show</p>
                </td><td>
                  <p>Show details about a volume.</p>
                </td></tr><tr><td>
                  <p>snapshot create</p>
                </td><td>
                  <p>Add a new snapshot.</p>
                </td></tr><tr><td>
                  <p>snapshot delete</p>
                </td><td>
                  <p>Remove a snapshot.</p>
                </td></tr><tr><td>
                  <p>snapshot list</p>
                </td><td>
                  <p>List all the snapshots.</p>
                </td></tr><tr><td>
                  <p>snapshot show</p>
                </td><td>
                  <p>Show details about a snapshot.</p>
                </td></tr><tr><td>
                  <p>volume type create</p>
                </td><td>
                  <p>Create a new volume type.</p>
                </td></tr><tr><td>
                  <p>volume type delete</p>
                </td><td>
                  <p>Delete a specific flavor</p>
                </td></tr><tr><td>
                  <p>volume type list</p>
                </td><td>
                  <p>Print a list of available 'volume types'.</p>
                </td></tr></tbody></table></div></div><p>For example, to list IDs and names of volumes, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+--------+--------------+-----------+------+-------------+
| ID     | Display Name | Status    | Size | Attached to |
+--------+--------------+-----------+------+-------------+
| 86e6cb | testnfs      | available |    1 |             |
| e389f7 | demo         | available |    1 |             |
+--------+--------------+-----------+------+-------------+</pre></div></div><div class="sect2 " id="compute-flavors"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Flavors</span> <a title="Permalink" class="permalink" href="#compute-flavors">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>compute-flavors</li></ul></div></div></div></div><p>Admin users can use the <code class="command">openstack flavor</code> command to customize and
manage flavors. To see information for this command, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor --help
Command "flavor" matches:
  flavor create
  flavor delete
  flavor list
  flavor set
  flavor show
  flavor unset</pre></div><div id="id-1.4.7.8.9.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Configuration rights can be delegated to additional users by
redefining the access controls for
<code class="literal">compute_extension:flavormanage</code> in <code class="literal">/etc/nova/policy.json</code>
on the <code class="literal">nova-api</code> server.</p></li><li class="listitem "><p>The Dashboard simulates the ability to modify a flavor
by deleting an existing flavor and creating a new one with the same name.</p></li></ul></div></div><p>Flavors define these elements:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Element</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Name</p>
                </td><td>
                  <p>A descriptive name. XX.SIZE_NAME is typically not required,
though some third party tools may rely on it.</p>
                </td></tr><tr><td>
                  <p>Memory MB</p>
                </td><td>
                  <p>Instance memory in megabytes.</p>
                </td></tr><tr><td>
                  <p>Disk</p>
                </td><td>
                  <p>Virtual root disk size in gigabytes. This is an ephemeral disk that the base image is copied into. When booting from a persistent volume it is not used. The "0" size is a special case which uses the native base image size as the size of the
ephemeral root volume.</p>
                </td></tr><tr><td>
                  <p>Ephemeral</p>
                </td><td>
                  <p>Specifies the size of a secondary ephemeral data disk. This
is an empty, unformatted disk and exists only for the life of the instance. Default value is <code class="literal">0</code>.</p>
                </td></tr><tr><td>
                  <p>Swap</p>
                </td><td>
                  <p>Optional swap space allocation for the instance. Default
value is <code class="literal">0</code>.</p>
                </td></tr><tr><td>
                  <p>VCPUs</p>
                </td><td>
                  <p>Number of virtual CPUs presented to the instance.</p>
                </td></tr><tr><td>
                  <p>RXTX Factor</p>
                </td><td>
                  <p>Optional property allows created servers to have a different
bandwidth cap than that defined in the network they are attached to. This factor is multiplied by the rxtx_base property of the network. Default value is <code class="literal">1.0</code>. That is, the same
as attached network. This parameter is only available for Xen
or NSX based systems.</p>
                </td></tr><tr><td>
                  <p>Is Public</p>
                </td><td>
                  <p>Boolean value, whether flavor is available to all users or private to the project it was created in. Defaults to <code class="literal">True</code>.</p>
                </td></tr><tr><td>
                  <p>Extra Specs</p>
                </td><td>
                  <p>Key and value pairs that define on which compute nodes a flavor can run. These pairs must match corresponding pairs on the compute nodes. Use to implement special resources, such as flavors that run on only compute nodes with GPU hardware.</p>
                </td></tr></tbody></table></div><div id="id-1.4.7.8.9.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Flavor customization can be limited by the hypervisor in use. For
example the libvirt driver enables quotas on CPUs available to a VM,
disk tuning, bandwidth I/O, watchdog behavior, random number generator
device control, and instance VIF traffic control.</p></div><div class="sect3 " id="id-1.4.7.8.9.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Is Public</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.9.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Flavors can be assigned to particular projects. By default, a flavor is public
and available to all projects. Private flavors are only accessible to those on
the access list and are invisible to other projects. To create and assign a
private flavor to a project, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor create --private p1.medium --id auto --ram 512 --disk 40 --vcpus 4</pre></div></div><div class="sect3 " id="id-1.4.7.8.9.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Extra Specs</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.9.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.8.9.9.2.1"><span class="term ">CPU limits</span></dt><dd><p>You can configure the CPU limits with control parameters with the
<code class="literal">nova</code> client. For example, to configure the I/O limit, use:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property quota:read_bytes_sec=10240000 \
    --property quota:write_bytes_sec=10240000</pre></div><p>Use these optional parameters to control weight shares, enforcement
intervals for runtime quotas, and a quota for maximum allowed
bandwidth:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">cpu_shares</code>: Specifies the proportional weighted share for the
domain. If this element is omitted, the service defaults to the
OS provided defaults. There is no unit for the value; it is a
relative measure based on the setting of other VMs. For example,
a VM configured with value 2048 gets twice as much CPU time as a
VM configured with value 1024.</p></li><li class="listitem "><p><code class="literal">cpu_shares_level</code>: On VMware, specifies the allocation level. Can
be <code class="literal">custom</code>, <code class="literal">high</code>, <code class="literal">normal</code>, or <code class="literal">low</code>. If you choose
<code class="literal">custom</code>, set the number of shares using <code class="literal">cpu_shares_share</code>.</p></li><li class="listitem "><p><code class="literal">cpu_period</code>: Specifies the enforcement interval (unit:
microseconds) for QEMU and LXC hypervisors. Within a period, each
VCPU of the domain is not allowed to consume more than the quota
worth of runtime. The value should be in range <code class="literal">[1000, 1000000]</code>.
A period with value 0 means no value.</p></li><li class="listitem "><p><code class="literal">cpu_limit</code>: Specifies the upper limit for VMware machine CPU
allocation in MHz. This parameter ensures that a machine never
uses more than the defined amount of CPU time. It can be used to
enforce a limit on the machine's CPU performance.</p></li><li class="listitem "><p><code class="literal">cpu_reservation</code>: Specifies the guaranteed minimum CPU
reservation in MHz for VMware. This means that if needed, the
machine will definitely get allocated the reserved amount of CPU
cycles.</p></li><li class="listitem "><p><code class="literal">cpu_quota</code>: Specifies the maximum allowed bandwidth (unit:
microseconds). A domain with a negative-value quota indicates
that the domain has infinite bandwidth, which means that it is
not bandwidth controlled. The value should be in range <code class="literal">[1000,
18446744073709551]</code> or less than 0. A quota with value 0 means no
value. You can use this feature to ensure that all vCPUs run at the
same speed. For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property quota:cpu_quota=10000 \
    --property quota:cpu_period=20000</pre></div><p>In this example, an instance of <code class="literal">FLAVOR-NAME</code> can only consume
a maximum of 50% CPU of a physical CPU computing capability.</p></li></ul></div></dd><dt id="id-1.4.7.8.9.9.2.2"><span class="term ">Memory limits</span></dt><dd><p>For VMware, you can configure the memory limits with control parameters.</p><p>Use these optional parameters to limit the memory allocation,
guarantee minimum memory reservation, and to specify shares
used in case of resource contention:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">memory_limit</code>: Specifies the upper limit for VMware machine
memory allocation in MB. The utilization of a virtual machine will
not exceed this limit, even if there are available resources. This
is typically used to ensure a consistent performance of
virtual machines independent of available resources.</p></li><li class="listitem "><p><code class="literal">memory_reservation</code>: Specifies the guaranteed minimum memory
reservation in MB for VMware. This means the specified amount of
memory will definitely be allocated to the machine.</p></li><li class="listitem "><p><code class="literal">memory_shares_level</code>: On VMware, specifies the allocation level.
This can be <code class="literal">custom</code>, <code class="literal">high</code>, <code class="literal">normal</code> or <code class="literal">low</code>. If you choose
<code class="literal">custom</code>, set the number of shares using <code class="literal">memory_shares_share</code>.</p></li><li class="listitem "><p><code class="literal">memory_shares_share</code>: Specifies the number of shares allocated
in the event that <code class="literal">custom</code> is used. There is no unit for this
value. It is a relative measure based on the settings for other VMs.
For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property quota:memory_shares_level=custom \
    --property quota:memory_shares_share=15</pre></div></li></ul></div></dd><dt id="id-1.4.7.8.9.9.2.3"><span class="term ">Disk I/O limits</span></dt><dd><p>For VMware, you can configure the resource limits for disk
with control parameters.</p><p>Use these optional parameters to limit the disk utilization,
guarantee disk allocation, and to specify shares
used in case of resource contention. This allows the VMware
driver to enable disk allocations for the running instance.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">disk_io_limit</code>: Specifies the upper limit for disk
utilization in I/O per second. The utilization of a
virtual machine will not exceed this limit, even
if there are available resources. The default value
is -1 which indicates unlimited usage.</p></li><li class="listitem "><p><code class="literal">disk_io_reservation</code>: Specifies the guaranteed minimum disk
allocation in terms of <a class="xref" href="#term-input-output-operations-per-second-iops" title="Input/Output Operations Per Second (IOPS)">Input/Output Operations Per Second (IOPS)</a>.</p></li><li class="listitem "><p><code class="literal">disk_io_shares_level</code>: Specifies the allocation
level. This can be <code class="literal">custom</code>, <code class="literal">high</code>, <code class="literal">normal</code> or <code class="literal">low</code>.
If you choose custom, set the number of shares
using <code class="literal">disk_io_shares_share</code>.</p></li><li class="listitem "><p><code class="literal">disk_io_shares_share</code>: Specifies the number of shares
allocated in the event that <code class="literal">custom</code> is used.
When there is resource contention, this value is used
to determine the resource allocation.</p><p>The example below sets the <code class="literal">disk_io_reservation</code> to 2000 IOPS.</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property quota:disk_io_reservation=2000</pre></div></li></ul></div></dd><dt id="id-1.4.7.8.9.9.2.4"><span class="term ">Disk tuning</span></dt><dd><p>Using disk I/O quotas, you can set maximum disk write to 10 MB per
second for a VM user. For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property quota:disk_write_bytes_sec=10485760</pre></div><p>The disk I/O options are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                      <code class="literal">disk_read_bytes_sec</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">disk_read_iops_sec</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">disk_write_bytes_sec</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">disk_write_iops_sec</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">disk_total_bytes_sec</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">disk_total_iops_sec</code>
                    </p></li></ul></div></dd><dt id="id-1.4.7.8.9.9.2.5"><span class="term ">Bandwidth I/O</span></dt><dd><p>The vif I/O options are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                      <code class="literal">vif_inbound_average</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">vif_inbound_burst</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">vif_inbound_peak</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">vif_outbound_average</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">vif_outbound_burst</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">vif_outbound_peak</code>
                    </p></li></ul></div><p>Incoming and outgoing traffic can be shaped independently. The
bandwidth element can have at most, one inbound and at most, one
outbound child element. If you leave any of these child elements
out, no <a class="xref" href="#term-quality-of-service-qos" title="Quality of Service (QoS)">Quality of Service (QoS)</a> is applied on that traffic
direction. So, if you want to shape only the network's incoming
traffic, use inbound only (and vice versa). Each element has one
mandatory attribute average, which specifies the average bit rate on
the interface being shaped.</p><p>There are also two optional attributes (integer): <code class="literal">peak</code>, which
specifies the maximum rate at which a bridge can send data
(kilobytes/second), and <code class="literal">burst</code>, the amount of bytes that can be
burst at peak speed (kilobytes). The rate is shared equally within
domains connected to the network.</p><p>The example below sets network traffic bandwidth limits for existing
flavor as follows:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Outbound traffic:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>average: 262 Mbps (32768 kilobytes/second)</p></li><li class="listitem "><p>peak: 524 Mbps (65536 kilobytes/second)</p></li><li class="listitem "><p>burst: 65536 kilobytes</p></li></ul></div></li><li class="listitem "><p>Inbound traffic:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>average: 262 Mbps (32768 kilobytes/second)</p></li><li class="listitem "><p>peak: 524 Mbps (65536 kilobytes/second)</p></li><li class="listitem "><p>burst: 65536 kilobytes</p></li></ul></div></li></ul></div><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property quota:vif_outbound_average=32768 \
    --property quota:vif_outbound_peak=65536 \
    --property quota:vif_outbound_burst=65536 \
    --property quota:vif_inbound_average=32768 \
    --property quota:vif_inbound_peak=65536 \
    --property quota:vif_inbound_burst=65536</pre></div><div id="id-1.4.7.8.9.9.2.5.2.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>All the speed limit values in above example are specified in
kilobytes/second. And burst values are in kilobytes. Values
were converted using 'Data rate units on
Wikipedia &lt;<a class="link" href="https://en.wikipedia.org/wiki/Data_rate_units" target="_blank">https://en.wikipedia.org/wiki/Data_rate_units</a>&gt;`_.</p></div></dd><dt id="id-1.4.7.8.9.9.2.6"><span class="term ">Watchdog behavior</span></dt><dd><p>For the libvirt driver, you can enable and set the behavior of a
virtual hardware watchdog device for each flavor. Watchdog devices
keep an eye on the guest server, and carry out the configured
action, if the server hangs. The watchdog uses the i6300esb device
(emulating a PCI Intel 6300ESB). If <code class="literal">hw:watchdog_action</code> is not
specified, the watchdog is disabled.</p><p>To set the behavior, use:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME --property hw:watchdog_action=ACTION</pre></div><p>Valid ACTION values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">disabled</code>: (default) The device is not attached.</p></li><li class="listitem "><p><code class="literal">reset</code>: Forcefully reset the guest.</p></li><li class="listitem "><p><code class="literal">poweroff</code>: Forcefully power off the guest.</p></li><li class="listitem "><p><code class="literal">pause</code>: Pause the guest.</p></li><li class="listitem "><p><code class="literal">none</code>: Only enable the watchdog; do nothing if the server hangs.</p></li></ul></div><div id="id-1.4.7.8.9.9.2.6.2.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Watchdog behavior set using a specific image's properties will
override behavior set using flavors.</p></div></dd><dt id="id-1.4.7.8.9.9.2.7"><span class="term ">Random-number generator</span></dt><dd><p>If a random-number generator device has been added to the instance
through its image properties, the device can be enabled and
configured using:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property hw_rng:allowed=True \
    --property hw_rng:rate_bytes=RATE-BYTES \
    --property hw_rng:rate_period=RATE-PERIOD</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>RATE-BYTES: (integer) Allowed amount of bytes that the guest can
read from the host's entropy per period.</p></li><li class="listitem "><p>RATE-PERIOD: (integer) Duration of the read period in seconds.</p></li></ul></div></dd><dt id="id-1.4.7.8.9.9.2.8"><span class="term ">CPU topology</span></dt><dd><p>For the libvirt driver, you can define the topology of the processors
in the virtual machine using properties. The properties with <code class="literal">max</code>
limit the number that can be selected by the user with image properties.</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property hw:cpu_sockets=FLAVOR-SOCKETS \
    --property hw:cpu_cores=FLAVOR-CORES \
    --property hw:cpu_threads=FLAVOR-THREADS \
    --property hw:cpu_max_sockets=FLAVOR-SOCKETS \
    --property hw:cpu_max_cores=FLAVOR-CORES \
    --property hw:cpu_max_threads=FLAVOR-THREADS</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>FLAVOR-SOCKETS: (integer) The number of sockets for the guest VM. By
default, this is set to the number of vCPUs requested.</p></li><li class="listitem "><p>FLAVOR-CORES: (integer) The number of cores per socket for the guest
VM. By default, this is set to <code class="literal">1</code>.</p></li><li class="listitem "><p>FLAVOR-THREADS: (integer) The number of threads per core for the guest
VM. By default, this is set to <code class="literal">1</code>.</p></li></ul></div></dd><dt id="id-1.4.7.8.9.9.2.9"><span class="term ">CPU pinning policy</span></dt><dd><p>For the libvirt driver, you can pin the virtual CPUs (vCPUs) of instances
to the host's physical CPU cores (pCPUs) using properties. You can further
refine this by stating how hardware CPU threads in a simultaneous
multithreading-based (SMT) architecture be used. These configurations will
result in improved per-instance determinism and performance.</p><div id="id-1.4.7.8.9.9.2.9.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>SMT-based architectures include Intel processors with Hyper-Threading
technology. In these architectures, processor cores share a number of
components with one or more other cores. Cores in such architectures
are commonly referred to as hardware threads, while the cores that a
given core share components with are known as thread siblings.</p></div><div id="id-1.4.7.8.9.9.2.9.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Host aggregates should be used to separate these pinned instances
from unpinned instances as the latter will not respect the resourcing
requirements of the former.</p></div><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property hw:cpu_policy=CPU-POLICY \
    --property hw:cpu_thread_policy=CPU-THREAD-POLICY</pre></div><p>Valid CPU-POLICY values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">shared</code>: (default) The guest vCPUs will be allowed to freely float
across host pCPUs, albeit potentially constrained by NUMA policy.</p></li><li class="listitem "><p><code class="literal">dedicated</code>: The guest vCPUs will be strictly pinned to a set of host
pCPUs. In the absence of an explicit vCPU topology request, the drivers
typically expose all vCPUs as sockets with one core and one thread.
When strict CPU pinning is in effect the guest CPU topology will be
setup to match the topology of the CPUs to which it is pinned. This
option implies an overcommit ratio of 1.0. For example, if a two vCPU
guest is pinned to a single host core with two threads, then the guest
will get a topology of one socket, one core, two threads.</p></li></ul></div><p>Valid CPU-THREAD-POLICY values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">prefer</code>: (default) The host may or may not have an SMT architecture.
Where an SMT architecture is present, thread siblings are preferred.</p></li><li class="listitem "><p><code class="literal">isolate</code>: The host must not have an SMT architecture or must emulate
a non-SMT architecture. If the host does not have an SMT architecture,
each vCPU is placed on a different core as expected. If the host does
have an SMT architecture - that is, one or more cores have thread
siblings - then each vCPU is placed on a different physical core. No
vCPUs from other guests are placed on the same core. All but one thread
sibling on each utilized core is therefore guaranteed to be unusable.</p></li><li class="listitem "><p><code class="literal">require</code>: The host must have an SMT architecture. Each vCPU is
allocated on thread siblings. If the host does not have an SMT
architecture, then it is not used. If the host has an SMT architecture,
but not enough cores with free thread siblings are available, then
scheduling fails.</p></li></ul></div><div id="id-1.4.7.8.9.9.2.9.2.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">hw:cpu_thread_policy</code> option is only valid if <code class="literal">hw:cpu_policy</code>
is set to <code class="literal">dedicated</code>.</p></div></dd><dt id="id-1.4.7.8.9.9.2.10"><span class="term ">NUMA topology</span></dt><dd><p>For the libvirt driver, you can define the host NUMA placement for the
instance vCPU threads as well as the allocation of instance vCPUs and
memory from the host NUMA nodes. For flavors whose memory and vCPU
allocations are larger than the size of NUMA nodes in the compute hosts,
the definition of a NUMA topology allows hosts to better utilize NUMA
and improve performance of the instance OS.</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property hw:numa_nodes=FLAVOR-NODES \
    --property hw:numa_cpus.N=FLAVOR-CORES \
    --property hw:numa_mem.N=FLAVOR-MEMORY</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>FLAVOR-NODES: (integer) The number of host NUMA nodes to restrict
execution of instance vCPU threads to. If not specified, the vCPU
threads can run on any number of the host NUMA nodes available.</p></li><li class="listitem "><p>N: (integer) The instance NUMA node to apply a given CPU or memory
configuration to, where N is in the range <code class="literal">0</code> to <code class="literal">FLAVOR-NODES</code>
- <code class="literal">1</code>.</p></li><li class="listitem "><p>FLAVOR-CORES: (comma-separated list of integers) A list of instance
vCPUs to map to instance NUMA node N. If not specified, vCPUs are evenly
divided among available NUMA nodes.</p></li><li class="listitem "><p>FLAVOR-MEMORY: (integer) The number of MB of instance memory to map to
instance NUMA node N. If not specified, memory is evenly divided
among available NUMA nodes.</p></li></ul></div><div id="id-1.4.7.8.9.9.2.10.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">hw:numa_cpus.N</code> and <code class="literal">hw:numa_mem.N</code> are only valid if
<code class="literal">hw:numa_nodes</code> is set. Additionally, they are only required if the
instance's NUMA nodes have an asymmetrical allocation of CPUs and RAM
(important for some NFV workloads).</p></div><div id="id-1.4.7.8.9.9.2.10.2.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">N</code> parameter is an index of <span class="emphasis"><em>guest</em></span> NUMA nodes and may not
correspond to <span class="emphasis"><em>host</em></span> NUMA nodes. For example, on a platform with two
NUMA nodes, the scheduler may opt to place guest NUMA node 0, as
referenced in <code class="literal">hw:numa_mem.0</code> on host NUMA node 1 and vice versa.
Similarly, the integers used for <code class="literal">FLAVOR-CORES</code> are indexes of
<span class="emphasis"><em>guest</em></span> vCPUs and may not correspond to <span class="emphasis"><em>host</em></span> CPUs. As such, this
feature cannot be used to constrain instances to specific host CPUs or
NUMA nodes.</p></div><div id="id-1.4.7.8.9.9.2.10.2.7" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>If the combined values of <code class="literal">hw:numa_cpus.N</code> or <code class="literal">hw:numa_mem.N</code>
are greater than the available number of CPUs or memory respectively,
an exception is raised.</p></div></dd><dt id="id-1.4.7.8.9.9.2.11"><span class="term ">Large pages allocation</span></dt><dd><p>You can configure the size of large pages used to back the VMs.</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property hw:mem_page_size=PAGE_SIZE</pre></div><p>Valid <code class="literal">PAGE_SIZE</code> values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">small</code>: (default) The smallest page size is used.
Example: 4 KB on x86.</p></li><li class="listitem "><p><code class="literal">large</code>: Only use larger page sizes for guest RAM.
Example: either 2 MB or 1 GB on x86.</p></li><li class="listitem "><p><code class="literal">any</code>: It is left up to the compute driver to decide. In this case,
the libvirt driver might try to find large pages, but fall back to small
pages. Other drivers may choose alternate policies for <code class="literal">any</code>.</p></li><li class="listitem "><p>pagesize: (string) An explicit page size can be set if the workload has
specific requirements. This value can be an integer value for the page
size in KB, or can use any standard suffix.
Example: <code class="literal">4KB</code>, <code class="literal">2MB</code>, <code class="literal">2048</code>, <code class="literal">1GB</code>.</p></li></ul></div><div id="id-1.4.7.8.9.9.2.11.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Large pages can be enabled for guest RAM without any regard to whether
the guest OS will use them or not. If the guest OS chooses not to
use huge pages, it will merely see small pages as before. Conversely,
if a guest OS does intend to use huge pages, it is very important that
the guest RAM be backed by huge pages. Otherwise, the guest OS will not
be getting the performance benefit it is expecting.</p></div></dd><dt id="id-1.4.7.8.9.9.2.12"><span class="term ">PCI passthrough</span></dt><dd><p>You can assign PCI devices to a guest by specifying them in the flavor.</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set FLAVOR-NAME \
    --property pci_passthrough:alias=ALIAS:COUNT</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>ALIAS: (string) The alias which correspond to a particular PCI device
class as configured in the nova configuration file (see <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/config-options.html" target="_blank">nova.conf
configuration options</a>).</p></li><li class="listitem "><p>COUNT: (integer) The amount of PCI devices of type ALIAS to be assigned
to a guest.</p></li></ul></div></dd></dl></div></div></div><div class="sect2 " id="id-1.4.7.8.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute service node firewall requirements</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Console connections for virtual machines, whether direct or through a
proxy, are received on ports <code class="literal">5900</code> to <code class="literal">5999</code>. The firewall on each
Compute service node must allow network traffic on these ports.</p><p>This procedure modifies the iptables firewall to allow incoming
connections to the Compute services.</p><p>
          <span class="bold"><strong>Configuring the service-node firewall</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the server that hosts the Compute service, as root.</p></li><li class="step "><p>Edit the <code class="literal">/etc/sysconfig/iptables</code> file, to add an INPUT rule that
allows TCP traffic on ports from <code class="literal">5900</code> to <code class="literal">5999</code>. Make sure the new
rule appears before any INPUT rules that REJECT traffic:</p><div class="verbatim-wrap"><pre class="screen">-A INPUT -p tcp -m multiport --dports 5900:5999 -j ACCEPT</pre></div></li><li class="step "><p>Save the changes to the <code class="literal">/etc/sysconfig/iptables</code> file, and restart the
<code class="literal">iptables</code> service to pick up the changes:</p><div class="verbatim-wrap"><pre class="screen">$ service iptables restart</pre></div></li><li class="step "><p>Repeat this process for each Compute service node.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.7.8.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Injecting the administrator password</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Compute can generate a random administrator (root) password and inject
that password into an instance. If this feature is enabled, users can
run <code class="command">ssh</code> to an instance without an <code class="command">ssh</code> keypair.
The random password appears in the output of the
<code class="command">openstack server create</code> command.
You can also view and set the admin password from the dashboard.</p><p>
          <span class="bold"><strong>Password injection using the dashboard</strong></span>
        </p><p>By default, the dashboard will display the <code class="literal">admin</code> password and allow
the user to modify it.</p><p>If you do not want to support password injection, disable the password
fields by editing the dashboard's <code class="literal">local_settings.py</code> file.</p><div class="verbatim-wrap"><pre class="screen">OPENSTACK_HYPERVISOR_FEATURES = {
...
    'can_set_password': False,
}</pre></div><p>
          <span class="bold"><strong>Password injection on libvirt-based hypervisors</strong></span>
        </p><p>For hypervisors that use the libvirt back end (such as KVM, QEMU, and
LXC), admin password injection is disabled by default. To enable it, set
this option in <code class="literal">/etc/nova/nova.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[libvirt]
inject_password=true</pre></div><p>When enabled, Compute will modify the password of the admin account by
editing the <code class="literal">/etc/shadow</code> file inside the virtual machine instance.</p><div id="id-1.4.7.8.11.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Users can only use <code class="command">ssh</code> to access the instance by using the admin
password if the virtual machine image is a Linux distribution, and it has
been configured to allow users to use <code class="command">ssh</code> as the root user. This
is not the case for <a class="link" href="http://uec-images.ubuntu.com" target="_blank">Ubuntu cloud images</a>
which, by default, does not allow users to use <code class="command">ssh</code> to access the
root account.</p></div><p>
          <span class="bold"><strong>Password injection and XenAPI (XenServer/XCP)</strong></span>
        </p><p>When using the XenAPI hypervisor back end, Compute uses the XenAPI agent
to inject passwords into guests. The virtual machine image must be
configured with the agent for password injection to work.</p><p>
          <span class="bold"><strong>Password injection and Windows images (all hypervisors)</strong></span>
        </p><p>For Windows virtual machines, configure the Windows image to retrieve
the admin password on boot by installing an agent such as
<a class="link" href="https://cloudbase.it/cloudbase-init" target="_blank">cloudbase-init</a>.</p></div><div class="sect2 " id="id-1.4.7.8.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage the cloud</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>System administrators can use the <code class="command">openstack</code> and
          <code class="command">euca2ools</code> commands to manage their clouds.</p><p>The <code class="literal">openstack</code> client and <code class="literal">euca2ools</code> can be used by all users, though
          specific commands might be restricted by the Identity service.</p><p>
          <span class="bold"><strong>Managing the cloud with the openstack client</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The <code class="literal">python-openstackclient</code> package provides an <code class="literal">openstack</code> shell that
              enables Compute API interactions from the command line. Install the client,
              and provide your user name and password (which can be set as environment
              variables for convenience), for the ability to administer the cloud from
              the command line.</p><p>To install python-openstackclient, follow the instructions in the
              <a class="link" href="http://docs.openstack.org/user-guide/common/cli-install-openstack-command-line-clients.html" target="_blank">OpenStack User Guide</a>.</p></li><li class="step "><p>Confirm the installation was successful:</p><div class="verbatim-wrap"><pre class="screen">$ openstack help
              usage: openstack [--version] [-v | -q] [--log-file LOG_FILE] [-h] [--debug]
              [--os-cloud &lt;cloud-config-name&gt;]
              [--os-region-name &lt;auth-region-name&gt;]
              [--os-cacert &lt;ca-bundle-file&gt;] [--verify | --insecure]
              [--os-default-domain &lt;auth-domain&gt;]
              ...</pre></div><p>Running <code class="command">openstack help</code> returns a list of <code class="literal">openstack</code> commands
              and parameters. To get help for a subcommand, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack help SUBCOMMAND</pre></div><p>For a complete list of <code class="literal">openstack</code> commands and parameters, see the
              <a class="link" href="http://docs.openstack.org/cli-reference/openstack.html" target="_blank">OpenStack Command-Line Reference</a>.</p></li><li class="step "><p>Set the required parameters as environment variables to make running
              commands easier. For example, you can add <code class="literal">--os-username</code> as an
              <code class="literal">openstack</code> option, or set it as an environment variable. To set the user
              name, password, and project as environment variables, use:</p><div class="verbatim-wrap"><pre class="screen">$ export OS_USERNAME=joecool
              $ export OS_PASSWORD=coolword
              $ export OS_TENANT_NAME=coolu</pre></div></li><li class="step "><p>The Identity service gives you an authentication endpoint,
              which Compute recognizes as <code class="literal">OS_AUTH_URL</code>:</p><div class="verbatim-wrap"><pre class="screen">$ export OS_AUTH_URL=http://hostname:5000/v2.0</pre></div></li></ol></div></div><div class="sect3 " id="id-1.4.7.8.12.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing the cloud with euca2ools</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.12.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">euca2ools</code> command-line tool provides a command line interface to
EC2 API calls. For more information, see the <a class="link" href="https://docs.eucalyptus.com/eucalyptus/" target="_blank">Official Eucalyptus Documentation</a>.</p></div><div class="sect3 " id="id-1.4.7.8.12.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Show usage statistics for hosts and instances</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.12.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can show basic statistics on resource usage for hosts and instances.</p><div id="id-1.4.7.8.12.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more sophisticated monitoring, see the
<a class="link" href="https://launchpad.net/ceilometer" target="_blank">ceilometer</a> project. You can
also use tools, such as <a class="link" href="http://ganglia.info/" target="_blank">Ganglia</a> or
<a class="link" href="http://graphite.wikidot.com/" target="_blank">Graphite</a>, to gather more detailed
data.</p></div><div class="sect4 " id="id-1.4.7.8.12.7.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.6.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Show host usage statistics</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.12.7.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following examples show the host usage statistics for a host called
<code class="literal">devstack</code>.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>List the hosts and the nova-related services that run on them:</p><div class="verbatim-wrap"><pre class="screen">$ openstack host list
+-----------+-------------+----------+
| Host Name | Service     | Zone     |
+-----------+-------------+----------+
| devstack  | conductor   | internal |
| devstack  | compute     | nova     |
| devstack  | cert        | internal |
| devstack  | network     | internal |
| devstack  | scheduler   | internal |
| devstack  | consoleauth | internal |
+-----------+-------------+----------+</pre></div></li><li class="listitem "><p>Get a summary of resource usage of all of the instances running on
the host:</p><div class="verbatim-wrap"><pre class="screen">$ openstack host show devstack
+----------+----------------------------------+-----+-----------+---------+
| Host     | Project                          | CPU | MEMORY MB | DISK GB |
+----------+----------------------------------+-----+-----------+---------+
| devstack | (total)                          | 2   | 4003      | 157     |
| devstack | (used_now)                       | 3   | 5120      | 40      |
| devstack | (used_max)                       | 3   | 4608      | 40      |
| devstack | b70d90d65e464582b6b2161cf3603ced | 1   | 512       | 0       |
| devstack | 66265572db174a7aa66eba661f58eb9e | 2   | 4096      | 40      |
+----------+----------------------------------+-----+-----------+---------+</pre></div><p>The <code class="literal">CPU</code> column shows the sum of the virtual CPUs for instances
running on the host.</p><p>The <code class="literal">MEMORY MB</code> column shows the sum of the memory (in MB)
allocated to the instances that run on the host.</p><p>The <code class="literal">DISK GB</code> column shows the sum of the root and ephemeral disk
sizes (in GB) of the instances that run on the host.</p><p>The row that has the value <code class="literal">used_now</code> in the <code class="literal">PROJECT</code> column
shows the sum of the resources allocated to the instances that run on
the host, plus the resources allocated to the virtual machine of the
host itself.</p><p>The row that has the value <code class="literal">used_max</code> in the <code class="literal">PROJECT</code> column
shows the sum of the resources allocated to the instances that run on
the host.</p><div id="id-1.4.7.8.12.7.4.3.2.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>These values are computed by using information about the flavors of
the instances that run on the hosts. This command does not query the
CPU usage, memory usage, or hard disk usage of the physical host.</p></div></li></ul></div></div><div class="sect4 " id="id-1.4.7.8.12.7.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.6.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Show instance usage statistics</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.12.7.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Get CPU, memory, I/O, and network statistics for an instance.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List instances:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server list
+----------+----------------------+--------+------------+-------------+------------------+------------+
| ID       | Name                 | Status | Task State | Power State | Networks         | Image Name |
+----------+----------------------+--------+------------+-------------+------------------+------------+
| 84c6e... | myCirrosServer       | ACTIVE | None       | Running     | private=10.0.0.3 | cirros     |
| 8a995... | myInstanceFromVolume | ACTIVE | None       | Running     | private=10.0.0.4 | ubuntu     |
+----------+----------------------+--------+------------+-------------+------------------+------------+</pre></div></li><li class="step "><p>Get diagnostic statistics:</p><div class="verbatim-wrap"><pre class="screen">$ nova diagnostics myCirrosServer
+---------------------------+--------+
| Property                  | Value  |
+---------------------------+--------+
| memory                    | 524288 |
| memory-actual             | 524288 |
| memory-rss                | 6444   |
| tap1fec8fb8-7a_rx         | 22137  |
| tap1fec8fb8-7a_rx_drop    | 0      |
| tap1fec8fb8-7a_rx_errors  | 0      |
| tap1fec8fb8-7a_rx_packets | 166    |
| tap1fec8fb8-7a_tx         | 18032  |
| tap1fec8fb8-7a_tx_drop    | 0      |
| tap1fec8fb8-7a_tx_errors  | 0      |
| tap1fec8fb8-7a_tx_packets | 130    |
| vda_errors                | -1     |
| vda_read                  | 2048   |
| vda_read_req              | 2      |
| vda_write                 | 182272 |
| vda_write_req             | 74     |
+---------------------------+--------+</pre></div></li></ol></div></div></li><li class="listitem "><p>Get summary statistics for each tenant:</p><div class="verbatim-wrap"><pre class="screen">$ openstack usage list
Usage from 2013-06-25 to 2013-07-24:
+---------+---------+--------------+-----------+---------------+
| Project | Servers | RAM MB-Hours | CPU Hours | Disk GB-Hours |
+---------+---------+--------------+-----------+---------------+
| demo    | 1       | 344064.44    | 672.00    | 0.00          |
| stack   | 3       | 671626.76    | 327.94    | 6558.86       |
+---------+---------+--------------+-----------+---------------+</pre></div></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.7.8.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.8.13.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging module</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.13.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Logging behavior can be changed by creating a configuration file. To
specify the configuration file, add this line to the
<code class="literal">/etc/nova/nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">log-config=/etc/nova/logging.conf</pre></div><p>To change the logging level, add <code class="literal">DEBUG</code>, <code class="literal">INFO</code>, <code class="literal">WARNING</code>, or
<code class="literal">ERROR</code> as a parameter.</p><p>The logging configuration file is an INI-style configuration file, which
must contain a section called <code class="literal">logger_nova</code>. This controls the
behavior of the logging facility in the <code class="literal">nova-*</code> services. For
example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[logger_nova]
level = INFO
handlers = stderr
qualname = nova</pre></div><p>This example sets the debugging level to <code class="literal">INFO</code> (which is less verbose
than the default <code class="literal">DEBUG</code> setting).</p><p>For more about the logging configuration syntax, including the
<code class="literal">handlers</code> and <code class="literal">quaname</code> variables, see the
<a class="link" href="http://docs.python.org/release/2.7/library/logging.html#configuration-file-format" target="_blank">Python documentation</a>
on logging configuration files.</p><p>For an example of the <code class="literal">logging.conf</code> file with various defined handlers, see
the <a class="link" href="http://docs.openstack.org/newton/config-reference/" target="_blank">OpenStack Configuration Reference</a>.</p></div><div class="sect3 " id="id-1.4.7.8.13.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Syslog</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.13.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Compute services can send logging information to syslog. This
is useful if you want to use rsyslog to forward logs to a remote
machine. Separately configure the Compute service (nova), the Identity
service (keystone), the Image service (glance), and, if you are using
it, the Block Storage service (cinder) to send log messages to syslog.
Open these configuration files:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">/etc/nova/nova.conf</code>
              </p></li><li class="listitem "><p>
                <code class="literal">/etc/keystone/keystone.conf</code>
              </p></li><li class="listitem "><p>
                <code class="literal">/etc/glance/glance-api.conf</code>
              </p></li><li class="listitem "><p>
                <code class="literal">/etc/glance/glance-registry.conf</code>
              </p></li><li class="listitem "><p>
                <code class="literal">/etc/cinder/cinder.conf</code>
              </p></li></ul></div><p>In each configuration file, add these lines:</p><div class="verbatim-wrap highlight ini"><pre class="screen">debug = False
use_syslog = True
syslog_log_facility = LOG_LOCAL0</pre></div><p>In addition to enabling syslog, these settings also turn off debugging output
from the log.</p><div id="id-1.4.7.8.13.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Although this example uses the same local facility for each service
(<code class="literal">LOG_LOCAL0</code>, which corresponds to syslog facility <code class="literal">LOCAL0</code>),
we recommend that you configure a separate local facility for each
service, as this provides better isolation and more flexibility. For
example, you can capture logging information at different severity
levels for different services. syslog allows you to define up to
eight local facilities, <code class="literal">LOCAL0, LOCAL1, ..., LOCAL7</code>. For more
information, see the syslog documentation.</p></div></div><div class="sect3 " id="id-1.4.7.8.13.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Rsyslog</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.13.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>rsyslog is useful for setting up a centralized log server across
multiple machines. This section briefly describe the configuration to
set up an rsyslog server. A full treatment of rsyslog is beyond the
scope of this book. This section assumes rsyslog has already been
installed on your hosts (it is installed by default on most Linux
distributions).</p><p>This example provides a minimal configuration for <code class="literal">/etc/rsyslog.conf</code>
on the log server host, which receives the log files</p><div class="verbatim-wrap"><pre class="screen"># provides TCP syslog reception
$ModLoad imtcp
$InputTCPServerRun 1024</pre></div><p>Add a filter rule to <code class="literal">/etc/rsyslog.conf</code> which looks for a host name.
This example uses COMPUTE_01 as the compute host name:</p><div class="verbatim-wrap highlight ini"><pre class="screen">:hostname, isequal, "COMPUTE_01" /mnt/rsyslog/logs/compute-01.log</pre></div><p>On each compute host, create a file named
<code class="literal">/etc/rsyslog.d/60-nova.conf</code>, with the following content:</p><div class="verbatim-wrap"><pre class="screen"># prevent debug from dnsmasq with the daemon.none parameter
*.*;auth,authpriv.none,daemon.none,local0.none -/var/log/syslog
# Specify a log level of ERROR
local0.error    @@172.20.1.43:1024</pre></div><p>Once you have created the file, restart the <code class="literal">rsyslog</code> service. Error-level
log messages on the compute hosts should now be sent to the log server.</p></div><div class="sect3 " id="id-1.4.7.8.13.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Serial console</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.13.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The serial console provides a way to examine kernel output and other
system messages during troubleshooting if the instance lacks network
connectivity.</p><p>Read-only access from server serial console is possible
using the <code class="literal">os-GetSerialOutput</code> server action. Most
cloud images enable this feature by default. For more information, see
<a class="xref" href="#compute-common-errors-and-fixes" title="5.5.3. Common errors and fixes for Compute">Section 5.5.3, “Common errors and fixes for Compute”</a>.</p><p>OpenStack Juno and later supports read-write access using the serial
console using the <code class="literal">os-GetSerialConsole</code> server action. This feature
also requires a websocket client to access the serial console.</p><p>
            <span class="bold"><strong>Configuring read-write serial console access</strong></span>
          </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>On a compute node, edit the <code class="literal">/etc/nova/nova.conf</code> file:</p><p>In the <code class="literal">[serial_console]</code> section, enable the serial console:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[serial_console]
...
enabled = true</pre></div></li><li class="step "><p>In the <code class="literal">[serial_console]</code> section, configure the serial console proxy
similar to graphical console proxies:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[serial_console]
...
base_url = ws://controller:6083/
listen = 0.0.0.0
proxyclient_address = MANAGEMENT_INTERFACE_IP_ADDRESS</pre></div><p>The <code class="literal">base_url</code> option specifies the base URL that clients receive from
the API upon requesting a serial console. Typically, this refers to the
host name of the controller node.</p><p>The <code class="literal">listen</code> option specifies the network interface nova-compute
should listen on for virtual console connections. Typically, 0.0.0.0
will enable listening on all interfaces.</p><p>The <code class="literal">proxyclient_address</code> option specifies which network interface the
proxy should connect to. Typically, this refers to the IP address of the
management interface.</p><p>When you enable read-write serial console access, Compute will add
serial console information to the Libvirt XML file for the instance. For
example:</p><div class="verbatim-wrap highlight xml"><pre class="screen">&lt;console type='tcp'&gt;
  &lt;source mode='bind' host='127.0.0.1' service='10000'/&gt;
  &lt;protocol type='raw'/&gt;
  &lt;target type='serial' port='0'/&gt;
  &lt;alias name='serial0'/&gt;
&lt;/console&gt;</pre></div></li></ol></div></div><p>
            <span class="bold"><strong>Accessing the serial console on an instance</strong></span>
          </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Use the <code class="command">nova get-serial-proxy</code> command to retrieve the websocket
URL for the serial console on the instance:</p><div class="verbatim-wrap"><pre class="screen">$ nova get-serial-proxy INSTANCE_NAME</pre></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                        <p>Type</p>
                      </td><td>
                        <p>Url</p>
                      </td></tr><tr><td>
                        <p>serial</p>
                      </td><td>
                        <p>ws://127.0.0.1:6083/?token=18510769-71ad-4e5a-8348-4218b5613b3d</p>
                      </td></tr></tbody></table></div><p>Alternatively, use the API directly:</p><div class="verbatim-wrap"><pre class="screen">$ curl -i 'http://&lt;controller&gt;:8774/v2.1/&lt;tenant_uuid&gt;/servers/
  &lt;instance_uuid&gt;/action' \
  -X POST \
  -H "Accept: application/json" \
  -H "Content-Type: application/json" \
  -H "X-Auth-Project-Id: &lt;project_id&gt;" \
  -H "X-Auth-Token: &lt;auth_token&gt;" \
  -d '{"os-getSerialConsole": {"type": "serial"}}'</pre></div></li><li class="step "><p>Use Python websocket with the URL to generate <code class="literal">.send</code>, <code class="literal">.recv</code>, and
<code class="literal">.fileno</code> methods for serial console access. For example:</p><div class="verbatim-wrap highlight python"><pre class="screen">import websocket
ws = websocket.create_connection(
    'ws://127.0.0.1:6083/?token=18510769-71ad-4e5a-8348-4218b5613b3d',
    subprotocols=['binary', 'base64'])</pre></div></li></ol></div></div><p>Alternatively, use a <a class="link" href="https://github.com/larsks/novaconsole/" target="_blank">Python websocket client</a>.</p><div id="id-1.4.7.8.13.5.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When you enable the serial console, typical instance logging using
the <code class="command">nova console-log</code> command is disabled. Kernel output
and other system messages will not be visible unless you are
actively viewing the serial console.</p></div></div></div><div class="sect2 " id="id-1.4.7.8.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Secure with rootwrap</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Rootwrap allows unprivileged users to safely run Compute actions as the
root user. Compute previously used <code class="command">sudo</code> for this purpose, but this
was difficult to maintain, and did not allow advanced filters. The
<code class="command">rootwrap</code> command replaces <code class="command">sudo</code> for Compute.</p><p>To use rootwrap, prefix the Compute command with <code class="command">nova-rootwrap</code>. For
example:</p><div class="verbatim-wrap"><pre class="screen">$ sudo nova-rootwrap /etc/nova/rootwrap.conf command</pre></div><p>A generic <code class="literal">sudoers</code> entry lets the Compute user run <code class="command">nova-rootwrap</code>
as root. The <code class="command">nova-rootwrap</code> code looks for filter definition
directories in its configuration file, and loads command filters from
them. It then checks if the command requested by Compute matches one of
those filters and, if so, executes the command (as root). If no filter
matches, it denies the request.</p><div id="id-1.4.7.8.14.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Be aware of issues with using NFS and root-owned files. The NFS
share must be configured with the <code class="literal">no_root_squash</code> option enabled,
in order for rootwrap to work correctly.</p></div><p>Rootwrap is fully controlled by the root user. The root user
owns the sudoers entry which allows Compute to run a specific
rootwrap executable as root, and only with a specific
configuration file (which should also be owned by root).
The <code class="command">nova-rootwrap</code> command imports the Python
modules it needs from a cleaned, system-default PYTHONPATH.
The root-owned configuration file points to root-owned
filter definition directories, which contain root-owned
filters definition files. This chain ensures that the Compute
user itself is not in control of the configuration or modules
used by the <code class="command">nova-rootwrap</code> executable.</p><div class="sect3 " id="id-1.4.7.8.14.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure rootwrap</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.14.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Configure rootwrap in the <code class="literal">rootwrap.conf</code> file. Because
it is in the trusted security path, it must be owned and writable
by only the root user. The <code class="literal">rootwrap_config=entry</code> parameter
specifies the file's location in the sudoers entry and in the
<code class="literal">nova.conf</code> configuration file.</p><p>The <code class="literal">rootwrap.conf</code> file uses an INI file format with these
sections and parameters:</p><div class="table" id="id-1.4.7.8.14.8.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.4: </span><span class="name">rootwrap.conf configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.14.8.4">#</a></h6></div><div class="table-contents"><table class="table" summary="rootwrap.conf configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                    <p>Configuration option=Default value</p>
                  </td><td>
                    <p>(Type) Description</p>
                  </td></tr><tr><td>
                    <p>[DEFAULT]
filters_path=/etc/nova/rootwrap.d,/usr/share/nova/rootwrap</p>
                  </td><td>
                    <p>(ListOpt) Comma-separated list of directories
containing filter definition files.
Defines where rootwrap filters are stored.
Directories defined on this line should all
exist, and be owned and writable only by the
root user.</p>
                  </td></tr></tbody></table></div></div><p>If the root wrapper is not performing correctly, you can add a
workaround option into the <code class="literal">nova.conf</code> configuration file. This
workaround re-configures the root wrapper configuration to fall back to
running commands as <code class="literal">sudo</code>, and is a Kilo release feature.</p><p>Including this workaround in your configuration file safeguards your
environment from issues that can impair root wrapper performance. Tool
changes that have impacted
<a class="link" href="https://git.openstack.org/cgit/openstack-dev/pbr/" target="_blank">Python Build Reasonableness (PBR)</a>
for example, are a known issue that affects root wrapper performance.</p><p>To set up this workaround, configure the <code class="literal">disable_rootwrap</code> option in
the <code class="literal">[workaround]</code> section of the <code class="literal">nova.conf</code> configuration file.</p><p>The filters definition files contain lists of filters that rootwrap will
use to allow or deny a specific command. They are generally suffixed by
<code class="literal">.filters</code>. Since they are in the trusted security path, they need to
be owned and writable only by the root user. Their location is specified
in the <code class="literal">rootwrap.conf</code> file.</p><p>Filter definition files use an INI file format with a <code class="literal">[Filters]</code>
section and several lines, each with a unique parameter name, which
should be different for each filter you define:</p><div class="table" id="id-1.4.7.8.14.8.10"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.5: </span><span class="name">Filters configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.14.8.10">#</a></h6></div><div class="table-contents"><table class="table" summary="Filters configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                    <p>Configuration option=Default value</p>
                  </td><td>
                    <p>(Type) Description</p>
                  </td></tr><tr><td>
                    <p>[Filters]
filter_name=kpartx: CommandFilter, /sbin/kpartx, root</p>
                  </td><td>
                    <p>(ListOpt) Comma-separated list containing the filter class to
use, followed by the Filter arguments (which vary depending
on the Filter class selected).</p>
                  </td></tr></tbody></table></div></div></div><div class="sect3 " id="id-1.4.7.8.14.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the rootwrap daemon</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.14.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Administrators can use rootwrap daemon support instead of running
rootwrap with <code class="command">sudo</code>. The rootwrap daemon reduces the
overhead and performance loss that results from running
<code class="literal">oslo.rootwrap</code> with <code class="command">sudo</code>. Each call that needs rootwrap
privileges requires a new instance of rootwrap. The daemon
prevents overhead from the repeated calls. The daemon does not support
long running processes, however.</p><p>To enable the rootwrap daemon, set <code class="literal">use_rootwrap_daemon</code> to <code class="literal">True</code>
in the Compute service configuration file.</p></div></div><div class="sect2 " id="section-configuring-compute-migrations"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure migrations</span> <a title="Permalink" class="permalink" href="#section-configuring-compute-migrations">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>section-configuring-compute-migrations</li></ul></div></div></div></div><div id="id-1.4.7.8.15.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only administrators can perform live migrations. If your cloud
is configured to use cells, you can perform live migration within
but not between cells.</p></div><p>Migration enables an administrator to move a virtual-machine instance
from one compute host to another. This feature is useful when a compute
host requires maintenance. Migration can also be useful to redistribute
the load when many VM instances are running on a specific physical
machine.</p><p>The migration types are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Non-live migration</strong></span> (sometimes referred to simply as 'migration').
The instance is shut down for a period of time to be moved to another
hypervisor. In this case, the instance recognizes that it was
rebooted.</p></li><li class="listitem "><p><span class="bold"><strong>Live migration</strong></span> (or 'true live migration'). Almost no instance
downtime. Useful when the instances must be kept running during the
migration. The different types of live migration are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Shared storage-based live migration</strong></span>. Both hypervisors have
access to shared storage.</p></li><li class="listitem "><p><span class="bold"><strong>Block live migration</strong></span>. No shared storage is required.
Incompatible with read-only devices such as CD-ROMs and
<a class="link" href="http://docs.openstack.org/user-guide/cli-config-drive.html" target="_blank">Configuration Drive (config_drive)</a>.</p></li><li class="listitem "><p><span class="bold"><strong>Volume-backed live migration</strong></span>. Instances are backed by volumes
rather than ephemeral disk, no shared storage is required, and
migration is supported (currently only available for libvirt-based
hypervisors).</p></li></ul></div></li></ul></div><p>The following sections describe how to configure your hosts and compute
nodes for migrations by using the KVM and XenServer hypervisors.</p><div class="sect3 " id="id-1.4.7.8.15.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">KVM-Libvirt</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="configuring-migrations-kvm-shared-storage"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Shared storage</span> <a title="Permalink" class="permalink" href="#configuring-migrations-kvm-shared-storage">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>configuring-migrations-kvm-shared-storage</li></ul></div></div></div></div><p>
              <span class="bold"><strong>Prerequisites</strong></span>
            </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Hypervisor:</strong></span> KVM with libvirt</p></li><li class="listitem "><p><span class="bold"><strong>Shared storage:</strong></span><code class="literal">NOVA-INST-DIR/instances/</code> (for example,
<code class="literal">/var/lib/nova/instances</code>) has to be mounted by shared storage.
This guide uses NFS but other options, including the
<a class="link" href="http://gluster.org/community/documentation//index.php/OSConnect" target="_blank">OpenStack Gluster Connector</a>
are available.</p></li><li class="listitem "><p><span class="bold"><strong>Instances:</strong></span> Instance can be migrated with iSCSI-based volumes.</p></li></ul></div><p>
              <span class="bold"><strong>Notes</strong></span>
            </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Because the Compute service does not use the libvirt live
migration functionality by default, guests are suspended before
migration and might experience several minutes of downtime. For
details, see <code class="literal">Enabling true live migration</code>.</p></li><li class="listitem "><p>Compute calculates the amount of downtime required using the RAM size of
the disk being migrated, in accordance with the <code class="literal">live_migration_downtime</code>
configuration parameters. Migration downtime is measured in steps, with an
exponential backoff between each step. This means that the maximum
downtime between each step starts off small, and is increased in ever
larger amounts as Compute waits for the migration to complete. This gives
the guest a chance to complete the migration successfully, with a minimum
amount of downtime.</p></li><li class="listitem "><p>This guide assumes the default value for <code class="literal">instances_path</code> in
your <code class="literal">nova.conf</code> file (<code class="literal">NOVA-INST-DIR/instances</code>). If you
have changed the <code class="literal">state_path</code> or <code class="literal">instances_path</code> variables,
modify the commands accordingly.</p></li><li class="listitem "><p>You must specify <code class="literal">vncserver_listen=0.0.0.0</code> or live migration
will not work correctly.</p></li><li class="listitem "><p>You must specify the <code class="literal">instances_path</code> in each node that runs
<code class="literal">nova-compute</code>. The mount point for <code class="literal">instances_path</code> must be the
same value for each node, or live migration will not work
correctly.</p></li></ul></div></div><div class="sect4 " id="id-1.4.7.8.15.7.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example Compute installation environment</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.7.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Prepare at least three servers. In this example, we refer to the
servers as <code class="literal">HostA</code>, <code class="literal">HostB</code>, and <code class="literal">HostC</code>:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">HostA</code> is the Cloud Controller, and should run these services:
<code class="literal">nova-api</code>, <code class="literal">nova-scheduler</code>, <code class="literal">nova-network</code>, <code class="literal">cinder-volume</code>,
and <code class="literal">nova-objectstore</code>.</p></li><li class="listitem "><p><code class="literal">HostB</code> and <code class="literal">HostC</code> are the compute nodes that run
<code class="literal">nova-compute</code>.</p></li></ul></div><p>Ensure that <code class="literal">NOVA-INST-DIR</code> (set with <code class="literal">state_path</code> in the
<code class="literal">nova.conf</code> file) is the same on all hosts.</p></li><li class="listitem "><p>In this example, <code class="literal">HostA</code> is the NFSv4 server that exports
<code class="literal">NOVA-INST-DIR/instances</code> directory. <code class="literal">HostB</code> and <code class="literal">HostC</code> are
NFSv4 clients that mount <code class="literal">HostA</code>.</p></li></ul></div><p>
              <span class="bold"><strong>Configuring your system</strong></span>
            </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure your DNS or <code class="literal">/etc/hosts</code> and ensure it is consistent across
all hosts. Make sure that the three hosts can perform name resolution
with each other. As a test, use the <code class="command">ping</code> command to ping each host
from one another:</p><div class="verbatim-wrap"><pre class="screen">$ ping HostA
$ ping HostB
$ ping HostC</pre></div></li><li class="step "><p>Ensure that the UID and GID of your Compute and libvirt users are
identical between each of your servers. This ensures that the
permissions on the NFS mount works correctly.</p></li><li class="step "><p>Ensure you can access SSH without a password and without
StrictHostKeyChecking between <code class="literal">HostB</code> and <code class="literal">HostC</code> as <code class="literal">nova</code>
user (set with the owner of <code class="literal">nova-compute</code> service). Direct access
from one compute host to another is needed to copy the VM file
across. It is also needed to detect if the source and target
compute nodes share a storage subsystem.</p></li><li class="step "><p>Export <code class="literal">NOVA-INST-DIR/instances</code> from <code class="literal">HostA</code>, and ensure it is
readable and writable by the Compute user on <code class="literal">HostB</code> and <code class="literal">HostC</code>.</p><p>For more information, see: <a class="link" href="https://help.ubuntu.com/community/SettingUpNFSHowTo" target="_blank">SettingUpNFSHowTo</a>
or <a class="link" href="http://www.cyberciti.biz/faq/centos-fedora-rhel-nfs-v4-configuration/" target="_blank">CentOS/Red Hat: Setup NFS v4.0 File Server</a></p></li><li class="step "><p>Configure the NFS server at <code class="literal">HostA</code> by adding the following line to
the <code class="literal">/etc/exports</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">NOVA-INST-DIR/instances HostA/255.255.0.0(rw,sync,fsid=0,no_root_squash)</pre></div><p>Change the subnet mask (<code class="literal">255.255.0.0</code>) to the appropriate value to
include the IP addresses of <code class="literal">HostB</code> and <code class="literal">HostC</code>. Then restart the
<code class="literal">NFS</code> server:</p><div class="verbatim-wrap"><pre class="screen"># /etc/init.d/nfs-kernel-server restart
# /etc/init.d/idmapd restart</pre></div></li><li class="step "><p>On both compute nodes, enable the <code class="literal">execute/search</code> bit on your shared
directory to allow qemu to be able to use the images within the
directories. On all hosts, run the following command:</p><div class="verbatim-wrap"><pre class="screen">$ chmod o+x NOVA-INST-DIR/instances</pre></div></li><li class="step "><p>Configure NFS on <code class="literal">HostB</code> and <code class="literal">HostC</code> by adding the following line to
the <code class="literal">/etc/fstab</code> file</p><div class="verbatim-wrap"><pre class="screen">HostA:/ /NOVA-INST-DIR/instances nfs4 defaults 0 0</pre></div><p>Ensure that you can mount the exported directory</p><div class="verbatim-wrap"><pre class="screen">$ mount -a -v</pre></div><p>Check that <code class="literal">HostA</code> can see the <code class="literal">NOVA-INST-DIR/instances/</code>
directory</p><div class="verbatim-wrap"><pre class="screen">$ ls -ld NOVA-INST-DIR/instances/
drwxr-xr-x 2 nova nova 4096 2012-05-19 14:34 nova-install-dir/instances/</pre></div><p>Perform the same check on <code class="literal">HostB</code> and <code class="literal">HostC</code>, paying special
attention to the permissions (Compute should be able to write)</p><div class="verbatim-wrap"><pre class="screen">$ ls -ld NOVA-INST-DIR/instances/
drwxr-xr-x 2 nova nova 4096 2012-05-07 14:34 nova-install-dir/instances/

$ df -k
Filesystem           1K-blocks      Used Available Use% Mounted on
/dev/sda1            921514972   4180880 870523828   1% /
none                  16498340      1228  16497112   1% /dev
none                  16502856         0  16502856   0% /dev/shm
none                  16502856       368  16502488   1% /var/run
none                  16502856         0  16502856   0% /var/lock
none                  16502856         0  16502856   0% /lib/init/rw
HostA:               921515008 101921792 772783104  12% /var/lib/nova/instances  ( &lt;--- this line is important.)</pre></div></li><li class="step "><p>Update the libvirt configurations so that the calls can be made
securely. These methods enable remote access over TCP and are not
documented here.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>SSH tunnel to libvirtd's UNIX socket</p></li><li class="listitem "><p>libvirtd TCP socket, with GSSAPI/Kerberos for auth+data encryption</p></li><li class="listitem "><p>libvirtd TCP socket, with TLS for encryption and x509 client certs
for authentication</p></li><li class="listitem "><p>libvirtd TCP socket, with TLS for encryption and Kerberos for
authentication</p></li></ul></div><p>Restart <code class="literal">libvirt</code>. After you run the command, ensure that libvirt is
successfully restarted</p><div class="verbatim-wrap"><pre class="screen"># stop libvirt-bin &amp;&amp; start libvirt-bin
$ ps -ef | grep libvirt
root 1145 1 0 Nov27 ? 00:00:03 /usr/sbin/libvirtd -d -l\</pre></div></li><li class="step "><p>Configure your firewall to allow libvirt to communicate between nodes.
By default, libvirt listens on TCP port 16509, and an ephemeral TCP
range from 49152 to 49261 is used for the KVM communications. Based on
the secure remote access TCP configuration you chose, be careful which
ports you open, and always understand who has access. For information
about ports that are used with libvirt,
see the <a class="link" href="http://libvirt.org/remote.html#Remote_libvirtd_configuration" target="_blank">libvirt documentation</a>.</p></li><li class="step "><p>Configure the downtime required for the migration by adjusting these
parameters in the <code class="literal">nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">live_migration_downtime = 500
live_migration_downtime_steps = 10
live_migration_downtime_delay = 75</pre></div><p>The <code class="literal">live_migration_downtime</code> parameter sets the maximum permitted
downtime for a live migration, in milliseconds. This setting defaults to
500 milliseconds.</p><p>The <code class="literal">live_migration_downtime_steps</code> parameter sets the total number of
incremental steps to reach the maximum downtime value. This setting
defaults to 10 steps.</p><p>The <code class="literal">live_migration_downtime_delay</code> parameter sets the amount of time
to wait between each step, in seconds. This setting defaults to 75 seconds.</p></li><li class="step "><p>You can now configure other options for live migration. In most cases, you
will not need to configure any options. For advanced configuration options,
see the <a class="link" href="http://docs.openstack.org/liberty/config-reference/content/list-of-compute-config-options.html#config_table_nova_livemigration" target="_blank">OpenStack Configuration Reference Guide</a>.</p></li></ol></div></div></div><div class="sect4 " id="id-1.4.7.8.15.7.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.9.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling true live migration</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.7.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Prior to the Kilo release, the Compute service did not use the libvirt
live migration function by default. To enable this function, add the
following line to the <code class="literal">[libvirt]</code> section of the <code class="literal">nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">live_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE,VIR_MIGRATE_TUNNELLED</pre></div><p>On versions older than Kilo, the Compute service does not use libvirt's
live migration by default because there is a risk that the migration
process will never end. This can happen if the guest operating system
uses blocks on the disk faster than they can be migrated.</p></div><div class="sect4 " id="id-1.4.7.8.15.7.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.9.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block migration</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.7.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Configuring KVM for block migration is exactly the same as the above
configuration in <a class="xref" href="#configuring-migrations-kvm-shared-storage" title="5.4.9.1.1. Shared storage">Section 5.4.9.1.1, “Shared storage”</a>
the section called shared storage, except that <code class="literal">NOVA-INST-DIR/instances</code>
is local to each host rather than shared. No NFS client or server
configuration is required.</p><div id="id-1.4.7.8.15.7.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To use block migration, you must use the <code class="literal">--block-migrate</code>
parameter with the live migration command.</p></li><li class="listitem "><p>Block migration is incompatible with read-only devices such as
CD-ROMs and <a class="link" href="http://docs.openstack.org/user-guide/cli-config-drive.html" target="_blank">Configuration Drive (config_drive)</a>.</p></li><li class="listitem "><p>Since the ephemeral drives are copied over the network in block
migration, migrations of instances with heavy I/O loads may never
complete if the drives are writing faster than the data can be
copied over the network.</p></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.8.15.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">XenServer</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.7.8.15.8.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.9.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Shared storage</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.8.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
              <span class="bold"><strong>Prerequisites</strong></span>
            </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Compatible XenServer hypervisors</strong></span>. For more information, see the
<a class="link" href="http://docs.vmd.citrix.com/XenServer/6.0.0/1.0/en_gb/reference.html#pooling_homogeneity_requirements" target="_blank">Requirements for Creating Resource Pools</a> section of the XenServer
Administrator's Guide.</p></li><li class="listitem "><p><span class="bold"><strong>Shared storage</strong></span>. An NFS export, visible to all XenServer hosts.</p><div id="id-1.4.7.8.15.8.2.3.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For the supported NFS versions, see the
<a class="link" href="http://docs.vmd.citrix.com/XenServer/6.0.0/1.0/en_gb/reference.html#id1002701" target="_blank">NFS VHD</a>
section of the XenServer Administrator's Guide.</p></div></li></ul></div><p>To use shared storage live migration with XenServer hypervisors, the
hosts must be joined to a XenServer pool. To create that pool, a host
aggregate must be created with specific metadata. This metadata is used
by the XAPI plug-ins to establish the pool.</p><p>
              <span class="bold"><strong>Using shared storage live migrations with XenServer Hypervisors</strong></span>
            </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Add an NFS VHD storage to your master XenServer, and set it as the
default storage repository. For more information, see NFS VHD in the
XenServer Administrator's Guide.</p></li><li class="step "><p>Configure all compute nodes to use the default storage repository
(<code class="literal">sr</code>) for pool operations. Add this line to your <code class="literal">nova.conf</code>
configuration files on all compute nodes:</p><div class="verbatim-wrap highlight ini"><pre class="screen">sr_matching_filter=default-sr:true</pre></div></li><li class="step "><p>Create a host aggregate. This command creates the aggregate, and then
displays a table that contains the ID of the new aggregate</p><div class="verbatim-wrap"><pre class="screen">$ openstack aggregate create --zone AVAILABILITY_ZONE POOL_NAME</pre></div><p>Add metadata to the aggregate, to mark it as a hypervisor pool</p><div class="verbatim-wrap"><pre class="screen">$ openstack aggregate set --property hypervisor_pool=true AGGREGATE_ID

$ openstack aggregate set --property operational_state=created AGGREGATE_ID</pre></div><p>Make the first compute node part of that aggregate</p><div class="verbatim-wrap"><pre class="screen">$ openstack aggregate add host AGGREGATE_ID MASTER_COMPUTE_NAME</pre></div><p>The host is now part of a XenServer pool.</p></li><li class="step "><p>Add hosts to the pool</p><div class="verbatim-wrap"><pre class="screen">$ openstack aggregate add host AGGREGATE_ID COMPUTE_HOST_NAME</pre></div><div id="id-1.4.7.8.15.8.2.6.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The added compute node and the host will shut down to join the host
to the XenServer pool. The operation will fail if any server other
than the compute node is running or suspended on the host.</p></div></li></ol></div></div></div><div class="sect4 " id="id-1.4.7.8.15.8.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.9.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block migration</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.15.8.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Compatible XenServer hypervisors</strong></span>.
The hypervisors must support the Storage XenMotion feature.
See your XenServer manual to make sure your edition
has this feature.</p><div id="id-1.4.7.8.15.8.3.2.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To use block migration, you must use the <code class="literal">--block-migrate</code>
parameter with the live migration command.</p></li><li class="listitem "><p>Block migration works only with EXT local storage storage
repositories, and the server must not have any volumes attached.</p></li></ul></div></div></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.7.8.16"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate instances</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.16">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section discusses how to migrate running instances from one
OpenStack Compute server to another OpenStack Compute server.</p><p>Before starting a migration, review the Configure migrations section.
<a class="xref" href="#section-configuring-compute-migrations" title="5.4.9. Configure migrations">Section 5.4.9, “Configure migrations”</a>.</p><div id="id-1.4.7.8.16.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Although the <code class="command">nova</code> command is called <code class="command">live-migration</code>,
under the default Compute configuration options, the instances
are suspended before migration. For more information, see
<a class="link" href="http://docs.openstack.org/newton/config-reference/compute/config-options.html" target="_blank">Configure migrations</a>.
in the OpenStack Configuration Reference.</p></div><p>
          <span class="bold"><strong>Migrating instances</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Check the ID of the instance to be migrated:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server list</pre></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                      <p>ID</p>
                    </th><th>
                      <p>Name</p>
                    </th><th>
                      <p>Status</p>
                    </th><th>
                      <p>Networks</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>d1df1b5a-70c4-4fed-98b7-423362f2c47c</p>
                    </td><td>
                      <p>vm1</p>
                    </td><td>
                      <p>ACTIVE</p>
                    </td><td>
                      <p>private=a.b.c.d</p>
                    </td></tr><tr><td>
                      <p>d693db9e-a7cf-45ef-a7c9-b3ecb5f22645</p>
                    </td><td>
                      <p>vm2</p>
                    </td><td>
                      <p>ACTIVE</p>
                    </td><td>
                      <p>private=e.f.g.h</p>
                    </td></tr></tbody></table></div></li><li class="step "><p>Check the information associated with the instance. In this example,
<code class="literal">vm1</code> is running on <code class="literal">HostB</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server show d1df1b5a-70c4-4fed-98b7-423362f2c47c</pre></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                      <p>Property</p>
                    </th><th>
                      <p>Value</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>...</p>
                      <p>OS-EXT-SRV-ATTR:host</p>
                      <p>...</p>
                      <p>flavor</p>
                      <p>id</p>
                      <p>name</p>
                      <p>private network</p>
                      <p>status</p>
                      <p>...</p>
                    </td><td>
                      <p>...</p>
                      <p>HostB</p>
                      <p>...</p>
                      <p>m1.tiny</p>
                      <p>d1df1b5a-70c4-4fed-98b7-423362f2c47c</p>
                      <p>vm1</p>
                      <p>a.b.c.d</p>
                      <p>ACTIVE</p>
                      <p>...</p>
                    </td></tr></tbody></table></div></li><li class="step "><p>Select the compute node the instance will be migrated to. In this
example, we will migrate the instance to <code class="literal">HostC</code>, because
<code class="literal">nova-compute</code> is running on it:</p><div class="table" id="id-1.4.7.8.16.6.3.2"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.6: </span><span class="name">openstack compute service list </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.16.6.3.2">#</a></h6></div><div class="table-contents"><table class="table" summary="openstack compute service list" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                      <p>Binary</p>
                    </th><th>
                      <p>Host</p>
                    </th><th>
                      <p>Zone</p>
                    </th><th>
                      <p>Status</p>
                    </th><th>
                      <p>State</p>
                    </th><th>
                      <p>Updated_at</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>nova-consoleauth</p>
                    </td><td>
                      <p>HostA</p>
                    </td><td>
                      <p>internal</p>
                    </td><td>
                      <p>enabled</p>
                    </td><td>
                      <p>up</p>
                    </td><td>
                      <p>2014-03-25T10:33:25.000000</p>
                    </td></tr><tr><td>
                      <p>nova-scheduler</p>
                    </td><td>
                      <p>HostA</p>
                    </td><td>
                      <p>internal</p>
                    </td><td>
                      <p>enabled</p>
                    </td><td>
                      <p>up</p>
                    </td><td>
                      <p>2014-03-25T10:33:25.000000</p>
                    </td></tr><tr><td>
                      <p>nova-conductor</p>
                    </td><td>
                      <p>HostA</p>
                    </td><td>
                      <p>internal</p>
                    </td><td>
                      <p>enabled</p>
                    </td><td>
                      <p>up</p>
                    </td><td>
                      <p>2014-03-25T10:33:27.000000</p>
                    </td></tr><tr><td>
                      <p>nova-compute</p>
                    </td><td>
                      <p>HostB</p>
                    </td><td>
                      <p>nova</p>
                    </td><td>
                      <p>enabled</p>
                    </td><td>
                      <p>up</p>
                    </td><td>
                      <p>2014-03-25T10:33:31.000000</p>
                    </td></tr><tr><td>
                      <p>nova-compute</p>
                    </td><td>
                      <p>HostC</p>
                    </td><td>
                      <p>nova</p>
                    </td><td>
                      <p>enabled</p>
                    </td><td>
                      <p>up</p>
                    </td><td>
                      <p>2014-03-25T10:33:31.000000</p>
                    </td></tr><tr><td>
                      <p>nova-cert</p>
                    </td><td>
                      <p>HostA</p>
                    </td><td>
                      <p>internal</p>
                    </td><td>
                      <p>enabled</p>
                    </td><td>
                      <p>up</p>
                    </td><td>
                      <p>2014-03-25T10:33:31.000000</p>
                    </td></tr></tbody></table></div></div></li><li class="step "><p>Check that <code class="literal">HostC</code> has enough resources for migration:</p><div class="verbatim-wrap"><pre class="screen"># openstack host show HostC</pre></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /></colgroup><thead><tr><th>
                      <p>HOST</p>
                    </th><th>
                      <p>PROJECT</p>
                    </th><th>
                      <p>cpu</p>
                    </th><th>
                      <p>memory_mb</p>
                    </th><th>
                      <p>disk_gb</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>HostC</p>
                    </td><td>
                      <p>(total)</p>
                    </td><td>
                      <p>16</p>
                    </td><td>
                      <p>32232</p>
                    </td><td>
                      <p>878</p>
                    </td></tr><tr><td>
                      <p>HostC</p>
                    </td><td>
                      <p>(used_now)</p>
                    </td><td>
                      <p>22</p>
                    </td><td>
                      <p>21284</p>
                    </td><td>
                      <p>442</p>
                    </td></tr><tr><td>
                      <p>HostC</p>
                    </td><td>
                      <p>(used_max)</p>
                    </td><td>
                      <p>22</p>
                    </td><td>
                      <p>21284</p>
                    </td><td>
                      <p>422</p>
                    </td></tr><tr><td>
                      <p>HostC</p>
                    </td><td>
                      <p>p1</p>
                    </td><td>
                      <p>22</p>
                    </td><td>
                      <p>21284</p>
                    </td><td>
                      <p>422</p>
                    </td></tr><tr><td>
                      <p>HostC</p>
                    </td><td>
                      <p>p2</p>
                    </td><td>
                      <p>22</p>
                    </td><td>
                      <p>21284</p>
                    </td><td>
                      <p>422</p>
                    </td></tr></tbody></table></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">cpu</code>: Number of CPUs</p></li><li class="listitem "><p><code class="literal">memory_mb</code>: Total amount of memory, in MB</p></li><li class="listitem "><p><code class="literal">disk_gb</code>: Total amount of space for NOVA-INST-DIR/instances, in GB</p></li></ul></div><p>In this table, the first row shows the total amount of resources
available on the physical server. The second line shows the currently
used resources. The third line shows the maximum used resources. The
fourth line and below shows the resources available for each project.</p></li><li class="step "><p>Migrate the instance using the <code class="command">openstack server migrate</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server migrate SERVER --live HOST_NAME</pre></div><p>In this example, SERVER can be the ID or name of the instance. Another
example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server migrate d1df1b5a-70c4-4fed-98b7-423362f2c47c --live HostC
Migration of d1df1b5a-70c4-4fed-98b7-423362f2c47c initiated.</pre></div><div id="id-1.4.7.8.16.6.5.5" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>When using live migration to move workloads between
Icehouse and Juno compute nodes, it may cause data loss
because libvirt live migration with shared block storage
was buggy (potential loss of data) before version 3.32.
This issue can be solved when we upgrade to RPC API version 4.0.</p></div></li><li class="step "><p>Check that the instance has been migrated successfully, using
<code class="command">openstack server list</code>. If the instance is still running on
<code class="literal">HostB</code>, check the log files at <code class="literal">src/dest</code> for <code class="literal">nova-compute</code> and
<code class="literal">nova-scheduler</code> to determine why.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.7.8.17"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure remote console access</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To provide a remote console or remote desktop access to guest virtual
machines, use VNC or SPICE HTML5 through either the OpenStack dashboard
or the command line. Best practice is to select one or the other to run.</p><div class="sect3 " id="id-1.4.7.8.17.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">About nova-consoleauth</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Both client proxies leverage a shared service to manage token
authentication called <code class="literal">nova-consoleauth</code>. This service must be running for
either proxy to work. Many proxies of either type can be run against a
single <code class="literal">nova-consoleauth</code> service in a cluster configuration.</p><p>Do not confuse the <code class="literal">nova-consoleauth</code> shared service with
<code class="literal">nova-console</code>, which is a XenAPI-specific service that most recent
VNC proxy architectures do not use.</p></div><div class="sect3 " id="id-1.4.7.8.17.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SPICE console</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Compute supports VNC consoles to guests. The VNC protocol is
fairly limited, lacking support for multiple monitors, bi-directional
audio, reliable cut-and-paste, video streaming and more. SPICE is a new
protocol that aims to address the limitations in VNC and provide good
remote desktop support.</p><p>SPICE support in OpenStack Compute shares a similar architecture to the
VNC implementation. The OpenStack dashboard uses a SPICE-HTML5 widget in
its console tab that communicates to the <code class="literal">nova-spicehtml5proxy</code> service by
using SPICE-over-websockets. The <code class="literal">nova-spicehtml5proxy</code> service
communicates directly with the hypervisor process by using SPICE.</p><p>VNC must be explicitly disabled to get access to the SPICE console. Set
the <code class="literal">vnc_enabled</code> option to <code class="literal">False</code> in the <code class="literal">[DEFAULT]</code> section to
disable the VNC console.</p><p>Use the following options to configure SPICE as the console for
OpenStack Compute:</p><div class="table" id="id-1.4.7.8.17.4.6"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.7: </span><span class="name">Description of SPICE configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.17.4.6">#</a></h6></div><div class="table-contents"><table class="table" summary="Description of SPICE configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>
                      <span class="bold"><strong>[spice]</strong></span>
                    </p>
                  </th><th> </th></tr></thead><tbody><tr><td>
                    <p>Spice configuration option = Default value</p>
                  </td><td>
                    <p>Description</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">agent_enabled = True</code>
                    </p>
                  </td><td>
                    <p>(BoolOpt) Enable spice guest agent support</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">enabled = False</code>
                    </p>
                  </td><td>
                    <p>(BoolOpt) Enable spice related features</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">html5proxy_base_url = http://127.0.0.1:6082/spice_auto.html</code>
                    </p>
                  </td><td>
                    <p>(StrOpt) Location of spice HTML5 console proxy, in the form
"<a class="link" href="http://127.0.0.1:6082/spice_auto.html" target="_blank">http://127.0.0.1:6082/spice_auto.html</a>"</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">html5proxy_host = 0.0.0.0</code>
                    </p>
                  </td><td>
                    <p>(StrOpt) Host on which to listen for incoming requests</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">html5proxy_port = 6082</code>
                    </p>
                  </td><td>
                    <p>(IntOpt) Port on which to listen for incoming requests</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">keymap = en-us</code>
                    </p>
                  </td><td>
                    <p>(StrOpt) Keymap for spice</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">server_listen = 127.0.0.1</code>
                    </p>
                  </td><td>
                    <p>(StrOpt) IP address on which instance spice server should listen</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">server_proxyclient_address = 127.0.0.1</code>
                    </p>
                  </td><td>
                    <p>(StrOpt) The address to which proxy clients (like nova-spicehtml5proxy)
should connect</p>
                  </td></tr></tbody></table></div></div></div><div class="sect3 " id="id-1.4.7.8.17.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VNC console proxy</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The VNC proxy is an OpenStack component that enables compute service
users to access their instances through VNC clients.</p><div id="id-1.4.7.8.17.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The web proxy console URLs do not support the websocket protocol
scheme (ws://) on python versions less than 2.7.4.</p></div><p>The VNC console connection works as follows:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>A user connects to the API and gets an <code class="literal">access_url</code> such as,
<code class="literal">http://ip:port/?token=xyz</code>.</p></li><li class="step "><p>The user pastes the URL in a browser or uses it as a client
parameter.</p></li><li class="step "><p>The browser or client connects to the proxy.</p></li><li class="step "><p>The proxy talks to <code class="literal">nova-consoleauth</code> to authorize the token for the
user, and maps the token to the <span class="emphasis"><em>private</em></span> host and port of the VNC
server for an instance.</p><p>The compute host specifies the address that the proxy should use to
connect through the <code class="literal">nova.conf</code> file option,
<code class="literal">vncserver_proxyclient_address</code>. In this way, the VNC proxy works
as a bridge between the public network and private host network.</p></li><li class="step "><p>The proxy initiates the connection to VNC server and continues to
proxy until the session ends.</p></li></ol></div></div><p>The proxy also tunnels the VNC protocol over WebSockets so that the
<code class="literal">noVNC</code> client can talk to VNC servers. In general, the VNC proxy:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Bridges between the public network where the clients live and the
private network where VNC servers live.</p></li><li class="listitem "><p>Mediates token authentication.</p></li><li class="listitem "><p>Transparently deals with hypervisor-specific connection details to
provide a uniform client experience.</p></li></ul></div><div class="figure" id="id-1.4.7.8.17.5.8"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/SCH_5009_V00_NUAC-VNC_OpenStack.png" target="_blank"><img src="images/SCH_5009_V00_NUAC-VNC_OpenStack.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.7: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5.8">#</a></h6></div></div><div class="sect4 " id="id-1.4.7.8.17.5.9"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.11.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VNC configuration options</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5.9">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To customize the VNC console, use the following configuration options in
your <code class="literal">nova.conf</code> file:</p><div id="id-1.4.7.8.17.5.9.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To support <a class="xref" href="#section-configuring-compute-migrations" title="5.4.9. Configure migrations">Section 5.4.9, “Configure migrations”</a>,
you cannot specify a specific IP address for <code class="literal">vncserver_listen</code>,
because that IP address does not exist on the destination host.</p></div><div class="table" id="id-1.4.7.8.17.5.9.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.8: </span><span class="name">Description of VNC configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5.9.4">#</a></h6></div><div class="table-contents"><table class="table" summary="Description of VNC configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                      <p>Configuration option = Default value</p>
                    </th><th>
                      <p>Description</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>
                        <span class="bold"><strong>[DEFAULT]</strong></span>
                      </p>
                    </td><td> </td></tr><tr><td>
                      <p>
                        <code class="literal">daemon = False</code>
                      </p>
                    </td><td>
                      <p>(BoolOpt) Become a daemon (background process)</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">key = None</code>
                      </p>
                    </td><td>
                      <p>(StrOpt) SSL key file (if separate from cert)</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">novncproxy_host = 0.0.0.0</code>
                      </p>
                    </td><td>
                      <p>(StrOpt) Host on which to listen for incoming requests</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">novncproxy_port = 6080</code>
                      </p>
                    </td><td>
                      <p>(IntOpt) Port on which to listen for incoming requests</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">record = False</code>
                      </p>
                    </td><td>
                      <p>(BoolOpt) Record sessions to FILE.[session_number]</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">source_is_ipv6 = False</code>
                      </p>
                    </td><td>
                      <p>(BoolOpt) Source is ipv6</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">ssl_only = False</code>
                      </p>
                    </td><td>
                      <p>(BoolOpt) Disallow non-encrypted connections</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">web = /usr/share/spice-html5</code>
                      </p>
                    </td><td>
                      <p>(StrOpt) Run webserver on same port. Serve files from DIR.</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>[vmware]</strong></span>
                      </p>
                    </td><td> </td></tr><tr><td>
                      <p>
                        <code class="literal">vnc_port = 5900</code>
                      </p>
                    </td><td>
                      <p>(IntOpt) VNC starting port</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">vnc_port_total = 10000</code>
                      </p>
                    </td><td>
                      <p>vnc_port_total = 10000</p>
                    </td></tr><tr><td>
                      <p>
                        <span class="bold"><strong>[vnc]</strong></span>
                      </p>
                    </td><td> </td></tr><tr><td>
                      <p>enabled = True</p>
                    </td><td>
                      <p>(BoolOpt) Enable VNC related features</p>
                    </td></tr><tr><td>
                      <p>novncproxy_base_url = <a class="link" href="http://127.0.0.1:6080/vnc_auto.html" target="_blank">http://127.0.0.1:6080/vnc_auto.html</a></p>
                    </td><td>
                      <p>(StrOpt) Location of VNC console proxy, in the form
"<a class="link" href="http://127.0.0.1:6080/vnc_auto.html" target="_blank">http://127.0.0.1:6080/vnc_auto.html</a>"</p>
                    </td></tr><tr><td>
                      <p>vncserver_listen = 127.0.0.1</p>
                    </td><td>
                      <p>(StrOpt) IP address on which instance vncservers should listen</p>
                    </td></tr><tr><td>
                      <p>vncserver_proxyclient_address = 127.0.0.1</p>
                    </td><td>
                      <p>(StrOpt) The address to which proxy clients 
should connect</p>
                    </td></tr></tbody></table></div></div><div id="id-1.4.7.8.17.5.9.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <code class="literal">vncserver_proxyclient_address</code> defaults to <code class="literal">127.0.0.1</code>,
which is the address of the compute host that Compute instructs
proxies to use when connecting to instance servers.</p></li><li class="listitem "><p>For all-in-one XenServer domU deployments, set this to
<code class="literal">169.254.0.1.</code></p></li><li class="listitem "><p>For multi-host XenServer domU deployments, set to a <code class="literal">dom0
management IP</code> on the same network as the proxies.</p></li><li class="listitem "><p>For multi-host libvirt deployments, set to a host management IP
on the same network as the proxies.</p></li></ul></div></div></div><div class="sect4 " id="id-1.4.7.8.17.5.10"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.11.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Typical deployment</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5.10">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A typical deployment has the following components:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A <code class="literal">nova-consoleauth</code> process. Typically runs on the controller host.</p></li><li class="listitem "><p>One or more <code class="literal">nova-novncproxy</code> services. Supports browser-based noVNC
clients. For simple deployments, this service typically runs on the
same machine as <code class="literal">nova-api</code> because it operates as a proxy between the
public network and the private compute host network.</p></li><li class="listitem "><p>One or more compute hosts. These compute hosts must have correctly
configured options, as follows.</p></li></ul></div></div><div class="sect4 " id="id-1.4.7.8.17.5.11"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.11.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">nova-novncproxy (noVNC)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5.11">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must install the noVNC package, which contains the <code class="literal">nova-novncproxy</code>
service. As root, run the following command:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install nova-novncproxy</pre></div><p>The service starts automatically on installation.</p><p>To restart the service, run:</p><div class="verbatim-wrap"><pre class="screen"># service nova-novncproxy restart</pre></div><p>The configuration option parameter should point to your <code class="literal">nova.conf</code>
file, which includes the message queue server address and credentials.</p><p>By default, <code class="literal">nova-novncproxy</code> binds on <code class="literal">0.0.0.0:6080</code>.</p><p>To connect the service to your Compute deployment, add the following
configuration options to your <code class="literal">nova.conf</code> file:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">vncserver_listen=0.0.0.0</code>
                </p><p>Specifies the address on which the VNC service should bind. Make sure
it is assigned one of the compute node interfaces. This address is
the one used by your domain file.</p><div class="verbatim-wrap"><pre class="screen">&lt;graphics type="vnc" autoport="yes" keymap="en-us" listen="0.0.0.0"/&gt;</pre></div><div id="id-1.4.7.8.17.5.11.10.1.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To use live migration, use the 0.0.0.0 address.</p></div></li><li class="listitem "><p>
                  <code class="literal">vncserver_proxyclient_address=127.0.0.1</code>
                </p><p>The address of the compute host that Compute instructs proxies to use
when connecting to instance <code class="literal">vncservers</code>.</p></li></ul></div></div><div class="sect4 " id="id-1.4.7.8.17.5.12"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.11.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Frequently asked questions about VNC access to virtual machines</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.17.5.12">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <span class="bold"><strong>Q: I want VNC support in the OpenStack dashboard. What services do
I need?</strong></span>
                </p><p>A: You need <code class="literal">nova-novncproxy</code>, <code class="literal">nova-consoleauth</code>, and correctly
configured compute hosts.</p></li><li class="listitem "><p>
                  <span class="bold"><strong>Q: When I use ``nova get-vnc-console`` or click on the VNC tab of
the OpenStack dashboard, it hangs. Why?</strong></span>
                </p><p>A: Make sure you are running <code class="literal">nova-consoleauth</code> (in addition to
<code class="literal">nova-novncproxy</code>). The proxies rely on <code class="literal">nova-consoleauth</code> to validate
tokens, and waits for a reply from them until a timeout is reached.</p></li><li class="listitem "><p>
                  <span class="bold"><strong>Q: My VNC proxy worked fine during my all-in-one test, but now it
doesn't work on multi host. Why?</strong></span>
                </p><p>A: The default options work for an all-in-one install, but changes
must be made on your compute hosts once you start to build a cluster.
As an example, suppose you have two servers:</p><div class="verbatim-wrap highlight bash"><pre class="screen">PROXYSERVER (public_ip=172.24.1.1, management_ip=192.168.1.1)
COMPUTESERVER (management_ip=192.168.1.2)</pre></div><p>Your <code class="literal">nova-compute</code> configuration file must set the following values:</p><div class="verbatim-wrap"><pre class="screen"># These flags help construct a connection data structure
vncserver_proxyclient_address=192.168.1.2
novncproxy_base_url=http://172.24.1.1:6080/vnc_auto.html


# This is the address where the underlying vncserver (not the proxy)
# will listen for connections.
vncserver_listen=192.168.1.2</pre></div></li><li class="listitem "><p>
                  <span class="bold"><strong>Q: My noVNC does not work with recent versions of web browsers. Why?</strong></span>
                </p><p>A: Make sure you have installed <code class="literal">python-numpy</code>, which is required
to support a newer version of the WebSocket protocol (HyBi-07+).</p></li><li class="listitem "><p>
                  <span class="bold"><strong>Q: How do I adjust the dimensions of the VNC window image in the
OpenStack dashboard?</strong></span>
                </p><p>A: These values are hard-coded in a Django HTML template. To alter
them, edit the <code class="literal">_detail_vnc.html</code> template file. The location of
this file varies based on Linux distribution. On Ubuntu 14.04, the
file is at
<code class="literal">/usr/share/pyshared/horizon/dashboards/nova/instances/templates/instances/_detail_vnc.html</code>.</p><p>Modify the <code class="literal">width</code> and <code class="literal">height</code> options, as follows:</p><div class="verbatim-wrap"><pre class="screen">&lt;iframe src="{{ vnc_url }}" width="720" height="430"&gt;&lt;/iframe&gt;</pre></div></li><li class="listitem "><p>
                  <span class="bold"><strong>Q: My noVNC connections failed with ValidationError: Origin header
protocol does not match. Why?</strong></span>
                </p><p>A: Make sure the <code class="literal">base_url</code> match your TLS setting. If you are
using https console connections, make sure that the value of
<code class="literal">novncproxy_base_url</code> is set explicitly where the <code class="literal">nova-novncproxy</code>
service is running.</p></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.7.8.18"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Compute service groups</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.18">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Compute service must know the status of each compute node to
effectively manage and use them. This can include events like a user
launching a new VM, the scheduler sending a request to a live node, or a
query to the ServiceGroup API to determine if a node is live.</p><p>When a compute worker running the nova-compute daemon starts, it calls
the join API to join the compute group. Any service (such as the
scheduler) can query the group's membership and the status of its nodes.
Internally, the ServiceGroup client driver automatically updates the
compute worker status.</p><div class="sect3 " id="id-1.4.7.8.18.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Database ServiceGroup driver</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.18.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By default, Compute uses the database driver to track if a node is live.
In a compute worker, this driver periodically sends a <code class="literal">db update</code>
command to the database, saying “I'm OK” with a timestamp. Compute uses
a pre-defined timeout (<code class="literal">service_down_time</code>) to determine if a node is
dead.</p><p>The driver has limitations, which can be problematic depending on your
environment. If a lot of compute worker nodes need to be checked, the
database can be put under heavy load, which can cause the timeout to
trigger, and a live node could incorrectly be considered dead. By
default, the timeout is 60 seconds. Reducing the timeout value can help
in this situation, but you must also make the database update more
frequently, which again increases the database workload.</p><p>The database contains data that is both transient (such as whether the
node is alive) and persistent (such as entries for VM owners). With the
ServiceGroup abstraction, Compute can treat each type separately.</p><div class="sect4 " id="id-1.4.7.8.18.4.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.12.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">ZooKeeper ServiceGroup driver</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.18.4.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ZooKeeper ServiceGroup driver works by using ZooKeeper ephemeral
nodes. ZooKeeper, unlike databases, is a distributed system, with its
load divided among several servers. On a compute worker node, the driver
can establish a ZooKeeper session, then create an ephemeral znode in the
group directory. Ephemeral znodes have the same lifespan as the session.
If the worker node or the nova-compute daemon crashes, or a network
partition is in place between the worker and the ZooKeeper server
quorums, the ephemeral znodes are removed automatically. The driver
can be given group membership by running the <code class="command">ls</code> command in the
group directory.</p><p>The ZooKeeper driver requires the ZooKeeper servers and client
libraries. Setting up ZooKeeper servers is outside the scope of this
guide (for more information, see <a class="link" href="http://zookeeper.apache.org/" target="_blank">Apache Zookeeper</a>). These client-side
Python libraries must be installed on every compute node:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.8.18.4.5.4.1"><span class="term ">
                  <span class="bold"><strong>python-zookeeper</strong></span>
                </span></dt><dd><p>The official Zookeeper Python binding</p></dd><dt id="id-1.4.7.8.18.4.5.4.2"><span class="term ">
                  <span class="bold"><strong>evzookeeper</strong></span>
                </span></dt><dd><p>This library makes the binding work with the eventlet threading model.</p></dd></dl></div><p>This example assumes the ZooKeeper server addresses and ports are
<code class="literal">192.168.2.1:2181</code>, <code class="literal">192.168.2.2:2181</code>, and <code class="literal">192.168.2.3:2181</code>.</p><p>These values in the <code class="literal">/etc/nova/nova.conf</code> file are required on every
node for the ZooKeeper driver:</p><div class="verbatim-wrap highlight ini"><pre class="screen"># Driver for the ServiceGroup service
servicegroup_driver="zk"

[zookeeper]
address="192.168.2.1:2181,192.168.2.2:2181,192.168.2.3:2181"</pre></div></div><div class="sect4 " id="id-1.4.7.8.18.4.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.12.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Memcache ServiceGroup driver</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.18.4.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The memcache ServiceGroup driver uses memcached, a distributed memory
object caching system that is used to increase site performance. For
more details, see <a class="link" href="http://memcached.org/" target="_blank">memcached.org</a>.</p><p>To use the memcache driver, you must install memcached. You might
already have it installed, as the same driver is also used for the
OpenStack Object Storage and OpenStack dashboard. To install
memcached, see the <span class="emphasis"><em>Environment -&gt; Memcached</em></span> section in the
<a class="link" href="http://docs.openstack.org/project-install-guide/newton" target="_blank">Installation Tutorials and Guides</a>
depending on your distribution.</p><p>These values in the <code class="literal">/etc/nova/nova.conf</code> file are required on every
node for the memcache driver:</p><div class="verbatim-wrap highlight ini"><pre class="screen"># Driver for the ServiceGroup service
servicegroup_driver = "mc"

# Memcached servers. Use either a list of memcached servers to use for caching (list value),
# or "&lt;None&gt;" for in-process caching (default).
memcached_servers = &lt;None&gt;

# Timeout; maximum time since last check-in for up service (integer value).
# Helps to define whether a node is dead
service_down_time = 60</pre></div></div></div></div><div class="sect2 " id="id-1.4.7.8.19"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Security hardening</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.19">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Compute can be integrated with various third-party
technologies to increase security. For more information, see the
<a class="link" href="http://docs.openstack.org/sec/" target="_blank">OpenStack Security Guide</a>.</p><div class="sect3 " id="id-1.4.7.8.19.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Trusted compute pools</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.19.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Administrators can designate a group of compute hosts as trusted using
trusted compute pools. The trusted hosts use hardware-based security
features, such as the Intel Trusted Execution Technology (TXT), to
provide an additional level of security. Combined with an external
stand-alone, web-based remote attestation server, cloud providers can
ensure that the compute node runs only software with verified
measurements and can ensure a secure cloud stack.</p><p>Trusted compute pools provide the ability for cloud subscribers to
request services run only on verified compute nodes.</p><p>The remote attestation server performs node verification like this:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Compute nodes boot with Intel TXT technology enabled.</p></li><li class="step "><p>The compute node BIOS, hypervisor, and operating system are measured.</p></li><li class="step "><p>When the attestation server challenges the compute node, the measured
data is sent to the attestation server.</p></li><li class="step "><p>The attestation server verifies the measurements against a known good
database to determine node trustworthiness.</p></li></ol></div></div><p>A description of how to set up an attestation service is beyond the
scope of this document. For an open source project that you can use to
implement an attestation service, see the <a class="link" href="https://github.com/OpenAttestation/OpenAttestation" target="_blank">Open
Attestation</a>
project.</p><div class="figure" id="id-1.4.7.8.19.3.7"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/OpenStackTrustedComputePool1.png" target="_blank"><img src="images/OpenStackTrustedComputePool1.png" width="" alt="Configuring Compute to use trusted compute pools" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.8: </span><span class="name">Configuring Compute to use trusted compute pools </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.19.3.7">#</a></h6></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Enable scheduling support for trusted compute pools by adding these
lines to the <code class="literal">DEFAULT</code> section of the <code class="literal">/etc/nova/nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
compute_scheduler_driver=nova.scheduler.filter_scheduler.FilterScheduler
scheduler_available_filters=nova.scheduler.filters.all_filters
scheduler_default_filters=AvailabilityZoneFilter,RamFilter,ComputeFilter,TrustedFilter</pre></div></li><li class="step "><p>Specify the connection information for your attestation service by
adding these lines to the <code class="literal">trusted_computing</code> section of the
<code class="literal">/etc/nova/nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[trusted_computing]
attestation_server = 10.1.71.206
attestation_port = 8443
# If using OAT v2.0 after, use this port:
# attestation_port = 8181
attestation_server_ca_file = /etc/nova/ssl.10.1.71.206.crt
# If using OAT v1.5, use this api_url:
attestation_api_url = /AttestationService/resources
# If using OAT pre-v1.5, use this api_url:
# attestation_api_url = /OpenAttestationWebServices/V1.0
attestation_auth_blob = i-am-openstack</pre></div><p>In this example:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.8.19.3.8.2.4.1"><span class="term ">server</span></dt><dd><p>Host name or IP address of the host that runs the attestation
service</p></dd><dt id="id-1.4.7.8.19.3.8.2.4.2"><span class="term ">port</span></dt><dd><p>HTTPS port for the attestation service</p></dd><dt id="id-1.4.7.8.19.3.8.2.4.3"><span class="term ">server_ca_file</span></dt><dd><p>Certificate file used to verify the attestation server's identity</p></dd><dt id="id-1.4.7.8.19.3.8.2.4.4"><span class="term ">api_url</span></dt><dd><p>The attestation service's URL path</p></dd><dt id="id-1.4.7.8.19.3.8.2.4.5"><span class="term ">auth_blob</span></dt><dd><p>An authentication blob, required by the attestation service.</p></dd></dl></div></li><li class="step "><p>Save the file, and restart the <code class="literal">nova-compute</code> and <code class="literal">nova-scheduler</code>
service to pick up the changes.</p></li></ol></div></div><p>To customize the trusted compute pools, use these configuration option
settings:</p><div class="table" id="id-1.4.7.8.19.3.10"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 5.9: </span><span class="name">Description of trusted computing configuration options </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.19.3.10">#</a></h6></div><div class="table-contents"><table class="table" summary="Description of trusted computing configuration options" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Configuration option = Default value</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr><tr><th>
                    <p>[trusted_computing]</p>
                  </th><th> </th></tr></thead><tbody><tr><td>
                    <p>attestation_api_url = /OpenAttestationWebServices/V1.0</p>
                  </td><td>
                    <p>(StrOpt) Attestation web API URL</p>
                  </td></tr><tr><td>
                    <p>attestation_auth_blob = None</p>
                  </td><td>
                    <p>(StrOpt) Attestation authorization blob - must change</p>
                  </td></tr><tr><td>
                    <p>attestation_auth_timeout = 60</p>
                  </td><td>
                    <p>(IntOpt) Attestation status cache valid period length</p>
                  </td></tr><tr><td>
                    <p>attestation_insecure_ssl = False</p>
                  </td><td>
                    <p>(BoolOpt) Disable SSL cert verification for Attestation service</p>
                  </td></tr><tr><td>
                    <p>attestation_port = 8443</p>
                  </td><td>
                    <p>(StrOpt) Attestation server port</p>
                  </td></tr><tr><td>
                    <p>attestation_server = None</p>
                  </td><td>
                    <p>(StrOpt) Attestation server HTTP</p>
                  </td></tr><tr><td>
                    <p>attestation_server_ca_file = None</p>
                  </td><td>
                    <p>(StrOpt) Attestation server Cert file for Identity verification</p>
                  </td></tr></tbody></table></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Flavors can be designated as trusted using the
<code class="command">nova flavor-key set</code> command. In this example, the <code class="literal">m1.tiny</code>
flavor is being set as trusted:</p><div class="verbatim-wrap"><pre class="screen">$ nova flavor-key m1.tiny set trust:trusted_host=trusted</pre></div></li><li class="step "><p>You can request that your instance is run on a trusted host by
specifying a trusted flavor when booting the instance:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server create --flavor m1.tiny \
  --key-name myKeypairName --image myImageID newInstanceName</pre></div></li></ol></div></div><div class="figure" id="id-1.4.7.8.19.3.12"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/OpenStackTrustedComputePool2.png" target="_blank"><img src="images/OpenStackTrustedComputePool2.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 5.9: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.7.8.19.3.12">#</a></h6></div></div></div><div class="sect3 " id="id-1.4.7.8.19.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Encrypt Compute metadata traffic</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.19.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
            <span class="bold"><strong>Enabling SSL encryption</strong></span>
          </p><p>OpenStack supports encrypting Compute metadata traffic with HTTPS.
Enable SSL encryption in the <code class="literal">metadata_agent.ini</code> file.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Enable the HTTPS protocol.</p><div class="verbatim-wrap highlight ini"><pre class="screen">nova_metadata_protocol = https</pre></div></li><li class="step "><p>Determine whether insecure SSL connections are accepted for Compute
metadata server requests. The default value is <code class="literal">False</code>.</p><div class="verbatim-wrap highlight ini"><pre class="screen">nova_metadata_insecure = False</pre></div></li><li class="step "><p>Specify the path to the client certificate.</p><div class="verbatim-wrap highlight ini"><pre class="screen">nova_client_cert = PATH_TO_CERT</pre></div></li><li class="step "><p>Specify the path to the private key.</p><div class="verbatim-wrap highlight ini"><pre class="screen">nova_client_priv_key = PATH_TO_KEY</pre></div></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.7.8.20"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Recover from a failed compute node</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.20">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you deploy Compute with a shared file system, you can use several methods
to quickly recover from a node failure. This section discusses manual
recovery.</p><div class="sect3 " id="id-1.4.7.8.20.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Evacuate instances</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.20.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If a hardware malfunction or other error causes the cloud compute node to
fail, you can use the <code class="command">nova evacuate</code> command to evacuate instances.
See the <a class="link" href="http://docs.openstack.org/admin-guide/cli-nova-evacuate.html" target="_blank">OpenStack Administrator Guide</a>.</p></div><div class="sect3 " id="id-1.4.7.8.20.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manual recovery</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.20.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To manually recover a failed compute node:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Identify the VMs on the affected hosts by using a combination of
the <code class="command">openstack server list</code> and <code class="command">openstack server show</code>
commands or the <code class="command">euca-describe-instances</code> command.</p><p>For example, this command displays information about the i-000015b9
instance that runs on the np-rcc54 node:</p><div class="verbatim-wrap"><pre class="screen">$ euca-describe-instances
i-000015b9 at3-ui02 running nectarkey (376, np-rcc54) 0 m1.xxlarge 2012-06-19T00:48:11.000Z 115.146.93.60</pre></div></li><li class="step "><p>Query the Compute database for the status of the host. This example
converts an EC2 API instance ID to an OpenStack ID. If you use the
<code class="command">nova</code> commands, you can substitute the ID directly. This example
output is truncated:</p><div class="verbatim-wrap"><pre class="screen">mysql&gt; SELECT * FROM instances WHERE id = CONV('15b9', 16, 10) \G;
*************************** 1. row ***************************
created_at: 2012-06-19 00:48:11
updated_at: 2012-07-03 00:35:11
deleted_at: NULL
...
id: 5561
...
power_state: 5
vm_state: shutoff
...
hostname: at3-ui02
host: np-rcc54
...
uuid: 3f57699a-e773-4650-a443-b4b37eed5a06
...
task_state: NULL
...</pre></div><div id="id-1.4.7.8.20.4.3.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Find the credentials for your database in <code class="literal">/etc/nova.conf</code> file.</p></div></li><li class="step "><p>Decide to which compute host to move the affected VM. Run this database
command to move the VM to that host:</p><div class="verbatim-wrap"><pre class="screen">mysql&gt; UPDATE instances SET host = 'np-rcc46' WHERE uuid = '3f57699a-e773-4650-a443-b4b37eed5a06';</pre></div></li><li class="step "><p>If you use a hypervisor that relies on libvirt, such as KVM, update the
<code class="literal">libvirt.xml</code> file in <code class="literal">/var/lib/nova/instances/[instance ID]</code> with
these changes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Change the <code class="literal">DHCPSERVER</code> value to the host IP address of the new
compute host.</p></li><li class="listitem "><p>Update the VNC IP to <code class="literal">0.0.0.0</code>.</p></li></ul></div></li><li class="step "><p>Reboot the VM:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server reboot 3f57699a-e773-4650-a443-b4b37eed5a06</pre></div></li></ol></div></div><p>Typically, the database update and <code class="command">openstack server reboot</code> command
recover a VM from a failed host. However, if problems persist, try one of
these actions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Use <code class="command">virsh</code> to recreate the network filter configuration.</p></li><li class="listitem "><p>Restart Compute services.</p></li><li class="listitem "><p>Update the <code class="literal">vm_state</code> and <code class="literal">power_state</code> fields in the Compute database.</p></li></ul></div></div><div class="sect3 " id="id-1.4.7.8.20.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.14.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Recover from a UID/GID mismatch</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.20.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Sometimes when you run Compute with a shared file system or an automated
configuration tool, files on your compute node might use the wrong UID or GID.
This UID or GID mismatch can prevent you from running live migrations or
starting virtual machines.</p><p>This procedure runs on <code class="literal">nova-compute</code> hosts, based on the KVM hypervisor:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Set the nova UID to the same number in <code class="literal">/etc/passwd</code> on all hosts. For
example, set the UID to <code class="literal">112</code>.</p><div id="id-1.4.7.8.20.5.4.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Choose UIDs or GIDs that are not in use for other users or groups.</p></div></li><li class="step "><p>Set the <code class="literal">libvirt-qemu</code> UID to the same number in the <code class="literal">/etc/passwd</code> file
on all hosts. For example, set the UID to <code class="literal">119</code>.</p></li><li class="step "><p>Set the <code class="literal">nova</code> group to the same number in the <code class="literal">/etc/group</code> file on all
hosts. For example, set the group to <code class="literal">120</code>.</p></li><li class="step "><p>Set the <code class="literal">libvirtd</code> group to the same number in the <code class="literal">/etc/group</code> file on
all hosts. For example, set the group to <code class="literal">119</code>.</p></li><li class="step "><p>Stop the services on the compute node.</p></li><li class="step "><p>Change all files that the nova user or group owns. For example:</p><div class="verbatim-wrap"><pre class="screen"># find / -uid 108 -exec chown nova {} \;
# note the 108 here is the old nova UID before the change
# find / -gid 120 -exec chgrp nova {} \;</pre></div></li><li class="step "><p>Repeat all steps for the <code class="literal">libvirt-qemu</code> files, if required.</p></li><li class="step "><p>Restart the services.</p></li><li class="step "><p>To verify that all files use the correct IDs, run the <code class="command">find</code>
command.</p></li></ol></div></div></div><div class="sect3 " id="id-1.4.7.8.20.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.14.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Recover cloud after disaster</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.20.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section describes how to manage your cloud after a disaster and back up
persistent storage volumes. Backups are mandatory, even outside of disaster
scenarios.</p><p>For a definition of a disaster recovery plan (DRP), see
<a class="link" href="http://en.wikipedia.org/wiki/Disaster_Recovery_Plan" target="_blank">http://en.wikipedia.org/wiki/Disaster_Recovery_Plan</a>.</p><p>A disk crash, network loss, or power failure can affect several components in
your cloud architecture. The worst disaster for a cloud is a power loss. A
power loss affects these components:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A cloud controller (<code class="literal">nova-api</code>, <code class="literal">nova-objectstore</code>, <code class="literal">nova-network</code>)</p></li><li class="listitem "><p>A compute node (<code class="literal">nova-compute</code>)</p></li><li class="listitem "><p>A storage area network (SAN) used by OpenStack Block Storage
(<code class="literal">cinder-volumes</code>)</p></li></ul></div><p>Before a power loss:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create an active iSCSI session from the SAN to the cloud controller
(used for the <code class="literal">cinder-volumes</code> LVM's VG).</p></li><li class="listitem "><p>Create an active iSCSI session from the cloud controller to the compute
node (managed by <code class="literal">cinder-volume</code>).</p></li><li class="listitem "><p>Create an iSCSI session for every volume (so 14 EBS volumes requires 14
iSCSI sessions).</p></li><li class="listitem "><p>Create <code class="literal">iptables</code> or <code class="literal">ebtables</code> rules from the cloud controller to the
compute node. This allows access from the cloud controller to the
running instance.</p></li><li class="listitem "><p>Save the current state of the database, the current state of the running
instances, and the attached volumes (mount point, volume ID, volume
status, etc), at least from the cloud controller to the compute node.</p></li></ul></div><p>After power resumes and all hardware components restart:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The iSCSI session from the SAN to the cloud no longer exists.</p></li><li class="listitem "><p>The iSCSI session from the cloud controller to the compute node no
longer exists.</p></li><li class="listitem "><p>nova-network reapplies configurations on boot and, as a result, recreates
the iptables and ebtables from the cloud controller to the compute node.</p></li><li class="listitem "><p>Instances stop running.</p><p>Instances are not lost because neither <code class="literal">destroy</code> nor <code class="literal">terminate</code> ran.
The files for the instances remain on the compute node.</p></li><li class="listitem "><p>The database does not update.</p></li></ul></div><p>
            <span class="bold"><strong>Begin recovery</strong></span>
          </p><div id="id-1.4.7.8.20.6.11" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Do not add any steps or change the order of steps in this procedure.</p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Check the current relationship between the volume and its instance, so
that you can recreate the attachment.</p><p>Use the <code class="command">openstack volume list</code> command to get this information.
Note that the <code class="command">openstack</code> client can get volume information
from OpenStack Block Storage.</p></li><li class="step "><p>Update the database to clean the stalled state. Do this for every
volume by using these queries:</p><div class="verbatim-wrap"><pre class="screen">mysql&gt; use cinder;
mysql&gt; update volumes set mountpoint=NULL;
mysql&gt; update volumes set status="available" where status &lt;&gt;"error_deleting";
mysql&gt; update volumes set attach_status="detached";
mysql&gt; update volumes set instance_id=0;</pre></div><p>Use <code class="command">openstack volume list</code> command to list all volumes.</p></li><li class="step "><p>Restart the instances by using the
<code class="command">openstack server reboot INSTANCE</code> command.</p><div id="id-1.4.7.8.20.6.12.3.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Some instances completely reboot and become reachable, while some might
stop at the plymouth stage. This is expected behavior. DO NOT reboot a
second time.</p><p>Instance state at this stage depends on whether you added an
<code class="literal">/etc/fstab</code> entry for that volume. Images built with the cloud-init
package remain in a <code class="literal">pending</code> state, while others skip the missing
volume and start. You perform this step to ask Compute to reboot every
instance so that the stored state is preserved. It does not matter if
not all instances come up successfully. For more information about
cloud-init, see
<a class="link" href="https://help.ubuntu.com/community/CloudInit/" target="_blank">help.ubuntu.com/community/CloudInit/</a>.</p></div></li><li class="step "><p>If required, run the <code class="command">openstack server add volume</code> command to
reattach the volumes to their respective instances. This example uses
a file of listed volumes to reattach them:</p><div class="verbatim-wrap highlight bash"><pre class="screen">#!/bin/bash

while read line; do
    volume=`echo $line | $CUT -f 1 -d " "`
    instance=`echo $line | $CUT -f 2 -d " "`
    mount_point=`echo $line | $CUT -f 3 -d " "`
        echo "ATTACHING VOLUME FOR INSTANCE - $instance"
    openstack server add volume $instance $volume $mount_point
    sleep 2
done &lt; $volumes_tmp_file</pre></div><p>Instances that were stopped at the plymouth stage now automatically
continue booting and start normally. Instances that previously started
successfully can now see the volume.</p></li><li class="step "><p>Log in to the instances with SSH and reboot them.</p><p>If some services depend on the volume or if a volume has an entry in fstab,
you can now restart the instance. Restart directly from the instance itself
and not through <code class="command">nova</code>:</p><div class="verbatim-wrap"><pre class="screen"># shutdown -r now</pre></div><p>When you plan for and complete a disaster recovery, follow these tips:</p></li></ol></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Use the <code class="literal">errors=remount</code> option in the <code class="literal">fstab</code> file to prevent
data corruption.</p><p>In the event of an I/O error, this option prevents writes to the disk. Add
this configuration option into the cinder-volume server that performs the
iSCSI connection to the SAN and into the instances' <code class="literal">fstab</code> files.</p></li><li class="listitem "><p>Do not add the entry for the SAN's disks to the cinder-volume's
<code class="literal">fstab</code> file.</p><p>Some systems hang on that step, which means you could lose access to
your cloud-controller. To re-run the session manually, run this
command before performing the mount:</p><div class="verbatim-wrap"><pre class="screen"># iscsiadm -m discovery -t st -p $SAN_IP $ iscsiadm -m node --target-name $IQN -p $SAN_IP -l</pre></div></li><li class="listitem "><p>On your instances, if you have the whole <code class="literal">/home/</code> directory on the
disk, leave a user's directory with the user's bash files and the
<code class="literal">authorized_keys</code> file instead of emptying the <code class="literal">/home/</code> directory
and mapping the disk on it.</p><p>This action enables you to connect to the instance without the volume
attached, if you allow only connections through public keys.</p></li></ul></div><p>To script the disaster recovery plan (DRP), use the
<a class="link" href="https://github.com/Razique/BashStuff/blob/master/SYSTEMS/OpenStack/SCR_5006_V00_NUAC-OPENSTACK-DRP-OpenStack.sh" target="_blank">https://github.com/Razique</a> bash script.</p><p>This script completes these steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Creates an array for instances and their attached volumes.</p></li><li class="step "><p>Updates the MySQL database.</p></li><li class="step "><p>Restarts all instances with euca2ools.</p></li><li class="step "><p>Reattaches the volumes.</p></li><li class="step "><p>Uses Compute credentials to make an SSH connection into every instance.</p></li></ol></div></div><p>The script includes a <code class="literal">test mode</code>, which enables you to perform the sequence
for only one instance.</p><p>To reproduce the power loss, connect to the compute node that runs that
instance and close the iSCSI session. Do not detach the volume by using the
<code class="command">openstack server remove volume</code> command. You must manually close the
iSCSI session. This example closes an iSCSI session with the number <code class="literal">15</code>:</p><div class="verbatim-wrap"><pre class="screen"># iscsiadm -m session -u -r 15</pre></div><p>Do not forget the <code class="literal">-r</code> option. Otherwise, all sessions close.</p><div id="id-1.4.7.8.20.6.21" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>There is potential for data loss while running instances during
this procedure. If you are using Liberty or earlier, ensure you have the
correct patch and set the options appropriately.</p></div></div></div><div class="sect2 " id="id-1.4.7.8.21"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Advanced configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack clouds run on platforms that differ greatly in the capabilities that
they provide. By default, the Compute service seeks to abstract the underlying
hardware that it runs on, rather than exposing specifics about the underlying
host platforms. This abstraction manifests itself in many ways. For example,
rather than exposing the types and topologies of CPUs running on hosts, the
service exposes a number of generic CPUs (virtual CPUs, or vCPUs) and allows
for overcommitting of these. In a similar manner, rather than exposing the
individual types of network devices available on hosts, generic
software-powered network ports are provided. These features are designed to
allow high resource utilization and allows the service to provide a generic
cost-effective and highly scalable cloud upon which to build applications.</p><p>This abstraction is beneficial for most workloads. However, there are some
workloads where determinism and per-instance performance are important, if
not vital. In these cases, instances can be expected to deliver near-native
performance. The Compute service provides features to improve individual
instance for these kind of workloads.</p><div class="sect3 " id="id-1.4.7.8.21.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Attaching physical PCI devices to guests</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The PCI passthrough feature in OpenStack allows full access and direct control
of a physical PCI device in guests. This mechanism is generic for any kind of
PCI device, and runs with a Network Interface Card (NIC), Graphics Processing
Unit (GPU), or any other devices that can be attached to a PCI bus. Correct
driver installation is the only requirement for the guest to properly
use the devices.</p><p>Some PCI devices provide Single Root I/O Virtualization and Sharing (SR-IOV)
capabilities. When SR-IOV is used, a physical device is virtualized and appears
as multiple PCI devices. Virtual PCI devices are assigned to the same or
different guests. In the case of PCI passthrough, the full physical device is
assigned to only one guest and cannot be shared.</p><div id="id-1.4.7.8.21.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For information on attaching virtual SR-IOV devices to guests, refer to the
<a class="link" href="http://docs.openstack.org/newton/networking-guide/config-sriov.html" target="_blank">Networking Guide</a>.</p></div><p>To enable PCI passthrough, follow the steps below:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure nova-scheduler (Controller)</p></li><li class="step "><p>Configure nova-api (Controller)**</p></li><li class="step "><p>Configure a flavor (Controller)</p></li><li class="step "><p>Enable PCI passthrough (Compute)</p></li><li class="step "><p>Configure PCI devices in nova-compute (Compute)</p></li></ol></div></div><div id="id-1.4.7.8.21.4.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The PCI device with address <code class="literal">0000:41:00.0</code> is used as an example. This
will differ between environments.</p></div><div class="sect4 " id="id-1.4.7.8.21.4.8"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure nova-scheduler (Controller)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4.8">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure <code class="literal">nova-scheduler</code> as specified in <a class="link" href="http://docs.openstack.org/newton/networking-guide/config-sriov.html#configure-nova-scheduler-controller" target="_blank">Configure nova-scheduler</a>.</p></li><li class="step "><p>Restart the <code class="literal">nova-scheduler</code> service.</p></li></ol></div></div></div><div class="sect4 " id="id-1.4.7.8.21.4.9"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure nova-api (Controller)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4.9">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Specify the PCI alias for the device.</p><p>Configure a PCI alias <code class="literal">a1</code> to request a PCI device with a <code class="literal">vendor_id</code> of
<code class="literal">0x8086</code> and a <code class="literal">product_id</code> of <code class="literal">0x154d</code>. The <code class="literal">vendor_id</code> and
<code class="literal">product_id</code> correspond the PCI device with address <code class="literal">0000:41:00.0</code>.</p><p>Edit <code class="literal">/etc/nova/nova.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
pci_alias = { "vendor_id":"8086", "product_id":"154d", "device_type":"type-PF", "name":"a1" }</pre></div><p>For more information about the syntax of <code class="literal">pci_alias</code>, refer to <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/config-options.html" target="_blank">nova.conf
configuration options</a>.</p></li><li class="step "><p>Restart the <code class="literal">nova-api</code> service.</p></li></ol></div></div></div><div class="sect4 " id="id-1.4.7.8.21.4.10"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure a flavor (Controller)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4.10">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Configure a flavor to request two PCI devices, each with <code class="literal">vendor_id</code> of
<code class="literal">0x8086</code> and <code class="literal">product_id</code> of <code class="literal">0x154d</code>:</p><div class="verbatim-wrap"><pre class="screen"># openstack flavor set m1.large --property "pci_passthrough:alias"="a1:2"</pre></div><p>For more information about the syntax for <code class="literal">pci_passthrough:alias</code>, refer to
<a class="link" href="http://docs.openstack.org/admin-guide/compute-flavors.html" target="_blank">flavor</a>.</p></div><div class="sect4 " id="id-1.4.7.8.21.4.11"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable PCI passthrough (Compute)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4.11">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Enable VT-d and IOMMU. For more information, refer to steps one and two in
<a class="link" href="http://docs.openstack.org/newton/networking-guide/config-sriov.html#create-virtual-functions-compute" target="_blank">Create Virtual Functions</a>.</p></div><div class="sect4 " id="id-1.4.7.8.21.4.12"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure PCI devices (Compute)</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4.12">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure <code class="literal">nova-compute</code> to allow the PCI device to pass through to
VMs. Edit <code class="literal">/etc/nova/nova.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
pci_passthrough_whitelist = { "address": "0000:41:00.0" }</pre></div><p>Alternatively specify multiple PCI devices using whitelisting:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
pci_passthrough_whitelist = { "vendor_id": "8086", "product_id": "10fb" }</pre></div><p>All PCI devices matching the <code class="literal">vendor_id</code> and <code class="literal">product_id</code> are added to
the pool of PCI devices available for passthrough to VMs.</p><p>For more information about the syntax of <code class="literal">pci_passthrough_whitelist</code>,
refer to <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/config-options.html" target="_blank">nova.conf configuration options</a>.</p></li><li class="step "><p>Specify the PCI alias for the device.</p><p>From the Newton release, to resize guest with PCI device, configure the PCI
alias on the compute node as well.</p><p>Configure a PCI alias <code class="literal">a1</code> to request a PCI device with a <code class="literal">vendor_id</code> of
<code class="literal">0x8086</code> and a <code class="literal">product_id</code> of <code class="literal">0x154d</code>. The <code class="literal">vendor_id</code> and
<code class="literal">product_id</code> correspond the PCI device with address <code class="literal">0000:41:00.0</code>.</p><p>Edit <code class="literal">/etc/nova/nova.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
pci_alias = { "vendor_id":"8086", "product_id":"154d", "device_type":"type-PF", "name":"a1" }</pre></div><p>For more information about the syntax of <code class="literal">pci_alias</code>, refer to <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/config-options.html" target="_blank">nova.conf
configuration options</a>.</p></li><li class="step "><p>Restart the <code class="literal">nova-compute</code> service.</p></li></ol></div></div></div><div class="sect4 " id="id-1.4.7.8.21.4.13"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create instances with PCI passthrough devices</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.4.13">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">nova-scheduler</code> selects a destination host that has PCI devices
available with the specified <code class="literal">vendor_id</code> and <code class="literal">product_id</code> that matches the
<code class="literal">pci_alias</code> from the flavor.</p><div class="verbatim-wrap"><pre class="screen"># openstack server create --flavor m1.large --image cirros-0.3.4-x86_64-uec --wait test-pci</pre></div></div></div><div class="sect3 " id="sec-cpu-topo"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">CPU topologies</span> <a title="Permalink" class="permalink" href="#sec-cpu-topo">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>sec-cpu-topo</li></ul></div></div></div></div><p>The NUMA topology and CPU pinning features in OpenStack provide high-level
control over how instances run on hypervisor CPUs and the topology of virtual
CPUs available to instances. These features help minimize latency and maximize
performance.</p><div class="sect4 " id="id-1.4.7.8.21.5.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SMP, NUMA, and SMT</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.5.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.8.21.5.3.2.1"><span class="term ">Symmetric multiprocessing (SMP)</span></dt><dd><p>SMP is a design found in many modern multi-core systems. In an SMP system,
there are two or more CPUs and these CPUs are connected by some interconnect.
This provides CPUs with equal access to system resources like memory and
input/output ports.</p></dd><dt id="id-1.4.7.8.21.5.3.2.2"><span class="term ">Non-uniform memory access (NUMA)</span></dt><dd><p>NUMA is a derivative of the SMP design that is found in many multi-socket
systems. In a NUMA system, system memory is divided into cells or nodes that
are associated with particular CPUs. Requests for memory on other nodes are
possible through an interconnect bus. However, bandwidth across this shared
bus is limited. As a result, competition for this resource can incur
performance penalties.</p></dd><dt id="id-1.4.7.8.21.5.3.2.3"><span class="term ">Simultaneous Multi-Threading (SMT)</span></dt><dd><p>SMT is a design complementary to SMP. Whereas CPUs in SMP systems share a bus
and some memory, CPUs in SMT systems share many more components. CPUs that
share components are known as thread siblings.  All CPUs appear as usable
CPUs on the system and can execute workloads in parallel. However, as with
NUMA, threads compete for shared resources.</p></dd></dl></div><p>In OpenStack, SMP CPUs are known as <span class="emphasis"><em>cores</em></span>, NUMA cells or nodes are known as
<span class="emphasis"><em>sockets</em></span>, and SMT CPUs are known as <span class="emphasis"><em>threads</em></span>. For example, a quad-socket,
eight core system with Hyper-Threading would have four sockets, eight cores per
socket and two threads per core, for a total of 64 CPUs.</p></div><div class="sect4 " id="id-1.4.7.8.21.5.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Customizing instance NUMA placement policies</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.5.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.7.8.21.5.4.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The functionality described below is currently only supported by the
libvirt/KVM driver.</p></div><p>When running workloads on NUMA hosts, it is important that the vCPUs executing
processes are on the same NUMA node as the memory used by these processes.
This ensures all memory accesses are local to the node and thus do not consume
the limited cross-node memory bandwidth, adding latency to memory accesses.
Similarly, large pages are assigned from memory and benefit from the same
performance improvements as memory allocated using standard pages. Thus, they
also should be local. Finally, PCI devices are directly associated with
specific NUMA nodes for the purposes of DMA. Instances that use PCI or SR-IOV
devices should be placed on the NUMA node associated with these devices.</p><p>By default, an instance floats across all NUMA nodes on a host. NUMA awareness
can be enabled implicitly through the use of huge pages or pinned CPUs or
explicitly through the use of flavor extra specs or image metadata.  In all
cases, the <code class="literal">NUMATopologyFilter</code> filter must be enabled. Details on this
filter are provided in <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/scheduler.html" target="_blank">Scheduling</a> configuration guide.</p><div id="id-1.4.7.8.21.5.4.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The NUMA node(s) used are normally chosen at random. However, if a PCI
passthrough or SR-IOV device is attached to the instance, then the NUMA
node that the device is associated with will be used. This can provide
important performance improvements. However, booting a large number of
similar instances can result in unbalanced NUMA node usage. Care should
be taken to mitigate this issue. See this <a class="link" href="http://lists.openstack.org/pipermail/openstack-dev/2016-March/090367.html" target="_blank">discussion</a> for more details.</p></div><div id="id-1.4.7.8.21.5.4.6" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Inadequate per-node resources will result in scheduling failures. Resources
that are specific to a node include not only CPUs and memory, but also PCI
and SR-IOV resources. It is not possible to use multiple resources from
different nodes without requesting a multi-node layout. As such, it may be
necessary to ensure PCI or SR-IOV resources are associated with the same
NUMA node or force a multi-node layout.</p></div><p>When used, NUMA awareness allows the operating system of the instance to
intelligently schedule the workloads that it runs and minimize cross-node
memory bandwidth. To restrict an instance's vCPUs to a single host NUMA node,
run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:numa_nodes=1</pre></div><p>Some workloads have very demanding requirements for memory access latency or
bandwidth that exceed the memory bandwidth available from a single NUMA node.
For such workloads, it is beneficial to spread the instance across multiple
host NUMA nodes, even if the instance's RAM/vCPUs could theoretically fit on a
single NUMA node. To force an instance's vCPUs to spread across two host NUMA
nodes, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:numa_nodes=2</pre></div><p>The allocation of instances vCPUs and memory from different host NUMA nodes can
be configured. This allows for asymmetric allocation of vCPUs and memory, which
can be important for some workloads. To spread the 6 vCPUs and 6 GB of memory
of an instance across two NUMA nodes and create an asymmetric 1:2 vCPU and
memory mapping between the two nodes, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:numa_nodes=2
$ openstack flavor set m1.large \  # configure guest node 0
  --property hw:numa_cpus.0=0,1 \
  --property hw:numa_mem.0=2048
$ openstack flavor set m1.large \  # configure guest node 1
  --property hw:numa_cpus.1=2,3,4,5 \
  --property hw:numa_mem.1=4096</pre></div><p>For more information about the syntax for <code class="literal">hw:numa_nodes</code>, <code class="literal">hw:numa_cpus.N</code>
and <code class="literal">hw:num_mem.N</code>, refer to the <a class="link" href="http://docs.openstack.org/admin-guide/compute-flavors.html" target="_blank">Flavors</a> guide.</p></div><div class="sect4 " id="id-1.4.7.8.21.5.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Customizing instance CPU pinning policies</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.5.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.7.8.21.5.5.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The functionality described below is currently only supported by the
libvirt/KVM driver.</p></div><p>By default, instance vCPU processes are not assigned to any particular host
CPU, instead, they float across host CPUs like any other process. This allows
for features like overcommitting of CPUs. In heavily contended systems, this
provides optimal system performance at the expense of performance and latency
for individual instances.</p><p>Some workloads require real-time or near real-time behavior, which is not
possible with the latency introduced by the default CPU policy. For such
workloads, it is beneficial to control which host CPUs are bound to an
instance's vCPUs. This process is known as pinning. No instance with pinned
CPUs can use the CPUs of another pinned instance, thus preventing resource
contention between instances. To configure a flavor to use pinned vCPUs, a
use a dedicated CPU policy. To force this, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:cpu_policy=dedicated</pre></div><div id="id-1.4.7.8.21.5.5.6" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Host aggregates should be used to separate pinned instances from unpinned
instances as the latter will not respect the resourcing requirements of
the former.</p></div><p>When running workloads on SMT hosts, it is important to be aware of the impact
that thread siblings can have. Thread siblings share a number of components
and contention on these components can impact performance. To configure how
to use threads, a CPU thread policy should be specified. For workloads where
sharing benefits performance, use thread siblings. To force this, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large \
  --property hw:cpu_policy=dedicated \
  --property hw:cpu_thread_policy=require</pre></div><p>For other workloads where performance is impacted by contention for resources,
use non-thread siblings or non-SMT hosts. To force this, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large \
  --property hw:cpu_policy=dedicated \
  --property hw:cpu_thread_policy=isolate</pre></div><p>Finally, for workloads where performance is minimally impacted, use thread
siblings if available. This is the default, but it can be set explicitly:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large \
  --property hw:cpu_policy=dedicated \
  --property hw:cpu_thread_policy=prefer</pre></div><p>For more information about the syntax for <code class="literal">hw:cpu_policy</code> and
<code class="literal">hw:cpu_thread_policy</code>, refer to the <a class="link" href="http://docs.openstack.org/admin-guide/compute-flavors.html" target="_blank">Flavors</a> guide.</p><p>Applications are frequently packaged as images. For applications that require
real-time or near real-time behavior, configure image metadata to ensure
created instances are always pinned regardless of flavor. To configure an
image to use pinned vCPUs and avoid thread siblings, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set [IMAGE_ID] \
  --property hw_cpu_policy=dedicated \
  --property hw_cpu_thread_policy=isolate</pre></div><p>Image metadata takes precedence over flavor extra specs. Thus, configuring
competing policies causes an exception. By setting a <code class="literal">shared</code> policy
through image metadata, administrators can prevent users configuring CPU
policies in flavors and impacting resource utilization. To configure this
policy, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set [IMAGE_ID] --property hw_cpu_policy=shared</pre></div><div id="id-1.4.7.8.21.5.5.18" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>There is no correlation required between the NUMA topology exposed in the
instance and how the instance is actually pinned on the host. This is by
design. See this <a class="link" href="https://bugs.launchpad.net/nova/+bug/1466780" target="_blank">invalid bug</a> for more information.</p></div><p>For more information about image metadata, refer to the <a class="link" href="http://docs.openstack.org/image-guide/image-metadata.html" target="_blank">Image metadata</a>
guide.</p></div><div class="sect4 " id="id-1.4.7.8.21.5.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Customizing instance CPU topologies</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.5.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.7.8.21.5.6.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The functionality described below is currently only supported by the
libvirt/KVM driver.</p></div><p>In addition to configuring how an instance is scheduled on host CPUs, it is
possible to configure how CPUs are represented in the instance itself. By
default, when instance NUMA placement is not specified, a topology of N
sockets, each with one core and one thread, is used for an instance, where N
corresponds to the number of instance vCPUs requested. When instance NUMA
placement is specified, the number of sockets is fixed to the number of host
NUMA nodes to use and the total number of instance CPUs is split over these
sockets.</p><p>Some workloads benefit from a custom topology. For example, in some operating
systems, a different license may be needed depending on the number of CPU
sockets. To configure a flavor to use a maximum of two sockets, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:cpu_sockets=2</pre></div><p>Similarly, to configure a flavor to use one core and one thread, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large \
  --property hw:cpu_cores=1 \
  --property hw:cpu_threads=1</pre></div><div id="id-1.4.7.8.21.5.6.8" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>If specifying all values, the product of sockets multiplied by cores
multiplied by threads must equal the number of instance vCPUs. If specifying
any one of these values or the multiple of two values, the values must be a
factor of the number of instance vCPUs to prevent an exception. For example,
specifying <code class="literal">hw:cpu_sockets=2</code> on a host with an odd number of cores fails.
Similarly, specifying <code class="literal">hw:cpu_cores=2</code> and <code class="literal">hw:cpu_threads=4</code> on a host
with ten cores fails.</p></div><p>For more information about the syntax for <code class="literal">hw:cpu_sockets</code>, <code class="literal">hw:cpu_cores</code>
and <code class="literal">hw:cpu_threads</code>, refer to the <a class="link" href="http://docs.openstack.org/admin-guide/compute-flavors.html" target="_blank">Flavors</a> guide.</p><p>It is also possible to set upper limits on the number of sockets, cores, and
threads used. Unlike the hard values above, it is not necessary for this exact
number to used because it only provides a limit. This can be used to provide
some flexibility in scheduling, while ensuring certains limits are not
exceeded. For example, to ensure no more than two sockets are defined in the
instance topology, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property=hw:cpu_max_sockets=2</pre></div><p>For more information about the syntax for <code class="literal">hw:cpu_max_sockets</code>,
<code class="literal">hw:cpu_max_cores</code>, and <code class="literal">hw:cpu_max_threads</code>, refer to the <a class="link" href="http://docs.openstack.org/admin-guide/compute-flavors.html" target="_blank">Flavors</a>
guide.</p><p>Applications are frequently packaged as images. For applications that prefer
certain CPU topologies, configure image metadata to hint that created instances
should have a given topology regardless of flavor. To configure an image to
request a two-socket, four-core per socket topology, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set [IMAGE_ID] \
  --property hw_cpu_sockets=2 \
  --property hw_cpu_cores=4</pre></div><p>To constrain instances to a given limit of sockets, cores or threads, use the
<code class="literal">max_</code> variants. To configure an image to have a maximum of two sockets and a
maximum of one thread, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set [IMAGE_ID] \
  --property hw_cpu_max_sockets=2 \
  --property hw_cpu_max_threads=1</pre></div><p>Image metadata takes precedence over flavor extra specs. Configuring competing
constraints causes an exception. By setting a <code class="literal">max</code> value for sockets, cores,
or threads, administrators can prevent users configuring topologies that might,
for example, incur an additional licensing fees.</p><p>For more information about image metadata, refer to the <a class="link" href="http://docs.openstack.org/image-guide/image-metadata.html" target="_blank">Image metadata</a>
guide.</p></div></div><div class="sect3 " id="id-1.4.7.8.21.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.4.15.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Huge pages</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The huge page feature in OpenStack provides important performance improvements
for applications that are highly memory IO-bound.</p><div id="id-1.4.7.8.21.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Huge pages may also be referred to hugepages or large pages, depending on
the source. These terms are synonyms.</p></div><div class="sect4 " id="id-1.4.7.8.21.6.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Pages, the TLB and huge pages</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.6.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.8.21.6.4.2.1"><span class="term ">Pages</span></dt><dd><p>Physical memory is segmented into a series of contiguous regions called
pages. Each page contains a number of bytes, referred to as the page size.
The system retrieves memory by accessing entire pages, rather than byte by
byte.</p></dd><dt id="id-1.4.7.8.21.6.4.2.2"><span class="term ">Translation Lookaside Buffer (TLB)</span></dt><dd><p>A TLB is used to map the virtual addresses of pages to the physical addresses
in actual memory. The TLB is a cache and is not limitless, storing only the
most recent or frequently accessed pages. During normal operation, processes
will sometimes attempt to retrieve pages that are not stored in the cache.
This is known as a TLB miss and results in a delay as the processor iterates
through the pages themselves to find the missing address mapping.</p></dd><dt id="id-1.4.7.8.21.6.4.2.3"><span class="term ">Huge Pages</span></dt><dd><p>The standard page size in x86 systems is 4 kB. This is optimal for general
purpose computing but larger page sizes - 2 MB and 1 GB - are also available.
These larger page sizes are known as huge pages. Huge pages result in less
efficient memory usage as a process will not generally use all memory
available in each page. However, use of huge pages will result in fewer
overall pages and a reduced risk of TLB misses. For processes that have
significant memory requirements or are memory intensive, the benefits of huge
pages frequently outweigh the drawbacks.</p></dd><dt id="id-1.4.7.8.21.6.4.2.4"><span class="term ">Persistent Huge Pages</span></dt><dd><p>On Linux hosts, persistent huge pages are huge pages that are reserved
upfront. The HugeTLB provides for the mechanism for this upfront
configuration of huge pages. The HugeTLB allows for the allocation of varying
quantities of different huge page sizes. Allocation can be made at boot time
or run time. Refer to the <a class="link" href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt" target="_blank">Linux hugetlbfs guide</a> for more information.</p></dd><dt id="id-1.4.7.8.21.6.4.2.5"><span class="term ">Transparent Huge Pages (THP)</span></dt><dd><p>On Linux hosts, transparent huge pages are huge pages that are automatically
provisioned based on process requests. Transparent huge pages are provisioned
on a best effort basis, attempting to provision 2 MB huge pages if available
but falling back to 4 kB small pages if not. However, no upfront
configuration is necessary. Refer to the <a class="link" href="https://www.kernel.org/doc/Documentation/vm/transhuge.txt" target="_blank">Linux THP guide</a> for more
information.</p></dd></dl></div></div><div class="sect4 " id="id-1.4.7.8.21.6.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling huge pages on the host</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.6.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Persistent huge pages are required owing to their guaranteed availability.
However, persistent huge pages are not enabled by default in most environments.
The steps for enabling huge pages differ from platform to platform and only the
steps for Linux hosts are described here. On Linux hosts, the number of
persistent huge pages on the host can be queried by checking <code class="literal">/proc/meminfo</code>:</p><div class="verbatim-wrap"><pre class="screen">$ grep Huge /proc/meminfo
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB</pre></div><p>In this instance, there are 0 persistent huge pages (<code class="literal">HugePages_Total</code>) and 0
transparent huge pages (<code class="literal">AnonHugePages</code>) allocated. Huge pages can be
allocated at boot time or run time. Huge pages require a contiguous area of
memory - memory that gets increasingly fragmented the long a host is running.
Identifying contiguous areas of memory is a issue for all huge page sizes, but
it's particularly problematic for larger huge page sizes such as 1 GB huge
pages. Allocating huge pages at boot time will ensure the correct number of huge
pages is always available, while allocating them at run time can fail if memory
has become too fragmented.</p><p>To allocate huge pages at run time, the kernel boot parameters must be extended
to include some huge page-specific parameters. This can be achieved by
modifying <code class="literal">/etc/default/grub</code> and appending the <code class="literal">hugepagesz</code>,
<code class="literal">hugepages</code>, and <code class="literal">transparent_hugepages=never</code> arguments to
<code class="literal">GRUB_CMDLINE_LINUX</code>. To allocate, for example, 2048 persistent 2 MB huge
pages at boot time, run:</p><div class="verbatim-wrap"><pre class="screen"># echo 'GRUB_CMDLINE_LINUX="$GRUB_CMDLINE_LINUX hugepagesz=2M hugepages=2048 transparent_hugepage=never"' &gt; /etc/default/grub
$ grep GRUB_CMDLINE_LINUX /etc/default/grub
GRUB_CMDLINE_LINUX="..."
GRUB_CMDLINE_LINUX="$GRUB_CMDLINE_LINUX hugepagesz=2M hugepages=2048 transparent_hugepage=never"</pre></div><div id="id-1.4.7.8.21.6.5.7" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Persistent huge pages are not usable by standard host OS processes. Ensure
enough free, non-huge page memory is reserved for these processes.</p></div><p>Reboot the host, then validate that huge pages are now available:</p><div class="verbatim-wrap"><pre class="screen">$ grep "Huge" /proc/meminfo
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
HugePages_Total:    2048
HugePages_Free:     2048
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB</pre></div><p>There are now 2048 2 MB huge pages totalling 4 GB of huge pages. These huge
pages must be mounted. On most platforms, this happens automatically. To verify
that the huge pages are mounted, run:</p><div class="verbatim-wrap"><pre class="screen"># mount | grep huge
hugetlbfs on /dev/hugepages type hugetlbfs (rw)</pre></div><p>In this instance, the huge pages are mounted at <code class="literal">/dev/hugepages</code>. This mount
point varies from platform to platform. If the above command did not return
anything, the hugepages must be mounted manually. To mount the huge pages at
<code class="literal">/dev/hugepages</code>, run:</p><div class="verbatim-wrap"><pre class="screen"># mkdir -p /dev/hugepages
# mount -t hugetlbfs hugetlbfs /dev/hugepages</pre></div><p>There are many more ways to configure huge pages, including allocating huge
pages at run time, specifying varying allocations for different huge page
sizes, or allocating huge pages from memory affinitized to different NUMA
nodes. For more information on configuring huge pages on Linux hosts, refer to
the <a class="link" href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt" target="_blank">Linux hugetlbfs guide</a>.</p></div><div class="sect4 " id="id-1.4.7.8.21.6.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">5.4.15.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Customizing instance huge pages allocations</span> <a title="Permalink" class="permalink" href="#id-1.4.7.8.21.6.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.7.8.21.6.6.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The functionality described below is currently only supported by the
libvirt/KVM driver.</p></div><div id="id-1.4.7.8.21.6.6.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>For performance reasons, configuring huge pages for an instance will
implicitly result in a NUMA topology being configured for the instance.
Configuring a NUMA topology for an instance requires enablement of
<code class="literal">NUMATopologyFilter</code>. Refer to <a class="xref" href="#sec-cpu-topo" title="5.4.15.2. CPU topologies">Section 5.4.15.2, “CPU topologies”</a> for more
information.</p></div><p>By default, an instance does not use huge pages for its underlying memory.
However, huge pages can bring important or required performance improvements
for some workloads. Huge pages must be requested explicitly through the use of
flavor extra specs or image metadata. To request an instance use huge pages,
run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:mem_page_size=large</pre></div><p>Different platforms offer different huge page sizes. For example: x86-based
platforms offer 2 MB and 1 GB huge page sizes. Specific huge page sizes can be
also be requested, with or without a unit suffix. The unit suffix must be one
of: Kb(it), Kib(it), Mb(it), Mib(it), Gb(it), Gib(it), Tb(it), Tib(it), KB,
KiB, MB, MiB, GB, GiB, TB, TiB. Where a unit suffix is not provided, Kilobytes
are assumed. To request an instance to use 2 MB huge pages, run one of:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:mem_page_size=2Mb</pre></div><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:mem_page_size=2048</pre></div><p>Enabling huge pages for an instance can have negative consequences for other
instances by consuming limited huge pages resources. To explicitly request
an instance use small pages, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:mem_page_size=small</pre></div><div id="id-1.4.7.8.21.6.6.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Explicitly requesting any page size will still result in a NUMA topology
being applied to the instance, as described earlier in this document.</p></div><p>Finally, to leave the decision of huge or small pages to the compute driver,
run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor set m1.large --property hw:mem_page_size=any</pre></div><p>For more information about the syntax for <code class="literal">hw:mem_page_size</code>, refer to the
<a class="link" href="http://docs.openstack.org/admin-guide/compute-flavors.html" target="_blank">Flavors</a> guide.</p><p>Applications are frequently packaged as images. For applications that require
the IO performance improvements that huge pages provides, configure image
metadata to ensure instances always request the specific page size regardless
of flavor. To configure an image to use 1 GB huge pages, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set [IMAGE_ID]  --property hw_mem_page_size=1GB</pre></div><p>Image metadata takes precedence over flavor extra specs. Thus, configuring
competing page sizes causes an exception. By setting a <code class="literal">small</code> page size
through image metadata, administrators can prevent users requesting huge pages
in flavors and impacting resource utilization. To configure this page size,
run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set [IMAGE_ID] --property hw_mem_page_size=small</pre></div><div id="id-1.4.7.8.21.6.6.19" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Explicitly requesting any page size will still result in a NUMA topology
being applied to the instance, as described earlier in this document.</p></div><p>For more information about image metadata, refer to the <a class="link" href="http://docs.openstack.org/image-guide/image-metadata.html" target="_blank">Image metadata</a>
guide.</p></div></div></div></div><div class="sect1 " id="id-1.4.7.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot Compute</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Common problems for Compute typically involve misconfigured
networking or credentials that are not sourced properly in the
environment. Also, most flat networking configurations do not
enable <code class="command">ping</code> or <code class="command">ssh</code> from a compute node
to the instances that run on that node. Another common problem
is trying to run 32-bit images on a 64-bit compute node.
This section shows you how to troubleshoot Compute.</p><div class="sect2 " id="id-1.4.7.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute service logging</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Compute stores a log file for each service in
<code class="literal">/var/log/nova</code>. For example, <code class="literal">nova-compute.log</code>
is the log for the <code class="literal">nova-compute</code> service. You can set the
following options to format log strings for the <code class="literal">nova.log</code>
module in the <code class="literal">nova.conf</code> file:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <code class="literal">logging_context_format_string</code>
            </p></li><li class="listitem "><p>
              <code class="literal">logging_default_format_string</code>
            </p></li></ul></div><p>If the log level is set to <code class="literal">debug</code>, you can also specify
<code class="literal">logging_debug_format_suffix</code> to append extra formatting.
For information about what variables are available for the
formatter, see <a class="link" href="http://docs.python.org/library/logging.html#formatter-objects" target="_blank">Formatter Objects</a>.</p><p>You have two logging options for OpenStack Compute based on
configuration settings. In <code class="literal">nova.conf</code>, include the
<code class="literal">logfile</code> option to enable logging. Alternatively you can set
<code class="literal">use_syslog = 1</code> so that the nova daemon logs to syslog.</p></div><div class="sect2 " id="id-1.4.7.9.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Guru Meditation reports</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A Guru Meditation report is sent by the Compute service upon receipt of the
<code class="literal">SIGUSR2</code> signal (<code class="literal">SIGUSR1</code> before Mitaka). This report is a
general-purpose error report that includes details about the current state
of the service. The error report is sent to <code class="literal">stderr</code>.</p><p>For example, if you redirect error output to <code class="literal">nova-api-err.log</code>
using <code class="command">nova-api 2&gt;/var/log/nova/nova-api-err.log</code>,
resulting in the process ID 8675, you can then run:</p><div class="verbatim-wrap"><pre class="screen"># kill -USR2 8675</pre></div><p>This command triggers the Guru Meditation report to be printed to
<code class="literal">/var/log/nova/nova-api-err.log</code>.</p><p>The report has the following sections:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Package: Displays information about the package to which the process
belongs, including version information.</p></li><li class="listitem "><p>Threads: Displays stack traces and thread IDs for each of the threads
within the process.</p></li><li class="listitem "><p>Green Threads: Displays stack traces for each of the green threads
within the process (green threads do not have thread IDs).</p></li><li class="listitem "><p>Configuration: Lists all configuration options currently accessible
through the CONF object for the current process.</p></li></ul></div><p>For more information, see <a class="link" href="http://docs.openstack.org/developer/nova/devref/gmr.html" target="_blank">Guru Meditation Reports</a>.</p></div><div class="sect2 " id="compute-common-errors-and-fixes"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Common errors and fixes for Compute</span> <a title="Permalink" class="permalink" href="#compute-common-errors-and-fixes">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>compute-common-errors-and-fixes</li></ul></div></div></div></div><p>The <a class="link" href="http://ask.openstack.org" target="_blank">ask.openstack.org</a> site offers a place to ask
and answer questions, and you can also mark questions as frequently asked
questions. This section describes some errors people have posted previously.
Bugs are constantly being fixed, so online resources are a great way to get
the most up-to-date errors and fixes.</p></div><div class="sect2 " id="id-1.4.7.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Credential errors, 401, and 403 forbidden errors</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.9.6.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.6.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Missing credentials cause a <code class="literal">403 forbidden</code> error.</p></div><div class="sect3 " id="id-1.4.7.9.6.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.6.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To resolve this issue, use one of these methods:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.9.6.3.3.1.1.1"><span class="term ">Manual method</span></dt><dd><p>Gets the <code class="literal">novarc</code> file from the project ZIP file, saves existing
credentials in case of override, and manually sources the <code class="literal">novarc</code>
file.</p></dd></dl></div></li><li class="step "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.7.9.6.3.3.2.1.1"><span class="term ">Script method</span></dt><dd><p>Generates <code class="literal">novarc</code> from the project ZIP file and sources it for you.</p></dd></dl></div></li></ol></div></div><p>When you run <code class="literal">nova-api</code> the first time, it generates the certificate
authority information, including <code class="literal">openssl.cnf</code>. If you
start the CA services before this, you might not be
able to create your ZIP file. Restart the services.
When your CA information is available, create your ZIP file.</p><p>Also, check your HTTP proxy settings to see whether they cause problems with
<code class="literal">novarc</code> creation.</p></div></div><div class="sect2 " id="id-1.4.7.9.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Instance errors</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.9.7.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.7.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Sometimes a particular instance shows <code class="literal">pending</code> or you cannot SSH to
it. Sometimes the image itself is the problem. For example, when you
use flat manager networking, you do not have a DHCP server and certain
images do not support interface injection; you cannot connect to
them.</p></div><div class="sect3 " id="id-1.4.7.9.7.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.7.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To fix instance errors use an image that does support
this method, such as Ubuntu, which obtains an IP address correctly
with FlatManager network settings.</p><p>To troubleshoot other possible problems with an instance, such as
an instance that stays in a spawning state, check the directory for
the particular instance under <code class="literal">/var/lib/nova/instances</code> on
the <code class="literal">nova-compute</code> host and make sure that these files are present:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">libvirt.xml</code>
              </p></li><li class="listitem "><p>
                <code class="literal">disk</code>
              </p></li><li class="listitem "><p>
                <code class="literal">disk-raw</code>
              </p></li><li class="listitem "><p>
                <code class="literal">kernel</code>
              </p></li><li class="listitem "><p>
                <code class="literal">ramdisk</code>
              </p></li><li class="listitem "><p><code class="literal">console.log</code>, after the instance starts.</p></li></ul></div><p>If any files are missing, empty, or very small, the <code class="literal">nova-compute</code>
service did not successfully download the images from the Image service.</p><p>Also check <code class="literal">nova-compute.log</code> for exceptions. Sometimes they do not
appear in the console output.</p><p>Next, check the log file for the instance in the <code class="literal">/var/log/libvirt/qemu</code>
directory to see if it exists and has any useful error messages in it.</p><p>Finally, from the <code class="literal">/var/lib/nova/instances</code> directory for the instance,
see if this command returns an error:</p><div class="verbatim-wrap"><pre class="screen"># virsh create libvirt.xml</pre></div></div></div><div class="sect2 " id="id-1.4.7.9.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Empty log output for Linux instances</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.9.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.8.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can view the log output of running instances
from either the <span class="guimenu ">Log</span> tab of the dashboard or the output of
<code class="command">nova console-log</code>. In some cases, the log output of a running
Linux instance will be empty or only display a single character (for example,
the <code class="literal">?</code> character).</p><p>This occurs when the Compute service attempts to retrieve the log output
of the instance via a serial console while the instance itself is not
configured to send output to the console.</p></div><div class="sect3 " id="id-1.4.7.9.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To rectify this, append the following parameters to kernel arguments
specified in the instance's boot loader:</p><div class="verbatim-wrap highlight ini"><pre class="screen">console=tty0 console=ttyS0,115200n8</pre></div><p>Upon rebooting, the instance will be configured to send output to the Compute
service.</p></div></div><div class="sect2 " id="id-1.4.7.9.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Reset the state of an instance</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.9.9.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.9.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Instances can remain in an intermediate state, such as <code class="literal">deleting</code>.</p></div><div class="sect3 " id="id-1.4.7.9.9.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.9.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can use the <code class="command">nova reset-state</code> command to manually reset
the state of an instance to an error state. You can then delete the
instance. For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova reset-state c6bbbf26-b40a-47e7-8d5c-eb17bf65c485
$ openstack server delete c6bbbf26-b40a-47e7-8d5c-eb17bf65c485</pre></div><p>You can also use the <code class="literal">--active</code> parameter to force the instance back
to an active state instead of an error state. For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova reset-state --active c6bbbf26-b40a-47e7-8d5c-eb17bf65c485</pre></div></div></div><div class="sect2 " id="id-1.4.7.9.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Injection problems</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.9.10.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.10.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Instances may boot slowly, or do not boot. File injection can cause this
problem.</p></div><div class="sect3 " id="id-1.4.7.9.10.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.10.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To disable injection in libvirt, set the following in <code class="literal">nova.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[libvirt]
inject_partition = -2</pre></div><div id="id-1.4.7.9.10.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you have not enabled the configuration drive and
you want to make user-specified files available from
the metadata server for to improve performance and
avoid boot failure if injection fails, you must
disable injection.</p></div></div></div><div class="sect2 " id="id-1.4.7.9.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disable live snapshotting</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.7.9.11.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.11.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Administrators using libvirt version <code class="literal">1.2.2</code> may experience problems
with live snapshot creation. Occasionally, libvirt version <code class="literal">1.2.2</code> fails
to create live snapshots under the load of creating concurrent snapshot.</p></div><div class="sect3 " id="id-1.4.7.9.11.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.7.9.11.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To effectively disable the libvirt live snapshotting, until the problem
is resolved, configure the <code class="literal">disable_libvirt_livesnapshot</code> option.
You can turn off the live snapshotting mechanism by setting up its value to
<code class="literal">True</code> in the <code class="literal">[workarounds]</code> section of the <code class="literal">nova.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[workarounds]
disable_libvirt_livesnapshot = True</pre></div></div></div></div></div><div class="chapter " id="id-1.4.8"><div class="titlepage"><div><div><h1 class="title"><span class="number">6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.8">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.8.3"><span class="number">6.1 </span><span class="name">Introduction to Object Storage</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.4"><span class="number">6.2 </span><span class="name">Features and benefits</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.5"><span class="number">6.3 </span><span class="name">Object Storage characteristics</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.6"><span class="number">6.4 </span><span class="name">Components</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.7"><span class="number">6.5 </span><span class="name">Ring-builder</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.8"><span class="number">6.6 </span><span class="name">Cluster architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.9"><span class="number">6.7 </span><span class="name">Replication</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.10"><span class="number">6.8 </span><span class="name">Large object support</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.11"><span class="number">6.9 </span><span class="name">Object Auditor</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.12"><span class="number">6.10 </span><span class="name">Erasure coding</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.13"><span class="number">6.11 </span><span class="name">Account reaper</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.14"><span class="number">6.12 </span><span class="name">Configure project-specific image locations with Object Storage</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.15"><span class="number">6.13 </span><span class="name">Object Storage monitoring</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.16"><span class="number">6.14 </span><span class="name">System administration for Object Storage</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.8.17"><span class="number">6.15 </span><span class="name">Troubleshoot Object Storage</span></a></span></dt></dl></div></div><div class="sect1 " id="id-1.4.8.3"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction to Object Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.8.3">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Object Storage (swift) is used for redundant, scalable data
storage using clusters of standardized servers to store petabytes of
accessible data. It is a long-term storage system for large amounts of
static data which can be retrieved and updated. Object Storage uses a
distributed architecture
with no central point of control, providing greater scalability,
redundancy, and permanence. Objects are written to multiple hardware
devices, with the OpenStack software responsible for ensuring data
replication and integrity across the cluster. Storage clusters scale
horizontally by adding new nodes. Should a node fail, OpenStack works to
replicate its content from other active nodes. Because OpenStack uses
software logic to ensure data replication and distribution across
different devices, inexpensive commodity hard drives and servers can be
used in lieu of more expensive equipment.</p><p>Object Storage is ideal for cost effective, scale-out storage. It
provides a fully distributed, API-accessible storage platform that can
be integrated directly into applications or used for backup, archiving,
and data retention.</p></div><div class="sect1 " id="id-1.4.8.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Features and benefits</span> <a title="Permalink" class="permalink" href="#id-1.4.8.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                <p>Features</p>
              </th><th>
                <p>Benefits</p>
              </th></tr></thead><tbody><tr><td>
                <p>Leverages commodity hardware</p>
              </td><td>
                <p>No lock-in, lower price/GB.</p>
              </td></tr><tr><td>
                <p>HDD/node failure agnostic</p>
              </td><td>
                <p>Self-healing, reliable, data redundancy protects from failures.</p>
              </td></tr><tr><td>
                <p>Unlimited storage</p>
              </td><td>
                <p>Large and flat namespace, highly scalable read/write access,
able to serve content directly from storage system.</p>
              </td></tr><tr><td>
                <p>Multi-dimensional scalability</p>
              </td><td>
                <p>Scale-out architecture: Scale vertically and
horizontally-distributed storage. Backs up and archives large
amounts of data with linear performance.</p>
              </td></tr><tr><td>
                <p>Account/container/object structure</p>
              </td><td>
                <p>No nesting, not a traditional file system: Optimized for scale,
it scales to multiple petabytes and billions of objects.</p>
              </td></tr><tr><td>
                <p>Built-in replication 3✕ + data redundancy (compared with 2✕ on
RAID)</p>
              </td><td>
                <p>A configurable number of accounts, containers and object copies
for high availability.</p>
              </td></tr><tr><td>
                <p>Easily add capacity (unlike RAID resize)</p>
              </td><td>
                <p>Elastic data scaling with ease.</p>
              </td></tr><tr><td>
                <p>No central database</p>
              </td><td>
                <p>Higher performance, no bottlenecks.</p>
              </td></tr><tr><td>
                <p>RAID not required</p>
              </td><td>
                <p>Handle many small, random reads and writes efficiently.</p>
              </td></tr><tr><td>
                <p>Built-in management utilities</p>
              </td><td>
                <p>Account management: Create, add, verify, and delete users;
Container management: Upload, download, and verify; Monitoring:
Capacity, host, network, log trawling, and cluster health.</p>
              </td></tr><tr><td>
                <p>Drive auditing</p>
              </td><td>
                <p>Detect drive failures preempting data corruption.</p>
              </td></tr><tr><td>
                <p>Expiring objects</p>
              </td><td>
                <p>Users can set an expiration time or a TTL on an object to
control access.</p>
              </td></tr><tr><td>
                <p>Direct object access</p>
              </td><td>
                <p>Enable direct browser access to content, such as for a control
panel.</p>
              </td></tr><tr><td>
                <p>Realtime visibility into client requests</p>
              </td><td>
                <p>Know what users are requesting.</p>
              </td></tr><tr><td>
                <p>Supports S3 API</p>
              </td><td>
                <p>Utilize tools that were designed for the popular S3 API.</p>
              </td></tr><tr><td>
                <p>Restrict containers per account</p>
              </td><td>
                <p>Limit access to control usage by user.</p>
              </td></tr><tr><td>
                <p>Support for NetApp, Nexenta, Solidfire</p>
              </td><td>
                <p>Unified support for block volumes using a variety of storage
systems.</p>
              </td></tr><tr><td>
                <p>Snapshot and backup API for block volumes.</p>
              </td><td>
                <p>Data protection and recovery for VM data.</p>
              </td></tr><tr><td>
                <p>Standalone volume API available</p>
              </td><td>
                <p>Separate endpoint and API for integration with other compute
systems.</p>
              </td></tr><tr><td>
                <p>Integration with Compute</p>
              </td><td>
                <p>Fully integrated with Compute for attaching block volumes and
reporting on usage.</p>
              </td></tr></tbody></table></div></div><div class="sect1 " id="id-1.4.8.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object Storage characteristics</span> <a title="Permalink" class="permalink" href="#id-1.4.8.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The key characteristics of Object Storage are that:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>All objects stored in Object Storage have a URL.</p></li><li class="listitem "><p>All objects stored are replicated 3✕ in as-unique-as-possible zones,
which can be defined as a group of drives, a node, a rack, and so on.</p></li><li class="listitem "><p>All objects have their own metadata.</p></li><li class="listitem "><p>Developers interact with the object storage system through a RESTful
HTTP API.</p></li><li class="listitem "><p>Object data can be located anywhere in the cluster.</p></li><li class="listitem "><p>The cluster scales by adding additional nodes without sacrificing
performance, which allows a more cost-effective linear storage
expansion than fork-lift upgrades.</p></li><li class="listitem "><p>Data does not have to be migrated to an entirely new storage system.</p></li><li class="listitem "><p>New nodes can be added to the cluster without downtime.</p></li><li class="listitem "><p>Failed nodes and disks can be swapped out without downtime.</p></li><li class="listitem "><p>It runs on industry-standard hardware, such as Dell, HP, and
Supermicro.</p></li></ul></div><p>Object Storage (swift)</p><div class="figure" id="id-1.4.8.5.5"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage.png" target="_blank"><img src="images/objectstorage.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.1: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.5.5">#</a></h6></div></div><p>Developers can either write directly to the Swift API or use one of the
many client libraries that exist for all of the popular programming
languages, such as Java, Python, Ruby, and C#. Amazon S3 and RackSpace
Cloud Files users should be very familiar with Object Storage. Users new
to object storage systems will have to adjust to a different approach
and mindset than those required for a traditional filesystem.</p></div><div class="sect1 " id="id-1.4.8.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Components</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Object Storage uses the following components to deliver high
availability, high durability, and high concurrency:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Proxy servers</strong></span> - Handle all of the incoming API requests.</p></li><li class="listitem "><p><span class="bold"><strong>Rings</strong></span> - Map logical names of data to locations on particular
disks.</p></li><li class="listitem "><p><span class="bold"><strong>Zones</strong></span> - Isolate data from other zones. A failure in one zone
does not impact the rest of the cluster as data replicates
across zones.</p></li><li class="listitem "><p><span class="bold"><strong>Accounts and containers</strong></span> - Each account and container are
individual databases that are distributed across the cluster. An
account database contains the list of containers in that account. A
container database contains the list of objects in that container.</p></li><li class="listitem "><p><span class="bold"><strong>Objects</strong></span> - The data itself.</p></li><li class="listitem "><p><span class="bold"><strong>Partitions</strong></span> - A partition stores objects, account databases, and
container databases and helps manage locations where data lives in
the cluster.</p></li></ul></div><p>
        <span class="bold"><strong>Object Storage building blocks</strong></span>
      </p><div class="figure" id="id-1.4.8.6.5"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-buildingblocks.png" target="_blank"><img src="images/objectstorage-buildingblocks.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.2: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.5">#</a></h6></div></div><div class="sect2 " id="id-1.4.8.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Proxy servers</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Proxy servers are the public face of Object Storage and handle all of
the incoming API requests. Once a proxy server receives a request, it
determines the storage node based on the object's URL, for example:
<a class="link" href="https://swift.example.com/v1/account/container/object" target="_blank">https://swift.example.com/v1/account/container/object</a>. Proxy servers
also coordinate responses, handle failures, and coordinate timestamps.</p><p>Proxy servers use a shared-nothing architecture and can be scaled as
needed based on projected workloads. A minimum of two proxy servers
should be deployed for redundancy. If one proxy server fails, the others
take over.</p><p>For more information concerning proxy server configuration, see
<a class="link" href="http://docs.openstack.org/newton/config-reference/object-storage/proxy-server.html" target="_blank">Configuration Reference</a>.</p></div><div class="sect2 " id="id-1.4.8.6.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Rings</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A ring represents a mapping between the names of entities stored on disks
and their physical locations. There are separate rings for accounts,
containers, and objects. When other components need to perform any
operation on an object, container, or account, they need to interact
with the appropriate ring to determine their location in the cluster.</p><p>The ring maintains this mapping using zones, devices, partitions, and
replicas. Each partition in the ring is replicated, by default, three
times across the cluster, and partition locations are stored in the
mapping maintained by the ring. The ring is also responsible for
determining which devices are used for handoff in failure scenarios.</p><p>Data can be isolated into zones in the ring. Each partition replica is
guaranteed to reside in a different zone. A zone could represent a
drive, a server, a cabinet, a switch, or even a data center.</p><p>The partitions of the ring are equally divided among all of the devices
in the Object Storage installation. When partitions need to be moved
around (for example, if a device is added to the cluster), the ring
ensures that a minimum number of partitions are moved at a time, and
only one replica of a partition is moved at a time.</p><p>You can use weights to balance the distribution of partitions on drives
across the cluster. This can be useful, for example, when differently
sized drives are used in a cluster.</p><p>The ring is used by the proxy server and several background processes
(like replication).</p><p>
          <span class="bold"><strong>The ring</strong></span>
        </p><div class="figure" id="id-1.4.8.6.7.9"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-ring.png" target="_blank"><img src="images/objectstorage-ring.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.3: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.7.9">#</a></h6></div></div><p>These rings are externally managed. The server processes themselves
do not modify the rings, they are instead given new rings modified by
other tools.</p><p>The ring uses a configurable number of bits from an <code class="literal">MD5</code> hash for a path
as a partition index that designates a device. The number of bits kept
from the hash is known as the partition power, and 2 to the partition
power indicates the partition count. Partitioning the full <code class="literal">MD5</code> hash ring
allows other parts of the cluster to work in batches of items at once
which ends up either more efficient or at least less complex than
working with each item separately or the entire cluster all at once.</p><p>Another configurable value is the replica count, which indicates how
many of the partition-device assignments make up a single ring. For a
given partition number, each replica's device will not be in the same
zone as any other replica's device. Zones can be used to group devices
based on physical locations, power separations, network separations, or
any other attribute that would improve the availability of multiple
replicas at the same time.</p></div><div class="sect2 " id="id-1.4.8.6.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Zones</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Object Storage allows configuring zones in order to isolate failure
boundaries. If possible, each data replica resides in a separate zone.
At the smallest level, a zone could be a single drive or a grouping of a
few drives. If there were five object storage servers, then each server
would represent its own zone. Larger deployments would have an entire
rack (or multiple racks) of object servers, each representing a zone.
The goal of zones is to allow the cluster to tolerate significant
outages of storage servers without losing all replicas of the data.</p><p>
          <span class="bold"><strong>Zones</strong></span>
        </p><div class="figure" id="id-1.4.8.6.8.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-zones.png" target="_blank"><img src="images/objectstorage-zones.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.4: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.8.4">#</a></h6></div></div></div><div class="sect2 " id="id-1.4.8.6.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accounts and containers</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Each account and container is an individual SQLite database that is
distributed across the cluster. An account database contains the list of
containers in that account. A container database contains the list of
objects in that container.</p><p>
          <span class="bold"><strong>Accounts and containers</strong></span>
        </p><div class="figure" id="id-1.4.8.6.9.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-accountscontainers.png" target="_blank"><img src="images/objectstorage-accountscontainers.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.5: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.9.4">#</a></h6></div></div><p>To keep track of object data locations, each account in the system has a
database that references all of its containers, and each container
database references each object.</p></div><div class="sect2 " id="id-1.4.8.6.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Partitions</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A partition is a collection of stored data. This includes account databases,
container databases, and objects. Partitions are core to the replication
system.</p><p>Think of a partition as a bin moving throughout a fulfillment center
warehouse. Individual orders get thrown into the bin. The system treats
that bin as a cohesive entity as it moves throughout the system. A bin
is easier to deal with than many little things. It makes for fewer
moving parts throughout the system.</p><p>System replicators and object uploads/downloads operate on partitions.
As the system scales up, its behavior continues to be predictable
because the number of partitions is a fixed number.</p><p>Implementing a partition is conceptually simple, a partition is just a
directory sitting on a disk with a corresponding hash table of what it
contains.</p><p>
          <span class="bold"><strong>Partitions</strong></span>
        </p><div class="figure" id="id-1.4.8.6.10.7"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-partitions.png" target="_blank"><img src="images/objectstorage-partitions.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.6: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.10.7">#</a></h6></div></div></div><div class="sect2 " id="id-1.4.8.6.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Replicators</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In order to ensure that there are three copies of the data everywhere,
replicators continuously examine each partition. For each local
partition, the replicator compares it against the replicated copies in
the other zones to see if there are any differences.</p><p>The replicator knows if replication needs to take place by examining
hashes. A hash file is created for each partition, which contains hashes
of each directory in the partition. Each of the three hash files is
compared. For a given partition, the hash files for each of the
partition's copies are compared. If the hashes are different, then it is
time to replicate, and the directory that needs to be replicated is
copied over.</p><p>This is where partitions come in handy. With fewer things in the system,
larger chunks of data are transferred around (rather than lots of little
TCP connections, which is inefficient) and there is a consistent number
of hashes to compare.</p><p>The cluster eventually has a consistent behavior where the newest data
has a priority.</p><p>
          <span class="bold"><strong>Replication</strong></span>
        </p><div class="figure" id="id-1.4.8.6.11.7"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-replication.png" target="_blank"><img src="images/objectstorage-replication.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.7: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.11.7">#</a></h6></div></div><p>If a zone goes down, one of the nodes containing a replica notices and
proactively copies data to a handoff location.</p></div><div class="sect2 " id="id-1.4.8.6.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.4.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use cases</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following sections show use cases for object uploads and downloads
and introduce the components.</p><div class="sect3 " id="id-1.4.8.6.12.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.4.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upload</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.12.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A client uses the REST API to make a HTTP request to PUT an object into
an existing container. The cluster receives the request. First, the
system must figure out where the data is going to go. To do this, the
account name, container name, and object name are all used to determine
the partition where this object should live.</p><p>Then a lookup in the ring figures out which storage nodes contain the
partitions in question.</p><p>The data is then sent to each storage node where it is placed in the
appropriate partition. At least two of the three writes must be
successful before the client is notified that the upload was successful.</p><p>Next, the container database is updated asynchronously to reflect that
there is a new object in it.</p><p>
            <span class="bold"><strong>Object Storage in use</strong></span>
          </p><div class="figure" id="id-1.4.8.6.12.3.7"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-usecase.png" target="_blank"><img src="images/objectstorage-usecase.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.8: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.6.12.3.7">#</a></h6></div></div></div><div class="sect3 " id="id-1.4.8.6.12.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.4.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Download</span> <a title="Permalink" class="permalink" href="#id-1.4.8.6.12.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A request comes in for an account/container/object. Using the same
consistent hashing, the partition name is generated. A lookup in the
ring reveals which storage nodes contain that partition. A request is
made to one of the storage nodes to fetch the object and, if that fails,
requests are made to the other nodes.</p></div></div></div><div class="sect1 " id="id-1.4.8.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ring-builder</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use the swift-ring-builder utility to build and manage rings. This
utility assigns partitions to devices and writes an optimized Python
structure to a gzipped, serialized file on disk for transmission to the
servers. The server processes occasionally check the modification time
of the file and reload in-memory copies of the ring structure as needed.
If you use a slightly older version of the ring, one of the three
replicas for a partition subset will be incorrect because of the way the
ring-builder manages changes to the ring. You can work around this
issue.</p><p>The ring-builder also keeps its own builder file with the ring
information and additional data required to build future rings. It is
very important to keep multiple backup copies of these builder files.
One option is to copy the builder files out to every server while
copying the ring files themselves. Another is to upload the builder
files into the cluster itself. If you lose the builder file, you have to
create a new ring from scratch. Nearly all partitions would be assigned
to different devices and, therefore, nearly all of the stored data would
have to be replicated to new locations. So, recovery from a builder file
loss is possible, but data would be unreachable for an extended time.</p><div class="sect2 " id="id-1.4.8.7.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ring data structure</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ring data structure consists of three top level fields: a list of
devices in the cluster, a list of lists of device ids indicating
partition to device assignments, and an integer indicating the number of
bits to shift an MD5 hash to calculate the partition for the hash.</p></div><div class="sect2 " id="id-1.4.8.7.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Partition assignment list</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This is a list of <code class="literal">array('H')</code> of devices ids. The outermost list
contains an <code class="literal">array('H')</code> for each replica. Each <code class="literal">array('H')</code> has a
length equal to the partition count for the ring. Each integer in the
<code class="literal">array('H')</code> is an index into the above list of devices. The partition
list is known internally to the Ring class as <code class="literal">_replica2part2dev_id</code>.</p><p>So, to create a list of device dictionaries assigned to a partition, the
Python code would look like:</p><div class="verbatim-wrap highlight python"><pre class="screen">devices = [self.devs[part2dev_id[partition]] for
part2dev_id in self._replica2part2dev_id]</pre></div><p>That code is a little simplistic because it does not account for the
removal of duplicate devices. If a ring has more replicas than devices,
a partition will have more than one replica on a device.</p><p><code class="literal">array('H')</code> is used for memory conservation as there may be millions
of partitions.</p></div><div class="sect2 " id="id-1.4.8.7.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Overload</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ring builder tries to keep replicas as far apart as possible while
still respecting device weights. When it can not do both, the overload
factor determines what happens. Each device takes an extra
fraction of its desired partitions to allow for replica dispersion;
after that extra fraction is exhausted, replicas are placed closer
together than optimal.</p><p>The overload factor lets the operator trade off replica
dispersion (durability) against data dispersion (uniform disk usage).</p><p>The default overload factor is 0, so device weights are strictly
followed.</p><p>With an overload factor of 0.1, each device accepts 10% more
partitions than it otherwise would, but only if it needs to maintain
partition dispersion.</p><p>For example, consider a 3-node cluster of machines with equal-size disks;
node A has 12 disks, node B has 12 disks, and node C has
11 disks. The ring has an overload factor of 0.1 (10%).</p><p>Without the overload, some partitions would end up with replicas only
on nodes A and B. However, with the overload, every device can accept
up to 10% more partitions for the sake of dispersion. The
missing disk in C means there is one disk's worth of partitions
to spread across the remaining 11 disks, which gives each
disk in C an extra 9.09% load. Since this is less than the 10%
overload, there is one replica of each partition on each node.</p><p>However, this does mean that the disks in node C have more data
than the disks in nodes A and B. If 80% full is the warning
threshold for the cluster, node C's disks reach 80% full while A
and B's disks are only 72.7% full.</p></div><div class="sect2 " id="id-1.4.8.7.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Replica counts</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To support the gradual change in replica counts, a ring can have a real
number of replicas and is not restricted to an integer number of
replicas.</p><p>A fractional replica count is for the whole ring and not for individual
partitions. It indicates the average number of replicas for each
partition. For example, a replica count of 3.2 means that 20 percent of
partitions have four replicas and 80 percent have three replicas.</p><p>The replica count is adjustable. For example:</p><div class="verbatim-wrap"><pre class="screen">$ swift-ring-builder account.builder set_replicas 4
$ swift-ring-builder account.builder rebalance</pre></div><p>Removing unneeded replicas saves on
the cost of disks.</p><p>You can gradually increase the replica count at a rate that does not
adversely affect cluster performance. For example:</p><div class="verbatim-wrap"><pre class="screen">$ swift-ring-builder object.builder set_replicas 3.01
$ swift-ring-builder object.builder rebalance
&lt;distribute rings and wait&gt;...

$ swift-ring-builder object.builder set_replicas 3.02
$ swift-ring-builder object.builder rebalance
&lt;distribute rings and wait&gt;...</pre></div><p>Changes take effect after the ring is rebalanced. Therefore, if you
intend to change from 3 replicas to 3.01 but you accidentally type
2.01, no data is lost.</p><p>Additionally, the <code class="command">swift-ring-builder X.builder create</code> command can
now take a decimal argument for the number of replicas.</p></div><div class="sect2 " id="id-1.4.8.7.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Partition shift value</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The partition shift value is known internally to the Ring class as
<code class="literal">_part_shift</code>. This value is used to shift an MD5 hash to calculate
the partition where the data for that hash should reside. Only the top
four bytes of the hash is used in this process. For example, to compute
the partition for the <code class="literal">/account/container/object</code> path using Python:</p><div class="verbatim-wrap highlight python"><pre class="screen">partition = unpack_from('&gt;I',
md5('/account/container/object').digest())[0] &gt;&gt;
self._part_shift</pre></div><p>For a ring generated with part_power P, the partition shift value is
<code class="literal">32 - P</code>.</p></div><div class="sect2 " id="id-1.4.8.7.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.5.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Build the ring</span> <a title="Permalink" class="permalink" href="#id-1.4.8.7.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ring builder process includes these high-level steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The utility calculates the number of partitions to assign to each
device based on the weight of the device. For example, for a
partition at the power of 20, the ring has 1,048,576 partitions. One
thousand devices of equal weight each want 1,048.576 partitions. The
devices are sorted by the number of partitions they desire and kept
in order throughout the initialization process.</p><div id="id-1.4.8.7.9.3.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Each device is also assigned a random tiebreaker value that is
used when two devices desire the same number of partitions. This
tiebreaker is not stored on disk anywhere, and so two different
rings created with the same parameters will have different
partition assignments. For repeatable partition assignments,
<code class="literal">RingBuilder.rebalance()</code> takes an optional seed value that
seeds the Python pseudo-random number generator.</p></div></li><li class="step "><p>The ring builder assigns each partition replica to the device that
requires most partitions at that point while keeping it as far away
as possible from other replicas. The ring builder searches for a
device in a different zone, or on a different server. If it does not
find one, it looks for a device with no replicas. Finally, if all
options are exhausted, the ring builder assigns the replica to the
device that has the fewest replicas already assigned.</p><div id="id-1.4.8.7.9.3.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The ring builder assigns multiple replicas to one device only if
the ring has fewer devices than it has replicas.</p></div></li><li class="step "><p>When building a new ring from an old ring, the ring builder
recalculates the desired number of partitions that each device wants.</p></li><li class="step "><p>The ring builder unassigns partitions and gathers these partitions
for reassignment, as follows:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The ring builder unassigns any assigned partitions from any
removed devices and adds these partitions to the gathered list.</p></li><li class="listitem "><p>The ring builder unassigns any partition replicas that can be
spread out for better durability and adds these partitions to the
gathered list.</p></li><li class="listitem "><p>The ring builder unassigns random partitions from any devices that
have more partitions than they need and adds these partitions to
the gathered list.</p></li></ul></div></li><li class="step "><p>The ring builder reassigns the gathered partitions to devices by
using a similar method to the one described previously.</p></li><li class="step "><p>When the ring builder reassigns a replica to a partition, the ring
builder records the time of the reassignment. The ring builder uses
this value when it gathers partitions for reassignment so that no
partition is moved twice in a configurable amount of time. The
RingBuilder class knows this configurable amount of time as
<code class="literal">min_part_hours</code>. The ring builder ignores this restriction for
replicas of partitions on removed devices because removal of a device
happens on device failure only, and reassignment is the only choice.</p></li></ol></div></div><p>These steps do not always perfectly rebalance a ring due to the random
nature of gathering partitions for reassignment. To help reach a more
balanced ring, the rebalance process is repeated until near perfect
(less than 1 percent off) or when the balance does not improve by at
least 1 percent (indicating we probably cannot get perfect balance due
to wildly imbalanced zones or too many partitions recently moved).</p></div></div><div class="sect1 " id="id-1.4.8.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.8.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.8.8.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Access tier</span> <a title="Permalink" class="permalink" href="#id-1.4.8.8.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Large-scale deployments segment off an access tier, which is considered
the Object Storage system's central hub. The access tier fields the
incoming API requests from clients and moves data in and out of the
system. This tier consists of front-end load balancers, ssl-terminators,
and authentication services. It runs the (distributed) brain of the
Object Storage system: the proxy server processes.</p><div id="id-1.4.8.8.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you want to use OpenStack Identity API v3 for authentication, you
have the following options available in <code class="literal">/etc/swift/dispersion.conf</code>:
<code class="literal">auth_version</code>, <code class="literal">user_domain_name</code>, <code class="literal">project_domain_name</code>,
and <code class="literal">project_name</code>.</p></div><p>
          <span class="bold"><strong>Object Storage architecture</strong></span>
        </p><div class="figure" id="id-1.4.8.8.2.5"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-arch.png" target="_blank"><img src="images/objectstorage-arch.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.9: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.8.2.5">#</a></h6></div></div><p>Because access servers are collocated in their own tier, you can scale
out read/write access regardless of the storage capacity. For example,
if a cluster is on the public Internet, requires SSL termination, and
has a high demand for data access, you can provision many access
servers. However, if the cluster is on a private network and used
primarily for archival purposes, you need fewer access servers.</p><p>Since this is an HTTP addressable storage service, you may incorporate a
load balancer into the access tier.</p><p>Typically, the tier consists of a collection of 1U servers. These
machines use a moderate amount of RAM and are network I/O intensive.
Since these systems field each incoming API request, you should
provision them with two high-throughput (10GbE) interfaces - one for the
incoming <code class="literal">front-end</code> requests and the other for the <code class="literal">back-end</code> access to
the object storage nodes to put and fetch data.</p><div class="sect3 " id="id-1.4.8.8.2.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.6.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Factors to consider</span> <a title="Permalink" class="permalink" href="#id-1.4.8.8.2.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For most publicly facing deployments as well as private deployments
available across a wide-reaching corporate network, you use SSL to
encrypt traffic to the client. SSL adds significant processing load to
establish sessions between clients, which is why you have to provision
more capacity in the access layer. SSL may not be required for private
deployments on trusted networks.</p></div></div><div class="sect2 " id="id-1.4.8.8.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storage nodes</span> <a title="Permalink" class="permalink" href="#id-1.4.8.8.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In most configurations, each of the five zones should have an equal
amount of storage capacity. Storage nodes use a reasonable amount of
memory and CPU. Metadata needs to be readily available to return objects
quickly. The object stores run services not only to field incoming
requests from the access tier, but to also run replicators, auditors,
and reapers. You can provision object stores provisioned with single
gigabit or 10 gigabit network interface depending on the expected
workload and desired performance.</p><p>
          <span class="bold"><strong>Object Storage (swift)</strong></span>
        </p><div class="figure" id="id-1.4.8.8.3.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/objectstorage-nodes.png" target="_blank"><img src="images/objectstorage-nodes.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 6.10: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.8.8.3.4">#</a></h6></div></div><p>Currently, a 2 TB or 3 TB SATA disk delivers good performance for the
price. You can use desktop-grade drives if you have responsive remote
hands in the datacenter and enterprise-grade drives if you don't.</p><div class="sect3 " id="id-1.4.8.8.3.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.6.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Factors to consider</span> <a title="Permalink" class="permalink" href="#id-1.4.8.8.3.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You should keep in mind the desired I/O performance for single-threaded
requests. This system does not use RAID, so a single disk handles each
request for an object. Disk performance impacts single-threaded response
rates.</p><p>To achieve apparent higher throughput, the object storage system is
designed to handle concurrent uploads/downloads. The network I/O
capacity (1GbE, bonded 1GbE pair, or 10GbE) should match your desired
concurrent throughput needs for reads and writes.</p></div></div></div><div class="sect1 " id="id-1.4.8.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Replication</span> <a title="Permalink" class="permalink" href="#id-1.4.8.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Because each replica in Object Storage functions independently and
clients generally require only a simple majority of nodes to respond to
consider an operation successful, transient failures like network
partitions can quickly cause replicas to diverge. These differences are
eventually reconciled by asynchronous, peer-to-peer replicator
processes. The replicator processes traverse their local file systems
and concurrently perform operations in a manner that balances load
across physical disks.</p><p>Replication uses a push model, with records and files generally only
being copied from local to remote replicas. This is important because
data on the node might not belong there (as in the case of hand offs and
ring changes), and a replicator cannot know which data it should pull in
from elsewhere in the cluster. Any node that contains data must ensure
that data gets to where it belongs. The ring handles replica placement.</p><p>To replicate deletions in addition to creations, every deleted record or
file in the system is marked by a tombstone. The replication process
cleans up tombstones after a time period known as the <code class="literal">consistency
window</code>. This window defines the duration of the replication and how
long transient failure can remove a node from the cluster. Tombstone
cleanup must be tied to replication to reach replica convergence.</p><p>If a replicator detects that a remote drive has failed, the replicator
uses the <code class="literal">get_more_nodes</code> interface for the ring to choose an
alternate node with which to synchronize. The replicator can maintain
desired levels of replication during disk failures, though some replicas
might not be in an immediately usable location.</p><div id="id-1.4.8.9.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The replicator does not maintain desired levels of replication when
failures such as entire node failures occur; most failures are
transient.</p></div><p>The main replication types are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.8.9.8.1.1.1"><span class="term ">Database replication</span></dt><dd><p>Replicates containers and objects.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.8.9.8.2.1.1"><span class="term ">Object replication</span></dt><dd><p>Replicates object data.</p></dd></dl></div></li></ul></div><div class="sect2 " id="id-1.4.8.9.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Database replication</span> <a title="Permalink" class="permalink" href="#id-1.4.8.9.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Database replication completes a low-cost hash comparison to determine
whether two replicas already match. Normally, this check can quickly
verify that most databases in the system are already synchronized. If
the hashes differ, the replicator synchronizes the databases by sharing
records added since the last synchronization point.</p><p>This synchronization point is a high water mark that notes the last
record at which two databases were known to be synchronized, and is
stored in each database as a tuple of the remote database ID and record
ID. Database IDs are unique across all replicas of the database, and
record IDs are monotonically increasing integers. After all new records
are pushed to the remote database, the entire synchronization table of
the local database is pushed, so the remote database can guarantee that
it is synchronized with everything with which the local database was
previously synchronized.</p><p>If a replica is missing, the whole local database file is transmitted to
the peer by using rsync(1) and is assigned a new unique ID.</p><p>In practice, database replication can process hundreds of databases per
concurrency setting per second (up to the number of available CPUs or
disks) and is bound by the number of database transactions that must be
performed.</p></div><div class="sect2 " id="id-1.4.8.9.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object replication</span> <a title="Permalink" class="permalink" href="#id-1.4.8.9.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The initial implementation of object replication performed an rsync to
push data from a local partition to all remote servers where it was
expected to reside. While this worked at small scale, replication times
skyrocketed once directory structures could no longer be held in RAM.
This scheme was modified to save a hash of the contents for each suffix
directory to a per-partition hashes file. The hash for a suffix
directory is no longer valid when the contents of that suffix directory
is modified.</p><p>The object replication process reads in hash files and calculates any
invalidated hashes. Then, it transmits the hashes to each remote server
that should hold the partition, and only suffix directories with
differing hashes on the remote server are rsynced. After pushing files
to the remote server, the replication process notifies it to recalculate
hashes for the rsynced suffix directories.</p><p>The number of uncached directories that object replication must
traverse, usually as a result of invalidated suffix directory hashes,
impedes performance. To provide acceptable replication speeds, object
replication is designed to invalidate around 2 percent of the hash space
on a normal node each day.</p></div></div><div class="sect1 " id="id-1.4.8.10"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Large object support</span> <a title="Permalink" class="permalink" href="#id-1.4.8.10">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Object Storage (swift) uses segmentation to support the upload of large
objects. By default, Object Storage limits the download size of a single
object to 5GB. Using segmentation, uploading a single object is virtually
unlimited. The segmentation process works by fragmenting the object,
and automatically creating a file that sends the segments together as
a single object. This option offers greater upload speed with the possibility
of parallel uploads.</p><div class="sect2 " id="id-1.4.8.10.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Large objects</span> <a title="Permalink" class="permalink" href="#id-1.4.8.10.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The large object is comprised of two types of objects:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Segment objects</strong></span> store the object content. You can divide your
content into segments, and upload each segment into its own segment
object. Segment objects do not have any special features. You create,
update, download, and delete segment objects just as you would normal
objects.</p></li><li class="listitem "><p>A <span class="bold"><strong>manifest object</strong></span> links the segment objects into one logical
large object. When you download a manifest object, Object Storage
concatenates and returns the contents of the segment objects in the
response body of the request. The manifest object types are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <span class="bold"><strong>Static large objects</strong></span>
                </p></li><li class="listitem "><p>
                  <span class="bold"><strong>Dynamic large objects</strong></span>
                </p></li></ul></div></li></ul></div><p>To find out more information on large object support, see <a class="link" href="http://docs.openstack.org/user-guide/cli-swift-large-object-creation.html" target="_blank">Large objects</a>
in the OpenStack End User Guide, or <a class="link" href="http://docs.openstack.org/developer/swift/overview_large_objects.html" target="_blank">Large Object Support</a>
in the developer documentation.</p></div></div><div class="sect1 " id="id-1.4.8.11"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object Auditor</span> <a title="Permalink" class="permalink" href="#id-1.4.8.11">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>On system failures, the XFS file system can sometimes truncate files it is
trying to write and produce zero-byte files. The object-auditor will catch
these problems but in the case of a system crash it is advisable to run
an extra, less rate limited sweep, to check for these specific files.
You can run this command as follows:</p><div class="verbatim-wrap"><pre class="screen">$ swift-object-auditor /path/to/object-server/config/file.conf once -z 1000</pre></div><div id="id-1.4.8.11.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>"-z" means to only check for zero-byte files at 1000 files per second.</p></div><p>It is useful to run the object auditor on a specific device or set of devices.
You can run the object-auditor once as follows:</p><div class="verbatim-wrap"><pre class="screen">$ swift-object-auditor /path/to/object-server/config/file.conf once \
  --devices=sda,sdb</pre></div><div id="id-1.4.8.11.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This will run the object auditor on only the <code class="literal">sda</code> and <code class="literal">sdb</code> devices.
This parameter accepts a comma-separated list of values.</p></div></div><div class="sect1 " id="id-1.4.8.12"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Erasure coding</span> <a title="Permalink" class="permalink" href="#id-1.4.8.12">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Erasure coding is a set of algorithms that allows the reconstruction of
missing data from a set of original data. In theory, erasure coding uses
less capacity with similar durability characteristics as replicas.
From an application perspective, erasure coding support is transparent.
Object Storage (swift) implements erasure coding as a Storage Policy.
See <a class="link" href="http://docs.openstack.org/developer/swift/overview_policies.html" target="_blank">Storage Policies</a>
for more details.</p><p>There is no external API related to erasure coding. Create a container using a
Storage Policy; the interaction with the cluster is the same as any
other durability policy. Because support implements as a Storage Policy,
you can isolate all storage devices that associate with your cluster's
erasure coding capability. It is entirely possible to share devices between
storage policies, but for erasure coding it may make more sense to use
not only separate devices but possibly even entire nodes dedicated for erasure
coding.</p><div id="id-1.4.8.12.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The erasure code support in Object Storage is considered beta in Kilo.
Most major functionality is included, but it has not been tested or
validated at large scale. This feature relies on <code class="literal">ssync</code> for durability.
We recommend deployers do extensive testing and not deploy production
data using an erasure code storage policy.
If any bugs are found during testing, please report them to
<a class="link" href="https://bugs.launchpad.net/swift" target="_blank">https://bugs.launchpad.net/swift</a></p></div></div><div class="sect1 " id="id-1.4.8.13"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Account reaper</span> <a title="Permalink" class="permalink" href="#id-1.4.8.13">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The purpose of the account reaper is to remove data from the deleted accounts.</p><p>A reseller marks an account for deletion by issuing a <code class="literal">DELETE</code> request
on the account's storage URL. This action sets the <code class="literal">status</code> column of
the account_stat table in the account database and replicas to
<code class="literal">DELETED</code>, marking the account's data for deletion.</p><p>Typically, a specific retention time or undelete are not provided.
However, you can set a <code class="literal">delay_reaping</code> value in the
<code class="literal">[account-reaper]</code> section of the <code class="literal">account-server.conf</code> file to
delay the actual deletion of data. At this time, to undelete you have to update
the account database replicas directly, set the status column to an
empty string and update the put_timestamp to be greater than the
delete_timestamp.</p><div id="id-1.4.8.13.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>It is on the development to-do list to write a utility that performs
this task, preferably through a REST call.</p></div><p>The account reaper runs on each account server and scans the server
occasionally for account databases marked for deletion. It only fires up
on the accounts for which the server is the primary node, so that
multiple account servers aren't trying to do it simultaneously. Using
multiple servers to delete one account might improve the deletion speed
but requires coordination to avoid duplication. Speed really is not a
big concern with data deletion, and large accounts aren't deleted often.</p><p>Deleting an account is simple. For each account container, all objects
are deleted and then the container is deleted. Deletion requests that
fail will not stop the overall process but will cause the overall
process to fail eventually (for example, if an object delete times out,
you will not be able to delete the container or the account). The
account reaper keeps trying to delete an account until it is empty, at
which point the database reclaim process within the db_replicator will
remove the database files.</p><p>A persistent error state may prevent the deletion of an object or
container. If this happens, you will see a message in the log, for example:</p><div class="verbatim-wrap"><pre class="screen">Account &lt;name&gt; has not been reaped since &lt;date&gt;</pre></div><p>You can control when this is logged with the <code class="literal">reap_warn_after</code> value in the
<code class="literal">[account-reaper]</code> section of the <code class="literal">account-server.conf</code> file.
The default value is 30 days.</p></div><div class="sect1 " id="id-1.4.8.14"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure project-specific image locations with Object Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.8.14">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For some deployers, it is not ideal to store all images in one place to
enable all projects and users to access them. You can configure the Image
service to store image data in project-specific image locations. Then,
only the following projects can use the Image service to access the
created image:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The project who owns the image</p></li><li class="listitem "><p>Projects that are defined in <code class="literal">swift_store_admin_tenants</code> and that
have admin-level accounts</p></li></ul></div><p>
        <span class="bold"><strong>To configure project-specific image locations</strong></span>
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure swift as your <code class="literal">default_store</code> in the
<code class="literal">glance-api.conf</code> file.</p></li><li class="step "><p>Set these configuration options in the <code class="literal">glance-api.conf</code> file:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.8.14.5.2.2.1.1.1"><span class="term ">swift_store_multi_tenant</span></dt><dd><p>Set to <code class="literal">True</code> to enable tenant-specific storage locations.
Default is <code class="literal">False</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.8.14.5.2.2.2.1.1"><span class="term ">swift_store_admin_tenants</span></dt><dd><p>Specify a list of tenant IDs that can grant read and write access to all
Object Storage containers that are created by the Image service.</p></dd></dl></div></li></ul></div></li></ol></div></div><p>With this configuration, images are stored in an Object Storage service
(swift) endpoint that is pulled from the service catalog for the
authenticated user.</p></div><div class="sect1 " id="id-1.4.8.15"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object Storage monitoring</span> <a title="Permalink" class="permalink" href="#id-1.4.8.15">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.8.15.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This section was excerpted from a blog post by <a class="link" href="http://swiftstack.com/blog/2012/04/11/swift-monitoring-with-statsd" target="_blank">Darrell
Bishop</a> and
has since been edited.</p></div><p>An OpenStack Object Storage cluster is a collection of many daemons that
work together across many nodes. With so many different components, you
must be able to tell what is going on inside the cluster. Tracking
server-level meters like CPU utilization, load, memory consumption, disk
usage and utilization, and so on is necessary, but not sufficient.</p><div class="sect2 " id="id-1.4.8.15.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swift Recon</span> <a title="Permalink" class="permalink" href="#id-1.4.8.15.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Swift Recon middleware (see
<a class="link" href="http://swift.openstack.org/admin_guide.html#cluster-telemetry-and-monitoring" target="_blank">Defining Storage Policies</a>)
provides general machine statistics, such as load average, socket
statistics, <code class="literal">/proc/meminfo</code> contents, as well as Swift-specific meters:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <code class="literal">MD5</code> sum of each ring file.</p></li><li class="listitem "><p>The most recent object replication time.</p></li><li class="listitem "><p>Count of each type of quarantined file: Account, container, or
object.</p></li><li class="listitem "><p>Count of "async_pendings" (deferred container updates) on disk.</p></li></ul></div><p>Swift Recon is middleware that is installed in the object servers
pipeline and takes one required option: A local cache directory. To
track <code class="literal">async_pendings</code>, you must set up an additional cron job for
each object server. You access data by either sending HTTP requests
directly to the object server or using the <code class="literal">swift-recon</code> command-line
client.</p><p>There are Object Storage cluster statistics but the typical
server meters overlap with existing server monitoring systems. To get
the Swift-specific meters into a monitoring system, they must be polled.
Swift Recon acts as a middleware meters collector. The
process that feeds meters to your statistics system, such as
<code class="literal">collectd</code> and <code class="literal">gmond</code>, should already run on the storage node.
You can choose to either talk to Swift Recon or collect the meters
directly.</p></div><div class="sect2 " id="id-1.4.8.15.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swift-Informant</span> <a title="Permalink" class="permalink" href="#id-1.4.8.15.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Swift-Informant middleware (see
<a class="link" href="https://github.com/pandemicsyn/swift-informant" target="_blank">swift-informant</a>) has
real-time visibility into Object Storage client requests. It sits in the
pipeline for the proxy server, and after each request to the proxy server it
sends three meters to a <code class="literal">StatsD</code> server:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A counter increment for a meter like <code class="literal">obj.GET.200</code> or
<code class="literal">cont.PUT.404</code>.</p></li><li class="listitem "><p>Timing data for a meter like <code class="literal">acct.GET.200</code> or <code class="literal">obj.GET.200</code>.
[The README says the meters look like <code class="literal">duration.acct.GET.200</code>, but
I do not see the <code class="literal">duration</code> in the code. I am not sure what the
Etsy server does but our StatsD server turns timing meters into five
derivative meters with new segments appended, so it probably works as
coded. The first meter turns into <code class="literal">acct.GET.200.lower</code>,
<code class="literal">acct.GET.200.upper</code>, <code class="literal">acct.GET.200.mean</code>,
<code class="literal">acct.GET.200.upper_90</code>, and <code class="literal">acct.GET.200.count</code>].</p></li><li class="listitem "><p>A counter increase by the bytes transferred for a meter like
<code class="literal">tfer.obj.PUT.201</code>.</p></li></ul></div><p>This is used for receiving information on the quality of service clients
experience with the timing meters, as well as sensing the volume of the
various modifications of a request server type, command, and response
code. Swift-Informant requires no change to core Object
Storage code because it is implemented as middleware. However, it gives
no insight into the workings of the cluster past the proxy server.
If the responsiveness of one storage node degrades, you can only see
that some of the requests are bad, either as high latency or error
status codes.</p></div><div class="sect2 " id="id-1.4.8.15.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.13.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Statsdlog</span> <a title="Permalink" class="permalink" href="#id-1.4.8.15.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <a class="link" href="https://github.com/pandemicsyn/statsdlog" target="_blank">Statsdlog</a>
project increments StatsD counters based on logged events. Like
Swift-Informant, it is also non-intrusive, however statsdlog can track
events from all Object Storage daemons, not just proxy-server. The
daemon listens to a UDP stream of syslog messages, and StatsD counters
are incremented when a log line matches a regular expression. Meter
names are mapped to regex match patterns in a JSON file, allowing
flexible configuration of what meters are extracted from the log stream.</p><p>Currently, only the first matching regex triggers a StatsD counter
increment, and the counter is always incremented by one. There is no way
to increment a counter by more than one or send timing data to StatsD
based on the log line content. The tool could be extended to handle more
meters for each line and data extraction, including timing data. But a
coupling would still exist between the log textual format and the log
parsing regexes, which would themselves be more complex to support
multiple matches for each line and data extraction. Also, log processing
introduces a delay between the triggering event and sending the data to
StatsD. It would be preferable to increment error counters where they
occur and send timing data as soon as it is known to avoid coupling
between a log string and a parsing regex and prevent a time delay
between events and sending data to StatsD.</p><p>The next section describes another method for gathering Object Storage
operational meters.</p></div><div class="sect2 " id="id-1.4.8.15.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.13.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swift StatsD logging</span> <a title="Permalink" class="permalink" href="#id-1.4.8.15.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>StatsD (see <a class="link" href="http://codeascraft.etsy.com/2011/02/15/measure-anything-measure-everything/" target="_blank">Measure Anything, Measure Everything</a>)
was designed for application code to be deeply instrumented. Meters are
sent in real-time by the code that just noticed or did something. The
overhead of sending a meter is extremely low: a <code class="literal">sendto</code> of one UDP
packet. If that overhead is still too high, the StatsD client library
can send only a random portion of samples and StatsD approximates the
actual number when flushing meters upstream.</p><p>To avoid the problems inherent with middleware-based monitoring and
after-the-fact log processing, the sending of StatsD meters is
integrated into Object Storage itself. The submitted change set (see
<a class="link" href="https://review.openstack.org/#change,6058" target="_blank">https://review.openstack.org/#change,6058</a>) currently reports 124 meters
across 15 Object Storage daemons and the tempauth middleware. Details of
the meters tracked are in the <a class="link" href="http://docs.openstack.org/developer/swift/admin_guide.html" target="_blank">Administrator's
Guide</a>.</p><p>The sending of meters is integrated with the logging framework. To
enable, configure <code class="literal">log_statsd_host</code> in the relevant config file. You
can also specify the port and a default sample rate. The specified
default sample rate is used unless a specific call to a statsd logging
method (see the list below) overrides it. Currently, no logging calls
override the sample rate, but it is conceivable that some meters may
require accuracy (<code class="literal">sample_rate=1</code>) while others may not.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
     ...
log_statsd_host = 127.0.0.1
log_statsd_port = 8125
log_statsd_default_sample_rate = 1</pre></div><p>Then the LogAdapter object returned by <code class="literal">get_logger()</code>, usually stored
in <code class="literal">self.logger</code>, has these new methods:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">set_statsd_prefix(self, prefix)</code> Sets the client library stat
prefix value which gets prefixed to every meter. The default prefix
is the <code class="literal">name</code> of the logger such as <code class="literal">object-server</code>,
<code class="literal">container-auditor</code>, and so on. This is currently used to turn
<code class="literal">proxy-server</code> into one of <code class="literal">proxy-server.Account</code>,
<code class="literal">proxy-server.Container</code>, or <code class="literal">proxy-server.Object</code> as soon as the
Controller object is determined and instantiated for the request.</p></li><li class="listitem "><p><code class="literal">update_stats(self, metric, amount, sample_rate=1)</code> Increments
the supplied meter by the given amount. This is used when you need
to add or subtract more that one from a counter, like incrementing
<code class="literal">suffix.hashes</code> by the number of computed hashes in the object
replicator.</p></li><li class="listitem "><p><code class="literal">increment(self, metric, sample_rate=1)</code> Increments the given counter
meter by one.</p></li><li class="listitem "><p><code class="literal">decrement(self, metric, sample_rate=1)</code> Lowers the given counter
meter by one.</p></li><li class="listitem "><p><code class="literal">timing(self, metric, timing_ms, sample_rate=1)</code> Record that the
given meter took the supplied number of milliseconds.</p></li><li class="listitem "><p><code class="literal">timing_since(self, metric, orig_time, sample_rate=1)</code>
Convenience method to record a timing meter whose value is "now"
minus an existing timestamp.</p></li></ul></div><div id="id-1.4.8.15.7.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>These logging methods may safely be called anywhere you have a
logger object. If StatsD logging has not been configured, the methods
are no-ops. This avoids messy conditional logic each place a meter is
recorded. These example usages show the new logging methods:</p><div class="verbatim-wrap highlight python"><pre class="screen"># swift/obj/replicator.py
def update(self, job):
     # ...
    begin = time.time()
    try:
        hashed, local_hash = tpool.execute(tpooled_get_hashes, job['path'],
                do_listdir=(self.replication_count % 10) == 0,
                reclaim_age=self.reclaim_age)
        # See tpooled_get_hashes "Hack".
        if isinstance(hashed, BaseException):
            raise hashed
        self.suffix_hash += hashed
        self.logger.update_stats('suffix.hashes', hashed)
        # ...
    finally:
        self.partition_times.append(time.time() - begin)
        self.logger.timing_since('partition.update.timing', begin)</pre></div><div class="verbatim-wrap highlight python"><pre class="screen"># swift/container/updater.py
def process_container(self, dbfile):
    # ...
    start_time = time.time()
    # ...
        for event in events:
            if 200 &lt;= event.wait() &lt; 300:
                successes += 1
            else:
                failures += 1
        if successes &gt; failures:
          self.logger.increment('successes')
            # ...
        else:
            self.logger.increment('failures')
            # ...
        # Only track timing data for attempted updates:
        self.logger.timing_since('timing', start_time)
    else:
        self.logger.increment('no_changes')
        self.no_changes += 1</pre></div></div></div></div><div class="sect1 " id="id-1.4.8.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System administration for Object Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.8.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By understanding Object Storage concepts, you can better monitor and
administer your storage solution. The majority of the administration
information is maintained in developer documentation at
<a class="link" href="http://docs.openstack.org/developer/swift/" target="_blank">docs.openstack.org/developer/swift/</a>.</p><p>See the <a class="link" href="http://docs.openstack.org/newton/config-reference/object-storage.html" target="_blank">OpenStack Configuration Reference</a>
for a list of configuration options for Object Storage.</p></div><div class="sect1 " id="id-1.4.8.17"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot Object Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For Object Storage, everything is logged in <code class="literal">/var/log/syslog</code> (or
<code class="literal">messages</code> on some distros). Several settings enable further
customization of logging, such as <code class="literal">log_name</code>, <code class="literal">log_facility</code>, and
<code class="literal">log_level</code>, within the object server configuration files.</p><div class="sect2 " id="id-1.4.8.17.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Drive failure</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.8.17.3.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.3.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Drive failure can prevent Object Storage performing replication.</p></div><div class="sect3 " id="id-1.4.8.17.3.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.3.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the event that a drive has failed, the first step is to make sure the
drive is unmounted. This will make it easier for Object Storage to work
around the failure until it has been resolved. If the drive is going to
be replaced immediately, then it is just best to replace the drive,
format it, remount it, and let replication fill it up.</p><p>If you cannot replace the drive immediately, then it is best to leave it
unmounted, and remove the drive from the ring. This will allow all the
replicas that were on that drive to be replicated elsewhere until the
drive is replaced. Once the drive is replaced, it can be re-added to the
ring.</p><p>You can look at error messages in the <code class="literal">/var/log/kern.log</code> file for
hints of drive failure.</p></div></div><div class="sect2 " id="id-1.4.8.17.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Server failure</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.8.17.4.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.4.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The server is potentially offline, and may have failed, or require a
reboot.</p></div><div class="sect3 " id="id-1.4.8.17.4.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.4.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If a server is having hardware issues, it is a good idea to make sure
the Object Storage services are not running. This will allow Object
Storage to work around the failure while you troubleshoot.</p><p>If the server just needs a reboot, or a small amount of work that should
only last a couple of hours, then it is probably best to let Object
Storage work around the failure and get the machine fixed and back
online. When the machine comes back online, replication will make sure
that anything that is missing during the downtime will get updated.</p><p>If the server has more serious issues, then it is probably best to
remove all of the server's devices from the ring. Once the server has
been repaired and is back online, the server's devices can be added back
into the ring. It is important that the devices are reformatted before
putting them back into the ring as it is likely to be responsible for a
different set of partitions than before.</p></div></div><div class="sect2 " id="id-1.4.8.17.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.15.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Detect failed drives</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.8.17.5.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.5.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When drives fail, it can be difficult to detect that a drive has failed,
and the details of the failure.</p></div><div class="sect3 " id="id-1.4.8.17.5.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.5.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>It has been our experience that when a drive is about to fail, error
messages appear in the <code class="literal">/var/log/kern.log</code> file. There is a script called
<code class="literal">swift-drive-audit</code> that can be run via cron to watch for bad drives. If
errors are detected, it will unmount the bad drive, so that Object
Storage can work around it. The script takes a configuration file with
the following settings:</p><div class="table" id="id-1.4.8.17.5.3.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 6.1: </span><span class="name">Description of configuration options for [drive-audit] in drive-audit.conf </span><a title="Permalink" class="permalink" href="#id-1.4.8.17.5.3.3">#</a></h6></div><div class="table-contents"><table class="table" summary="Description of configuration options for [drive-audit] in drive-audit.conf" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Configuration option = Default value</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>
                      <code class="literal">device_dir = /srv/node</code>
                    </p>
                  </td><td>
                    <p>Directory devices are mounted under</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">error_limit = 1</code>
                    </p>
                  </td><td>
                    <p>Number of errors to find before a device is unmounted</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">log_address = /dev/log</code>
                    </p>
                  </td><td>
                    <p>Location where syslog sends the logs to</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">log_facility = LOG_LOCAL0</code>
                    </p>
                  </td><td>
                    <p>Syslog log facility</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">log_file_pattern = /var/log/kern.*[!.][!g][!z]</code>
                    </p>
                  </td><td>
                    <p>Location of the log file with globbing pattern to check against device
errors locate device blocks with errors in the log file</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">log_level = INFO</code>
                    </p>
                  </td><td>
                    <p>Logging level</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">log_max_line_length = 0</code>
                    </p>
                  </td><td>
                    <p>Caps the length of log lines to the value given; no limit if set to 0,
the default.</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">log_to_console = False</code>
                    </p>
                  </td><td>
                    <p>No help text available for this option.</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">minutes = 60</code>
                    </p>
                  </td><td>
                    <p>Number of minutes to look back in <code class="literal">/var/log/kern.log</code></p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">recon_cache_path = /var/cache/swift</code>
                    </p>
                  </td><td>
                    <p>Directory where stats for a few items will be stored</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">regex_pattern_1 = \berror\b.*\b(dm-[0-9]{1,2}\d?)\b</code>
                    </p>
                  </td><td>
                    <p>No help text available for this option.</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">unmount_failed_device = True</code>
                    </p>
                  </td><td>
                    <p>No help text available for this option.</p>
                  </td></tr></tbody></table></div></div><div id="id-1.4.8.17.5.3.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>This script has only been tested on Ubuntu 10.04; use with caution on
other operating systems in production.</p></div></div></div><div class="sect2 " id="id-1.4.8.17.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">6.15.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Emergency recovery of ring builder files</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.8.17.6.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.6.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An emergency might prevent a successful backup from restoring the
cluster to operational status.</p></div><div class="sect3 " id="id-1.4.8.17.6.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">6.15.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.8.17.6.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You should always keep a backup of swift ring builder files. However, if
an emergency occurs, this procedure may assist in returning your cluster
to an operational state.</p><p>Using existing swift tools, there is no way to recover a builder file
from a <code class="literal">ring.gz</code> file. However, if you have a knowledge of Python, it
is possible to construct a builder file that is pretty close to the one
you have lost.</p><div id="id-1.4.8.17.6.3.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>This procedure is a last-resort for emergency circumstances. It
requires knowledge of the swift python code and may not succeed.</p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Load the ring and a new ringbuilder object in a Python REPL:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; from swift.common.ring import RingData, RingBuilder
&gt;&gt;&gt; ring = RingData.load('/path/to/account.ring.gz')</pre></div></li><li class="step "><p>Start copying the data we have in the ring into the builder:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; import math
&gt;&gt;&gt; partitions = len(ring._replica2part2dev_id[0])
&gt;&gt;&gt; replicas = len(ring._replica2part2dev_id)

&gt;&gt;&gt; builder = RingBuilder(int(math.log(partitions, 2)), replicas, 1)
&gt;&gt;&gt; builder.devs = ring.devs
&gt;&gt;&gt; builder._replica2part2dev = ring._replica2part2dev_id
&gt;&gt;&gt; builder._last_part_moves_epoch = 0
&gt;&gt;&gt; from array import array
&gt;&gt;&gt; builder._last_part_moves = array('B', (0 for _ in xrange(partitions)))
&gt;&gt;&gt; builder._set_parts_wanted()
&gt;&gt;&gt; for d in builder._iter_devs():
            d['parts'] = 0
&gt;&gt;&gt; for p2d in builder._replica2part2dev:
            for dev_id in p2d:
                builder.devs[dev_id]['parts'] += 1

This is the extent of the recoverable fields.</pre></div></li><li class="step "><p>For <code class="literal">min_part_hours</code> you either have to remember what the value you
used was, or just make up a new one:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; builder.change_min_part_hours(24) # or whatever you want it to be</pre></div></li><li class="step "><p>Validate the builder. If this raises an exception, check your
previous code:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; builder.validate()</pre></div></li><li class="step "><p>After it validates, save the builder and create a new <code class="literal">account.builder</code>:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; import pickle
&gt;&gt;&gt; pickle.dump(builder.to_dict(), open('account.builder', 'wb'), protocol=2)
&gt;&gt;&gt; exit ()</pre></div></li><li class="step "><p>You should now have a file called <code class="literal">account.builder</code> in the current
working directory. Run
<code class="command">swift-ring-builder account.builder write_ring</code> and compare the new
<code class="literal">account.ring.gz</code> to the <code class="literal">account.ring.gz</code> that you started
from. They probably are not byte-for-byte identical, but if you load them
in a REPL and their <code class="literal">_replica2part2dev_id</code> and <code class="literal">devs</code> attributes are
the same (or nearly so), then you are in good shape.</p></li><li class="step "><p>Repeat the procedure for <code class="literal">container.ring.gz</code> and
<code class="literal">object.ring.gz</code>, and you might get usable builder files.</p></li></ol></div></div></div></div></div></div><div class="chapter " id="id-1.4.9"><div class="titlepage"><div><div><h1 class="title"><span class="number">7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.9">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.9.6"><span class="number">7.1 </span><span class="name">Increase Block Storage API service throughput</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.9.7"><span class="number">7.2 </span><span class="name">Manage volumes</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.9.8"><span class="number">7.3 </span><span class="name">Troubleshoot your installation</span></a></span></dt></dl></div></div><p>The OpenStack Block Storage service works through the interaction of
a series of daemon processes named <code class="literal">cinder-*</code> that reside
persistently on the host machine or machines. You can run all the
binaries from a single node, or spread across multiple nodes. You can
also run them on the same node as other OpenStack services.</p><p>To administer the OpenStack Block Storage service, it is helpful to
understand a number of concepts. You must make certain choices when
you configure the Block Storage service in OpenStack. The bulk of the
options come down to two choices - single node or multi-node install.
You can read a longer discussion about <a class="link" href="http://docs.openstack.org/ops-guide/arch-storage.html" target="_blank">Storage Decisions</a> in the
<a class="link" href="http://docs.openstack.org/ops-guide/" target="_blank">OpenStack Operations Guide</a>.</p><p>OpenStack Block Storage enables you to add extra block-level storage
to your OpenStack Compute instances. This service is similar to the
Amazon EC2 Elastic Block Storage (EBS) offering.</p><div class="sect1 " id="id-1.4.9.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Increase Block Storage API service throughput</span> <a title="Permalink" class="permalink" href="#id-1.4.9.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By default, the Block Storage API service runs in one process. This
limits the number of API requests that the Block Storage service can
process at any given time. In a production environment, you should
increase the Block Storage API throughput by allowing the Block Storage
API service to run in as many processes as the machine capacity allows.</p><div id="id-1.4.9.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The Block Storage API service is named <code class="literal">openstack-cinder-api</code> on
the following distributions: CentOS, Fedora, openSUSE, Red Hat
Enterprise Linux, and SUSE Linux Enterprise. In Ubuntu and Debian
distributions, the Block Storage API service is named <code class="literal">cinder-api</code>.</p></div><p>To do so, use the Block Storage API service option <code class="literal">osapi_volume_workers</code>.
This option allows you to specify the number of API service workers
(or OS processes) to launch for the Block Storage API service.</p><p>To configure this option, open the <code class="literal">/etc/cinder/cinder.conf</code>
configuration file and set the <code class="literal">osapi_volume_workers</code> configuration
key to the number of CPU cores/threads on a machine.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT osapi_volume_workers CORES</pre></div><p>Replace <code class="literal">CORES</code> with the number of CPU cores/threads on a machine.</p></div><div class="sect1 " id="id-1.4.9.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage volumes</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The default OpenStack Block Storage service implementation is an
iSCSI solution that uses <a class="xref" href="#term-logical-volume-manager-lvm" title="Logical Volume Manager (LVM)">Logical Volume Manager (LVM)</a> for Linux.</p><div id="id-1.4.9.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The OpenStack Block Storage service is not a shared storage
solution like a Network Attached Storage (NAS) of NFS volumes
where you can attach a volume to multiple servers. With the
OpenStack Block Storage service, you can attach a volume to only
one instance at a time.</p><p>The OpenStack Block Storage service also provides drivers that
enable you to use several vendors' back-end storage devices in
addition to the base LVM implementation.  These storage devices can
also be used instead of the base LVM installation.</p></div><p>This high-level procedure shows you how to create and attach a volume
to a server instance.</p><p>
        <span class="bold"><strong>To create and attach a volume to an instance</strong></span>
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure the OpenStack Compute and the OpenStack Block Storage
services through the <code class="literal">/etc/cinder/cinder.conf</code> file.</p></li><li class="step "><p>Use the <code class="command">openstack volume create</code> command to create a volume.
This command creates an LV into the volume group (VG) <code class="literal">cinder-volumes</code>.</p></li><li class="step "><p>Use the <code class="command">openstack server add volume</code> command to attach the
volume to an instance. This command creates a unique <a class="xref" href="#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a> that is exposed to the compute node.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The compute node, which runs the instance, now has an active
iSCSI session and new local storage (usually a <code class="literal">/dev/sdX</code>
disk).</p></li><li class="listitem "><p>Libvirt uses that local storage as storage for the instance. The
instance gets a new disk (usually a <code class="literal">/dev/vdX</code> disk).</p></li></ul></div></li></ol></div></div><p>For this particular walkthrough, one cloud controller runs
<code class="literal">nova-api</code>, <code class="literal">nova-scheduler</code>, <code class="literal">nova-objectstore</code>,
<code class="literal">nova-network</code> and <code class="literal">cinder-*</code> services. Two additional compute
nodes run <code class="literal">nova-compute</code>. The walkthrough uses a custom
partitioning scheme that carves out 60 GB of space and labels it as
LVM. The network uses the <code class="literal">FlatManager</code> and <code class="literal">NetworkManager</code>
settings for OpenStack Compute.</p><p>The network mode does not interfere with OpenStack Block Storage
operations, but you must set up networking for Block Storage to work.
For details, see <a class="xref" href="#networking" title="Chapter 9. Networking">Chapter 9, <em>Networking</em></a>.</p><p>To set up Compute to use volumes, ensure that Block Storage is
installed along with <code class="literal">lvm2</code>. This guide describes how to
troubleshoot your installation and back up your Compute volumes.</p><div class="sect2 " id="id-1.4.9.7.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Boot from volume</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In some cases, you can store and run instances from inside volumes.
For information, see the <a class="link" href="http://docs.openstack.org/user-guide/cli-nova-launch-instance-from-volume.html" target="_blank">Launch an instance from a volume</a> section
in the <a class="link" href="http://docs.openstack.org/user-guide/" target="_blank">OpenStack End User Guide</a>.</p></div><div class="sect2 " id="id-1.4.9.7.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure an NFS storage back end</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section explains how to configure OpenStack Block Storage to use
NFS storage. You must be able to access the NFS shares from the server
that hosts the <code class="literal">cinder</code> volume service.</p><div id="id-1.4.9.7.11.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">cinder</code> volume service is named <code class="literal">openstack-cinder-volume</code>
on the following distributions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div><p>In Ubuntu and Debian distributions, the <code class="literal">cinder</code> volume service is
named <code class="literal">cinder-volume</code>.</p></div><p>
          <span class="bold"><strong>Configure Block Storage to use an NFS storage back end</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in as <code class="literal">root</code> to the system hosting the <code class="literal">cinder</code> volume
service.</p></li><li class="step "><p>Create a text file named <code class="literal">nfsshares</code> in the <code class="literal">/etc/cinder/</code> directory.</p></li><li class="step "><p>Add an entry to <code class="literal">/etc/cinder/nfsshares</code> for each NFS share
that the <code class="literal">cinder</code> volume service should use for back end storage.
Each entry should be a separate line, and should use the following
format:</p><div class="verbatim-wrap highlight ini"><pre class="screen">HOST:SHARE</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>HOST is the IP address or host name of the NFS server.</p></li><li class="listitem "><p>SHARE is the absolute path to an existing and accessible NFS share.</p></li></ul></div></li><li class="step "><p>Set <code class="literal">/etc/cinder/nfsshares</code> to be owned by the <code class="literal">root</code> user and
the <code class="literal">cinder</code> group:</p><div class="verbatim-wrap"><pre class="screen"># chown root:cinder /etc/cinder/nfsshares</pre></div></li><li class="step "><p>Set <code class="literal">/etc/cinder/nfsshares</code> to be readable by members of the
cinder group:</p><div class="verbatim-wrap"><pre class="screen"># chmod 0640 /etc/cinder/nfsshares</pre></div></li><li class="step "><p>Configure the <code class="literal">cinder</code> volume service to use the
<code class="literal">/etc/cinder/nfsshares</code> file created earlier. To do so, open
the <code class="literal">/etc/cinder/cinder.conf</code> configuration file and set
the <code class="literal">nfs_shares_config</code> configuration key
to <code class="literal">/etc/cinder/nfsshares</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_shares_config /etc/cinder/nfsshares</pre></div><p>The following distributions include openstack-config:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div></li><li class="step "><p>Optionally, provide any additional NFS mount options required in
your environment in the <code class="literal">nfs_mount_options</code> configuration key
of <code class="literal">/etc/cinder/cinder.conf</code>. If your NFS shares do not
require any additional mount options (or if you are unsure),
skip this step.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can
configure this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_mount_options OPTIONS</pre></div><p>Replace OPTIONS with the mount options to be used when accessing
NFS shares. See the manual page for NFS for more information on
available mount options (<code class="command">man nfs</code>).</p></li><li class="step "><p>Configure the <code class="literal">cinder</code> volume service to use the correct volume
driver, namely <code class="literal">cinder.volume.drivers.nfs.NfsDriver</code>. To do so,
open the <code class="literal">/etc/cinder/cinder.conf</code> configuration file and
set the volume_driver configuration key
to <code class="literal">cinder.volume.drivers.nfs.NfsDriver</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT volume_driver cinder.volume.drivers.nfs.NfsDriver</pre></div></li><li class="step "><p>You can now restart the service to apply the configuration.</p><div id="id-1.4.9.7.11.5.9.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">nfs_sparsed_volumes</code> configuration key determines whether
volumes are created as sparse files and grown as needed or fully
allocated up front. The default and recommended value is <code class="literal">true</code>,
which ensures volumes are initially created as sparse files.</p><p>Setting <code class="literal">nfs_sparsed_volumes</code> to <code class="literal">false</code> will result in
volumes being fully allocated at the time of creation. This leads
to increased delays in volume creation.</p><p>However, should you choose to set <code class="literal">nfs_sparsed_volumes</code> to
<code class="literal">false</code>, you can do so directly in <code class="literal">/etc/cinder/cinder.conf</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can
configure this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT nfs_sparsed_volumes false</pre></div></div><div id="id-1.4.9.7.11.5.9.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>If a client host has SELinux enabled, the <code class="literal">virt_use_nfs</code>
boolean should also be enabled if the host requires access to
NFS volumes on an instance. To enable this boolean, run the
following command as the <code class="literal">root</code> user:</p><div class="verbatim-wrap"><pre class="screen"># setsebool -P virt_use_nfs on</pre></div><p>This command also makes the boolean persistent across reboots.
Run this command on all client hosts that require access to NFS
volumes on an instance. This includes all compute nodes.</p></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.9.7.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure a GlusterFS back end</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section explains how to configure OpenStack Block Storage to use
GlusterFS as a back end. You must be able to access the GlusterFS shares
from the server that hosts the <code class="literal">cinder</code> volume service.</p><div id="id-1.4.9.7.12.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The cinder volume service is named <code class="literal">openstack-cinder-volume</code> on the
following distributions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div><p>In Ubuntu and Debian distributions, the <code class="literal">cinder</code> volume service is
named <code class="literal">cinder-volume</code>.</p></div><p>Mounting GlusterFS volumes requires utilities and libraries from the
<code class="literal">glusterfs-fuse</code> package. This package must be installed on all systems
that will access volumes backed by GlusterFS.</p><div id="id-1.4.9.7.12.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The utilities and libraries required for mounting GlusterFS volumes on
Ubuntu and Debian distributions are available from the <code class="literal">glusterfs-client</code>
package instead.</p></div><p>For information on how to install and configure GlusterFS, refer to the
<a class="link" href="http://www.gluster.org/community/documentation/index.php/Main_Page" target="_blank">GlusterDocumentation</a> page.</p><p>
          <span class="bold"><strong>Configure GlusterFS for OpenStack Block Storage</strong></span>
        </p><p>The GlusterFS server must also be configured accordingly in order to allow
OpenStack Block Storage to use GlusterFS shares:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in as <code class="literal">root</code> to the GlusterFS server.</p></li><li class="step "><p>Set each Gluster volume to use the same UID and GID as the <code class="literal">cinder</code> user:</p><div class="verbatim-wrap"><pre class="screen"># gluster volume set VOL_NAME storage.owner-uid CINDER_UID
# gluster volume set VOL_NAME storage.owner-gid CINDER_GID</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>VOL_NAME is the Gluster volume name.</p></li><li class="listitem "><p>CINDER_UID is the UID of the <code class="literal">cinder</code> user.</p></li><li class="listitem "><p>CINDER_GID is the GID of the <code class="literal">cinder</code> user.</p></li></ul></div><div id="id-1.4.9.7.12.9.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The default UID and GID of the <code class="literal">cinder</code> user is 165 on
most distributions.</p></div></li><li class="step "><p>Configure each Gluster volume to accept <code class="literal">libgfapi</code> connections.
To do this, set each Gluster volume to allow insecure ports:</p><div class="verbatim-wrap"><pre class="screen"># gluster volume set VOL_NAME server.allow-insecure on</pre></div></li><li class="step "><p>Enable client connections from unprivileged ports. To do this,
add the following line to <code class="literal">/etc/glusterfs/glusterd.vol</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">option rpc-auth-allow-insecure on</pre></div></li><li class="step "><p>Restart the <code class="literal">glusterd</code> service:</p><div class="verbatim-wrap"><pre class="screen"># service glusterd restart</pre></div></li></ol></div></div><p>
          <span class="bold"><strong>Configure Block Storage to use a GlusterFS back end</strong></span>
        </p><p>After you configure the GlusterFS service, complete these steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in as <code class="literal">root</code> to the system hosting the Block Storage service.</p></li><li class="step "><p>Create a text file named <code class="literal">glusterfs</code> in <code class="literal">/etc/cinder/</code> directory.</p></li><li class="step "><p>Add an entry to <code class="literal">/etc/cinder/glusterfs</code> for each GlusterFS
share that OpenStack Block Storage should use for back end storage.
Each entry should be a separate line, and should use the following
format:</p><div class="verbatim-wrap highlight ini"><pre class="screen">HOST:/VOL_NAME</pre></div><p>Where:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>HOST is the IP address or host name of the Red Hat Storage server.</p></li><li class="listitem "><p>VOL_NAME is the name of an existing and accessible volume on the
GlusterFS server.</p></li></ul></div><p>Optionally, if your environment requires additional mount options for
a share, you can add them to the share's entry:</p><div class="verbatim-wrap highlight ini"><pre class="screen">HOST:/VOL_NAME -o OPTIONS</pre></div><p>Replace OPTIONS with a comma-separated list of mount options.</p></li><li class="step "><p>Set <code class="literal">/etc/cinder/glusterfs</code> to be owned by the root user
and the <code class="literal">cinder</code> group:</p><div class="verbatim-wrap"><pre class="screen"># chown root:cinder /etc/cinder/glusterfs</pre></div></li><li class="step "><p>Set <code class="literal">/etc/cinder/glusterfs</code> to be readable by members of
the <code class="literal">cinder</code> group:</p><div class="verbatim-wrap"><pre class="screen"># chmod 0640 /etc/cinder/glusterfs</pre></div></li><li class="step "><p>Configure OpenStack Block Storage to use the <code class="literal">/etc/cinder/glusterfs</code>
file created earlier. To do so, open the <code class="literal">/etc/cinder/cinder.conf</code>
configuration file and set the <code class="literal">glusterfs_shares_config</code> configuration
key to <code class="literal">/etc/cinder/glusterfs</code>.</p><p>On distributions that include openstack-config, you can configure this
by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT glusterfs_shares_config /etc/cinder/glusterfs</pre></div><p>The following distributions include <code class="literal">openstack-config</code>:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>CentOS</p></li><li class="listitem "><p>Fedora</p></li><li class="listitem "><p>openSUSE</p></li><li class="listitem "><p>Red Hat Enterprise Linux</p></li><li class="listitem "><p>SUSE Linux Enterprise</p></li></ul></div></li><li class="step "><p>Configure OpenStack Block Storage to use the correct volume driver,
namely <code class="literal">cinder.volume.drivers.glusterfs.GlusterfsDriver</code>. To do so,
open the <code class="literal">/etc/cinder/cinder.conf</code> configuration file and set
the <code class="literal">volume_driver</code> configuration key to
<code class="literal">cinder.volume.drivers.glusterfs.GlusterfsDriver</code>.</p><p>On distributions that include <code class="literal">openstack-config</code>, you can configure
this by running the following command instead:</p><div class="verbatim-wrap"><pre class="screen"># openstack-config --set /etc/cinder/cinder.conf \
  DEFAULT volume_driver cinder.volume.drivers.glusterfs.GlusterfsDriver</pre></div></li><li class="step "><p>You can now restart the service to apply the configuration.</p></li></ol></div></div><p>OpenStack Block Storage is now configured to use a GlusterFS back end.</p><div id="id-1.4.9.7.12.14" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>If a client host has SELinux enabled, the <code class="literal">virt_use_fusefs</code> boolean
should also be enabled if the host requires access to GlusterFS volumes
on an instance. To enable this Boolean, run the following command as
the <code class="literal">root</code> user:</p><div class="verbatim-wrap"><pre class="screen"># setsebool -P virt_use_fusefs on</pre></div><p>This command also makes the Boolean persistent across reboots. Run
this command on all client hosts that require access to GlusterFS
volumes on an instance. This includes all compute nodes.</p></div></div><div class="sect2 " id="multi-backend"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure multiple-storage back ends</span> <a title="Permalink" class="permalink" href="#multi-backend">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>multi-backend</li></ul></div></div></div></div><p>When you configure multiple-storage back ends, you can create several
back-end storage solutions that serve the same OpenStack Compute
configuration and one <code class="literal">cinder-volume</code> is launched for each back-end
storage or back-end storage pool.</p><p>In a multiple-storage back-end configuration, each back end has a name
(<code class="literal">volume_backend_name</code>). Several back ends can have the same name.
In that case, the scheduler properly decides which back end the volume
has to be created in.</p><p>The name of the back end is declared as an extra-specification of a
volume type (such as, <code class="literal">volume_backend_name=LVM</code>). When a volume
is created, the scheduler chooses an appropriate back end to handle the
request, according to the volume type specified by the user.</p><div class="sect3 " id="id-1.4.9.7.13.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable multiple-storage back ends</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.13.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable a multiple-storage back ends, you must set the
<code class="literal">enabled_backends</code> flag in the <code class="literal">cinder.conf</code> file.
This flag defines the names (separated by a comma) of the configuration
groups for the different back ends: one name is associated to one
configuration group for a back end (such as, <code class="literal">[lvmdriver-1]</code>).</p><div id="id-1.4.9.7.13.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The configuration group name is not related to the <code class="literal">volume_backend_name</code>.</p></div><div id="id-1.4.9.7.13.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>After setting the <code class="literal">enabled_backends</code> flag on an existing cinder
service, and restarting the Block Storage services, the original <code class="literal">host</code>
service is replaced with a new host service. The new service appears
with a name like <code class="literal">host@backend</code>. Use:</p><div class="verbatim-wrap"><pre class="screen">$ cinder-manage volume update_host --currenthost CURRENTHOST --newhost CURRENTHOST@BACKEND</pre></div><p>to convert current block devices to the new host name.</p></div><p>The options for a configuration group must be defined in the group
(or default options are used). All the standard Block Storage
configuration options (<code class="literal">volume_group</code>, <code class="literal">volume_driver</code>, and so on)
might be used in a configuration group. Configuration values in
the <code class="literal">[DEFAULT]</code> configuration group are not used.</p><p>These examples show three back ends:</p><div class="verbatim-wrap highlight ini"><pre class="screen">enabled_backends=lvmdriver-1,lvmdriver-2,lvmdriver-3
[lvmdriver-1]
volume_group=cinder-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
[lvmdriver-2]
volume_group=cinder-volumes-2
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
[lvmdriver-3]
volume_group=cinder-volumes-3
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM_b</pre></div><p>In this configuration, <code class="literal">lvmdriver-1</code> and <code class="literal">lvmdriver-2</code> have the same
<code class="literal">volume_backend_name</code>. If a volume creation requests the <code class="literal">LVM</code>
back end name, the scheduler uses the capacity filter scheduler to choose
the most suitable driver, which is either <code class="literal">lvmdriver-1</code> or <code class="literal">lvmdriver-2</code>.
The capacity filter scheduler is enabled by default. The next section
provides more information. In addition, this example presents a
<code class="literal">lvmdriver-3</code> back end.</p><div id="id-1.4.9.7.13.5.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For Fiber Channel drivers that support multipath, the configuration group
requires the <code class="literal">use_multipath_for_image_xfer=true</code> option. In
the example below, you can see details for HPE 3PAR and EMC Fiber
Channel drivers.</p></div><div class="verbatim-wrap highlight ini"><pre class="screen">[3par]
use_multipath_for_image_xfer = true
volume_driver = cinder.volume.drivers.hpe.hpe_3par_fc.HPE3PARFCDriver
volume_backend_name = 3parfc

[emc]
use_multipath_for_image_xfer = true
volume_driver = cinder.volume.drivers.emc.emc_smis_fc.EMCSMISFCDriver
volume_backend_name = emcfc</pre></div></div><div class="sect3 " id="id-1.4.9.7.13.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Block Storage scheduler multi back end</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.13.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must enable the <code class="literal">filter_scheduler</code> option to use
multiple-storage back ends. The filter scheduler:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Filters the available back ends. By default, <code class="literal">AvailabilityZoneFilter</code>,
<code class="literal">CapacityFilter</code> and <code class="literal">CapabilitiesFilter</code> are enabled.</p></li><li class="step "><p>Weights the previously filtered back ends. By default, the
<code class="literal">CapacityWeigher</code> option is enabled. When this option is
enabled, the filter scheduler assigns the highest weight to back
ends with the most available capacity.</p></li></ol></div></div><p>The scheduler uses filters and weights to pick the best back end to
handle the request. The scheduler uses volume types to explicitly create
volumes on specific back ends. For more information about filter and weighing,
see <a class="xref" href="#filter-weigh-scheduler" title="7.2.13. Configure and use driver filter and weighing for scheduler">Section 7.2.13, “Configure and use driver filter and weighing for scheduler”</a>.</p></div><div class="sect3 " id="id-1.4.9.7.13.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume type</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.13.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Before using it, a volume type has to be declared to Block Storage.
This can be done by the following command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-username admin --os-tenant-name admin volume type create lvm</pre></div><p>Then, an extra-specification has to be created to link the volume
type to a back end name. Run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-username admin --os-tenant-name admin volume type set lvm \
  --property volume_backend_name=LVM_iSCSI</pre></div><p>This example creates a <code class="literal">lvm</code> volume type with
<code class="literal">volume_backend_name=LVM_iSCSI</code> as extra-specifications.</p><p>Create another volume type:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-username admin --os-tenant-name admin volume type create lvm_gold

$ openstack --os-username admin --os-tenant-name admin volume type set lvm_gold \
  --property volume_backend_name=LVM_iSCSI_b</pre></div><p>This second volume type is named <code class="literal">lvm_gold</code> and has <code class="literal">LVM_iSCSI_b</code> as
back end name.</p><div id="id-1.4.9.7.13.7.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To list the extra-specifications, use this command:</p><div class="verbatim-wrap"><pre class="screen">$ cinder --os-username admin --os-tenant-name admin extra-specs-list</pre></div></div><div id="id-1.4.9.7.13.7.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If a volume type points to a <code class="literal">volume_backend_name</code> that does not
exist in the Block Storage configuration, the <code class="literal">filter_scheduler</code>
returns an error that it cannot find a valid host with the suitable
back end.</p></div></div><div class="sect3 " id="id-1.4.9.7.13.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.13.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you create a volume, you must specify the volume type.
The extra-specifications of the volume type are used to determine which
back end has to be used.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --size 1 --type lvm test_multi_backend</pre></div><p>Considering the <code class="literal">cinder.conf</code> described previously, the scheduler
creates this volume on <code class="literal">lvmdriver-1</code> or <code class="literal">lvmdriver-2</code>.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --size 1 --type lvm_gold test_multi_backend</pre></div><p>This second volume is created on <code class="literal">lvmdriver-3</code>.</p></div></div><div class="sect2 " id="id-1.4.9.7.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Back up Block Storage service disks</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>While you can use the LVM snapshot to create snapshots, you can also use
it to back up your volumes. By using LVM snapshot, you reduce the size
of the backup; only existing data is backed up instead of the entire
volume.</p><p>To back up a volume, you must create a snapshot of it. An LVM snapshot
is the exact copy of a logical volume, which contains data in a frozen
state. This prevents data corruption because data cannot be manipulated
during the volume creation process. Remember that the volumes created
through a <code class="command">nova volume-create</code> command exist in an LVM logical
volume.</p><p>You must also make sure that the operating system is not using the
volume and that all data has been flushed on the guest file systems.
This usually means that those file systems have to be unmounted during
the snapshot creation. They can be mounted again as soon as the logical
volume snapshot has been created.</p><p>Before you create the snapshot you must have enough space to save it.
As a precaution, you should have at least twice as much space as the
potential snapshot size. If insufficient space is available, the snapshot
might become corrupted.</p><p>For this example assume that a 100 GB volume named <code class="literal">volume-00000001</code>
was created for an instance while only 4 GB are used. This example uses
these commands to back up only those 4 GB:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="command">lvm2</code> command. Directly manipulates the volumes.</p></li><li class="listitem "><p><code class="command">kpartx</code> command. Discovers the partition table created inside the
instance.</p></li><li class="listitem "><p><code class="command">tar</code> command. Creates a minimum-sized backup.</p></li><li class="listitem "><p><code class="command">sha1sum</code> command. Calculates the backup checksum to check its
consistency.</p></li></ul></div><p>You can apply this process to volumes of any size.</p><p>
          <span class="bold"><strong>To back up Block Storage service disks</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create a snapshot of a used volume</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Use this command to list all volumes</p><div class="verbatim-wrap"><pre class="screen"># lvdisplay</pre></div></li><li class="listitem "><p>Create the snapshot; you can do this while the volume is attached
to an instance:</p><div class="verbatim-wrap"><pre class="screen"># lvcreate --size 10G --snapshot --name volume-00000001-snapshot \
  /dev/cinder-volumes/volume-00000001</pre></div><p>Use the <code class="literal">--snapshot</code> configuration option to tell LVM that you want a
snapshot of an already existing volume. The command includes the size
of the space reserved for the snapshot volume, the name of the snapshot,
and the path of an already existing volume. Generally, this path
is <code class="literal">/dev/cinder-volumes/VOLUME_NAME</code>.</p><p>The size does not have to be the same as the volume of the snapshot.
The <code class="literal">--size</code> parameter defines the space that LVM reserves
for the snapshot volume. As a precaution, the size should be the same
as that of the original volume, even if the whole space is not
currently used by the snapshot.</p></li><li class="listitem "><p>Run the <code class="command">lvdisplay</code> command again to verify the snapshot:</p><div class="verbatim-wrap"><pre class="screen">--- Logical volume ---
LV Name                /dev/cinder-volumes/volume-00000001
VG Name                cinder-volumes
LV UUID                gI8hta-p21U-IW2q-hRN1-nTzN-UC2G-dKbdKr
LV Write Access        read/write
LV snapshot status     source of
                       /dev/cinder-volumes/volume-00000026-snap [active]
LV Status              available
# open                 1
LV Size                15,00 GiB
Current LE             3840
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           251:13

--- Logical volume ---
LV Name                /dev/cinder-volumes/volume-00000001-snap
VG Name                cinder-volumes
LV UUID                HlW3Ep-g5I8-KGQb-IRvi-IRYU-lIKe-wE9zYr
LV Write Access        read/write
LV snapshot status     active destination for /dev/cinder-volumes/volume-00000026
LV Status              available
# open                 0
LV Size                15,00 GiB
Current LE             3840
COW-table size         10,00 GiB
COW-table LE           2560
Allocated to snapshot  0,00%
Snapshot chunk size    4,00 KiB
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           251:14</pre></div></li></ul></div></li><li class="step "><p>Partition table discovery</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To exploit the snapshot with the <code class="command">tar</code> command, mount
your partition on the Block Storage service server.</p><p>The <code class="command">kpartx</code> utility discovers and maps table partitions.
You can use it to view partitions that are created inside the
instance. Without using the partitions created inside instances,
you cannot see its content and create efficient backups.</p><div class="verbatim-wrap"><pre class="screen"># kpartx -av /dev/cinder-volumes/volume-00000001-snapshot</pre></div><div id="id-1.4.9.7.14.10.2.2.1.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>On a Debian-based distribution, you can use the
<code class="command">apt-get install kpartx</code> command to install
<code class="command">kpartx</code>.</p></div><p>If the tools successfully find and map the partition table,
no errors are returned.</p></li><li class="listitem "><p>To check the partition table map, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ ls /dev/mapper/nova*</pre></div><p>You can see the <code class="literal">cinder--volumes-volume--00000001--snapshot1</code>
partition.</p><p>If you created more than one partition on that volume, you see
several partitions; for example:
<code class="literal">cinder--volumes-volume--00000001--snapshot2</code>,
<code class="literal">cinder--volumes-volume--00000001--snapshot3</code>, and so on.</p></li><li class="listitem "><p>Mount your partition</p><div class="verbatim-wrap"><pre class="screen"># mount /dev/mapper/cinder--volumes-volume--volume--00000001--snapshot1 /mnt</pre></div><p>If the partition mounts successfully, no errors are returned.</p><p>You can directly access the data inside the instance. If a message
prompts you for a partition or you cannot mount it, determine whether
enough space was allocated for the snapshot or the <code class="command">kpartx</code>
command failed to discover the partition table.</p><p>Allocate more space to the snapshot and try the process again.</p></li></ul></div></li><li class="step "><p>Use the <code class="command">tar</code> command to create archives</p><p>Create a backup of the volume:</p><div class="verbatim-wrap"><pre class="screen">$ tar --exclude="lost+found" --exclude="some/data/to/exclude" -czf \
  volume-00000001.tar.gz -C /mnt/ /backup/destination</pre></div><p>This command creates a <code class="literal">tar.gz</code> file that contains the data,
<span class="emphasis"><em>and data only</em></span>. This ensures that you do not waste space by backing
up empty sectors.</p></li><li class="step "><p>Checksum calculation I</p><p>You should always have the checksum for your backup files. When you
transfer the same file over the network, you can run a checksum
calculation to ensure that your file was not corrupted during its
transfer. The checksum is a unique ID for a file. If the checksums are
different, the file is corrupted.</p><p>Run this command to run a checksum for your file and save the result
to a file:</p><div class="verbatim-wrap"><pre class="screen">$ sha1sum volume-00000001.tar.gz &gt; volume-00000001.checksum</pre></div><div id="id-1.4.9.7.14.10.4.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Use the <code class="command">sha1sum</code> command carefully because the time it
takes to complete the calculation is directly proportional to the
size of the file.</p><p>Depending on your CPU, the process might take a long time for
files larger than around 4 to 6 GB.</p></div></li><li class="step "><p>After work cleaning</p><p>Now that you have an efficient and consistent backup, use this command
to clean up the file system:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Unmount the volume.</p><div class="verbatim-wrap"><pre class="screen">$ umount /mnt</pre></div></li><li class="listitem "><p>Delete the partition table.</p><div class="verbatim-wrap"><pre class="screen">$ kpartx -dv /dev/cinder-volumes/volume-00000001-snapshot</pre></div></li><li class="listitem "><p>Remove the snapshot.</p><div class="verbatim-wrap"><pre class="screen">$ lvremove -f /dev/cinder-volumes/volume-00000001-snapshot</pre></div></li></ul></div><p>Repeat these steps for all your volumes.</p></li><li class="step "><p>Automate your backups</p><p>Because more and more volumes might be allocated to your Block Storage
service, you might want to automate your backups.
The <a class="link" href="https://github.com/Razique/BashStuff/blob/master/SYSTEMS/OpenStack/SCR_5005_V01_NUAC-OPENSTACK-EBS-volumes-backup.sh" target="_blank">SCR_5005_V01_NUAC-OPENSTACK-EBS-volumes-backup.sh</a> script assists
you with this task. The script performs the operations from the previous
example, but also provides a mail report and runs the backup based on
the <code class="literal">backups_retention_days</code> setting.</p><p>Launch this script from the server that runs the Block Storage service.</p><p>This example shows a mail report:</p><div class="verbatim-wrap"><pre class="screen">Backup Start Time - 07/10 at 01:00:01
Current retention - 7 days

The backup volume is mounted. Proceed...
Removing old backups...  : /BACKUPS/EBS-VOL/volume-00000019/volume-00000019_28_09_2011.tar.gz
     /BACKUPS/EBS-VOL/volume-00000019 - 0 h 1 m and 21 seconds. Size - 3,5G

The backup volume is mounted. Proceed...
Removing old backups...  : /BACKUPS/EBS-VOL/volume-0000001a/volume-0000001a_28_09_2011.tar.gz
     /BACKUPS/EBS-VOL/volume-0000001a - 0 h 4 m and 15 seconds. Size - 6,9G
---------------------------------------
Total backups size - 267G - Used space : 35%
Total execution time - 1 h 75 m and 35 seconds</pre></div><p>The script also enables you to SSH to your instances and run a
<code class="command">mysqldump</code> command into them. To make this work, enable
the connection to the Compute project keys. If you do not want to
run the <code class="command">mysqldump</code> command, you can add
<code class="literal">enable_mysql_dump=0</code> to the script to turn off this functionality.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.9.7.15"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate volumes</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.15">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack has the ability to migrate volumes between back ends which support
its volume-type. Migrating a volume transparently moves its data from the
current back end for the volume to a new one. This is an administrator
function, and can be used for functions including storage evacuation (for
maintenance or decommissioning), or manual optimizations (for example,
performance, reliability, or cost).</p><p>These workflows are possible for a migration:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>If the storage can migrate the volume on its own, it is given the
opportunity to do so. This allows the Block Storage driver to enable
optimizations that the storage might be able to perform. If the back end
is not able to perform the migration, the Block Storage uses one of two
generic flows, as follows.</p></li><li class="step "><p>If the volume is not attached, the Block Storage service creates a volume
and copies the data from the original to the new volume.</p><div id="id-1.4.9.7.15.4.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>While most back ends support this function, not all do. See the <a class="link" href="http://docs.openstack.org/newton/config-reference/block-storage/volume-drivers.html" target="_blank">driver
documentation</a>
in the OpenStack Configuration Reference for more details.</p></div></li><li class="step "><p>If the volume is attached to a VM instance, the Block Storage creates a
volume, and calls Compute to copy the data from the original to the new
volume. Currently this is supported only by the Compute libvirt driver.</p></li></ol></div></div><p>As an example, this scenario shows two LVM back ends and migrates an attached
volume from one to the other. This scenario uses the third migration flow.</p><p>First, list the available back ends:</p><div class="verbatim-wrap"><pre class="screen"># cinder get-pools
+----------+----------------------------------------------------+
| Property |                       Value                        |
+----------+----------------------------------------------------+
|   name   |           server1@lvmstorage-1#lvmstorage-1        |
+----------+----------------------------------------------------+
+----------+----------------------------------------------------+
| Property |                      Value                         |
+----------+----------------------------------------------------+
|   name   |           server2@lvmstorage-2#lvmstorage-2        |
+----------+----------------------------------------------------+</pre></div><div id="id-1.4.9.7.15.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only Block Storage V2 API supports <code class="command">cinder get-pools</code>.</p></div><p>You can also get available back ends like following:</p><div class="verbatim-wrap"><pre class="screen"># cinder-manage host list
server1@lvmstorage-1    zone1
server2@lvmstorage-2    zone1</pre></div><p>But it needs to add pool name in the end. For example,
<code class="literal">server1@lvmstorage-1#zone1</code>.</p><p>Next, as the admin user, you can see the current status of the volume
(replace the example ID with your own):</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume show 6088f80a-f116-4331-ad48-9afb0dfb196c

+--------------------------------+--------------------------------------+
| Field                          | Value                                |
+--------------------------------+--------------------------------------+
| attachments                    | []                                   |
| availability_zone              | zone1                                |
| bootable                       | false                                |
| consistencygroup_id            | None                                 |
| created_at                     | 2013-09-01T14:53:22.000000           |
| description                    | test                                 |
| encrypted                      | False                                |
| id                             | 6088f80a-f116-4331-ad48-9afb0dfb196c |
| migration_status               | None                                 |
| multiattach                    | False                                |
| name                           | test                                 |
| os-vol-host-attr:host          | controller@lvm#LVM                   |
| os-vol-mig-status-attr:migstat | None                                 |
| os-vol-mig-status-attr:name_id | None                                 |
| os-vol-tenant-attr:tenant_id   | d88310717a8e4ebcae84ed075f82c51e     |
| properties                     | readonly='False'                     |
| replication_status             | disabled                             |
| size                           | 1                                    |
| snapshot_id                    | None                                 |
| source_volid                   | None                                 |
| status                         | in-use                               |
| type                           | None                                 |
| updated_at                     | 2016-07-31T07:22:19.000000           |
| user_id                        | d8e5e5727f3a4ce1886ac8ecec058e83     |
+--------------------------------+--------------------------------------+</pre></div><p>Note these attributes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">os-vol-host-attr:host</code> - the volume's current back end.</p></li><li class="listitem "><p><code class="literal">os-vol-mig-status-attr:migstat</code> - the status of this volume's migration
(None means that a migration is not currently in progress).</p></li><li class="listitem "><p><code class="literal">os-vol-mig-status-attr:name_id</code> - the volume ID that this volume's name
on the back end is based on. Before a volume is ever migrated, its name on
the back end storage may be based on the volume's ID (see the
<code class="literal">volume_name_template</code> configuration parameter). For example, if
<code class="literal">volume_name_template</code> is kept as the default value (<code class="literal">volume-%s</code>), your
first LVM back end has a logical volume named
<code class="literal">volume-6088f80a-f116-4331-ad48-9afb0dfb196c</code>. During the course of a
migration, if you create a volume and copy over the data, the volume get
the new name but keeps its original ID. This is exposed by the <code class="literal">name_id</code>
attribute.</p><div id="id-1.4.9.7.15.15.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you plan to decommission a block storage node, you must stop the
<code class="literal">cinder</code> volume service on the node after performing the migration.</p><p>On nodes that run CentOS, Fedora, openSUSE, Red Hat Enterprise Linux,
or SUSE Linux Enterprise, run:</p><div class="verbatim-wrap"><pre class="screen"># service openstack-cinder-volume stop
# chkconfig openstack-cinder-volume off</pre></div><p>On nodes that run Ubuntu or Debian, run:</p><div class="verbatim-wrap"><pre class="screen"># service cinder-volume stop
# chkconfig cinder-volume off</pre></div><p>Stopping the cinder volume service will prevent volumes from being
allocated to the node.</p></div></li></ul></div><p>Migrate this volume to the second LVM back end:</p><div class="verbatim-wrap"><pre class="screen">$ cinder migrate 6088f80a-f116-4331-ad48-9afb0dfb196c \
  server2@lvmstorage-2#lvmstorage-2</pre></div><p>You can use the <code class="command">openstack volume show</code> command to see the status of
the migration. While migrating, the <code class="literal">migstat</code> attribute shows states such as
<code class="literal">migrating</code> or <code class="literal">completing</code>. On error, <code class="literal">migstat</code> is set to None and the
host attribute shows the original <code class="literal">host</code>. On success, in this example, the
output looks like:</p><div class="verbatim-wrap"><pre class="screen">+--------------------------------+--------------------------------------+
| Field                          | Value                                |
+--------------------------------+--------------------------------------+
| attachments                    | []                                   |
| availability_zone              | zone1                                |
| bootable                       | false                                |
| consistencygroup_id            | None                                 |
| created_at                     | 2013-09-01T14:53:22.000000           |
| description                    | test                                 |
| encrypted                      | False                                |
| id                             | 6088f80a-f116-4331-ad48-9afb0dfb196c |
| migration_status               | None                                 |
| multiattach                    | False                                |
| name                           | test                                 |
| os-vol-host-attr:host          | controller@lvm#LVM                   |
| os-vol-mig-status-attr:migstat | None                                 |
| os-vol-mig-status-attr:name_id | None                                 |
| os-vol-tenant-attr:tenant_id   | d88310717a8e4ebcae84ed075f82c51e     |
| properties                     | readonly='False'                     |
| replication_status             | disabled                             |
| size                           | 1                                    |
| snapshot_id                    | None                                 |
| source_volid                   | None                                 |
| status                         | in-use                               |
| type                           | None                                 |
| updated_at                     | 2016-07-31T07:22:19.000000           |
| user_id                        | d8e5e5727f3a4ce1886ac8ecec058e83     |
+--------------------------------+--------------------------------------+</pre></div><p>Note that <code class="literal">migstat</code> is None, host is the new host, and <code class="literal">name_id</code> holds the
ID of the volume created by the migration. If you look at the second LVM back
end, you find the logical volume
<code class="literal">volume-133d1f56-9ffc-4f57-8798-d5217d851862</code>.</p><div id="id-1.4.9.7.15.21" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The migration is not visible to non-admin users (for example, through the
volume <code class="literal">status</code>). However, some operations are not allowed while a
migration is taking place, such as attaching/detaching a volume and
deleting a volume. If a user performs such an action during a migration,
an error is returned.</p></div><div id="id-1.4.9.7.15.22" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Migrating volumes that have snapshots are currently not allowed.</p></div></div><div class="sect2 " id="id-1.4.9.7.16"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Gracefully remove a GlusterFS volume from usage</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.16">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Configuring the <code class="literal">cinder</code> volume service to use GlusterFS involves creating a
shares file (for example, <code class="literal">/etc/cinder/glusterfs</code>). This shares file
lists each GlusterFS volume (with its corresponding storage server) that
the <code class="literal">cinder</code> volume service can use for back end storage.</p><p>To remove a GlusterFS volume from usage as a back end, delete the volume's
corresponding entry from the shares file. After doing so, restart the Block
Storage services.</p><p>Restarting the Block Storage services will prevent the <code class="literal">cinder</code> volume
service from exporting the deleted GlusterFS volume. This will prevent any
instances from mounting the volume from that point onwards.</p><p>However, the removed GlusterFS volume might still be mounted on an instance
at this point. Typically, this is the case when the volume was already
mounted while its entry was deleted from the shares file.
Whenever this occurs, you will have to unmount the volume as normal after
the Block Storage services are restarted.</p></div><div class="sect2 " id="volume-backups"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Back up and restore volumes and snapshots</span> <a title="Permalink" class="permalink" href="#volume-backups">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>volume-backups</li></ul></div></div></div></div><p>The <code class="literal">openstack</code> command-line interface provides the tools for creating a
volume backup. You can restore a volume from a backup as long as the
backup's associated database information (or backup metadata) is intact
in the Block Storage database.</p><p>Run this command to create a backup of a volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume backup create [--incremental] [--force] VOLUME</pre></div><p>Where <code class="literal">VOLUME</code> is the name or ID of the volume, <code class="literal">incremental</code> is
a flag that indicates whether an incremental backup should be performed,
and <code class="literal">force</code> is a flag that allows or disallows backup of a volume
when the volume is attached to an instance.</p><p>Without the <code class="literal">incremental</code> flag, a full backup is created by default.
With the <code class="literal">incremental</code> flag, an incremental backup is created.</p><p>Without the <code class="literal">force</code> flag, the volume will be backed up only if its
status is <code class="literal">available</code>. With the <code class="literal">force</code> flag, the volume will be
backed up whether its status is <code class="literal">available</code> or <code class="literal">in-use</code>. A volume
is <code class="literal">in-use</code> when it is attached to an instance. The backup of an
<code class="literal">in-use</code> volume means your data is crash consistent. The <code class="literal">force</code>
flag is False by default.</p><div id="id-1.4.9.7.17.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">incremental</code> and <code class="literal">force</code> flags are only available for block
storage API v2. You have to specify <code class="literal">[--os-volume-api-version 2]</code> in the
<code class="literal">cinder</code> command-line interface to use this parameter.</p></div><div id="id-1.4.9.7.17.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">force</code> flag is new in OpenStack Liberty.</p></div><p>The incremental backup is based on a parent backup which is an existing
backup with the latest timestamp. The parent backup can be a full backup
or an incremental backup depending on the timestamp.</p><div id="id-1.4.9.7.17.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The first backup of a volume has to be a full backup. Attempting to do
an incremental backup without any existing backups will fail.
There is an <code class="literal">is_incremental</code> flag that indicates whether a backup is
incremental when showing details on the backup.
Another flag, <code class="literal">has_dependent_backups</code>, returned when showing backup
details, will indicate whether the backup has dependent backups.
If it is <code class="literal">true</code>, attempting to delete this backup will fail.</p></div><p>A new configure option <code class="literal">backup_swift_block_size</code> is introduced into
<code class="literal">cinder.conf</code> for the default Swift backup driver. This is the size in
bytes that changes are tracked for incremental backups. The existing
<code class="literal">backup_swift_object_size</code> option, the size in bytes of Swift backup
objects, has to be a multiple of <code class="literal">backup_swift_block_size</code>. The default
is 32768 for <code class="literal">backup_swift_block_size</code>, and the default is 52428800 for
<code class="literal">backup_swift_object_size</code>.</p><p>The configuration option <code class="literal">backup_swift_enable_progress_timer</code> in
<code class="literal">cinder.conf</code> is used when backing up the volume to Object Storage
back end. This option enables or disables the timer. It is enabled by default
to send the periodic progress notifications to the Telemetry service.</p><p>This command also returns a backup ID. Use this backup ID when restoring
the volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume backup restore BACKUP_ID VOLUME_ID</pre></div><p>When restoring from a full backup, it is a full restore.</p><p>When restoring from an incremental backup, a list of backups is built based
on the IDs of the parent backups. A full restore is performed based on the
full backup first, then restore is done based on the incremental backup,
laying on top of it in order.</p><p>You can view a backup list with the <code class="command">cinder backup-list</code>
command. Optional arguments to clarify the status of your backups
include: running <code class="literal">--name</code>, <code class="literal">--status</code>, and
<code class="literal">--volume-id</code> to filter through backups by the specified name,
status, or volume-id. Search with <code class="literal">--all-tenants</code> for details of the
projects associated with the listed backups.</p><p>Because volume backups are dependent on the Block Storage database, you must
also back up your Block Storage database regularly to ensure data recovery.</p><div id="id-1.4.9.7.17.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Alternatively, you can export and save the metadata of selected volume
backups. Doing so precludes the need to back up the entire Block Storage
database. This is useful if you need only a small subset of volumes to
survive a catastrophic database failure.</p><p>If you specify a UUID encryption key when setting up the volume
specifications, the backup metadata ensures that the key will remain valid
when you back up and restore the volume.</p><p>For more information about how to export and import volume backup metadata,
see the section called <a class="xref" href="#volume-backups-export-import" title="7.2.9. Export and import backup metadata">Section 7.2.9, “Export and import backup metadata”</a>.</p></div><p>By default, the swift object store is used for the backup repository.</p><p>If instead you want to use an NFS export as the backup repository, add the
following configuration options to the <code class="literal">[DEFAULT]</code> section of the
<code class="literal">cinder.conf</code> file and restart the Block Storage services:</p><div class="verbatim-wrap highlight ini"><pre class="screen">backup_driver = cinder.backup.drivers.nfs
backup_share = HOST:EXPORT_PATH</pre></div><p>For the <code class="literal">backup_share</code> option, replace <code class="literal">HOST</code> with the DNS resolvable
host name or the IP address of the storage server for the NFS share, and
<code class="literal">EXPORT_PATH</code> with the path to that share. If your environment requires
that non-default mount options be specified for the share, set these as
follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">backup_mount_options = MOUNT_OPTIONS</pre></div><p><code class="literal">MOUNT_OPTIONS</code> is a comma-separated string of NFS mount options as detailed
in the NFS man page.</p><p>There are several other options whose default values may be overridden as
appropriate for your environment:</p><div class="verbatim-wrap highlight ini"><pre class="screen">backup_compression_algorithm = zlib
backup_sha_block_size_bytes = 32768
backup_file_size = 1999994880</pre></div><p>The option <code class="literal">backup_compression_algorithm</code> can be set to <code class="literal">bz2</code> or <code class="literal">None</code>.
The latter can be a useful setting when the server providing the share for the
backup repository itself performs deduplication or compression on the backup
data.</p><p>The option <code class="literal">backup_file_size</code> must be a multiple of
<code class="literal">backup_sha_block_size_bytes</code>. It is effectively the maximum file size to be
used, given your environment, to hold backup data. Volumes larger than this
will be stored in multiple files in the backup repository. The
<code class="literal">backup_sha_block_size_bytes</code> option determines the size of blocks from the
cinder volume being backed up on which digital signatures are calculated in
order to enable incremental backup capability.</p><p>You also have the option of resetting the state of a backup. When creating or
restoring a backup, sometimes it may get stuck in the creating or restoring
states due to problems like the database or rabbitmq being down. In situations
like these resetting the state of the backup can restore it to a functional
status.</p><p>Run this command to restore the state of a backup:</p><div class="verbatim-wrap"><pre class="screen">$ cinder backup-reset-state [--state STATE] BACKUP_ID-1 BACKUP_ID-2 ...</pre></div><p>Run this command to create a backup of a snapshot:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume backup create [--incremental] [--force] \
  [--snapshot SNAPSHOT_ID] VOLUME</pre></div><p>Where <code class="literal">VOLUME</code> is the name or ID of the volume, <code class="literal">SNAPSHOT_ID</code> is the ID of
the volume's snapshot.</p></div><div class="sect2 " id="volume-backups-export-import"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Export and import backup metadata</span> <a title="Permalink" class="permalink" href="#volume-backups-export-import">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>volume-backups-export-import</li></ul></div></div></div></div><p>A volume backup can only be restored on the same Block Storage service. This
is because restoring a volume from a backup requires metadata available on
the database used by the Block Storage service.</p><div id="id-1.4.9.7.18.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For information about how to back up and restore a volume, see
the section called <a class="xref" href="#volume-backups" title="7.2.8. Back up and restore volumes and snapshots">Section 7.2.8, “Back up and restore volumes and snapshots”</a>.</p></div><p>You can, however, export the metadata of a volume backup. To do so, run
this command as an OpenStack <code class="literal">admin</code> user (presumably, after creating
a volume backup):</p><div class="verbatim-wrap"><pre class="screen">$ cinder backup-export BACKUP_ID</pre></div><p>Where <code class="literal">BACKUP_ID</code> is the volume backup's ID. This command should return the
backup's corresponding database information as encoded string metadata.</p><p>Exporting and storing this encoded string metadata allows you to completely
restore the backup, even in the event of a catastrophic database failure.
This will preclude the need to back up the entire Block Storage database,
particularly if you only need to keep complete backups of a small subset
of volumes.</p><p>If you have placed encryption on your volumes, the encryption will still be
in place when you restore the volume if a UUID encryption key is specified
when creating volumes. Using backup metadata support, UUID keys set up for
a volume (or volumes) will remain valid when you restore a backed-up volume.
The restored volume will remain encrypted, and will be accessible with your
credentials.</p><p>In addition, having a volume backup and its backup metadata also provides
volume portability. Specifically, backing up a volume and exporting its
metadata will allow you to restore the volume on a completely different Block
Storage database, or even on a different cloud service. To do so, first
import the backup metadata to the Block Storage database and then restore
the backup.</p><p>To import backup metadata, run the following command as an OpenStack
<code class="literal">admin</code>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder backup-import METADATA</pre></div><p>Where <code class="literal">METADATA</code> is the backup metadata exported earlier.</p><p>Once you have imported the backup metadata into a Block Storage database,
restore the volume (see the section called <a class="xref" href="#volume-backups" title="7.2.8. Back up and restore volumes and snapshots">Section 7.2.8, “Back up and restore volumes and snapshots”</a>).</p></div><div class="sect2 " id="id-1.4.9.7.19"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use LIO iSCSI support</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.19">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The default mode for the <code class="literal">iscsi_helper</code> tool is <code class="literal">tgtadm</code>.
To use LIO iSCSI, install the <code class="literal">python-rtslib</code> package, and set
<code class="literal">iscsi_helper=lioadm</code> in the <code class="literal">cinder.conf</code> file.</p><p>Once configured, you can use the <code class="command">cinder-rtstool</code> command to
manage the volumes. This command enables you to create, delete, and
verify volumes and determine targets and add iSCSI initiators to the
system.</p></div><div class="sect2 " id="id-1.4.9.7.20"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure and use volume number weigher</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.20">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage enables you to choose a volume back end according
to <code class="literal">free_capacity</code> and <code class="literal">allocated_capacity</code>. The volume number weigher
feature lets the scheduler choose a volume back end based on its volume
number in the volume back end. This can provide another means to improve
the volume back ends' I/O balance and the volumes' I/O performance.</p><div class="sect3 " id="id-1.4.9.7.20.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable volume number weigher</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.20.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable a volume number weigher, set the
<code class="literal">scheduler_default_weighers</code> to <code class="literal">VolumeNumberWeigher</code> flag in the
<code class="literal">cinder.conf</code> file to define <code class="literal">VolumeNumberWeigher</code>
as the selected weigher.</p></div><div class="sect3 " id="id-1.4.9.7.20.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure multiple-storage back ends</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.20.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To configure <code class="literal">VolumeNumberWeigher</code>, use <code class="literal">LVMVolumeDriver</code>
as the volume driver.</p><p>This configuration defines two LVM volume groups: <code class="literal">stack-volumes</code> with
10 GB capacity and <code class="literal">stack-volumes-1</code> with 60 GB capacity.
This example configuration defines two back ends:</p><div class="verbatim-wrap highlight ini"><pre class="screen">scheduler_default_weighers=VolumeNumberWeigher
enabled_backends=lvmdriver-1,lvmdriver-2
[lvmdriver-1]
volume_group=stack-volumes
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM

[lvmdriver-2]
volume_group=stack-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM</pre></div></div><div class="sect3 " id="id-1.4.9.7.20.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume type</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.20.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Define a volume type in Block Storage:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type create lvm</pre></div><p>Create an extra specification that links the volume type to a back-end name:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type set lvm --property volume_backend_name=LVM</pre></div><p>This example creates a lvm volume type with
<code class="literal">volume_backend_name=LVM</code> as extra specifications.</p></div><div class="sect3 " id="id-1.4.9.7.20.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.11.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.20.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create six 1-GB volumes, run the
<code class="command">openstack volume create --size 1 --type lvm volume1</code> command
six times:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --size 1 --type lvm volume1</pre></div><p>This command creates three volumes in <code class="literal">stack-volumes</code> and
three volumes in <code class="literal">stack-volumes-1</code>.</p><p>List the available volumes:</p><div class="verbatim-wrap"><pre class="screen"># lvs
LV                                          VG              Attr      LSize  Pool Origin Data%  Move Log Copy%  Convert
volume-3814f055-5294-4796-b5e6-1b7816806e5d stack-volumes   -wi-a----  1.00g
volume-72cf5e79-99d2-4d23-b84e-1c35d3a293be stack-volumes   -wi-a----  1.00g
volume-96832554-0273-4e9d-902b-ad421dfb39d1 stack-volumes   -wi-a----  1.00g
volume-169386ef-3d3e-4a90-8439-58ceb46889d9 stack-volumes-1 -wi-a----  1.00g
volume-460b0bbb-d8a0-4bc3-9882-a129a5fe8652 stack-volumes-1 -wi-a----  1.00g
volume-9a08413b-0dbc-47c9-afb8-41032ab05a41 stack-volumes-1 -wi-a----  1.00g</pre></div></div></div><div class="sect2 " id="id-1.4.9.7.21"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Consistency groups</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.21">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Consistency group support is available in OpenStack Block Storage. The
support is added for creating snapshots of consistency groups. This
feature leverages the storage level consistency technology. It allows
snapshots of multiple volumes in the same consistency group to be taken
at the same point-in-time to ensure data consistency. The consistency
group operations can be performed using the Block Storage command line.</p><div id="id-1.4.9.7.21.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only Block Storage V2 API supports consistency groups. You can
specify <code class="literal">--os-volume-api-version 2</code> when using Block Storage
command line for consistency group operations.</p></div><p>Before using consistency groups, make sure the Block Storage driver that
you are running has consistency group support by reading the Block
Storage manual or consulting the driver maintainer. There are a small
number of drivers that have implemented this feature. The default LVM
driver does not support consistency groups yet because the consistency
technology is not available at the storage level.</p><p>Before using consistency groups, you must change policies for the
consistency group APIs in the <code class="literal">/etc/cinder/policy.json</code> file.
By default, the consistency group APIs are disabled.
Enable them before running consistency group operations.</p><p>Here are existing policy entries for consistency groups:</p><div class="verbatim-wrap highlight json"><pre class="screen">"consistencygroup:create": "group:nobody",
"consistencygroup:delete": "group:nobody",
"consistencygroup:update": "group:nobody",
"consistencygroup:get": "group:nobody",
"consistencygroup:get_all": "group:nobody",
"consistencygroup:create_cgsnapshot" : "group:nobody",
"consistencygroup:delete_cgsnapshot": "group:nobody",
"consistencygroup:get_cgsnapshot": "group:nobody",
"consistencygroup:get_all_cgsnapshots": "group:nobody",</pre></div><p>Remove <code class="literal">group:nobody</code> to enable these APIs:</p><div class="verbatim-wrap highlight json"><pre class="screen">"consistencygroup:create": "",
"consistencygroup:delete": "",
"consistencygroup:update": "",
"consistencygroup:get": "",
"consistencygroup:get_all": "",
"consistencygroup:create_cgsnapshot" : "",
"consistencygroup:delete_cgsnapshot": "",
"consistencygroup:get_cgsnapshot": "",
"consistencygroup:get_all_cgsnapshots": "",</pre></div><p>Restart Block Storage API service after changing policies.</p><p>The following consistency group operations are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a consistency group, given volume types.</p><div id="id-1.4.9.7.21.12.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A consistency group can support more than one volume type. The
scheduler is responsible for finding a back end that can support
all given volume types.</p><p>A consistency group can only contain volumes hosted by the same
back end.</p><p>A consistency group is empty upon its creation. Volumes need to
be created and added to it later.</p></div></li><li class="listitem "><p>Show a consistency group.</p></li><li class="listitem "><p>List consistency groups.</p></li><li class="listitem "><p>Create a volume and add it to a consistency group, given volume type
and consistency group id.</p></li><li class="listitem "><p>Create a snapshot for a consistency group.</p></li><li class="listitem "><p>Show a snapshot of a consistency group.</p></li><li class="listitem "><p>List consistency group snapshots.</p></li><li class="listitem "><p>Delete a snapshot of a consistency group.</p></li><li class="listitem "><p>Delete a consistency group.</p></li><li class="listitem "><p>Modify a consistency group.</p></li><li class="listitem "><p>Create a consistency group from the snapshot of another consistency
group.</p></li><li class="listitem "><p>Create a consistency group from a source consistency group.</p></li></ul></div><p>The following operations are not allowed if a volume is in a consistency
group:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume migration.</p></li><li class="listitem "><p>Volume retype.</p></li><li class="listitem "><p>Volume deletion.</p><div id="id-1.4.9.7.21.14.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A consistency group has to be deleted as a whole with all the
volumes.</p></div></li></ul></div><p>The following operations are not allowed if a volume snapshot is in a
consistency group snapshot:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume snapshot deletion.</p><div id="id-1.4.9.7.21.16.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A consistency group snapshot has to be deleted as a whole with
all the volume snapshots.</p></div></li></ul></div><p>The details of consistency group operations are shown in the following.</p><div id="id-1.4.9.7.21.18" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Currently, no OpenStack client command is available to run in
place of the cinder consistency group creation commands. Use the
cinder commands detailed in the following examples.</p></div><p><span class="bold"><strong>Create a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder consisgroup-create
[--name name]
[--description description]
[--availability-zone availability-zone]
volume-types</pre></div><div id="id-1.4.9.7.21.21" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">volume-types</code> is required. It can be a list of
names or UUIDs of volume types separated by commas without spaces in
between. For example, <code class="literal">volumetype1,volumetype2,volumetype3.</code>.</p></div><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create --name bronzeCG2 volume_type_1

+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
| availability_zone |                 nova                 |
|     created_at    |      2014-12-29T12:59:08.000000      |
|    description    |                 None                 |
|         id        | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|        name       |              bronzeCG2               |
|       status      |               creating               |
+-------------------+--------------------------------------+</pre></div><p><span class="bold"><strong>Show a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-show 1de80c27-3b2f-47a6-91a7-e867cbe36462

+-------------------+--------------------------------------+
|      Property     |                Value                 |
+-------------------+--------------------------------------+
| availability_zone |                 nova                 |
|     created_at    |      2014-12-29T12:59:08.000000      |
|    description    |                 None                 |
|         id        | 2a6b2bda-1f43-42ce-9de8-249fa5cbae9a |
|        name       |              bronzeCG2               |
|       status      |              available               |
|     volume_types  |              volume_type_1           |
+-------------------+--------------------------------------+</pre></div><p><span class="bold"><strong>List consistency groups</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-list

+--------------------------------------+-----------+-----------+
|                  ID                  |   Status  |    Name   |
+--------------------------------------+-----------+-----------+
| 1de80c27-3b2f-47a6-91a7-e867cbe36462 | available | bronzeCG2 |
| 3a2b3c42-b612-479a-91eb-1ed45b7f2ad5 |   error   |  bronzeCG |
+--------------------------------------+-----------+-----------+</pre></div><p><span class="bold"><strong>Create a volume and add it to a consistency group</strong></span>:</p><div id="id-1.4.9.7.21.28" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When creating a volume and adding it to a consistency group, a
volume type and a consistency group id must be provided. This is
because a consistency group can support more than one volume type.</p></div><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --type volume_type_1 --consistency-group \
  1de80c27-3b2f-47a6-91a7-e867cbe36462 --size 1 cgBronzeVol

+---------------------------------------+--------------------------------------+
| Field                                 | Value                                |
+---------------------------------------+--------------------------------------+
|              attachments              |                  []                  |
|           availability_zone           |                 nova                 |
|                bootable               |                false                 |
|          consistencygroup_id          | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|               created_at              |      2014-12-29T13:16:47.000000      |
|              description              |                 None                 |
|               encrypted               |                False                 |
|                   id                  | 5e6d1386-4592-489f-a56b-9394a81145fe |
|                metadata               |                  {}                  |
|                  name                 |             cgBronzeVol              |
|         os-vol-host-attr:host         |      server-1@backend-1#pool-1       |
|     os-vol-mig-status-attr:migstat    |                 None                 |
|     os-vol-mig-status-attr:name_id    |                 None                 |
|      os-vol-tenant-attr:tenant_id     |   1349b21da2a046d8aa5379f0ed447bed   |
|   os-volume-replication:driver_data   |                 None                 |
| os-volume-replication:extended_status |                 None                 |
|           replication_status          |               disabled               |
|                  size                 |                  1                   |
|              snapshot_id              |                 None                 |
|              source_volid             |                 None                 |
|                 status                |               creating               |
|                user_id                |   93bdea12d3e04c4b86f9a9f172359859   |
|              volume_type              |            volume_type_1             |
+---------------------------------------+--------------------------------------+</pre></div><p><span class="bold"><strong>Create a snapshot for a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-create 1de80c27-3b2f-47a6-91a7-e867cbe36462

+---------------------+--------------------------------------+
|       Property      |                Value                 |
+---------------------+--------------------------------------+
| consistencygroup_id | 1de80c27-3b2f-47a6-91a7-e867cbe36462 |
|      created_at     |      2014-12-29T13:19:44.000000      |
|     description     |                 None                 |
|          id         | d4aff465-f50c-40b3-b088-83feb9b349e9 |
|         name        |                 None                 |
|        status       |               creating               |
+---------------------+-------------------------------------+</pre></div><p><span class="bold"><strong>Show a snapshot of a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-show d4aff465-f50c-40b3-b088-83feb9b349e9</pre></div><p><span class="bold"><strong>List consistency group snapshots</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-list

+--------------------------------------+--------+----------+
|                  ID                  | Status | Name     |
+--------------------------------------+--------+----------+
| 6d9dfb7d-079a-471e-b75a-6e9185ba0c38 | available  | None |
| aa129f4d-d37c-4b97-9e2d-7efffda29de0 | available  | None |
| bb5b5d82-f380-4a32-b469-3ba2e299712c | available  | None |
| d4aff465-f50c-40b3-b088-83feb9b349e9 | available  | None |
+--------------------------------------+--------+----------+</pre></div><p><span class="bold"><strong>Delete a snapshot of a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder cgsnapshot-delete d4aff465-f50c-40b3-b088-83feb9b349e9</pre></div><p><span class="bold"><strong>Delete a consistency group</strong></span>:</p><div id="id-1.4.9.7.21.39" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The force flag is needed when there are volumes in the consistency
group:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-delete --force 1de80c27-3b2f-47a6-91a7-e867cbe36462</pre></div></div><p><span class="bold"><strong>Modify a consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder consisgroup-update
[--name NAME]
[--description DESCRIPTION]
[--add-volumes UUID1,UUID2,......]
[--remove-volumes UUID3,UUID4,......]
CG</pre></div><p>The parameter <code class="literal">CG</code> is required. It can be a name or UUID of a consistency
group. UUID1,UUID2,...... are UUIDs of one or more volumes to be added
to the consistency group, separated by commas. Default is None.
UUID3,UUID4,...... are UUIDs of one or more volumes to be removed from
the consistency group, separated by commas. Default is None.</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-update --name 'new name' --description 'new descripti\
  on' --add-volumes 0b3923f5-95a4-4596-a536-914c2c84e2db,1c02528b-3781-4e3\
  2-929c-618d81f52cf3 --remove-volumes 8c0f6ae4-efb1-458f-a8fc-9da2afcc5fb\
  1,a245423f-bb99-4f94-8c8c-02806f9246d8 1de80c27-3b2f-47a6-91a7-e867cbe36462</pre></div><p><span class="bold"><strong>Create a consistency group from the snapshot of another consistency
group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src
[--cgsnapshot CGSNAPSHOT]
[--name NAME]
[--description DESCRIPTION]</pre></div><p>The parameter <code class="literal">CGSNAPSHOT</code> is a name or UUID of a snapshot of a
consistency group:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src --cgsnapshot 6d9dfb7d-079a-471e-b75a-\
  6e9185ba0c38 --name 'new cg' --description 'new cg from cgsnapshot'</pre></div><p><span class="bold"><strong>Create a consistency group from a source consistency group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src
[--source-cg SOURCECG]
[--name NAME]
[--description DESCRIPTION]</pre></div><p>The parameter <code class="literal">SOURCECG</code> is a name or UUID of a source
consistency group:</p><div class="verbatim-wrap"><pre class="screen">$ cinder consisgroup-create-from-src --source-cg 6d9dfb7d-079a-471e-b75a-\
  6e9185ba0c38 --name 'new cg' --description 'new cloned cg'</pre></div></div><div class="sect2 " id="filter-weigh-scheduler"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure and use driver filter and weighing for scheduler</span> <a title="Permalink" class="permalink" href="#filter-weigh-scheduler">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>filter-weigh-scheduler</li></ul></div></div></div></div><p>OpenStack Block Storage enables you to choose a volume back end based on
back-end specific properties by using the DriverFilter and
GoodnessWeigher for the scheduler. The driver filter and weigher
scheduling can help ensure that the scheduler chooses the best back end
based on requested volume properties as well as various back-end
specific properties.</p><div class="sect3 " id="id-1.4.9.7.22.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What is driver filter and weigher and when to use it</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The driver filter and weigher gives you the ability to more finely
control how the OpenStack Block Storage scheduler chooses the best back
end to use when handling a volume request. One example scenario where
using the driver filter and weigher can be if a back end that utilizes
thin-provisioning is used. The default filters use the <code class="literal">free capacity</code>
property to determine the best back end, but that is not always perfect.
If a back end has the ability to provide a more accurate back-end
specific value you can use that as part of the weighing. Another example
of when the driver filter and weigher can prove useful is if a back end
exists where there is a hard limit of 1000 volumes. The maximum volume
size is 500 GB. Once 75% of the total space is occupied the performance
of the back end degrades. The driver filter and weigher can provide a
way for these limits to be checked for.</p></div><div class="sect3 " id="id-1.4.9.7.22.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable driver filter and weighing</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable the driver filter, set the <code class="literal">scheduler_default_filters</code> option in
the <code class="literal">cinder.conf</code> file to <code class="literal">DriverFilter</code> or add it to the list if
other filters are already present.</p><p>To enable the goodness filter as a weigher, set the
<code class="literal">scheduler_default_weighers</code> option in the <code class="literal">cinder.conf</code> file to
<code class="literal">GoodnessWeigher</code> or add it to the list if other weighers are already
present.</p><p>You can choose to use the <code class="literal">DriverFilter</code> without the
<code class="literal">GoodnessWeigher</code> or vice-versa. The filter and weigher working
together, however, create the most benefits when helping the scheduler
choose an ideal back end.</p><div id="id-1.4.9.7.22.4.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The support for the <code class="literal">DriverFilter</code> and <code class="literal">GoodnessWeigher</code> is
optional for back ends. If you are using a back end that does not
support the filter and weigher functionality you may not get the
full benefit.</p></div><p>Example <code class="literal">cinder.conf</code> configuration file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher</pre></div><div id="id-1.4.9.7.22.4.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>It is useful to use the other filters and weighers available in
OpenStack in combination with these custom ones. For example, the
<code class="literal">CapacityFilter</code> and <code class="literal">CapacityWeigher</code> can be combined with
these.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Defining your own filter and goodness functions</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can define your own filter and goodness functions through the use of
various properties that OpenStack Block Storage has exposed. Properties
exposed include information about the volume request being made,
<code class="literal">volume_type</code> settings, and back-end specific information about drivers.
All of these allow for a lot of control over how the ideal back end for
a volume request will be decided.</p><p>The <code class="literal">filter_function</code> option is a string defining an equation that
will determine whether a back end should be considered as a potential
candidate in the scheduler.</p><p>The <code class="literal">goodness_function</code> option is a string defining an equation that
will rate the quality of the potential host (0 to 100, 0 lowest, 100
highest).</p><div id="id-1.4.9.7.22.5.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The drive filter and weigher will use default values for filter and
goodness functions for each back end if you do not define them
yourself. If complete control is desired then a filter and goodness
function should be defined for each of the back ends in
the <code class="literal">cinder.conf</code> file.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported operations in filter and goodness functions</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Below is a table of all the operations currently usable in custom filter
and goodness functions created by you:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operations</p>
                  </th><th>
                    <p>Type</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>+, -, *, /, ^</p>
                  </td><td>
                    <p>standard math</p>
                  </td></tr><tr><td>
                    <p>not, and, or, &amp;, |, !</p>
                  </td><td>
                    <p>logic</p>
                  </td></tr><tr><td>
                    <p>&gt;, &gt;=, &lt;, &lt;=, ==, &lt;&gt;, !=</p>
                  </td><td>
                    <p>equality</p>
                  </td></tr><tr><td>
                    <p>+, -</p>
                  </td><td>
                    <p>sign</p>
                  </td></tr><tr><td>
                    <p>x ? a : b</p>
                  </td><td>
                    <p>ternary</p>
                  </td></tr><tr><td>
                    <p>abs(x), max(x, y), min(x, y)</p>
                  </td><td>
                    <p>math helper functions</p>
                  </td></tr></tbody></table></div><div id="id-1.4.9.7.22.6.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Syntax errors you define in filter or goodness strings
are thrown at a volume request time.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Available properties when creating custom functions</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are various properties that can be used in either the
<code class="literal">filter_function</code> or the <code class="literal">goodness_function</code> strings. The properties allow
access to volume info, qos settings, extra specs, and so on.</p><p>The following properties and their sub-properties are currently
available for use:</p><div class="sect4 " id="id-1.4.9.7.22.7.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.2.13.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Host stats for a back end</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.7.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.9.7.22.7.4.2.1"><span class="term ">host</span></dt><dd><p>The host's name</p></dd><dt id="id-1.4.9.7.22.7.4.2.2"><span class="term ">volume_backend_name</span></dt><dd><p>The volume back end name</p></dd><dt id="id-1.4.9.7.22.7.4.2.3"><span class="term ">vendor_name</span></dt><dd><p>The vendor name</p></dd><dt id="id-1.4.9.7.22.7.4.2.4"><span class="term ">driver_version</span></dt><dd><p>The driver version</p></dd><dt id="id-1.4.9.7.22.7.4.2.5"><span class="term ">storage_protocol</span></dt><dd><p>The storage protocol</p></dd><dt id="id-1.4.9.7.22.7.4.2.6"><span class="term ">QoS_support</span></dt><dd><p>Boolean signifying whether QoS is supported</p></dd><dt id="id-1.4.9.7.22.7.4.2.7"><span class="term ">total_capacity_gb</span></dt><dd><p>The total capacity in GB</p></dd><dt id="id-1.4.9.7.22.7.4.2.8"><span class="term ">allocated_capacity_gb</span></dt><dd><p>The allocated capacity in GB</p></dd><dt id="id-1.4.9.7.22.7.4.2.9"><span class="term ">reserved_percentage</span></dt><dd><p>The reserved storage percentage</p></dd></dl></div></div><div class="sect4 " id="id-1.4.9.7.22.7.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.2.13.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capabilities specific to a back end</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.7.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These properties are determined by the specific back end
you are creating filter and goodness functions for. Some back ends
may not have any properties available here.</p></div><div class="sect4 " id="id-1.4.9.7.22.7.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.2.13.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Requested volume properties</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.7.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.9.7.22.7.6.2.1"><span class="term ">status</span></dt><dd><p>Status for the requested volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.2"><span class="term ">volume_type_id</span></dt><dd><p>The volume type ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.3"><span class="term ">display_name</span></dt><dd><p>The display name of the volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.4"><span class="term ">volume_metadata</span></dt><dd><p>Any metadata the volume has</p></dd><dt id="id-1.4.9.7.22.7.6.2.5"><span class="term ">reservations</span></dt><dd><p>Any reservations the volume has</p></dd><dt id="id-1.4.9.7.22.7.6.2.6"><span class="term ">user_id</span></dt><dd><p>The volume's user ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.7"><span class="term ">attach_status</span></dt><dd><p>The attach status for the volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.8"><span class="term ">display_description</span></dt><dd><p>The volume's display description</p></dd><dt id="id-1.4.9.7.22.7.6.2.9"><span class="term ">id</span></dt><dd><p>The volume's ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.10"><span class="term ">replication_status</span></dt><dd><p>The volume's replication status</p></dd><dt id="id-1.4.9.7.22.7.6.2.11"><span class="term ">snapshot_id</span></dt><dd><p>The volume's snapshot ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.12"><span class="term ">encryption_key_id</span></dt><dd><p>The volume's encryption key ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.13"><span class="term ">source_volid</span></dt><dd><p>The source volume ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.14"><span class="term ">volume_admin_metadata</span></dt><dd><p>Any admin metadata for this volume</p></dd><dt id="id-1.4.9.7.22.7.6.2.15"><span class="term ">source_replicaid</span></dt><dd><p>The source replication ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.16"><span class="term ">consistencygroup_id</span></dt><dd><p>The consistency group ID</p></dd><dt id="id-1.4.9.7.22.7.6.2.17"><span class="term ">size</span></dt><dd><p>The size of the volume in GB</p></dd><dt id="id-1.4.9.7.22.7.6.2.18"><span class="term ">metadata</span></dt><dd><p>General metadata</p></dd></dl></div><p>The property most used from here will most likely be the <code class="literal">size</code> sub-property.</p></div></div><div class="sect3 " id="id-1.4.9.7.22.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Extra specs for the requested volume type</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>View the available properties for volume types by running:</p><div class="verbatim-wrap"><pre class="screen">$ cinder extra-specs-list</pre></div></div><div class="sect3 " id="id-1.4.9.7.22.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Current QoS specs for the requested volume type</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>View the available properties for volume types by running:</p><div class="verbatim-wrap"><pre class="screen">$ cinder qos-list</pre></div><p>In order to access these properties in a custom string use the following
format:</p><p>
            <code class="literal">&lt;property&gt;.&lt;sub_property&gt;</code>
          </p></div><div class="sect3 " id="id-1.4.9.7.22.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.13.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Driver filter and weigher usage examples</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.22.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Below are examples for using the filter and weigher separately,
together, and using driver-specific properties.</p><p>Example <code class="literal">cinder.conf</code> file configuration for customizing the filter
function:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_filters = DriverFilter
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "volume.size &lt; 10"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "volume.size &gt;= 10"</pre></div><p>The above example will filter volumes to different back ends depending
on the size of the requested volume. Default OpenStack Block Storage
scheduler weighing is done. Volumes with a size less than 10 GB are sent
to lvm-1 and volumes with a size greater than or equal to 10 GB are sent
to lvm-2.</p><p>Example <code class="literal">cinder.conf</code> file configuration for customizing the goodness
function:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
goodness_function = "(volume.size &lt; 5) ? 100 : 50"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
goodness_function = "(volume.size &gt;= 5) ? 100 : 25"</pre></div><p>The above example will determine the goodness rating of a back end based
off of the requested volume's size. Default OpenStack Block Storage
scheduler filtering is done. The example shows how the ternary if
statement can be used in a filter or goodness function. If a requested
volume is of size 10 GB then lvm-1 is rated as 50 and lvm-2 is rated as
100. In this case lvm-2 wins. If a requested volume is of size 3 GB then
lvm-1 is rated 100 and lvm-2 is rated 25. In this case lvm-1 would win.</p><p>Example <code class="literal">cinder.conf</code> file configuration for customizing both the
filter and goodness functions:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1, lvm-2

[lvm-1]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "stats.total_capacity_gb &lt; 500"
goodness_function = "(volume.size &lt; 25) ? 100 : 50"

[lvm-2]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = sample_LVM
filter_function = "stats.total_capacity_gb &gt;= 500"
goodness_function = "(volume.size &gt;= 25) ? 100 : 75"</pre></div><p>The above example combines the techniques from the first two examples.
The best back end is now decided based off of the total capacity of the
back end and the requested volume's size.</p><p>Example <code class="literal">cinder.conf</code> file configuration for accessing driver specific
properties:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[default]
scheduler_default_filters = DriverFilter
scheduler_default_weighers = GoodnessWeigher
enabled_backends = lvm-1,lvm-2,lvm-3

[lvm-1]
volume_group = stack-volumes-lvmdriver-1
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = lvmdriver-1
filter_function = "volume.size &lt; 5"
goodness_function = "(capabilities.total_volumes &lt; 3) ? 100 : 50"

[lvm-2]
volume_group = stack-volumes-lvmdriver-2
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name = lvmdriver-2
filter_function = "volumes.size &lt; 5"
goodness_function = "(capabilities.total_volumes &lt; 8) ? 100 : 50"

[lvm-3]
volume_group = stack-volumes-lvmdriver-3
volume_driver = cinder.volume.drivers.LVMVolumeDriver
volume_backend_name = lvmdriver-3
goodness_function = "55"</pre></div><p>The above is an example of how back-end specific properties can be used
in the filter and goodness functions. In this example the LVM driver's
<code class="literal">total_volumes</code> capability is being used to determine which host gets
used during a volume request. In the above example, lvm-1 and lvm-2 will
handle volume requests for all volumes with a size less than 5 GB. The
lvm-1 host will have priority until it contains three or more volumes.
After than lvm-2 will have priority until it contains eight or more
volumes. The lvm-3 will collect all volumes greater or equal to 5 GB as
well as all volumes once lvm-1 and lvm-2 lose priority.</p></div></div><div class="sect2 " id="id-1.4.9.7.23"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Rate-limit volume copy bandwidth</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.23">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you create a new volume from an image or an existing volume, or
when you upload a volume image to the Image service, large data copy
may stress disk and network bandwidth. To mitigate slow down of data
access from the instances, OpenStack Block Storage supports rate-limiting
of volume data copy bandwidth.</p><div class="sect3 " id="id-1.4.9.7.23.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure volume copy bandwidth limit</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.23.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To configure the volume copy bandwidth limit, set the
<code class="literal">volume_copy_bps_limit</code> option in the configuration groups for each
back end in the <code class="literal">cinder.conf</code> file. This option takes the integer of
maximum bandwidth allowed for volume data copy in byte per second. If
this option is set to <code class="literal">0</code>, the rate-limit is disabled.</p><p>While multiple volume data copy operations are running in the same back
end, the specified bandwidth is divided to each copy.</p><p>Example <code class="literal">cinder.conf</code> configuration file to limit volume copy bandwidth
of <code class="literal">lvmdriver-1</code> up to 100 MiB/s:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[lvmdriver-1]
volume_group=cinder-volumes-1
volume_driver=cinder.volume.drivers.lvm.LVMVolumeDriver
volume_backend_name=LVM
volume_copy_bps_limit=104857600</pre></div><div id="id-1.4.9.7.23.3.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This feature requires libcgroup to set up blkio cgroup for disk I/O
bandwidth limit. The libcgroup is provided by the cgroup-bin package
in Debian and Ubuntu, or by the libcgroup-tools package in Fedora,
Red Hat Enterprise Linux, CentOS, openSUSE, and SUSE Linux Enterprise.</p></div><div id="id-1.4.9.7.23.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Some back ends which use remote file systems such as NFS are not
supported by this feature.</p></div></div></div><div class="sect2 " id="id-1.4.9.7.24"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Oversubscription in thin provisioning</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage enables you to choose a volume back end based on
virtual capacities for thin provisioning using the oversubscription ratio.</p><p>A reference implementation is provided for the default LVM driver. The
illustration below uses the LVM driver as an example.</p><div class="sect3 " id="id-1.4.9.7.24.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure oversubscription settings</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To support oversubscription in thin provisioning, a flag
<code class="literal">max_over_subscription_ratio</code> is introduced into <code class="literal">cinder.conf</code>.
This is a float representation of the oversubscription ratio when thin
provisioning is involved. Default ratio is 20.0, meaning provisioned
capacity can be 20 times of the total physical capacity. A ratio of 10.5
means provisioned capacity can be 10.5 times of the total physical capacity.
A ratio of 1.0 means provisioned capacity cannot exceed the total physical
capacity. A ratio lower than 1.0 is ignored and the default value is used
instead.</p><div id="id-1.4.9.7.24.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">max_over_subscription_ratio</code> can be configured for each back end when
multiple-storage back ends are enabled. It is provided as a reference
implementation and is used by the LVM driver. However, it is not a
requirement for a driver to use this option from <code class="literal">cinder.conf</code>.</p><p><code class="literal">max_over_subscription_ratio</code> is for configuring a back end. For a
driver that supports multiple pools per back end, it can report this
ratio for each pool. The LVM driver does not support multiple pools.</p></div><p>The existing <code class="literal">reserved_percentage</code> flag is used to prevent over provisioning.
This flag represents the percentage of the back-end capacity that is reserved.</p><div id="id-1.4.9.7.24.4.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>There is a change on how <code class="literal">reserved_percentage</code> is used. It was measured
against the free capacity in the past. Now it is measured against the total
capacity.</p></div></div><div class="sect3 " id="id-1.4.9.7.24.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capabilities</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Drivers can report the following capabilities for a back end or a pool:</p><div class="verbatim-wrap highlight ini"><pre class="screen">thin_provisioning_support = True(or False)
thick_provisioning_support = True(or False)
provisioned_capacity_gb = PROVISIONED_CAPACITY
max_over_subscription_ratio = MAX_RATIO</pre></div><p>Where <code class="literal">PROVISIONED_CAPACITY</code> is the apparent allocated space indicating
how much capacity has been provisioned and <code class="literal">MAX_RATIO</code> is the maximum
oversubscription ratio. For the LVM driver, it is
<code class="literal">max_over_subscription_ratio</code> in <code class="literal">cinder.conf</code>.</p><p>Two capabilities are added here to allow a back end or pool to claim support
for thin provisioning, or thick provisioning, or both.</p><p>The LVM driver reports <code class="literal">thin_provisioning_support=True</code> and
<code class="literal">thick_provisioning_support=False</code> if the <code class="literal">lvm_type</code> flag in
<code class="literal">cinder.conf</code> is <code class="literal">thin</code>. Otherwise it reports
<code class="literal">thin_provisioning_support=False</code> and <code class="literal">thick_provisioning_support=True</code>.</p></div><div class="sect3 " id="id-1.4.9.7.24.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume type extra specs</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If volume type is provided as part of the volume creation request, it can
have the following extra specs defined:</p><div class="verbatim-wrap highlight ini"><pre class="screen">'capabilities:thin_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'
'capabilities:thick_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'</pre></div><div id="id-1.4.9.7.24.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">capabilities</code> scope key before <code class="literal">thin_provisioning_support</code> and
<code class="literal">thick_provisioning_support</code> is not required. So the following works too:</p></div><div class="verbatim-wrap highlight ini"><pre class="screen">'thin_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'
'thick_provisioning_support': '&lt;is&gt; True' or '&lt;is&gt; False'</pre></div><p>The above extra specs are used by the scheduler to find a back end that
supports thin provisioning, thick provisioning, or both to match the needs
of a specific volume type.</p></div><div class="sect3 " id="id-1.4.9.7.24.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume replication extra specs</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage has the ability to create volume replicas.
Administrators can define a storage policy that includes
replication by adjusting the cinder volume driver. Volume replication
for OpenStack Block Storage helps safeguard OpenStack environments from
data loss during disaster recovery.</p><p>To enable replication when creating volume types, configure the cinder
volume with <code class="literal">capabilities:replication="&lt;is&gt; True"</code>.</p><p>Each volume created with the replication capability set to <code class="literal">True</code>
generates a copy of the volume on a storage back end.</p><p>One use case for replication involves an OpenStack cloud environment
installed across two data centers located nearby each other. The
distance between the two data centers in this use case is the length of
a city.</p><p>At each data center, a cinder host supports the Block Storage service.
Both data centers include storage back ends.</p><p>Depending on the storage requirements, there can be one or two cinder
hosts. The administrator accesses the
<code class="literal">/etc/cinder/cinder.conf</code> configuration file and sets
<code class="literal">capabilities:replication="&lt;is&gt; True"</code>.</p><p>If one data center experiences a service failure, administrators
can redeploy the VM. The VM will run using a replicated, backed up
volume on a host in the second data center.</p></div><div class="sect3 " id="id-1.4.9.7.24.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capacity filter</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the capacity filter, <code class="literal">max_over_subscription_ratio</code> is used when
choosing a back end if <code class="literal">thin_provisioning_support</code> is True and
<code class="literal">max_over_subscription_ratio</code> is greater than 1.0.</p></div><div class="sect3 " id="id-1.4.9.7.24.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.15.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Capacity weigher</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.24.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the capacity weigher, virtual free capacity is used for ranking if
<code class="literal">thin_provisioning_support</code> is True. Otherwise, real free capacity
will be used as before.</p></div></div><div class="sect2 " id="id-1.4.9.7.25"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image-Volume cache</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.25">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage has an optional Image cache which can dramatically
improve the performance of creating a volume from an image. The improvement
depends on many factors, primarily how quickly the configured back end can
clone a volume.</p><p>When a volume is first created from an image, a new cached image-volume
will be created that is owned by the Block Storage Internal Tenant. Subsequent
requests to create volumes from that image will clone the cached version
instead of downloading the image contents and copying data to the volume.</p><p>The cache itself is configurable per back end and will contain the most
recently used images.</p><div class="sect3 " id="id-1.4.9.7.25.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Internal Tenant</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.25.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Image-Volume cache requires that the Internal Tenant be configured for
the Block Storage services. This project will own the cached image-volumes so
they can be managed like normal users including tools like volume quotas. This
protects normal users from having to see the cached image-volumes, but does
not make them globally hidden.</p><p>To enable the Block Storage services to have access to an Internal Tenant, set
the following options in the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">cinder_internal_tenant_project_id = PROJECT_ID
cinder_internal_tenant_user_id = USER_ID</pre></div><p>An example <code class="literal">cinder.conf</code> configuration file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">cinder_internal_tenant_project_id = b7455b8974bb4064ad247c8f375eae6c
cinder_internal_tenant_user_id = f46924c112a14c80ab0a24a613d95eef</pre></div><div id="id-1.4.9.7.25.5.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The actual user and project that are configured for the Internal Tenant do
not require any special privileges. They can be the Block Storage service
project or can be any normal project and user.</p></div></div><div class="sect3 " id="id-1.4.9.7.25.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Image-Volume cache</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.25.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable the Image-Volume cache, set the following configuration option in
the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_volume_cache_enabled = True</pre></div><div id="id-1.4.9.7.25.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you use Ceph as a back end, set the following configuration option in
the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[ceph]
image_volume_cache_enabled = True</pre></div></div><p>This can be scoped per back end definition or in the default options.</p><p>There are optional configuration settings that can limit the size of the cache.
These can also be scoped per back end or in the default options in
the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_volume_cache_max_size_gb = SIZE_GB
image_volume_cache_max_count = MAX_COUNT</pre></div><p>By default they will be set to 0, which means unlimited.</p><p>For example, a configuration which would limit the max size to 200 GB and 50
cache entries will be configured as:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_volume_cache_max_size_gb = 200
image_volume_cache_max_count = 50</pre></div></div><div class="sect3 " id="id-1.4.9.7.25.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notifications</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.25.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Cache actions will trigger Telemetry messages. There are several that will be
sent.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">image_volume_cache.miss</code> - A volume is being created from an image which
was not found in the cache. Typically this will mean a new cache entry would
be created for it.</p></li><li class="listitem "><p><code class="literal">image_volume_cache.hit</code> - A volume is being created from an image which
was found in the cache and the fast path can be taken.</p></li><li class="listitem "><p><code class="literal">image_volume_cache.evict</code> - A cached image-volume has been deleted from
the cache.</p></li></ul></div></div><div class="sect3 " id="id-1.4.9.7.25.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.16.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Managing cached Image-Volumes</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.25.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In normal usage there should be no need for manual intervention with the cache.
The entries and their backing Image-Volumes are managed automatically.</p><p>If needed, you can delete these volumes manually to clear the cache.
By using the standard volume deletion APIs, the Block Storage service will
clean up correctly.</p></div></div><div class="sect2 " id="id-1.4.9.7.26"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.17 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Volume-backed image</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.26">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Block Storage can quickly create a volume from an image that refers
to a volume storing image data (Image-Volume). Compared to the other stores
such as file and swift, creating a volume from a Volume-backed image performs
better when the block storage driver supports efficient volume cloning.</p><p>If the image is set to public in the Image service, the volume data can be
shared among projects.</p><div class="sect3 " id="id-1.4.9.7.26.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.17.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure the Volume-backed image</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.26.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Volume-backed image feature requires locations information from the cinder
store of the Image service. To enable the Image service to use the cinder
store, add <code class="literal">cinder</code> to the <code class="literal">stores</code> option in the <code class="literal">glance_store</code> section
of the <code class="literal">glance-api.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">stores = file, http, swift, cinder</pre></div><p>To expose locations information, set the following options in the <code class="literal">DEFAULT</code>
section of the <code class="literal">glance-api.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">show_multiple_locations = True</pre></div><p>To enable the Block Storage services to create a new volume by cloning Image-
Volume, set the following options in the <code class="literal">DEFAULT</code> section of the
<code class="literal">cinder.conf</code> file. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">glance_api_version = 2
allowed_direct_url_schemes = cinder</pre></div><p>To enable the <code class="command">openstack image create --volume &lt;volume&gt;</code> command to
create an image that refers an <code class="literal">Image-Volume</code>, set the following options in
each back-end section of the <code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_upload_use_cinder_backend = True</pre></div><p>By default, the <code class="command">openstack image create --volume &lt;volume&gt;</code> command
creates the Image-Volume in the current project. To store the Image-Volume into
the internal project, set the following options in each back-end section of the
<code class="literal">cinder.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">image_upload_use_internal_tenant = True</pre></div><p>To make the Image-Volume in the internal project accessible from the Image
service, set the following options in the <code class="literal">glance_store</code> section of
the <code class="literal">glance-api.conf</code> file:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">cinder_store_auth_address</code>
              </p></li><li class="listitem "><p>
                <code class="literal">cinder_store_user_name</code>
              </p></li><li class="listitem "><p>
                <code class="literal">cinder_store_password</code>
              </p></li><li class="listitem "><p>
                <code class="literal">cinder_store_project_name</code>
              </p></li></ul></div></div><div class="sect3 " id="id-1.4.9.7.26.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.17.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Volume-backed image</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.26.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To register an existing volume as a new Volume-backed image, use the following
commands:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --disk-format raw --container-format bare IMAGE_NAME

$ glance location-add &lt;image-uuid&gt; --url cinder://&lt;volume-uuid&gt;</pre></div><p>If the <code class="literal">image_upload_use_cinder_backend</code> option is enabled, the following
command creates a new Image-Volume by cloning the specified volume and then
registers its location to a new image. The disk format and the container format
must be raw and bare (default). Otherwise, the image is uploaded to the default
store of the Image service.</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --volume SOURCE_VOLUME IMAGE_NAME</pre></div></div></div><div class="sect2 " id="id-1.4.9.7.27"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.18 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Get capabilities</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.27">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When an administrator configures <code class="literal">volume type</code> and <code class="literal">extra specs</code> of storage
on the back end, the administrator has to read the right documentation that
corresponds to the version of the storage back end. Deep knowledge of
storage is also required.</p><p>OpenStack Block Storage enables administrators to configure <code class="literal">volume type</code>
and <code class="literal">extra specs</code> without specific knowledge of the storage back end.</p><div id="id-1.4.9.7.27.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">Volume Type</code>: A group of volume policies.</p></li><li class="listitem "><p><code class="literal">Extra Specs</code>: The definition of a volume type. This is a group of
policies. For example, provision type, QOS that will be used to
define a volume at creation time.</p></li><li class="listitem "><p><code class="literal">Capabilities</code>: What the current deployed back end in Cinder is able
to do. These correspond to extra specs.</p></li></ul></div></div><div class="sect3 " id="id-1.4.9.7.27.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage of cinder client</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.27.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When an administrator wants to define new volume types for their
OpenStack cloud, the administrator would fetch a list of <code class="literal">capabilities</code>
for a particular back end using the cinder client.</p><p>First, get a list of the services:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume service list
+------------------+-------------------+------+---------+-------+----------------------------+
| Binary           | Host              | Zone | Status  | State | Updated At                 |
+------------------+-------------------+------+---------+-------+----------------------------+
| cinder-scheduler | controller        | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
| cinder-volume    | block1@ABC-driver | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
+------------------+-------------------+------+---------+-------+----------------------------+</pre></div><p>With one of the listed hosts, pass that to <code class="literal">get-capabilities</code>, then
the administrator can obtain volume stats and also back end <code class="literal">capabilities</code>
as listed below.</p><div class="verbatim-wrap"><pre class="screen">$ cinder get-capabilities block1@ABC-driver
+---------------------+----------------------------------------------+
|     Volume stats    |                    Value                     |
+---------------------+----------------------------------------------+
|     description     |                     None                     |
|     display_name    |   Capabilities of Cinder Vendor ABC driver   |
|    driver_version   |                    2.0.0                     |
|      namespace      | OS::Storage::Capabilities::block1@ABC-driver |
|      pool_name      |                     None                     |
| replication_targets |                      []                      |
|   storage_protocol  |                    iSCSI                     |
|     vendor_name     |                  Vendor ABC                  |
|      visibility     |                     pool                     |
| volume_backend_name |                  ABC-driver                  |
+---------------------+----------------------------------------------+
+----------------------+-----------------------------------------------------+
|  Backend properties  |                     Value                           |
+----------------------+-----------------------------------------------------+
|      compression     | {u'type':u'boolean', u'title':u'Compression',  ...} |
| ABC:compression_type | {u'enum':u'['lossy', 'lossless', 'special']',  ...} |
|         qos          | {u'type':u'boolean', u'title':u'QoS',          ...} |
|     replication      | {u'type':u'boolean', u'title':u'Replication',  ...} |
|  thin_provisioning   | {u'type':u'boolean', u'title':u'Thin Provisioning'} |
|     ABC:minIOPS      | {u'type':u'integer', u'title':u'Minimum IOPS QoS',} |
|     ABC:maxIOPS      | {u'type':u'integer', u'title':u'Maximum IOPS QoS',} |
|    ABC:burstIOPS     | {u'type':u'integer', u'title':u'Burst IOPS QoS',..} |
+----------------------+-----------------------------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.9.7.27.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disable a service</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.27.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When an administrator wants to disable a service, identify the Binary
and the Host of the service. Use the <code class="command">cinder service-disable</code>
command combined with the Binary and Host to disable the service:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Determine the binary and host of the service you want to remove
initially.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume service list
+------------------+----------------------+------+---------+-------+----------------------------+
| Binary           | Host                 | Zone | Status  | State | Updated At                 |
+------------------+----------------------+------+---------+-------+----------------------------+
| cinder-scheduler | devstack             | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
| cinder-volume    | devstack@lvmdriver-1 | nova | enabled | up    | 2016-10-24T13:53:35.000000 |
+------------------+----------------------+------+---------+-------+----------------------------+</pre></div></li><li class="step "><p>Disable the service using the Binary and Host name, placing the Host
before the Binary name.</p><div class="verbatim-wrap"><pre class="screen">$ cinder service-disable HOST_NAME BINARY_NAME</pre></div></li><li class="step "><p>Remove the service from the database.</p><div class="verbatim-wrap"><pre class="screen">$ cinder-manage service remove BINARY_NAME HOST_NAME</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.9.7.27.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage of REST API</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.27.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>New endpoint to <code class="literal">get capabilities</code> list for specific storage back end
is also available. For more details, refer to the Block Storage API reference.</p><p>API request:</p><div class="verbatim-wrap"><pre class="screen">GET /v2/{tenant_id}/capabilities/{hostname}</pre></div><p>Example of return value:</p><div class="verbatim-wrap highlight json"><pre class="screen">{
  "namespace": "OS::Storage::Capabilities::block1@ABC-driver",
  "volume_backend_name": "ABC-driver",
  "pool_name": "pool",
  "driver_version": "2.0.0",
  "storage_protocol": "iSCSI",
  "display_name": "Capabilities of Cinder Vendor ABC driver",
  "description": "None",
  "visibility": "public",
  "properties": {
   "thin_provisioning": {
      "title": "Thin Provisioning",
      "description": "Sets thin provisioning.",
      "type": "boolean"
    },
    "compression": {
      "title": "Compression",
      "description": "Enables compression.",
      "type": "boolean"
    },
    "ABC:compression_type": {
      "title": "Compression type",
      "description": "Specifies compression type.",
      "type": "string",
      "enum": [
        "lossy", "lossless", "special"
      ]
    },
    "replication": {
      "title": "Replication",
      "description": "Enables replication.",
      "type": "boolean"
    },
    "qos": {
      "title": "QoS",
      "description": "Enables QoS.",
      "type": "boolean"
    },
    "ABC:minIOPS": {
      "title": "Minimum IOPS QoS",
      "description": "Sets minimum IOPS if QoS is enabled.",
      "type": "integer"
    },
    "ABC:maxIOPS": {
      "title": "Maximum IOPS QoS",
      "description": "Sets maximum IOPS if QoS is enabled.",
      "type": "integer"
    },
    "ABC:burstIOPS": {
      "title": "Burst IOPS QoS",
      "description": "Sets burst IOPS if QoS is enabled.",
      "type": "integer"
    },
  }
}</pre></div></div><div class="sect3 " id="id-1.4.9.7.27.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.2.18.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage of volume type access extension</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.27.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Some volume types should be restricted only. For example, test volume types
where you are testing a new technology or ultra high performance volumes
(for special cases) where you do not want most users to be able to select
these volumes. An administrator/operator can then define private volume types
using cinder client.
Volume type access extension adds the ability to manage volume type access.
Volume types are public by default. Private volume types can be created by
setting the <code class="literal">is_public</code> Boolean field to <code class="literal">False</code> at creation time. Access to a
private volume type can be controlled by adding or removing a project from it.
Private volume types without projects are only visible by users with the
admin role/context.</p><p>Create a public volume type by setting <code class="literal">is_public</code> field to <code class="literal">True</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type create vol_Type1 --description test1 --public
+-------------+--------------------------------------+
| Field       | Value                                |
+-------------+--------------------------------------+
| description | test1                                |
| id          | b7dbed9e-de78-49f8-a840-651ae7308592 |
| is_public   | True                                 |
| name        | vol_Type1                            |
+-------------+--------------------------------------+</pre></div><p>Create a private volume type by setting <code class="literal">is_public</code> field to <code class="literal">False</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type create vol_Type2 --description test2 --private
+-------------+--------------------------------------+
| Field       | Value                                |
+-------------+--------------------------------------+
| description | test2                                |
| id          | 154baa73-d2c4-462f-8258-a2df251b0d39 |
| is_public   | False                                |
| name        | vol_Type2                            |
+-------------+--------------------------------------+</pre></div><p>Get a list of the volume types:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type list
+--------------------------------------+-------------+
| ID                                   | Name        |
+--------------------------------------+-------------+
| 0a948c84-bad5-4fba-88a2-c062006e4f6b | vol_Type1   |
| 87e5be6f-9491-4ea5-9906-9ac56494bb91 | lvmdriver-1 |
| fd508846-213f-4a07-aaf2-40518fb9a23f | vol_Type2   |
+--------------------------------------+-------------+</pre></div><p>Get a list of the projects:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| 4105ead90a854100ab6b121266707f2b | alt_demo           |
| 4a22a545cedd4fcfa9836eb75e558277 | admin              |
| 71f9cdb1a3ab4b8e8d07d347a2e146bb | service            |
| c4860af62ffe465e99ed1bc08ef6082e | demo               |
| e4b648ba5108415cb9e75bff65fa8068 | invisible_to_admin |
+----------------------------------+--------------------+</pre></div><p>Add volume type access for the given demo project, using its project-id:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type set --project c4860af62ffe465e99ed1bc08ef6082e \
  vol_Type2</pre></div><p>List the access information about the given volume type:</p><div class="verbatim-wrap"><pre class="screen">$ cinder type-access-list --volume-type vol_Type2
+--------------------------------------+----------------------------------+
|            Volume_type_ID            |            Project_ID            |
+--------------------------------------+----------------------------------+
| fd508846-213f-4a07-aaf2-40518fb9a23f | c4860af62ffe465e99ed1bc08ef6082e |
+--------------------------------------+----------------------------------+</pre></div><p>Remove volume type access for the given project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume type unset --project c4860af62ffe465e99ed1bc08ef6082e \
  vol_Type2
$ cinder type-access-list --volume-type vol_Type2
+----------------+------------+
| Volume_type_ID | Project_ID |
+----------------+------------+
+----------------+------------+</pre></div></div></div><div class="sect2 " id="id-1.4.9.7.28"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.2.19 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Generic volume groups</span> <a title="Permalink" class="permalink" href="#id-1.4.9.7.28">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Generic volume group support is available in OpenStack Block Storage (cinder)
since the Newton release. The support is added for creating group types and
group specs, creating groups of volumes, and creating snapshots of groups.
The group operations can be performed using the Block Storage command line.</p><p>A group type is a type for a group just like a volume type for a volume.
A group type can also have associated group specs similar to extra specs
for a volume type.</p><p>In cinder, there is a group construct called <code class="literal">consistency group</code>. Consistency
groups only support consistent group snapshots and only a small number of
drivers can support it. The following is a list of drivers that support
consistency groups and the release when the support was added:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Juno: EMC VNX</p></li><li class="listitem "><p>Kilo: EMC VMAX, IBM (GPFS, Storwize, SVC, and XIV), ProphetStor, Pure</p></li><li class="listitem "><p>Liberty: Dell Storage Center, EMC XtremIO, HPE 3Par and LeftHand</p></li><li class="listitem "><p>Mitaka: EMC ScaleIO, NetApp Data ONTAP and E-Series, SolidFire</p></li><li class="listitem "><p>Newton: CoprHD, FalconStor, Huawei</p></li></ul></div><p>Consistency group cannot be extended easily to serve other purposes. A tenant
may want to put volumes used in the same application together in a group so
that it is easier to manage them together, and this group of volumes may or
may not support consistent group snapshot. Generic volume group is introduced
to solve this problem.</p><p>There is a plan to migrate existing consistency group operations to use
generic volume group operations in future releases. More information can be
found in <a class="link" href="https://github.com/openstack/cinder-specs/blob/master/specs/newton/group-snapshots.rst" target="_blank">Cinder specs</a>.</p><div id="id-1.4.9.7.28.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only Block Storage V3 API supports groups. You can
specify <code class="literal">--os-volume-api-version 3.x</code> when using the <code class="literal">cinder</code>
command line for group operations where <code class="literal">3.x</code> contains a microversion value
for that command. The generic volume group feature was completed in several
patches. As a result, the minimum required microversion is different for
group types, groups, and group snapshots APIs.</p></div><p>The following group type operations are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a group type.</p></li><li class="listitem "><p>Delete a group type.</p></li><li class="listitem "><p>Set group spec for a group type.</p></li><li class="listitem "><p>Unset group spec for a group type.</p></li><li class="listitem "><p>List group types.</p></li><li class="listitem "><p>Show a group type details.</p></li><li class="listitem "><p>Update a group.</p></li><li class="listitem "><p>List group types and group specs.</p></li></ul></div><p>The following group and group snapshot operations are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a group, given group type and volume types.</p><div id="id-1.4.9.7.28.12.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A group must have one group type. A group can support more than one
volume type. The scheduler is responsible for finding a back end that
can support the given group type and volume types.</p><p>A group can only contain volumes hosted by the same back end.</p><p>A group is empty upon its creation. Volumes need to be created and added
to it later.</p></div></li><li class="listitem "><p>Show a group.</p></li><li class="listitem "><p>List groups.</p></li><li class="listitem "><p>Delete a group.</p></li><li class="listitem "><p>Modify a group.</p></li><li class="listitem "><p>Create a volume and add it to a group.</p></li><li class="listitem "><p>Create a snapshot for a group.</p></li><li class="listitem "><p>Show a group snapshot.</p></li><li class="listitem "><p>List group snapshots.</p></li><li class="listitem "><p>Delete a group snapshot.</p></li><li class="listitem "><p>Create a group from a group snapshot.</p></li><li class="listitem "><p>Create a group from a source group.</p></li></ul></div><p>The following operations are not allowed if a volume is in a group:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume migration.</p></li><li class="listitem "><p>Volume retype.</p></li><li class="listitem "><p>Volume deletion.</p><div id="id-1.4.9.7.28.14.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A group has to be deleted as a whole with all the volumes.</p></div></li></ul></div><p>The following operations are not allowed if a volume snapshot is in a
group snapshot:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Volume snapshot deletion.</p><div id="id-1.4.9.7.28.16.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A group snapshot has to be deleted as a whole with all the volume
snapshots.</p></div></li></ul></div><p>The details of group type operations are shown in the following. The minimum
microversion to support group type and group specs is 3.11:</p><p><span class="bold"><strong>Create a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-create
[--description DESCRIPTION]
[--is-public IS_PUBLIC]
NAME</pre></div><div id="id-1.4.9.7.28.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">NAME</code> is required. The
<code class="literal">--is-public IS_PUBLIC</code> determines whether the group type is
accessible to the public. It is <code class="literal">True</code> by default. By default, the
policy on privileges for creating a group type is admin-only.</p></div><p><span class="bold"><strong>Show a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-show
GROUP_TYPE</pre></div><div id="id-1.4.9.7.28.23" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE</code> is the name or UUID of a group type.</p></div><p><span class="bold"><strong>List group types</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-list</pre></div><div id="id-1.4.9.7.28.26" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only admin can see private group types.</p></div><p><span class="bold"><strong>Update a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-update
[--name NAME]
[--description DESCRIPTION]
[--is-public IS_PUBLIC]
GROUP_TYPE_ID</pre></div><div id="id-1.4.9.7.28.29" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE_ID</code> is the UUID of a group type. By default,
the policy on privileges for updating a group type is admin-only.</p></div><p><span class="bold"><strong>Delete group type or types</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-delete
GROUP_TYPE [GROUP_TYPE ...]</pre></div><div id="id-1.4.9.7.28.32" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE</code> is name or UUID of the group type or
group types to be deleted. By default, the policy on privileges for
deleting a group type is admin-only.</p></div><p><span class="bold"><strong>Set or unset group spec for a group type</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-type-key
GROUP_TYPE ACTION KEY=VALUE [KEY=VALUE ...]</pre></div><div id="id-1.4.9.7.28.35" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_TYPE</code> is the name or UUID of a group type. Valid
values for the parameter <code class="literal">ACTION</code> are <code class="literal">set</code> or <code class="literal">unset</code>.
<code class="literal">KEY=VALUE</code> is the group specs key and value pair to set or unset.
For unset, specify only the key. By default, the policy on privileges
for setting or unsetting group specs key is admin-only.</p></div><p><span class="bold"><strong>List group types and group specs</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.11 group-specs-list</pre></div><div id="id-1.4.9.7.28.38" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>By default, the policy on privileges for seeing group specs is admin-only.</p></div><p>The details of group operations are shown in the following. The minimum
microversion to support groups operations is 3.13.</p><p><span class="bold"><strong>Create a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-create
[--name NAME]
[--description DESCRIPTION]
[--availability-zone AVAILABILITY_ZONE]
GROUP_TYPE VOLUME_TYPES</pre></div><div id="id-1.4.9.7.28.42" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameters <code class="literal">GROUP_TYPE</code> and <code class="literal">VOLUME_TYPES</code> are required.
<code class="literal">GROUP_TYPE</code> is the name or UUID of a group type. <code class="literal">VOLUME_TYPES</code>
can be a list of names or UUIDs of volume types separated by commas
without spaces in between. For example,
<code class="literal">volumetype1,volumetype2,volumetype3.</code>.</p></div><p><span class="bold"><strong>Show a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-show
GROUP</pre></div><div id="id-1.4.9.7.28.45" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP</code> is the name or UUID of a group.</p></div><p><span class="bold"><strong>List groups</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-list
[--all-tenants [&lt;0|1&gt;]]</pre></div><div id="id-1.4.9.7.28.48" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">--all-tenants</code> specifies whether to list groups for all tenants.
Only admin can use this option.</p></div><p><span class="bold"><strong>Create a volume and add it to a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 create
--volume-type VOLUME_TYPE
--group-id GROUP_ID SIZE</pre></div><div id="id-1.4.9.7.28.51" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When creating a volume and adding it to a group, the parameters
<code class="literal">VOLUME_TYPE</code> and <code class="literal">GROUP_ID</code> must be provided. This is because a group
can support more than one volume type.</p></div><p><span class="bold"><strong>Delete a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-delete
[--delete-volumes]
GROUP [GROUP ...]</pre></div><div id="id-1.4.9.7.28.54" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">--delete-volumes</code> allows or disallows groups to be deleted
if they are not empty. If the group is empty, it can be deleted without
<code class="literal">--delete-volumes</code>. If the group is not empty, the flag is
required for it to be deleted. When the flag is specified, the group
and all volumes in the group will be deleted.</p></div><p><span class="bold"><strong>Modify a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.13 group-update
[--name NAME]
[--description DESCRIPTION]
[--add-volumes UUID1,UUID2,......]
[--remove-volumes UUID3,UUID4,......]
GROUP</pre></div><div id="id-1.4.9.7.28.57" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">UUID1,UUID2,......</code> is the UUID of one or more volumes
to be added to the group, separated by commas. Similarly the parameter
<code class="literal">UUID3,UUID4,......</code> is the UUID of one or more volumes to be removed
from the group, separated by commas.</p></div><p>The details of group snapshots operations are shown in the following. The
minimum microversion to support group snapshots operations is 3.14.</p><p><span class="bold"><strong>Create a snapshot for a group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-create
[--name NAME]
[--description DESCRIPTION]
GROUP</pre></div><div id="id-1.4.9.7.28.61" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP</code> is the name or UUID of a group.</p></div><p><span class="bold"><strong>Show a group snapshot</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-show
GROUP_SNAPSHOT</pre></div><div id="id-1.4.9.7.28.64" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_SNAPSHOT</code> is the name or UUID of a group snapshot.</p></div><p><span class="bold"><strong>List group snapshots</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-list
[--all-tenants [&lt;0|1&gt;]]
[--status STATUS]
[--group-id GROUP_ID]</pre></div><div id="id-1.4.9.7.28.67" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">--all-tenants</code> specifies whether to list group snapshots for
all tenants. Only admin can use this option. <code class="literal">--status STATUS</code>
filters results by a status. <code class="literal">--group-id GROUP_ID</code> filters
results by a group id.</p></div><p><span class="bold"><strong>Delete group snapshot</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">cinder --os-volume-api-version 3.14 group-snapshot-delete
GROUP_SNAPSHOT [GROUP_SNAPSHOT ...]</pre></div><div id="id-1.4.9.7.28.70" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_SNAPSHOT</code> specifies the name or UUID of one or more
group snapshots to be deleted.</p></div><p><span class="bold"><strong>Create a group from a group snapshot or a source group</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ cinder --os-volume-api-version 3.14 group-create-from-src
[--group-snapshot GROUP_SNAPSHOT]
[--source-group SOURCE_GROUP]
[--name NAME]
[--description DESCRIPTION]</pre></div><div id="id-1.4.9.7.28.73" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The parameter <code class="literal">GROUP_SNAPSHOT</code> is a name or UUID of a group snapshot.
The parameter <code class="literal">SOURCE_GROUP</code> is a name or UUID of a source group.
Either <code class="literal">GROUP_SNAPSHOT</code> or <code class="literal">SOURCE_GROUP</code> must be specified, but not
both.</p></div></div></div><div class="sect1 " id="id-1.4.9.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot your installation</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section provides useful tips to help you troubleshoot your Block
Storage installation.</p><div class="sect2 " id="id-1.4.9.8.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot the Block Storage configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Most Block Storage errors are caused by incorrect volume configurations
that result in volume creation failures. To resolve these failures,
review these logs:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">cinder-api</code> log (<code class="literal">/var/log/cinder/api.log</code>)</p></li><li class="listitem "><p><code class="literal">cinder-volume</code> log (<code class="literal">/var/log/cinder/volume.log</code>)</p></li></ul></div><p>The <code class="literal">cinder-api</code> log is useful for determining if you have endpoint or
connectivity issues. If you send a request to create a volume and it
fails, review the <code class="literal">cinder-api</code> log to determine whether the request made
it to the Block Storage service. If the request is logged and you see no
errors or tracebacks, check the <code class="literal">cinder-volume</code> log for errors or
tracebacks.</p><div id="id-1.4.9.8.3.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Create commands are listed in the <code class="literal">cinder-api</code> log.</p></div><p>These entries in the <code class="literal">cinder.openstack.common.log</code> file can be used to
assist in troubleshooting your Block Storage configuration.</p><div class="verbatim-wrap"><pre class="screen"># Print debugging output (set logging level to DEBUG instead
# of default WARNING level). (boolean value)
# debug=false

# Print more verbose output (set logging level to INFO instead
# of default WARNING level). (boolean value)
# verbose=false

# Log output to standard error (boolean value)
# use_stderr=true

# Default file mode used when creating log files (string
# value)
# logfile_mode=0644

# format string to use for log messages with context (string
# value)
# logging_context_format_string=%(asctime)s.%(msecs)03d %(levelname)s
# %(name)s [%(request_id)s %(user)s %(tenant)s] %(instance)s%(message)s

# format string to use for log mes #logging_default_format_string=%(asctime)s.
# %(msecs)03d %(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s

# data to append to log format when level is DEBUG (string
# value)
# logging_debug_format_suffix=%(funcName)s %(pathname)s:%(lineno)d

# prefix each line of exception output with this format
# (string value)
# logging_exception_prefix=%(asctime)s.%(msecs)03d %(process)d TRACE %(name)s
# %(instance)s

# list of logger=LEVEL pairs (list value)
# default_log_levels=amqplib=WARN,sqlalchemy=WARN,boto=WARN,suds=INFO,
# keystone=INFO,eventlet.wsgi.server=WARNsages without context
# (string value)

# If an instance is passed with the log message, format it
# like this (string value)
# instance_format="[instance: %(uuid)s]"

# If an instance UUID is passed with the log message, format
# it like this (string value)
#instance_uuid_format="[instance: %(uuid)s] "

# Format string for %%(asctime)s in log records. Default:
# %(default)s (string value)
# log_date_format=%Y-%m-%d %H:%M:%S

# (Optional) Name of log file to output to. If not set,
# logging will go to stdout. (string value)
# log_file=&lt;None&gt;

# (Optional) The directory to keep log files in (will be
# prepended to --log-file) (string value)
# log_dir=&lt;None&gt;
# instance_uuid_format="[instance: %(uuid)s]"

# If this option is specified, the logging configuration file
# specified is used and overrides any other logging options
# specified. Please see the Python logging module
# documentation for details on logging configuration files.
# (string value)
# Use syslog for logging. (boolean value)
# use_syslog=false

# syslog facility to receive log lines (string value)
# syslog_log_facility=LOG_USER
# log_config=&lt;None&gt;</pre></div><p>These common issues might occur during configuration, and the following
potential solutions describe how to address the issues.</p><div class="sect3 " id="id-1.4.9.8.3.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Issues with <code class="literal">state_path</code> and <code class="literal">volumes_dir</code> settings</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.9.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.9.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Block Storage uses <code class="literal">tgtd</code> as the default iSCSI helper
and implements persistent targets. This means that in the case of a
<code class="literal">tgt</code> restart, or even a node reboot, your existing volumes on that
node will be restored automatically with their original <a class="xref" href="#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a>.</p><p>By default, Block Storage uses a <code class="literal">state_path</code> variable, which if
installing with Yum or APT should be set to <code class="literal">/var/lib/cinder/</code>.
The next part is the <code class="literal">volumes_dir</code> variable, by default this appends
a <code class="literal">volumes</code> directory to the <code class="literal">state_path</code>. The result is a
file-tree: <code class="literal">/var/lib/cinder/volumes/</code>.</p></div><div class="sect4 " id="id-1.4.9.8.3.9.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.9.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In order to ensure nodes are restored to their original IQN,
the iSCSI target information needs to be stored in a file on creation
that can be queried in case of restart of the <code class="literal">tgt daemon</code>. While the
installer should handle all this, it can go wrong.</p><p>If you have trouble creating volumes and this directory does not exist
you should see an error message in the <code class="literal">cinder-volume</code> log indicating
that the <code class="literal">volumes_dir</code> does not exist, and it should provide
information about which path it was looking for.</p></div></div><div class="sect3 " id="id-1.4.9.8.3.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The persistent tgt include file</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.10.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.10.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Block Storage service may have issues locating the persistent
<code class="literal">tgt include</code> file. Along with the <code class="literal">volumes_dir</code> option, the
iSCSI target driver also needs to be configured to look in the correct
place for the persistent <code class="literal">tgt include `` file. This is an entry
in the ``/etc/tgt/conf.d</code> file that should have been set during the
OpenStack installation.</p></div><div class="sect4 " id="id-1.4.9.8.3.10.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.10.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If issues occur, verify that you have a <code class="literal">/etc/tgt/conf.d/cinder.conf</code>
file. If the file is not present, create it with:</p><div class="verbatim-wrap"><pre class="screen"># echo 'include /var/lib/cinder/volumes/ *' &gt;&gt; /etc/tgt/conf.d/cinder.conf</pre></div></div></div><div class="sect3 " id="id-1.4.9.8.3.11"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">No sign of attach call in the <code class="literal">cinder-api</code> log</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.11">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.11.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.11.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The attach call is unavailable, or not appearing in the <code class="literal">cinder-api</code> log.</p></div><div class="sect4 " id="id-1.4.9.8.3.11.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.11.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Adjust the <code class="literal">nova.conf</code> file, and make sure that your <code class="literal">nova.conf</code>
has this entry:</p><div class="verbatim-wrap highlight ini"><pre class="screen">volume_api_class=nova.volume.cinder.API</pre></div></div></div><div class="sect3 " id="id-1.4.9.8.3.12"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to create iscsi target error in the <code class="literal">cinder-volume.log</code> file</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.12">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.9.8.3.12.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.12.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">2013-03-12 01:35:43 1248 TRACE cinder.openstack.common.rpc.amqp \
ISCSITargetCreateFailed: \
Failed to create iscsi target for volume \
volume-137641b2-af72-4a2f-b243-65fdccd38780.</pre></div><p>You might see this error in <code class="literal">cinder-volume.log</code> after trying to
create a volume that is 1 GB.</p></div><div class="sect4 " id="id-1.4.9.8.3.12.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">7.3.1.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.3.12.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To fix this issue, change the content of the <code class="literal">/etc/tgt/targets.conf</code>
file from <code class="literal">include /etc/tgt/conf.d/*.conf</code> to
<code class="literal">include /etc/tgt/conf.d/cinder_tgt.conf</code>, as follows:</p><div class="verbatim-wrap highlight ini"><pre class="screen">include /etc/tgt/conf.d/cinder_tgt.conf
include /etc/tgt/conf.d/cinder.conf
default-driver iscsi</pre></div><p>Restart <code class="literal">tgt</code> and <code class="literal">cinder-*</code> services, so they pick up the new
configuration.</p></div></div></div><div class="sect2 " id="id-1.4.9.8.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Multipath call failed exit</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.4.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.4.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Multipath call failed exit. This warning occurs in the Compute log
if you do not have the optional <code class="literal">multipath-tools</code> package installed
on the compute node. This is an optional package and the volume
attachment does work without the multipath tools installed.
If the <code class="literal">multipath-tools</code> package is installed on the compute node,
it is used to perform the volume attachment.
The IDs in your message are unique to your system.</p><div class="verbatim-wrap"><pre class="screen">WARNING nova.storage.linuxscsi [req-cac861e3-8b29-4143-8f1b-705d0084e571
    admin admin|req-cac861e3-8b29-4143-8f1b-705d0084e571 admin admin]
    Multipath call failed exit (96)</pre></div></div><div class="sect3 " id="id-1.4.9.8.4.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.4.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run the following command on the compute node to install the
<code class="literal">multipath-tools</code> packages.</p><div class="verbatim-wrap"><pre class="screen"># apt-get install multipath-tools</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Addressing discrepancies in reported volume sizes for EqualLogic storage</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.5.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.5.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There is a discrepancy between both the actual volume size in EqualLogic
(EQL) storage and the image size in the Image service, with what is
reported to OpenStack database. This could lead to confusion
if a user is creating volumes from an image that was uploaded from an EQL
volume (through the Image service). The image size is slightly larger
than the target volume size; this is because EQL size reporting accounts
for additional storage used by EQL for internal volume metadata.</p><p>To reproduce the issue follow the steps in the following procedure.</p><p>This procedure assumes that the EQL array is provisioned, and that
appropriate configuration settings have been included in
<code class="literal">/etc/cinder/cinder.conf</code> to connect to the EQL array.</p><p>Create a new volume. Note the ID and size of the volume. In the
following example, the ID and size are
<code class="literal">74cf9c04-4543-47ae-a937-a9b7c6c921e7</code> and <code class="literal">1</code>, respectively:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create volume1 --size 1

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-12-06T11:33:30.957318           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | 74cf9c04-4543-47ae-a937-a9b7c6c921e7 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | volume1                              |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | iscsi                                |
| updated_at          | None                                 |
| user_id             | c36cec73b0e44876a4478b1e6cd749bb     |
+---------------------+--------------------------------------+</pre></div><p>Verify the volume size on the EQL array by using its command-line
interface.</p><p>The actual size (<code class="literal">VolReserve</code>) is 1.01 GB. The EQL Group Manager
should also report a volume size of 1.01 GB:</p><div class="verbatim-wrap"><pre class="screen">eql&gt; volume select volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
eql (volume_volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7)&gt; show
_______________________________ Volume Information ________________________________
Name: volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
Size: 1GB
VolReserve: 1.01GB
VolReservelnUse: 0MB
ReplReservelnUse: 0MB
iSCSI Alias: volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
iSCSI Name: iqn.2001-05.com.equallogic:0-8a0906-19f91850c-067000000b4532cl-volume-74cf9c04-4543-47ae-a937-a9b7c6c921e7
ActualMembers: 1
Snap-Warn: 10%
Snap-Depletion: delete-oldest
Description:
Snap-Reserve: 100%
Snap-Reserve-Avail: 100% (1.01GB)
Permission: read-write
DesiredStatus: online
Status: online
Connections: O
Snapshots: O
Bind:
Type: not-replicated
ReplicationReserveSpace: 0MB</pre></div><p>Create a new image from this volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --volume volume1 \
  --disk-format raw --container-format bare image_from_volume1

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| container_format    | bare                                 |
| disk_format         | raw                                  |
| display_description | None                                 |
| id                  | 850fd393-a968-4259-9c65-6b495cba5209 |
| image_id            | 3020a21d-ba37-4495-8899-07fc201161b9 |
| image_name          | image_from_volume1                   |
| is_public           | False                                |
| protected           | False                                |
| size                | 1                                    |
| status              | uploading                            |
| updated_at          | 2016-12-05T12:43:56.000000           |
| volume_type         | iscsi                                |
+---------------------+--------------------------------------+</pre></div><p>When you uploaded the volume in the previous step, the Image service
reported the volume's size as <code class="literal">1</code> (GB). However, when using
<code class="command">openstack image show</code> to show the image, the displayed size is
1085276160 bytes, or roughly 1.01 GB:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><tbody><tr><td>
                    <p>Property</p>
                  </td><td>
                    <p>Value</p>
                  </td></tr><tr><td>
                    <p>checksum
container_format
created_at
disk_format
id
min_disk
min_ram
name
owner
protected
size
status
tags
updated_at
virtual_size
visibility</p>
                  </td><td>
                    <p>cd573cfaace07e7949bc0c46028904ff
bare
2016-12-06T11:39:06Z
raw
3020a21d-ba37-4495-8899-07fc201161b9
0
0
image_from_volume1
5669caad86a04256994cdf755df4d3c1
False
1085276160
active
[]
2016-12-06T11:39:24Z
None
private</p>
                  </td></tr></tbody></table></div><p>Create a new volume using the previous image (<code class="literal">image_id 3020a21d-ba37-4495
-8899-07fc201161b9</code> in this example) as
the source. Set the target volume size to 1 GB; this is the size
reported by the <code class="literal">cinder</code> tool when you uploaded the volume to the
Image service:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create volume2 --size 1 --image 3020a21d-ba37-4495-8899-07fc201161b9
ERROR: Invalid input received: Size of specified image 2 is larger
than volume size 1. (HTTP 400) (Request-ID: req-4b9369c0-dec5-4e16-a114-c0cdl6bSd210)</pre></div><p>The attempt to create a new volume based on the size reported by the
<code class="literal">cinder</code> tool will then fail.</p></div><div class="sect3 " id="id-1.4.9.8.5.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.5.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To work around this problem, increase the target size of the new image
to the next whole number. In the problem example, you created a 1 GB
volume to be used as volume-backed image, so a new volume using this
volume-backed image should use a size of 2 GB:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create volume2 --size 1 --image 3020a21d-ba37-4495-8899-07fc201161b9
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-12-06T11:49:06.031768           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | a70d6305-f861-4382-84d8-c43128be0013 |
| migration_status    | None                                 |
| multiattach         | False                                |
| name                | volume2                              |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | iscsi                                |
| updated_at          | None                                 |
| user_id             | c36cec73b0e44876a4478b1e6cd749bb     |
+---------------------+--------------------------------------+</pre></div><div id="id-1.4.9.8.5.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The dashboard suggests a suitable size when you create a new volume
based on a volume-backed image.</p></div><p>You can then check this new volume into the EQL array:</p><div class="verbatim-wrap"><pre class="screen">eql&gt; volume select volume-64e8eb18-d23f-437b-bcac-b352afa6843a
eql (volume_volume-61e8eb18-d23f-437b-bcac-b352afa6843a)&gt; show
______________________________ Volume Information _______________________________
Name: volume-64e8eb18-d23f-437b-bcac-b352afa6843a
Size: 2GB
VolReserve: 2.01GB
VolReserveInUse: 1.01GB
ReplReserveInUse: 0MB
iSCSI Alias: volume-64e8eb18-d23f-437b-bcac-b352afa6843a
iSCSI Name: iqn.2001-05.com.equallogic:0-8a0906-e3091850e-eae000000b7S32cl-volume-64e8eb18-d23f-437b-bcac-b3S2afa6Bl3a
ActualMembers: 1
Snap-Warn: 10%
Snap-Depletion: delete-oldest
Description:
Snap-Reserve: 100%
Snap-Reserve-Avail: 100% (2GB)
Permission: read-write
DesiredStatus: online
Status: online
Connections: 1
Snapshots: O
Bind:
Type: not-replicated
ReplicationReserveSpace: 0MB</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to Attach Volume, Missing sg_scan</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.6.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.6.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Failed to attach volume to an instance, <code class="literal">sg_scan</code> file not found. This
error occurs when the sg3-utils package is not installed on the compute node.
The IDs in your message are unique to your system:</p><div class="verbatim-wrap"><pre class="screen">ERROR nova.compute.manager [req-cf2679fd-dd9e-4909-807f-48fe9bda3642 admin admin|req-cf2679fd-dd9e-4909-807f-48fe9bda3642 admin admin]
[instance: 7d7c92e0-49fa-4a8e-87c7-73f22a9585d5|instance:  7d7c92e0-49fa-4a8e-87c7-73f22a9585d5]
Failed to attach volume  4cc104c4-ac92-4bd6-9b95-c6686746414a at /dev/vdcTRACE nova.compute.manager
[instance:  7d7c92e0-49fa-4a8e-87c7-73f22a9585d5|instance: 7d7c92e0-49fa-4a8e-87c7-73f22a9585d5]
Stdout: '/usr/local/bin/nova-rootwrap: Executable not found: /usr/bin/sg_scan'</pre></div></div><div class="sect3 " id="id-1.4.9.8.6.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.6.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run this command on the compute node to install the <code class="literal">sg3-utils</code> package:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install sg3-utils</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">HTTP bad request in cinder volume log</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.7.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.7.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These errors appear in the <code class="literal">cinder-volume.log</code> file:</p><div class="verbatim-wrap"><pre class="screen">2013-05-03 15:16:33 INFO [cinder.volume.manager] Updating volume status
2013-05-03 15:16:33 DEBUG [hp3parclient.http]
REQ: curl -i https://10.10.22.241:8080/api/v1/cpgs -X GET -H "X-Hp3Par-Wsapi-Sessionkey: 48dc-b69ed2e5
f259c58e26df9a4c85df110c-8d1e8451" -H "Accept: application/json" -H "User-Agent: python-3parclient"

2013-05-03 15:16:33 DEBUG [hp3parclient.http] RESP:{'content-length': 311, 'content-type': 'text/plain',
'status': '400'}

2013-05-03 15:16:33 DEBUG [hp3parclient.http] RESP BODY:Second simultaneous read on fileno 13 detected.
Unless you really know what you're doing, make sure that only one greenthread can read any particular socket.
Consider using a pools.Pool. If you do know what you're doing and want to disable this error,
call eventlet.debug.hub_multiple_reader_prevention(False)

2013-05-03 15:16:33 ERROR [cinder.manager] Error during VolumeManager._report_driver_status: Bad request (HTTP 400)
Traceback (most recent call last):
File "/usr/lib/python2.7/dist-packages/cinder/manager.py", line 167, in periodic_tasks task(self, context)
File "/usr/lib/python2.7/dist-packages/cinder/volume/manager.py", line 690, in _report_driver_status volume_stats =
self.driver.get_volume_stats(refresh=True)
File "/usr/lib/python2.7/dist-packages/cinder/volume/drivers/san/hp/hp_3par_fc.py", line 77, in get_volume_stats stats =
self.common.get_volume_stats(refresh, self.client)
File "/usr/lib/python2.7/dist-packages/cinder/volume/drivers/san/hp/hp_3par_common.py", line 421, in get_volume_stats cpg =
client.getCPG(self.config.hp3par_cpg)
File "/usr/lib/python2.7/dist-packages/hp3parclient/client.py", line 231, in getCPG cpgs = self.getCPGs()
File "/usr/lib/python2.7/dist-packages/hp3parclient/client.py", line 217, in getCPGs response, body = self.http.get('/cpgs')
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 255, in get return self._cs_request(url, 'GET', **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 224, in _cs_request **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 198, in _time_request resp, body = self.request(url, method, **kwargs)
File "/usr/lib/python2.7/dist-packages/hp3parclient/http.py", line 192, in request raise exceptions.from_response(resp, body)
HTTPBadRequest: Bad request (HTTP 400)</pre></div></div><div class="sect3 " id="id-1.4.9.8.7.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.7.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You need to update your copy of the <code class="literal">hp_3par_fc.py</code> driver which
contains the synchronization code.</p></div></div><div class="sect2 " id="id-1.4.9.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Duplicate 3PAR host</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.8.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This error may be caused by a volume being exported outside of OpenStack
using a host name different from the system name that OpenStack expects.
This error could be displayed with the <a class="xref" href="#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a> if the host was exported using iSCSI:</p><div class="verbatim-wrap"><pre class="screen">Duplicate3PARHost: 3PAR Host already exists: Host wwn 50014380242B9750 \
already used by host cld4b5ubuntuW(id = 68. The hostname must be called\
'cld4b5ubuntu'.</pre></div></div><div class="sect3 " id="id-1.4.9.8.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Change the 3PAR host name to match the one that OpenStack expects. The
3PAR host constructed by the driver uses just the local host name, not
the fully qualified domain name (FQDN) of the compute host. For example,
if the FQDN was <span class="emphasis"><em>myhost.example.com</em></span>, just <span class="emphasis"><em>myhost</em></span> would be used as the
3PAR host name. IP addresses are not allowed as host names on the 3PAR
storage server.</p></div></div><div class="sect2 " id="id-1.4.9.8.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to attach volume after detaching</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.9.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.9.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Failed to attach a volume after detaching the same volume.</p></div><div class="sect3 " id="id-1.4.9.8.9.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.9.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must change the device name on the <code class="command">nova-attach</code> command. The VM
might not clean up after a <code class="command">nova-detach</code> command runs. This example
shows how the <code class="command">nova-attach</code> command fails when you use the <code class="literal">vdb</code>,
<code class="literal">vdc</code>, or <code class="literal">vdd</code> device names:</p><div class="verbatim-wrap"><pre class="screen"># ls -al /dev/disk/by-path/
total 0
drwxr-xr-x 2 root root 200 2012-08-29 17:33 .
drwxr-xr-x 5 root root 100 2012-08-29 17:33 ..
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0 -&gt; ../../vda
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part1 -&gt; ../../vda1
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part2 -&gt; ../../vda2
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:04.0-virtio-pci-virtio0-part5 -&gt; ../../vda5
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:06.0-virtio-pci-virtio2 -&gt; ../../vdb
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:08.0-virtio-pci-virtio3 -&gt; ../../vdc
lrwxrwxrwx 1 root root 9 2012-08-29 17:33 pci-0000:00:09.0-virtio-pci-virtio4 -&gt; ../../vdd
lrwxrwxrwx 1 root root 10 2012-08-29 17:33 pci-0000:00:09.0-virtio-pci-virtio4-part1 -&gt; ../../vdd1</pre></div><p>You might also have this problem after attaching and detaching the same
volume from the same VM with the same mount point multiple times. In
this case, restart the KVM host.</p></div></div><div class="sect2 " id="id-1.4.9.8.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to attach volume, systool is not installed</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.10.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.10.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This warning and error occurs if you do not have the required
<code class="literal">sysfsutils</code> package installed on the compute node:</p><div class="verbatim-wrap"><pre class="screen">WARNING nova.virt.libvirt.utils [req-1200f887-c82b-4e7c-a891-fac2e3735dbb\
admin admin|req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin admin] systool\
is not installed
ERROR nova.compute.manager [req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin\
admin|req-1200f887-c82b-4e7c-a891-fac2e3735dbb admin admin]
[instance: df834b5a-8c3f-477a-be9b-47c97626555c|instance: df834b5a-8c3f-47\
7a-be9b-47c97626555c]
Failed to attach volume 13d5c633-903a-4764-a5a0-3336945b1db1 at /dev/vdk.</pre></div></div><div class="sect3 " id="id-1.4.9.8.10.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.10.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run the following command on the compute node to install the
<code class="literal">sysfsutils</code> packages:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install sysfsutils</pre></div></div></div><div class="sect2 " id="id-1.4.9.8.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failed to connect volume in FC SAN</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.11.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.11.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The compute node failed to connect to a volume in a Fibre Channel (FC) SAN
configuration. The WWN may not be zoned correctly in your FC SAN that
links the compute host to the storage array:</p><div class="verbatim-wrap"><pre class="screen">ERROR nova.compute.manager [req-2ddd5297-e405-44ab-aed3-152cd2cfb8c2 admin\
demo|req-2ddd5297-e405-44ab-aed3-152cd2cfb8c2 admin demo] [instance: 60ebd\
6c7-c1e3-4bf0-8ef0-f07aa4c3d5f3|instance: 60ebd6c7-c1e3-4bf0-8ef0-f07aa4c3\
d5f3]
Failed to connect to volume 6f6a6a9c-dfcf-4c8d-b1a8-4445ff883200 while\
attaching at /dev/vdjTRACE nova.compute.manager [instance: 60ebd6c7-c1e3-4\
bf0-8ef0-f07aa4c3d5f3|instance: 60ebd6c7-c1e3-4bf0-8ef0-f07aa4c3d5f3]
Traceback (most recent call last):…f07aa4c3d5f3\] ClientException: The\
server has either erred or is incapable of performing the requested\
operation.(HTTP 500)(Request-ID: req-71e5132b-21aa-46ee-b3cc-19b5b4ab2f00)</pre></div></div><div class="sect3 " id="id-1.4.9.8.11.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.11.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The network administrator must configure the FC SAN fabric by correctly
zoning the WWN (port names) from your compute node HBAs.</p></div></div><div class="sect2 " id="id-1.4.9.8.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cannot find suitable emulator for x86_64</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.12.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.12.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you attempt to create a VM, the error shows the VM is in the
<code class="literal">BUILD</code> then <code class="literal">ERROR</code> state.</p></div><div class="sect3 " id="id-1.4.9.8.12.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.12.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>On the KVM host, run <code class="command">cat /proc/cpuinfo</code>. Make sure the <code class="literal">vmx</code> or
<code class="literal">svm</code> flags are set.</p><p>Follow the instructions in the <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/hypervisor-kvm.html#enable-kvm" target="_blank">Enable KVM</a> section in the OpenStack Configuration Reference to enable hardware
virtualization support in your BIOS.</p></div></div><div class="sect2 " id="id-1.4.9.8.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Non-existent host</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.13.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.13.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This error could be caused by a volume being exported outside of
OpenStack using a host name different from the system name that
OpenStack expects. This error could be displayed with the <a class="xref" href="#term-iscsi-qualified-name-iqn" title="iSCSI Qualified Name (IQN)">iSCSI Qualified Name (IQN)</a> if the host was exported using iSCSI.</p><div class="verbatim-wrap"><pre class="screen">2013-04-19 04:02:02.336 2814 ERROR cinder.openstack.common.rpc.common [-] Returning exception Not found (HTTP 404)
NON_EXISTENT_HOST - HOST '10' was not found to caller.</pre></div></div><div class="sect3 " id="id-1.4.9.8.13.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.13.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Host names constructed by the driver use just the local host name, not
the fully qualified domain name (FQDN) of the Compute host. For example,
if the FQDN was <span class="bold"><strong>myhost.example.com</strong></span>, just <span class="bold"><strong>myhost</strong></span> would be used as the
3PAR host name. IP addresses are not allowed as host names on the 3PAR
storage server.</p></div></div><div class="sect2 " id="id-1.4.9.8.14"><div class="titlepage"><div><div><h3 class="title"><span class="number">7.3.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Non-existent VLUN</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.14">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.9.8.14.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.14.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This error occurs if the 3PAR host exists with the correct host name
that the OpenStack Block Storage drivers expect but the volume was
created in a different domain.</p><div class="verbatim-wrap"><pre class="screen">HTTPNotFound: Not found (HTTP 404) NON_EXISTENT_VLUN - VLUN 'osv-DqT7CE3mSrWi4gZJmHAP-Q' was not found.</pre></div></div><div class="sect3 " id="id-1.4.9.8.14.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">7.3.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.9.8.14.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">hpe3par_domain</code> configuration items either need to be updated to
use the domain the 3PAR host currently resides in, or the 3PAR host
needs to be moved to the domain that the volume was created in.</p></div></div></div></div><div class="chapter " id="id-1.4.10"><div class="titlepage"><div><div><h1 class="title"><span class="number">8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Shared File Systems</span> <a title="Permalink" class="permalink" href="#id-1.4.10">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.10.5"><span class="number">8.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.6"><span class="number">8.2 </span><span class="name">Key concepts</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.7"><span class="number">8.3 </span><span class="name">Share management</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.8"><span class="number">8.4 </span><span class="name">Migrate shares</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-share-types"><span class="number">8.5 </span><span class="name">Share types</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-snapshots"><span class="number">8.6 </span><span class="name">Share snapshots</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-security-services"><span class="number">8.7 </span><span class="name">Security services</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-cgroups"><span class="number">8.8 </span><span class="name">Consistency groups</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.13"><span class="number">8.9 </span><span class="name">Share replication</span></a></span></dt><dt><span class="sect1"><a href="#shared-file-systems-multi-backend"><span class="number">8.10 </span><span class="name">Multi-storage configuration</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.15"><span class="number">8.11 </span><span class="name">Networking</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.10.16"><span class="number">8.12 </span><span class="name">Troubleshoot Shared File Systems service</span></a></span></dt></dl></div></div><p>Shared File Systems service provides a set of services for management of
shared file systems in a multi-project cloud environment. The service resembles
OpenStack block-based storage management from the OpenStack Block Storage
service project. With the Shared File Systems service, you can
create a remote file system, mount the file system on your instances, and then
read and write data from your instances to and from your file system.</p><p>The Shared File Systems service serves same purpose as the Amazon Elastic File
System (EFS) does.</p><div class="sect1 " id="id-1.4.10.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction</span> <a title="Permalink" class="permalink" href="#id-1.4.10.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack File Share service allows you to offer shared file systems
service to OpenStack users in your installation. The Shared File Systems
service can run in a single-node or multiple node configuration.
The Shared File Systems service can be configured to provision shares
from one or more back ends, so it is required to declare at least one
back end. Shared File System service contains several configurable
components.</p><p>It is important to understand these components:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Share networks</p></li><li class="listitem "><p>Shares</p></li><li class="listitem "><p>Multi-tenancy</p></li><li class="listitem "><p>Back ends</p></li></ul></div><p>The Shared File Systems service consists of four types of services,
most of which are similar to those of the Block Storage service:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
            <code class="literal">manila-api</code>
          </p></li><li class="listitem "><p>
            <code class="literal">manila-data</code>
          </p></li><li class="listitem "><p>
            <code class="literal">manila-scheduler</code>
          </p></li><li class="listitem "><p>
            <code class="literal">manila-share</code>
          </p></li></ul></div><p>Installation of first three - <code class="literal">manila-api</code>, <code class="literal">manila-data</code>, and
<code class="literal">manila-scheduler</code> is common for almost all deployments. But configuration
of <code class="literal">manila-share</code> is backend-specific and can differ from deployment to
deployment.</p></div><div class="sect1 " id="id-1.4.10.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Key concepts</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.10.6.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the Shared File Systems service <code class="literal">share</code> is the fundamental resource unit
allocated by the Shared File System service. It represents an allocation of a
persistent, readable, and writable filesystems. Compute instances access these
filesystems. Depending on the deployment configuration, clients outside of
OpenStack can also access the filesystem.</p><div id="id-1.4.10.6.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A <code class="literal">share</code> is an abstract storage object that may or may not directly
map to a "share" concept from the underlying storage provider.
See the description of <code class="literal">share instance</code> for more details.</p></div></div><div class="sect2 " id="id-1.4.10.6.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share instance</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This concept is tied with <code class="literal">share</code> and represents created resource on specific
back end, when <code class="literal">share</code> represents abstraction between end user and
back-end storages. In common cases, it is one-to-one relation.
One single <code class="literal">share</code> has more than one <code class="literal">share instance</code> in two cases:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>When <code class="literal">share migration</code> is being applied</p></li><li class="listitem "><p>When <code class="literal">share replication</code> is enabled</p></li></ul></div><p>Therefore, each <code class="literal">share instance</code> stores information specific to real
allocated resource on storage. And <code class="literal">share</code> represents the information
that is common for <code class="literal">share instances</code>.
A user with <code class="literal">member</code> role will not be able to work with it directly. Only
a user with <code class="literal">admin</code> role has rights to perform actions against specific
share instances.</p></div><div class="sect2 " id="id-1.4.10.6.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A <code class="literal">snapshot</code> is a point-in-time, read-only copy of a <code class="literal">share</code>. You can
create <code class="literal">Snapshots</code> from an existing, operational <code class="literal">share</code> regardless
of whether a client has mounted the file system. A <code class="literal">snapshot</code>
can serve as the content source for a new <code class="literal">share</code>. Specify the
<span class="bold"><strong>Create from snapshot</strong></span> option when creating a new <code class="literal">share</code> on the
dashboard.</p></div><div class="sect2 " id="id-1.4.10.6.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storage Pools</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>With the Kilo release of OpenStack, Shared File Systems can use
<code class="literal">storage pools</code>. The storage may present one or more logical storage
resource pools that the Shared File Systems service
will select as a storage location when provisioning <code class="literal">shares</code>.</p></div><div class="sect2 " id="id-1.4.10.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share Type</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><code class="literal">Share type</code> is an abstract collection of criteria used to characterize
<code class="literal">shares</code>. They are most commonly used to create a hierarchy of functional
capabilities. This hierarchy represents tiered storage services levels. For
example, an administrator might define a premium <code class="literal">share type</code> that
indicates a greater level of performance than a basic <code class="literal">share type</code>.
Premium represents the best performance level.</p></div><div class="sect2 " id="id-1.4.10.6.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share Access Rules</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><code class="literal">Share access rules</code> define which users can access a particular <code class="literal">share</code>.
For example, administrators can declare rules for NFS shares by
listing the valid IP networks which will access the <code class="literal">share</code>. List the
IP networks in CIDR notation.</p></div><div class="sect2 " id="id-1.4.10.6.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Security Services</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><code class="literal">Security services``allow granular client access rules for
administrators. They can declare rules for authentication or
authorization to access ``share</code> content. External services including LDAP,
Active Directory, and Kerberos can be declared as resources. Examine and
consult these resources when making an access decision for a
particular <code class="literal">share</code>. You can associate <code class="literal">Shares</code> with multiple
security services, but only one service per one type.</p></div><div class="sect2 " id="id-1.4.10.6.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share Networks</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A <code class="literal">share network</code> is an object that defines a relationship between a
project network and subnet, as defined in an OpenStack Networking service or
Compute service. The <code class="literal">share network</code> is also defined in <code class="literal">shares</code>
created by the same project. A project may find it desirable to
provision <code class="literal">shares</code> such that only instances connected to a particular
OpenStack-defined network have access to the <code class="literal">share</code>. Also,
<code class="literal">security services</code> can be attached to <code class="literal">share networks</code>,
because most of auth protocols require some interaction with network services.</p><p>The Shared File Systems service has the ability to work outside of OpenStack.
That is due to the <code class="literal">StandaloneNetworkPlugin</code>. The plugin is compatible with
any network platform, and does not require specific network services in
OpenStack like Compute or Networking service. You can set the network
parameters in the <code class="literal">manila.conf</code> file.</p></div><div class="sect2 " id="id-1.4.10.6.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.2.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share Servers</span> <a title="Permalink" class="permalink" href="#id-1.4.10.6.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A <code class="literal">share server</code> is a logical entity that hosts the shares created
on a specific <code class="literal">share network</code>. A <code class="literal">share server</code> may be a
configuration object within the storage controller, or it may represent
logical resources provisioned within an OpenStack deployment used to
support the data path used to access <code class="literal">shares</code>.</p><p><code class="literal">Share servers</code> interact with network services to determine the appropriate
IP addresses on which to export <code class="literal">shares</code> according to the related <code class="literal">share
network</code>. The Shared File Systems service has a pluggable network model that
allows <code class="literal">share servers</code> to work with different implementations of
the Networking service.</p></div></div><div class="sect1 " id="id-1.4.10.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share management</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A share is a remote, mountable file system. You can mount a share to and access
a share from several hosts by several users at a time.</p><p>You can create a share and associate it with a network, list shares, and show
information for, update, and delete a specified share.
You can also create snapshots of shares. To create a snapshot, you specify the
ID of the share that you want to snapshot.</p><p>The shares are based on of the supported Shared File Systems protocols:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="emphasis"><em>NFS</em></span>. Network File System (NFS).</p></li><li class="listitem "><p><span class="emphasis"><em>CIFS</em></span>. Common Internet File System (CIFS).</p></li><li class="listitem "><p><span class="emphasis"><em>GLUSTERFS</em></span>. Gluster file system (GlusterFS).</p></li><li class="listitem "><p><span class="emphasis"><em>HDFS</em></span>. Hadoop Distributed File System (HDFS).</p></li><li class="listitem "><p><span class="emphasis"><em>CEPHFS</em></span>. Ceph File System (CephFS).</p></li></ul></div><p>The Shared File Systems service provides set of drivers that enable you to use
various network file storage devices, instead of the base implementation. That
is the real purpose of the Shared File Systems service in production.</p><div class="sect2 " id="id-1.4.10.7.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share basic operations</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.7.7.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">General concepts</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.7.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create a file share, and access it, the following general concepts
are prerequisite knowledge:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To create a share, use <code class="command">manila create</code> command and
specify the required arguments: the size of the share and the shared file
system protocol. <code class="literal">NFS</code>, <code class="literal">CIFS</code>, <code class="literal">GlusterFS</code>, <code class="literal">HDFS</code>, or
<code class="literal">CephFS</code> share file system protocols are supported.</p></li><li class="step "><p>You can also optionally specify the share network and the share type.</p></li><li class="step "><p>After the share becomes available, use the <code class="command">manila show</code> command
to get the share export locations.</p></li><li class="step "><p>After getting the share export locations, you can create an
<a class="xref" href="#access-to-share" title="8.3.1.8. Manage access to share">Section 8.3.1.8, “Manage access to share”</a> for the share, mount it and work with
files on the remote file system.</p></li></ol></div></div><p>There are big number of the share drivers created by different vendors in the
Shared File Systems service. As a Python class, each share driver can be set
for the <a class="xref" href="#shared-file-systems-multi-backend" title="8.10. Multi-storage configuration">Section 8.10, “Multi-storage configuration”</a> and run in the back
end to manage the share operations.</p><p>Initially there are two driver modes for the back ends:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>no share servers mode</p></li><li class="listitem "><p>share servers mode</p></li></ul></div><p>Each share driver supports one or two of possible back end modes that can be
configured in the <code class="literal">manila.conf</code> file. The configuration option
<code class="literal">driver_handles_share_servers</code> in the <code class="literal">manila.conf</code> file sets the share
servers mode or no share servers mode, and defines the driver mode for share
storage lifecycle management:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                    <p>Mode</p>
                  </th><th>
                    <p>Config option</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>no share servers</p>
                  </td><td>
                    <p>driver_handles_share_servers = False</p>
                  </td><td>
                    <p>An administrator
rather than a share
driver manages the
bare metal storage
with some net
interface instead
of the presence of
the share servers.</p>
                  </td></tr><tr><td>
                    <p>share servers</p>
                  </td><td>
                    <p>driver_handles_share_servers = True</p>
                  </td><td>
                    <p>The share driver
creates the share
server and manages,
or handles, the
share server life
cycle.</p>
                  </td></tr></tbody></table></div><p>It is <a class="xref" href="#shared-file-systems-share-types" title="8.5. Share types">Section 8.5, “Share types”</a> which have the
extra specifications that help scheduler to filter back ends and choose the
appropriate back end for the user that requested to create a share. The
required extra boolean specification for each share type is
<code class="literal">driver_handles_share_servers</code>. As an administrator, you can create the share
types with the specifications you need. For details of managing the share types
and configuration the back ends, see <a class="xref" href="#shared-file-systems-share-types" title="8.5. Share types">Section 8.5, “Share types”</a> and
<a class="xref" href="#shared-file-systems-multi-backend" title="8.10. Multi-storage configuration">Section 8.10, “Multi-storage configuration”</a> documentation.</p><p>You can create a share in two described above modes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>in a no share servers mode without specifying the share network and
specifying the share type with <code class="literal">driver_handles_share_servers = False</code>
parameter. See subsection <a class="xref" href="#create-share-in-no-share-server-mode" title="8.3.1.2. Create a share in no share servers mode">Section 8.3.1.2, “Create a share in no share servers mode”</a>.</p></li><li class="listitem "><p>in a share servers mode with specifying the share network and the share
type with <code class="literal">driver_handles_share_servers = True</code> parameter. See subsection
<a class="xref" href="#create-share-in-share-server-mode" title="8.3.1.3. Create a share in share servers mode">Section 8.3.1.3, “Create a share in share servers mode”</a>.</p></li></ul></div></div><div class="sect3 " id="create-share-in-no-share-server-mode"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a share in no share servers mode</span> <a title="Permalink" class="permalink" href="#create-share-in-no-share-server-mode">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>create-share-in-no-share-server-mode</li></ul></div></div></div></div><p>To create a file share in no share servers mode, you need to:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To create a share, use <code class="command">manila create</code> command and
specify the required arguments: the size of the share and the shared file
system protocol. <code class="literal">NFS</code>, <code class="literal">CIFS</code>, <code class="literal">GlusterFS</code>, <code class="literal">HDFS</code>, or
<code class="literal">CephFS</code> share file system protocols are supported.</p></li><li class="step "><p>You should specify the <a class="xref" href="#shared-file-systems-share-types" title="8.5. Share types">Section 8.5, “Share types”</a>
with <code class="literal">driver_handles_share_servers = False</code> extra specification.</p></li><li class="step "><p>You must not specify the <code class="literal">share network</code> because no share servers are
created. In this mode the Shared File Systems service expects that
administrator has some bare metal storage with some net interface.</p></li><li class="step "><p>The <code class="command">manila create</code> command creates a share. This command does the
following things:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <a class="xref" href="#shared-file-systems-scheduling" title="8.10.1. Scheduling">Section 8.10.1, “Scheduling”</a> service will
find the back end with <code class="literal">driver_handles_share_servers = False</code> mode due
to filtering the extra specifications of the share type.</p></li><li class="listitem "><p>The share is created using the storage that is specified in the found
back end.</p></li></ul></div></li><li class="step "><p>After the share becomes available, use the <code class="command">manila show</code> command
to get the share export locations.</p></li></ol></div></div><p>In the example to create a share, the created already share type named
<code class="literal">my_type</code> with <code class="literal">driver_handles_share_servers = False</code> extra specification
is used.</p><p>Check share types that exist, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila type-list
+------+---------+------------+------------+--------------------------------------+-------------------------+
| ID   | Name    | visibility | is_default | required_extra_specs                 | optional_extra_specs    |
+------+---------+------------+------------+--------------------------------------+-------------------------+
| %ID% | my_type | public     | -          | driver_handles_share_servers : False | snapshot_support : True |
+------+---------+------------+------------+--------------------------------------+-------------------------+</pre></div><p>Create a private share with <code class="literal">my_type</code> share type, NFS shared file system
protocol, and size 1 GB:</p><div class="verbatim-wrap"><pre class="screen">$ manila create nfs 1 --name Share1 --description "My share" --share-type my_type
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | creating                             |
| share_type_name             | my_type                              |
| description                 | My share                             |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| share_server_id             | None                                 |
| host                        |                                      |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 |
| size                        | 1                                    |
| name                        | Share1                               |
| share_type                  | 14ee8575-aac2-44af-8392-d9c9d344f392 |
| has_replicas                | False                                |
| replication_type            | None                                 |
| created_at                  | 2016-03-25T12:02:46.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 907004508ef4447397ce6741a8f037c1     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</pre></div><p>New share <code class="literal">Share2</code> should have a status <code class="literal">available</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila show Share2
+-----------------------------+----------------------------------------------------------+
| Property                    | Value                                                    |
+-----------------------------+----------------------------------------------------------+
| status                      | available                                                |
| share_type_name             | my_type                                                  |
| description                 | My share                                                 |
| availability_zone           | nova                                                     |
| share_network_id            | None                                                     |
| export_locations            |                                                          |
|                             | path = 10.0.0.4:/shares/manila_share_a5fb1ab7_...        |
|                             | preferred = False                                        |
|                             | is_admin_only = False                                    |
|                             | id = 9e078eee-bcad-40b8-b4fe-1c916cf98ed1                |
|                             | share_instance_id = a5fb1ab7-0bbd-465b-ac14-05706294b6e9 |
|                             | path = 172.18.198.52:/shares/manila_share_a5fb1ab7_...   |
|                             | preferred = False                                        |
|                             | is_admin_only = True                                     |
|                             | id = 44933f59-e0e3-4483-bb88-72ba7c486f41                |
|                             | share_instance_id = a5fb1ab7-0bbd-465b-ac14-05706294b6e9 |
| share_server_id             | None                                                     |
| host                        | manila@paris#epsilon                                     |
| access_rules_status         | active                                                   |
| snapshot_id                 | None                                                     |
| is_public                   | False                                                    |
| task_state                  | None                                                     |
| snapshot_support            | True                                                     |
| id                          | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88                     |
| size                        | 1                                                        |
| name                        | Share1                                                   |
| share_type                  | 14ee8575-aac2-44af-8392-d9c9d344f392                     |
| has_replicas                | False                                                    |
| replication_type            | None                                                     |
| created_at                  | 2016-03-25T12:02:46.000000                               |
| share_proto                 | NFS                                                      |
| consistency_group_id        | None                                                     |
| source_cgsnapshot_member_id | None                                                     |
| project_id                  | 907004508ef4447397ce6741a8f037c1                         |
| metadata                    | {}                                                       |
+-----------------------------+----------------------------------------------------------+</pre></div></div><div class="sect3 " id="create-share-in-share-server-mode"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a share in share servers mode</span> <a title="Permalink" class="permalink" href="#create-share-in-share-server-mode">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>create-share-in-share-server-mode</li></ul></div></div></div></div><p>To create a file share in share servers mode, you need to:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To create a share, use <code class="command">manila create</code> command and
specify the required arguments: the size of the share and the shared file
system protocol. <code class="literal">NFS</code>, <code class="literal">CIFS</code>, <code class="literal">GlusterFS</code>, <code class="literal">HDFS</code>, or
<code class="literal">CephFS</code> share file system protocols are supported.</p></li><li class="step "><p>You should specify the <a class="xref" href="#shared-file-systems-share-types" title="8.5. Share types">Section 8.5, “Share types”</a>
with <code class="literal">driver_handles_share_servers = True</code> extra specification.</p></li><li class="step "><p>You should specify the
<a class="xref" href="#shared-file-systems-share-networks" title="8.11.1. Share networks">Section 8.11.1, “Share networks”</a>.</p></li><li class="step "><p>The <code class="command">manila create</code> command creates a share. This command does the
following things:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <a class="xref" href="#shared-file-systems-scheduling" title="8.10.1. Scheduling">Section 8.10.1, “Scheduling”</a> service will
find the back end with <code class="literal">driver_handles_share_servers = True</code> mode due to
filtering the extra specifications of the share type.</p></li><li class="listitem "><p>The share driver will create a share server with the share network. For
details of creating the resources, see the <a class="link" href="http://docs.openstack.org/developer/manila/devref/index.html#share-backends" target="_blank">documentation</a> of the
specific share driver.</p></li></ul></div></li><li class="step "><p>After the share becomes available, use the <code class="command">manila show</code> command
to get the share export location.</p></li></ol></div></div><p>In the example to create a share, the default share type and the already
existing share network are used.</p><div id="id-1.4.10.7.7.4.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>There is no default share type just after you started manila as the
administrator. See <a class="xref" href="#shared-file-systems-share-types" title="8.5. Share types">Section 8.5, “Share types”</a> to
create the default share type. To create a share network, use
<a class="xref" href="#shared-file-systems-share-networks" title="8.11.1. Share networks">Section 8.11.1, “Share networks”</a>.</p></div><p>Check share types that exist, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila type-list
+------+---------+------------+------------+--------------------------------------+-------------------------+
| ID   | Name    | visibility | is_default | required_extra_specs                 | optional_extra_specs    |
+------+---------+------------+------------+--------------------------------------+-------------------------+
| %id% | default | public     | YES        | driver_handles_share_servers : True  | snapshot_support : True |
+------+---------+------------+------------+--------------------------------------+-------------------------+</pre></div><p>Check share networks that exist, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila share-network-list
+--------------------------------------+--------------+
| id                                   | name         |
+--------------------------------------+--------------+
| c895fe26-92be-4152-9e6c-f2ad230efb13 | my_share_net |
+--------------------------------------+--------------+</pre></div><p>Create a public share with <code class="literal">my_share_net</code> network, <code class="literal">default</code>
share type, NFS shared file system protocol, and size 1 GB:</p><div class="verbatim-wrap"><pre class="screen">$ manila create nfs 1 \
    --name "Share2" \
    --description "My second share" \
    --share-type default \
    --share-network my_share_net \
    --metadata aim=testing \
    --public
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | creating                             |
| share_type_name             | default                              |
| description                 | My second share                      |
| availability_zone           | None                                 |
| share_network_id            | c895fe26-92be-4152-9e6c-f2ad230efb13 |
| share_server_id             | None                                 |
| host                        |                                      |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | True                                 |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | 195e3ba2-9342-446a-bc93-a584551de0ac |
| size                        | 1                                    |
| name                        | Share2                               |
| share_type                  | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf |
| has_replicas                | False                                |
| replication_type            | None                                 |
| created_at                  | 2016-03-25T12:13:40.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 907004508ef4447397ce6741a8f037c1     |
| metadata                    | {u'aim': u'testing'}                 |
+-----------------------------+--------------------------------------+</pre></div><p>The share also can be created from a share snapshot. For details, see
<a class="xref" href="#shared-file-systems-snapshots" title="8.6. Share snapshots">Section 8.6, “Share snapshots”</a>.</p><p>See the share in a share list:</p><div class="verbatim-wrap"><pre class="screen">$ manila list
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| ID                                   | Name    | Size | Share Proto | Status    | Is Public | Share Type Name | Host                 | Availability Zone |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 | Share1  | 1    | NFS         | available | False     | my_type         | manila@paris#epsilon | nova              |
| 195e3ba2-9342-446a-bc93-a584551de0ac | Share2  | 1    | NFS         | available | True      | default         | manila@london#LONDON | nova              |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+</pre></div><p>Check the share status and see the share export locations. After <code class="literal">creating</code>
status share should have status <code class="literal">available</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila show Share2
+----------------------+----------------------------------------------------------------------+
| Property             | Value                                                                |
+----------------------+----------------------------------------------------------------------+
| status               | available                                                            |
| share_type_name      | default                                                              |
| description          | My second share                                                      |
| availability_zone    | nova                                                                 |
| share_network_id     | c895fe26-92be-4152-9e6c-f2ad230efb13                                 |
| export_locations     |                                                                      |
|                      | path = 10.254.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965 |
|                      | preferred = False                                                    |
|                      | is_admin_only = False                                                |
|                      | id = de6d4012-6158-46f0-8b28-4167baca51a7                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
|                      | path = 10.0.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965   |
|                      | preferred = False                                                    |
|                      | is_admin_only = True                                                 |
|                      | id = 602d0f5c-921b-4e45-bfdb-5eec8a89165a                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
| share_server_id      | 2e9d2d02-883f-47b5-bb98-e053b8d1e683                                 |
| host                 | manila@london#LONDON                                                 |
| access_rules_status  | active                                                               |
| snapshot_id          | None                                                                 |
| is_public            | True                                                                 |
| task_state           | None                                                                 |
| snapshot_support     | True                                                                 |
| id                   | 195e3ba2-9342-446a-bc93-a584551de0ac                                 |
| size                 | 1                                                                    |
| name                 | Share2                                                               |
| share_type           | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf                                 |
| has_replicas         | False                                                                |
| replication_type     | None                                                                 |
| created_at           | 2016-03-25T12:13:40.000000                                           |
| share_proto          | NFS                                                                  |
| consistency_group_id | None                                                                 |
| project_id           | 907004508ef4447397ce6741a8f037c1                                     |
| metadata             | {u'aim': u'testing'}                                                 |
+----------------------+----------------------------------------------------------------------+</pre></div><p><code class="literal">is_public</code> defines the level of visibility for the share: whether other
projects can or cannot see the share. By default, the share is private.</p></div><div class="sect3 " id="id-1.4.10.7.7.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.7.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Update the name, or description, or level of visibility for all projects for
the share if you need:</p><div class="verbatim-wrap"><pre class="screen">$ manila update Share2 --description "My second share. Updated" --is-public False

$ manila show Share2
+----------------------+----------------------------------------------------------------------+
| Property             | Value                                                                |
+----------------------+----------------------------------------------------------------------+
| status               | available                                                            |
| share_type_name      | default                                                              |
| description          | My second share. Updated                                             |
| availability_zone    | nova                                                                 |
| share_network_id     | c895fe26-92be-4152-9e6c-f2ad230efb13                                 |
| export_locations     |                                                                      |
|                      | path = 10.254.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965 |
|                      | preferred = False                                                    |
|                      | is_admin_only = False                                                |
|                      | id = de6d4012-6158-46f0-8b28-4167baca51a7                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
|                      | path = 10.0.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965   |
|                      | preferred = False                                                    |
|                      | is_admin_only = True                                                 |
|                      | id = 602d0f5c-921b-4e45-bfdb-5eec8a89165a                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
| share_server_id      | 2e9d2d02-883f-47b5-bb98-e053b8d1e683                                 |
| host                 | manila@london#LONDON                                                 |
| access_rules_status  | active                                                               |
| snapshot_id          | None                                                                 |
| is_public            | False                                                                |
| task_state           | None                                                                 |
| snapshot_support     | True                                                                 |
| id                   | 195e3ba2-9342-446a-bc93-a584551de0ac                                 |
| size                 | 1                                                                    |
| name                 | Share2                                                               |
| share_type           | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf                                 |
| has_replicas         | False                                                                |
| replication_type     | None                                                                 |
| created_at           | 2016-03-25T12:13:40.000000                                           |
| share_proto          | NFS                                                                  |
| consistency_group_id | None                                                                 |
| project_id           | 907004508ef4447397ce6741a8f037c1                                     |
| metadata             | {u'aim': u'testing'}                                                 |
+----------------------+----------------------------------------------------------------------+</pre></div><p>A share can have one of these status values:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Status</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>creating</p>
                  </td><td>
                    <p>The share is being created.</p>
                  </td></tr><tr><td>
                    <p>deleting</p>
                  </td><td>
                    <p>The share is being deleted.</p>
                  </td></tr><tr><td>
                    <p>error</p>
                  </td><td>
                    <p>An error occurred during share creation.</p>
                  </td></tr><tr><td>
                    <p>error_deleting</p>
                  </td><td>
                    <p>An error occurred during share deletion.</p>
                  </td></tr><tr><td>
                    <p>available</p>
                  </td><td>
                    <p>The share is ready to use.</p>
                  </td></tr><tr><td>
                    <p>manage_starting</p>
                  </td><td>
                    <p>Share manage started.</p>
                  </td></tr><tr><td>
                    <p>manage_error</p>
                  </td><td>
                    <p>Share manage failed.</p>
                  </td></tr><tr><td>
                    <p>unmanage_starting</p>
                  </td><td>
                    <p>Share unmanage started.</p>
                  </td></tr><tr><td>
                    <p>unmanage_error</p>
                  </td><td>
                    <p>Share cannot be unmanaged.</p>
                  </td></tr><tr><td>
                    <p>unmanaged</p>
                  </td><td>
                    <p>Share was unmanaged.</p>
                  </td></tr><tr><td>
                    <p>extending</p>
                  </td><td>
                    <p>The extend, or increase, share size
request was issued successfully.</p>
                  </td></tr><tr><td>
                    <p>extending_error</p>
                  </td><td>
                    <p>Extend share failed.</p>
                  </td></tr><tr><td>
                    <p>shrinking</p>
                  </td><td>
                    <p>Share is being shrunk.</p>
                  </td></tr><tr><td>
                    <p>shrinking_error</p>
                  </td><td>
                    <p>Failed to update quota on share
shrinking.</p>
                  </td></tr><tr><td>
                    <p>shrinking_possible_data_loss_error</p>
                  </td><td>
                    <p>Shrink share failed due to possible data
loss.</p>
                  </td></tr><tr><td>
                    <p>migrating</p>
                  </td><td>
                    <p>Share migration is in progress.</p>
                  </td></tr></tbody></table></div></div><div class="sect3 " id="id-1.4.10.7.7.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share metadata</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.7.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you want to set the metadata key-value pairs on the share, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila metadata Share2 set project=my_abc deadline=01/20/16</pre></div><p>Get all metadata key-value pairs of the share:</p><div class="verbatim-wrap"><pre class="screen">$ manila metadata-show Share2
+----------+----------+
| Property | Value    |
+----------+----------+
| aim      | testing  |
| project  | my_abc   |
| deadline | 01/20/16 |
+----------+----------+</pre></div><p>You can update the metadata:</p><div class="verbatim-wrap"><pre class="screen">$ manila metadata-update-all Share2 deadline=01/30/16
+----------+----------+
| Property | Value    |
+----------+----------+
| deadline | 01/30/16 |
+----------+----------+</pre></div><p>You also can unset the metadata using
<span class="bold"><strong>manila metadata &lt;share_name&gt; unset &lt;metadata_key(s)&gt;</strong></span>.</p></div><div class="sect3 " id="id-1.4.10.7.7.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Reset share state</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.7.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As administrator, you can reset the state of a share.</p><p>Use <span class="bold"><strong>manila reset-state [--state &lt;state&gt;] &lt;share&gt;</strong></span> command to reset share
state, where <code class="literal">state</code> indicates which state to assign the share. Options
include <code class="literal">available</code>, <code class="literal">error</code>, <code class="literal">creating</code>, <code class="literal">deleting</code>,
<code class="literal">error_deleting</code> states.</p><div class="verbatim-wrap"><pre class="screen">$ manila reset-state Share2 --state deleting

$ manila show Share2
+----------------------+----------------------------------------------------------------------+
| Property             | Value                                                                |
+----------------------+----------------------------------------------------------------------+
| status               | deleting                                                             |
| share_type_name      | default                                                              |
| description          | My second share. Updated                                             |
| availability_zone    | nova                                                                 |
| share_network_id     | c895fe26-92be-4152-9e6c-f2ad230efb13                                 |
| export_locations     |                                                                      |
|                      | path = 10.254.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965 |
|                      | preferred = False                                                    |
|                      | is_admin_only = False                                                |
|                      | id = de6d4012-6158-46f0-8b28-4167baca51a7                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
|                      | path = 10.0.0.3:/shares/share-fe874928-39a2-441b-8d24-29e6f0fde965   |
|                      | preferred = False                                                    |
|                      | is_admin_only = True                                                 |
|                      | id = 602d0f5c-921b-4e45-bfdb-5eec8a89165a                            |
|                      | share_instance_id = fe874928-39a2-441b-8d24-29e6f0fde965             |
| share_server_id      | 2e9d2d02-883f-47b5-bb98-e053b8d1e683                                 |
| host                 | manila@london#LONDON                                                 |
| access_rules_status  | active                                                               |
| snapshot_id          | None                                                                 |
| is_public            | False                                                                |
| task_state           | None                                                                 |
| snapshot_support     | True                                                                 |
| id                   | 195e3ba2-9342-446a-bc93-a584551de0ac                                 |
| size                 | 1                                                                    |
| name                 | Share2                                                               |
| share_type           | bf6ada49-990a-47c3-88bc-c0cb31d5c9bf                                 |
| has_replicas         | False                                                                |
| replication_type     | None                                                                 |
| created_at           | 2016-03-25T12:13:40.000000                                           |
| share_proto          | NFS                                                                  |
| consistency_group_id | None                                                                 |
| project_id           | 907004508ef4447397ce6741a8f037c1                                     |
| metadata             | {u'deadline': u'01/30/16'}                                           |
+----------------------+----------------------------------------------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.10.7.7.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete and force-delete share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.7.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You also can force-delete a share.
The shares cannot be deleted in transitional states. The transitional
states are <code class="literal">creating</code>, <code class="literal">deleting</code>, <code class="literal">managing</code>, <code class="literal">unmanaging</code>,
<code class="literal">migrating</code>, <code class="literal">extending</code>, and <code class="literal">shrinking</code> statuses for the shares.
Force-deletion deletes an object in any state. Use the <code class="literal">policy.json</code> file
to grant permissions for this action to other roles.</p><div id="id-1.4.10.7.7.8.3" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>The configuration file <code class="literal">policy.json</code> may be used from different places.
The path <code class="literal">/etc/manila/policy.json</code> is one of expected paths by default.</p></div><p>Use <span class="bold"><strong>manila delete &lt;share_name_or_ID&gt;</strong></span> command to delete a specified share:</p><div class="verbatim-wrap"><pre class="screen">$ manila delete %share_name_or_id%</pre></div><div id="id-1.4.10.7.7.8.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you specified <a class="xref" href="#shared-file-systems-cgroups" title="8.8. Consistency groups">Section 8.8, “Consistency groups”</a>
while creating a share, you should provide the <code class="literal">--consistency-group</code>
parameter to delete the share:</p></div><div class="verbatim-wrap"><pre class="screen">$ manila delete %share_name_or_id% --consistency-group %consistency-group-id%</pre></div><p>If you try to delete the share in one of the transitional
state using soft-deletion you'll get an error:</p><div class="verbatim-wrap"><pre class="screen">$ manila delete Share2
Delete for share 195e3ba2-9342-446a-bc93-a584551de0ac failed: Invalid share: Share status must be one of ('available', 'error', 'inactive'). (HTTP 403) (Request-ID: req-9a77b9a0-17d2-4d97-8a7a-b7e23c27f1fe)
ERROR: Unable to delete any of the specified shares.</pre></div><p>A share cannot be deleted in a transitional status, that it why an error from
<code class="literal">python-manilaclient</code> appeared.</p><p>Print the list of all shares for all projects:</p><div class="verbatim-wrap"><pre class="screen">$ manila list --all-tenants
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| ID                                   | Name    | Size | Share Proto | Status    | Is Public | Share Type Name | Host                 | Availability Zone |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 | Share1  | 1    | NFS         | available | False     | my_type         | manila@paris#epsilon | nova              |
| 195e3ba2-9342-446a-bc93-a584551de0ac | Share2  | 1    | NFS         | available | False     | default         | manila@london#LONDON | nova              |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+</pre></div><p>Force-delete Share2 and check that it is absent in the list of shares,
run:</p><div class="verbatim-wrap"><pre class="screen">$ manila force-delete Share2

$ manila list
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| ID                                   | Name    | Size | Share Proto | Status    | Is Public | Share Type Name | Host                 | Availability Zone |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+
| 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 | Share1  | 1    | NFS         | available | False     | my_type         | manila@paris#epsilon | nova              |
+--------------------------------------+---------+------+-------------+-----------+-----------+-----------------+----------------------+-------------------+</pre></div></div><div class="sect3 " id="access-to-share"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.1.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage access to share</span> <a title="Permalink" class="permalink" href="#access-to-share">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>access-to-share</li></ul></div></div></div></div><p>The Shared File Systems service allows to grant or deny access to a specified
share, and list the permissions for a specified share.</p><p>To grant or deny access to a share, specify one of these supported share
access levels:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>rw</strong></span>. Read and write (RW) access. This is the default value.</p></li><li class="listitem "><p><span class="bold"><strong>ro</strong></span>. Read-only (RO) access.</p></li></ul></div><p>You must also specify one of these supported authentication methods:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>ip</strong></span>. Authenticates an instance through its IP address. A valid
format is <code class="literal">XX.XX.XX.XX</code> or <code class="literal">XX.XX.XX.XX/XX</code>. For example <code class="literal">0.0.0.0/0</code>.</p></li><li class="listitem "><p><span class="bold"><strong>user</strong></span>. Authenticates by a specified user or group name. A valid value is
an alphanumeric string that can contain some special characters and is from
4 to 32 characters long.</p></li><li class="listitem "><p><span class="bold"><strong>cert</strong></span>. Authenticates an instance through a TLS certificate. Specify the
TLS identity as the IDENTKEY. A valid value is any string up to 64 characters
long in the common name (CN) of the certificate. The meaning of a string
depends on its interpretation.</p></li><li class="listitem "><p><span class="bold"><strong>cephx</strong></span>. Ceph authentication system. Specify the Ceph auth ID that needs
to be authenticated and authorized for share access by the Ceph back end. A
valid value must be non-empty, consist of ASCII printable characters, and not
contain periods.</p></li></ul></div><p>Try to mount NFS share with export path
<code class="literal">10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9</code> on the
node with IP address <code class="literal">10.0.0.13</code>:</p><div class="verbatim-wrap"><pre class="screen">$ sudo mount -v -t nfs 10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9 /mnt/
mount.nfs: timeout set for Tue Oct  6 10:37:23 2015
mount.nfs: trying text-based options 'vers=4,addr=10.0.0.4,clientaddr=10.0.0.13'
mount.nfs: mount(2): Permission denied
mount.nfs: access denied by server while mounting 10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9</pre></div><p>An error message "Permission denied" appeared, so you are not allowed to mount
a share without an access rule. Allow access to the share with <code class="literal">ip</code> access
type and <code class="literal">10.0.0.13</code> IP address:</p><div class="verbatim-wrap"><pre class="screen">$ manila access-allow Share1 ip 10.0.0.13 --access-level rw
+--------------+--------------------------------------+
| Property     | Value                                |
+--------------+--------------------------------------+
| share_id     | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 |
| access_type  | ip                                   |
| access_to    | 10.0.0.13                            |
| access_level | rw                                   |
| state        | new                                  |
| id           | de715226-da00-4cfc-b1ab-c11f3393745e |
+--------------+--------------------------------------+</pre></div><p>Try to mount a share again. This time it is mounted successfully:</p><div class="verbatim-wrap"><pre class="screen">$ sudo mount -v -t nfs 10.0.0.4:/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9 /mnt/</pre></div><p>Since it is allowed node on 10.0.0.13 read and write access, try to create
a file on a mounted share:</p><div class="verbatim-wrap"><pre class="screen">$ cd /mnt
$ ls
lost+found
$ touch my_file.txt</pre></div><p>Connect via SSH to the <code class="literal">10.0.0.4</code> node and check new file <code class="literal">my_file.txt</code>
in the <code class="literal">/shares/manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9</code> directory:</p><div class="verbatim-wrap"><pre class="screen">$ ssh 10.0.0.4
$ cd /shares
$ ls
manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9
$ cd manila_share_a5fb1ab7_0bbd_465b_ac14_05706294b6e9
$ ls
lost+found  my_file.txt</pre></div><p>You have successfully created a file from instance that was given access by
its IP address.</p><p>Allow access to the share with <code class="literal">user</code> access type:</p><div class="verbatim-wrap"><pre class="screen">$ manila access-allow Share1 user demo --access-level rw
+--------------+--------------------------------------+
| Property     | Value                                |
+--------------+--------------------------------------+
| share_id     | 10f5a2a1-36f5-45aa-a8e6-00e94e592e88 |
| access_type  | user                                 |
| access_to    | demo                                 |
| access_level | rw                                   |
| state        | new                                  |
| id           | 4f391c6b-fb4f-47f5-8b4b-88c5ec9d568a |
+--------------+--------------------------------------+</pre></div><div id="id-1.4.10.7.7.9.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Different share features are supported by different share drivers.
For the example, the Generic driver with the Block Storage service as a
back-end doesn't support <code class="literal">user</code> and <code class="literal">cert</code> authentications methods. For
details of supporting of features by different drivers, see <a class="link" href="http://docs.openstack.org/developer/manila/devref/share_back_ends_feature_support_mapping.html" target="_blank">Manila share
features support mapping</a>.</p></div><p>To verify that the access rules (ACL) were configured correctly for a share,
you list permissions for a share:</p><div class="verbatim-wrap"><pre class="screen">$ manila access-list Share1
+--------------------------------------+-------------+------------+--------------+--------+
| id                                   | access type | access to  | access level | state  |
+--------------------------------------+-------------+------------+--------------+--------+
| 4f391c6b-fb4f-47f5-8b4b-88c5ec9d568a | user        | demo       | rw           | error  |
| de715226-da00-4cfc-b1ab-c11f3393745e | ip          | 10.0.0.13  | rw           | active |
+--------------------------------------+-------------+------------+--------------+--------+</pre></div><p>Deny access to the share and check that deleted access rule is absent in the
access rule list:</p><div class="verbatim-wrap"><pre class="screen">$ manila access-deny Share1 de715226-da00-4cfc-b1ab-c11f3393745e

$ manila access-list Share1
+--------------------------------------+-------------+-----------+--------------+-------+
| id                                   | access type | access to | access level | state |
+--------------------------------------+-------------+-----------+--------------+-------+
| 4f391c6b-fb4f-47f5-8b4b-88c5ec9d568a | user        | demo      | rw           | error |
+--------------------------------------+-------------+-----------+--------------+-------+</pre></div></div></div><div class="sect2 " id="id-1.4.10.7.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage and unmanage share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To <code class="literal">manage</code> a share means that an administrator, rather than a share
driver, manages the storage lifecycle. This approach is appropriate when an
administrator already has the custom non-manila share with its size, shared
file system protocol, and export path, and an administrator wants to
register it in the Shared File System service.</p><p>To <code class="literal">unmanage</code> a share means to unregister a specified share from the Shared
File Systems service. Administrators can revert an unmanaged share to managed
status if needed.</p><div class="sect3 " id="id-1.4.10.7.8.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Unmanage a share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.8.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">unmanage</code> operation is not supported for shares that were
created on top of share servers and created with share networks.
The Share service should have the
option <code class="literal">driver_handles_share_servers = False</code>
set in the <code class="literal">manila.conf</code> file. You can unmanage a share that has
no dependent snapshots.</p><p>To unmanage managed share, run the <code class="command">manila unmanage &lt;share&gt;</code>
command. Then try to print the information about the share. The
returned result should indicate that Shared File Systems service won't
find the share:</p><div class="verbatim-wrap"><pre class="screen">$ manila unmanage share_for_docs
$ manila show share_for_docs
ERROR: No share with a name or ID of 'share_for_docs' exists.</pre></div></div><div class="sect3 " id="id-1.4.10.7.8.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage a share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.8.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To register the non-managed share in the File System service, run the
<code class="command">manila manage</code> command:</p><div class="verbatim-wrap"><pre class="screen">manila manage [--name &lt;name&gt;] [--description &lt;description&gt;]
              [--share_type &lt;share-type&gt;]
              [--driver_options [&lt;key=value&gt; [&lt;key=value&gt; ...]]]
              &lt;service_host&gt; &lt;protocol&gt; &lt;export_path&gt;</pre></div><p>The positional arguments are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>service_host. The manage-share service host in
<code class="literal">host@backend#POOL</code> format, which consists of the host name for
the back end, the name of the back end, and the pool name for the
back end.</p></li><li class="listitem "><p>protocol. The Shared File Systems protocol of the share to manage. Valid
values are NFS, CIFS, GlusterFS, or HDFS.</p></li><li class="listitem "><p>export_path. The share export path in the format appropriate for the
protocol:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>NFS protocol. 10.0.0.1:/foo_path.</p></li><li class="listitem "><p>CIFS protocol. \\10.0.0.1\foo_name_of_cifs_share.</p></li><li class="listitem "><p>HDFS protocol. hdfs://10.0.0.1:foo_port/foo_share_name.</p></li><li class="listitem "><p>GlusterFS. 10.0.0.1:/foo_volume.</p></li></ul></div></li></ul></div><p>The <code class="literal">driver_options</code> is an optional set of one or more key and value pairs
that describe driver options. Note that the share type must have the
<code class="literal">driver_handles_share_servers = False</code> option. As a result, a special share
type named <code class="literal">for_managing</code> was used in example.</p><p>To manage share, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila manage \
    manila@paris#shares \
    nfs \
    1.0.0.4:/shares/manila_share_6d2142d8_2b9b_4405_867f_8a48094c893f \
    --name share_for_docs \
    --description "We manage share." \
    --share_type for_managing
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | manage_starting                      |
| share_type_name             | for_managing                         |
| description                 | We manage share.                     |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| share_server_id             | None                                 |
| host                        | manila@paris#shares                  |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | ddfb1240-ed5e-4071-a031-b842035a834a |
| size                        | None                                 |
| name                        | share_for_docs                       |
| share_type                  | 14ee8575-aac2-44af-8392-d9c9d344f392 |
| has_replicas                | False                                |
| replication_type            | None                                 |
| created_at                  | 2016-03-25T15:22:43.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 907004508ef4447397ce6741a8f037c1     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</pre></div><p>Check that the share is available:</p><div class="verbatim-wrap"><pre class="screen">$ manila show share_for_docs
+----------------------+--------------------------------------------------------------------------+
| Property             | Value                                                                    |
+----------------------+--------------------------------------------------------------------------+
| status               | available                                                                |
| share_type_name      | for_managing                                                             |
| description          | We manage share.                                                         |
| availability_zone    | None                                                                     |
| share_network_id     | None                                                                     |
| export_locations     |                                                                          |
|                      | path = 1.0.0.4:/shares/manila_share_6d2142d8_2b9b_4405_867f_8a48094c893f |
|                      | preferred = False                                                        |
|                      | is_admin_only = False                                                    |
|                      | id = d4d048bf-4159-4a94-8027-e567192b8d30                                |
|                      | share_instance_id = 4c8e3887-4f9a-4775-bab4-e5840a09c34e                 |
|                      | path = 2.0.0.3:/shares/manila_share_6d2142d8_2b9b_4405_867f_8a48094c893f |
|                      | preferred = False                                                        |
|                      | is_admin_only = True                                                     |
|                      | id = 1dd4f0a3-778d-486a-a851-b522f6e7cf5f                                |
|                      | share_instance_id = 4c8e3887-4f9a-4775-bab4-e5840a09c34e                 |
| share_server_id      | None                                                                     |
| host                 | manila@paris#shares                                                      |
| access_rules_status  | active                                                                   |
| snapshot_id          | None                                                                     |
| is_public            | False                                                                    |
| task_state           | None                                                                     |
| snapshot_support     | True                                                                     |
| id                   | ddfb1240-ed5e-4071-a031-b842035a834a                                     |
| size                 | 1                                                                        |
| name                 | share_for_docs                                                           |
| share_type           | 14ee8575-aac2-44af-8392-d9c9d344f392                                     |
| has_replicas         | False                                                                    |
| replication_type     | None                                                                     |
| created_at           | 2016-03-25T15:22:43.000000                                               |
| share_proto          | NFS                                                                      |
| consistency_group_id | None                                                                     |
| project_id           | 907004508ef4447397ce6741a8f037c1                                         |
| metadata             | {}                                                                       |
+----------------------+--------------------------------------------------------------------------+</pre></div></div></div><div class="sect2 " id="id-1.4.10.7.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage and unmanage share snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To <code class="literal">manage</code> a share snapshot means that an administrator, rather than a
share driver, manages the storage lifecycle. This approach is appropriate
when an administrator manages share snapshots outside of the Shared File
Systems service and wants to register it with the service.</p><p>To <code class="literal">unmanage</code> a share snapshot means to unregister a specified share
snapshot from the Shared File Systems service. Administrators can revert an
unmanaged share snapshot to managed status if needed.</p><div class="sect3 " id="id-1.4.10.7.9.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Unmanage a share snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.9.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">unmanage</code> operation is not supported for shares that were
created on top of share servers and created with share networks.
The Share service should have the option
<code class="literal">driver_handles_share_servers = False</code> set in the <code class="literal">manila.conf</code> file.</p><p>To unmanage managed share snapshot, run the :command:
<code class="literal">manila snapshot-unmanage &lt;share_snapshot&gt;</code> command. Then try to print the
information about the share snapshot. The returned result should indicate that
Shared File Systems service won't find the share snapshot:</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-unmanage my_test_share_snapshot
$ manila snapshot-show my_test_share_snapshot
ERROR: No sharesnapshot with a name or ID of 'my_test_share_snapshot'
exists.</pre></div></div><div class="sect3 " id="id-1.4.10.7.9.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage a share snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.9.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To register the non-managed share snapshot in the File System service, run the
<code class="command">manila snapshot-manage</code> command:</p><div class="verbatim-wrap"><pre class="screen">manila snapshot-manage [--name &lt;name&gt;] [--description &lt;description&gt;]
              [--driver_options [&lt;key=value&gt; [&lt;key=value&gt; ...]]]
              &lt;share&gt; &lt;provider_location&gt;</pre></div><p>The positional arguments are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>share. Name or ID of the share.</p></li><li class="listitem "><p>provider_location. Provider location of the share snapshot on the backend.</p></li></ul></div><p>The <code class="literal">driver_options</code> is an optional set of one or more key and value pairs
that describe driver options.</p><p>To manage share snapshot, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-manage \
    9ba52cc6-c97e-4b40-8653-4bcbaaf9628d \
    4d1e2863-33dd-4243-bf39-f7354752097d \
    --name my_test_share_snapshot \
    --description "My test share snapshot" \
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | manage_starting                      |
| share_id          | 9ba52cc6-c97e-4b40-8653-4bcbaaf9628d |
| user_id           | d9f4003655c94db5b16c591920be1f91     |
| description       | My test share snapshot               |
| created_at        | 2016-07-25T04:49:42.600980           |
| size              | None                                 |
| share_proto       | NFS                                  |
| provider_location | 4d1e2863-33dd-4243-bf39-f7354752097d |
| id                | 89c663b5-026d-45c7-a43b-56ef0ba0faab |
| project_id        | aaa33a0ca4324965a3e65ae47e864e94     |
| share_size        | 1                                    |
| name              | my_test_share_snapshot               |
+-------------------+--------------------------------------+</pre></div><p>Check that the share snapshot is available:</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-show my_test_share_snapshot
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | available                            |
| share_id          | 9ba52cc6-c97e-4b40-8653-4bcbaaf9628d |
| user_id           | d9f4003655c94db5b16c591920be1f91     |
| description       | My test share snapshot               |
| created_at        | 2016-07-25T04:49:42.000000           |
| size              | 1                                    |
| share_proto       | NFS                                  |
| provider_location | 4d1e2863-33dd-4243-bf39-f7354752097d |
| id                | 89c663b5-026d-45c7-a43b-56ef0ba0faab |
| project_id        | aaa33a0ca4324965a3e65ae47e864e94     |
| share_size        | 1                                    |
| name              | my_test_share_snapshot               |
+-------------------+--------------------------------------+</pre></div></div></div><div class="sect2 " id="id-1.4.10.7.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Resize share</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To change file share size, use the <code class="command">manila extend</code> command and
the <code class="command">manila shrink</code> command. For most drivers it is safe
operation. If you want to be sure that your data is safe, you can make
a share back up by creating a snapshot of it.</p><p>You can extend and shrink the share with the <code class="command">manila extend</code> and
<code class="command">manila shrink</code> commands respectively, and specify the share
with the new size that does not exceed the quota. For details, see
<a class="xref" href="#shared-file-systems-quotas" title="8.3.5. Quotas and limits">Section 8.3.5, “Quotas and limits”</a>. You also cannot shrink
share size to 0 or to a greater value than the current share size.</p><p>While extending, the share has an <code class="literal">extending</code> status. This means that
the increase share size request was issued successfully.</p><p>To extend the share and check the result, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila extend docs_resize 2
$ manila show docs_resize
+----------------------+--------------------------------------------------------------------------+
| Property             | Value                                                                    |
+----------------------+--------------------------------------------------------------------------+
| status               | available                                                                |
| share_type_name      | my_type                                                                  |
| description          | None                                                                     |
| availability_zone    | nova                                                                     |
| share_network_id     | None                                                                     |
| export_locations     |                                                                          |
|                      | path = 1.0.0.4:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = False                                                    |
|                      | id = 3ffb76f4-92b9-4639-83fd-025bc3e302ff                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
|                      | path = 2.0.0.3:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = True                                                     |
|                      | id = 1f0e263f-370d-47d3-95f6-1be64088b9da                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
| share_server_id      | None                                                                     |
| host                 | manila@paris#shares                                                      |
| access_rules_status  | active                                                                   |
| snapshot_id          | None                                                                     |
| is_public            | False                                                                    |
| task_state           | None                                                                     |
| snapshot_support     | True                                                                     |
| id                   | b07dbebe-a328-403c-b402-c8871c89e3d1                                     |
| size                 | 2                                                                        |
| name                 | docs_resize                                                              |
| share_type           | 14ee8575-aac2-44af-8392-d9c9d344f392                                     |
| has_replicas         | False                                                                    |
| replication_type     | None                                                                     |
| created_at           | 2016-03-25T15:33:18.000000                                               |
| share_proto          | NFS                                                                      |
| consistency_group_id | None                                                                     |
| project_id           | 907004508ef4447397ce6741a8f037c1                                         |
| metadata             | {}                                                                       |
+----------------------+--------------------------------------------------------------------------+</pre></div><p>While shrinking, the share has a <code class="literal">shrinking</code> status. This means that the
decrease share size request was issued successfully. To shrink the share and
check the result, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila shrink docs_resize 1
$ manila show docs_resize
+----------------------+--------------------------------------------------------------------------+
| Property             | Value                                                                    |
+----------------------+--------------------------------------------------------------------------+
| status               | available                                                                |
| share_type_name      | my_type                                                                  |
| description          | None                                                                     |
| availability_zone    | nova                                                                     |
| share_network_id     | None                                                                     |
| export_locations     |                                                                          |
|                      | path = 1.0.0.4:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = False                                                    |
|                      | id = 3ffb76f4-92b9-4639-83fd-025bc3e302ff                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
|                      | path = 2.0.0.3:/shares/manila_share_b8afc508_8487_442b_b170_ea65b07074a8 |
|                      | preferred = False                                                        |
|                      | is_admin_only = True                                                     |
|                      | id = 1f0e263f-370d-47d3-95f6-1be64088b9da                                |
|                      | share_instance_id = b8afc508-8487-442b-b170-ea65b07074a8                 |
| share_server_id      | None                                                                     |
| host                 | manila@paris#shares                                                      |
| access_rules_status  | active                                                                   |
| snapshot_id          | None                                                                     |
| is_public            | False                                                                    |
| task_state           | None                                                                     |
| snapshot_support     | True                                                                     |
| id                   | b07dbebe-a328-403c-b402-c8871c89e3d1                                     |
| size                 | 1                                                                        |
| name                 | docs_resize                                                              |
| share_type           | 14ee8575-aac2-44af-8392-d9c9d344f392                                     |
| has_replicas         | False                                                                    |
| replication_type     | None                                                                     |
| created_at           | 2016-03-25T15:33:18.000000                                               |
| share_proto          | NFS                                                                      |
| consistency_group_id | None                                                                     |
| project_id           | 907004508ef4447397ce6741a8f037c1                                         |
| metadata             | {}                                                                       |
+----------------------+--------------------------------------------------------------------------+</pre></div></div><div class="sect2 " id="shared-file-systems-quotas"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Quotas and limits</span> <a title="Permalink" class="permalink" href="#shared-file-systems-quotas">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-quotas</li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.7.11.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Limits</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.11.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Limits are the resource limitations that are allowed for each project.
An administrator can configure limits in the <code class="literal">manila.conf</code> file.</p><p>Users can query their rate and absolute limits.</p><p>To see the absolute limits, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila absolute-limits
+----------------------------+-------+
| Name                       | Value |
+----------------------------+-------+
| maxTotalShareGigabytes     | 1000  |
| maxTotalShareNetworks      | 10    |
| maxTotalShareSnapshots     | 50    |
| maxTotalShares             | 50    |
| maxTotalSnapshotGigabytes  | 1000  |
| totalShareGigabytesUsed    | 1     |
| totalShareNetworksUsed     | 2     |
| totalShareSnapshotsUsed    | 1     |
| totalSharesUsed            | 1     |
| totalSnapshotGigabytesUsed | 1     |
+----------------------------+-------+</pre></div><p>Rate limits control the frequency at which users can issue specific API
requests. Administrators use rate limiting to configure limits on the type and
number of API calls that can be made in a specific time interval. For example,
a rate limit can control the number of <code class="literal">GET</code> requests processed
during a one-minute period.</p><p>To set the API rate limits, modify the
<code class="literal">etc/manila/api-paste.ini</code> file, which is a part of the WSGI pipeline and
defines the actual limits. You need to restart <code class="literal">manila-api</code> service after
you edit the <code class="literal">etc/manila/api-paste.ini</code> file.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[filter:ratelimit]
paste.filter_factory = manila.api.v1.limits:RateLimitingMiddleware.factory
limits = (POST, "*/shares", ^/shares, 120, MINUTE);(PUT, "*/shares", .*, 120, MINUTE);(DELETE, "*", .*, 120, MINUTE)</pre></div><p>Also, add the <code class="literal">ratelimit</code> to <code class="literal">noauth</code>, <code class="literal">keystone</code>, <code class="literal">keystone_nolimit</code>
parameters in the <code class="literal">[composite:openstack_share_api]</code> and
<code class="literal">[composite:openstack_share_api_v2]</code> groups.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[composite:openstack_share_api]
use = call:manila.api.middleware.auth:pipeline_factory
noauth = cors faultwrap ssl ratelimit sizelimit noauth api
keystone = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext api
keystone_nolimit = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext api

[composite:openstack_share_api_v2]
use = call:manila.api.middleware.auth:pipeline_factory
noauth = cors faultwrap ssl ratelimit sizelimit noauth apiv2
keystone = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext apiv2
keystone_nolimit = cors faultwrap ssl ratelimit sizelimit authtoken keystonecontext apiv2</pre></div><p>To see the rate limits, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila rate-limits
+--------+------------+-------+--------+--------+----------------------+
| Verb   | URI        | Value | Remain | Unit   | Next_Available       |
+--------+------------+-------+--------+--------+----------------------+
| DELETE | "*"        | 120   | 120    | MINUTE | 2015-10-20T15:17:20Z |
| POST   | "*/shares" | 120   | 120    | MINUTE | 2015-10-20T15:17:20Z |
| PUT    | "*/shares" | 120   | 120    | MINUTE | 2015-10-20T15:17:20Z |
+--------+------------+-------+--------+--------+----------------------+</pre></div></div><div class="sect3 " id="id-1.4.10.7.11.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.3.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.10.7.11.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Quota sets provide quota management support.</p><p>To list the quotas for a project or user, use the <code class="command">manila quota-show</code>
command. If you specify the optional <code class="literal">--user</code> parameter, you get the
quotas for this user in the specified project. If you omit this parameter,
you get the quotas for the specified project.</p><div id="id-1.4.10.7.11.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The Shared File Systems service does not perform mapping of usernames and
project names to IDs. Provide only ID values to get correct setup
of quotas. Setting it by names you set quota for nonexistent project/user.
In case quota is not set explicitly by project/user ID,
The Shared File Systems service just applies default quotas.</p></div><div class="verbatim-wrap"><pre class="screen">$ manila quota-show --tenant %project_id% --user %user_id%
+--------------------+-------+
| Property           | Value |
+--------------------+-------+
| gigabytes          | 1000  |
| snapshot_gigabytes | 1000  |
| snapshots          | 50    |
| shares             | 50    |
| share_networks     | 10    |
+--------------------+-------+</pre></div><p>There are default quotas for a project that are set from the
<code class="literal">manila.conf</code> file. To list the default quotas for a project, use
the <code class="command">manila quota-defaults</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ manila quota-defaults --tenant %project_id%
+--------------------+-------+
| Property           | Value |
+--------------------+-------+
| gigabytes          | 1000  |
| snapshot_gigabytes | 1000  |
| snapshots          | 50    |
| shares             | 50    |
| share_networks     | 10    |
+--------------------+-------+</pre></div><p>The administrator can update the quotas for a specific project, or for a
specific user by providing both the <code class="literal">--tenant</code> and <code class="literal">--user</code> optional
arguments. It is possible to update the <code class="literal">shares</code>, <code class="literal">snapshots</code>,
<code class="literal">gigabytes</code>, <code class="literal">snapshot-gigabytes</code>, and <code class="literal">share-networks</code> quotas.</p><div class="verbatim-wrap"><pre class="screen">$ manila quota-update %project_id% --user %user_id% --shares 49 --snapshots 49</pre></div><p>As administrator, you can also permit or deny the force-update of a quota that
is already used, or if the requested value exceeds the configured quota limit.
To force-update a quota, use <code class="literal">force</code> optional key.</p><div class="verbatim-wrap"><pre class="screen">$ manila quota-update %project_id% --shares 51 --snapshots 51 --force</pre></div><p>To revert quotas to default for a project or for a user, delete quotas:</p><div class="verbatim-wrap"><pre class="screen">$ manila quota-delete --tenant %project_id% --user %user_id%</pre></div></div></div></div><div class="sect1 " id="id-1.4.10.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate shares</span> <a title="Permalink" class="permalink" href="#id-1.4.10.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrator, you can migrate a share with its data from one
location to another in a manner that is transparent to users and
workloads. You can use <code class="literal">manila</code> client commands to complete a share
migration.</p><p>Possible use cases for data migration include:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Bring down a physical storage device for maintenance without
disrupting workloads.</p></li><li class="listitem "><p>Modify the properties of a share.</p></li><li class="listitem "><p>Free up space in a thinly-provisioned back end.</p></li></ul></div><p>Migrate a share with the <code class="command">manila migrate</code> command, as shown in the
following example:</p><div class="verbatim-wrap"><pre class="screen">$ manila migrate shareID destinationHost --force-host-copy True|False</pre></div><p>In this example, <code class="literal">--force-host-copy True</code> forces the generic
host-based migration mechanism and bypasses any driver optimizations.
<code class="literal">destinationHost</code> is in this format <code class="literal">host#pool</code> which includes
destination host and pool.</p><div id="id-1.4.10.8.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If the user is not an administrator, the migration fails.</p></div></div><div class="sect1 " id="shared-file-systems-share-types"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share types</span> <a title="Permalink" class="permalink" href="#shared-file-systems-share-types">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-share-types</li></ul></div></div></div></div><p>A share type enables you to filter or choose back ends before you create a
share and to set data for the share driver. A share type behaves in the same
way as a Block Storage volume type behaves.</p><p>In the Shared File Systems configuration file <code class="literal">manila.conf</code>, the
administrator can set the share type used by default for the share creation
and then create a default share type.</p><p>To create a share type, use <code class="command">manila type-create</code> command as:</p><div class="verbatim-wrap"><pre class="screen">manila type-create [--snapshot_support &lt;snapshot_support&gt;]
                   [--is_public &lt;is_public&gt;]
                   &lt;name&gt; &lt;spec_driver_handles_share_servers&gt;</pre></div><p>where the <code class="literal">name</code> is the share type name, <code class="literal">--is_public</code> defines the level of
the visibility for the share type, <code class="literal">snapshot_support</code> and
<code class="literal">spec_driver_handles_share_servers</code> are the extra specifications used to
filter back ends. Administrators can create share types with these extra
specifications for the back ends filtering:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">driver_handles_share_servers</code>. Required. Defines the driver mode for share
server lifecycle management. Valid values are <code class="literal">true</code>/<code class="literal">1</code> and
<code class="literal">false</code>/<code class="literal">0</code>.
Set to True when the share driver can manage, or handle, the share server
lifecycle.
Set to False when an administrator, rather than a share driver, manages
the bare metal storage with some net interface instead of the presence
of the share servers.</p></li><li class="listitem "><p><code class="literal">snapshot_support</code>. Filters back ends by whether they do or do not support
share snapshots. Default is <code class="literal">True</code>.
Set to True to find back ends that support share snapshots.
Set to False to find back ends that do not support share snapshots.</p></li></ul></div><div id="id-1.4.10.9.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The extra specifications set in the share types are operated in the
<a class="xref" href="#shared-file-systems-scheduling" title="8.10.1. Scheduling">Section 8.10.1, “Scheduling”</a>.</p></div><p>Administrators can also set additional extra specifications for a share type
for the following purposes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="emphasis"><em>Filter back ends</em></span>. Unqualified extra specifications written in
this format: <code class="literal">extra_spec=value</code>. For example, <span class="bold"><strong>netapp_raid_type=raid4</strong></span>.</p></li><li class="listitem "><p><span class="emphasis"><em>Set data for the driver</em></span>. Qualified extra specifications always written
with the prefix with a colon, except for the special <code class="literal">capabilities</code>
prefix, in this format: <code class="literal">vendor:extra_spec=value</code>. For example,
<span class="bold"><strong>netapp:thin_provisioned=true</strong></span>.</p></li></ul></div><p>The scheduler uses the special capabilities prefix for filtering. The scheduler
can only create a share on a back end that reports capabilities matching the
un-scoped extra-spec keys for the share type. For details, see <a class="link" href="http://docs.openstack.org/developer/manila/devref/capabilities_and_extra_specs.html" target="_blank">Capabilities
and Extra-Specs</a>.</p><p>Each driver implementation determines which extra specification keys it uses.
For details, see the documentation for the driver.</p><p>An administrator can use the <code class="literal">policy.json</code> file to grant permissions for
share type creation with extra specifications to other roles.</p><p>You set a share type to private or public and
<a class="xref" href="#share-type-access" title="8.5.2. Share type access">Section 8.5.2, “Share type access”</a> to the private share types. By
default a share type is created as publicly accessible. Set
<code class="literal">--is_public</code> to <code class="literal">False</code> to make the share type private.</p><div class="sect2 " id="id-1.4.10.9.15"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share type operations</span> <a title="Permalink" class="permalink" href="#id-1.4.10.9.15">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create a new share type you need to specify the name of the new share
type. You also require an extra spec <code class="literal">driver_handles_share_servers</code>.
The new share type can also be public.</p><div class="verbatim-wrap"><pre class="screen">$ manila type-create netapp1 False --is_public True

$ manila type-list
+-----+--------+-----------+-----------+-----------------------------------+-----------------------+
| ID  | Name   | Visibility| is_default| required_extra_specs              | optional_extra_specs  |
+-----+--------+-----------+-----------+-----------------------------------+-----------------------+
| c0..| netapp1| public    | -         | driver_handles_share_servers:False| snapshot_support:True |
+-----+--------+-----------+-----------+-----------------------------------+-----------------------+</pre></div><p>You can set or unset extra specifications for a share type
using <span class="bold"><strong>manila type-key &lt;share_type&gt; set &lt;key=value&gt;</strong></span> command. Since it is up
to each driver what extra specification keys it uses, see the documentation
for the specified driver.</p><div class="verbatim-wrap"><pre class="screen">$ manila type-key netapp1 set thin_provisioned=True</pre></div><p>It is also possible to view a list of current share types and extra
specifications:</p><div class="verbatim-wrap"><pre class="screen">$ manila extra-specs-list
+-------------+---------+-------------------------------------+
| ID          | Name    | all_extra_specs                     |
+-------------+---------+-------------------------------------+
| c0086582-...| netapp1 | snapshot_support : True             |
|             |         | thin_provisioned : True             |
|             |         | driver_handles_share_servers : True |
+-------------+---------+-------------------------------------+</pre></div><p>Use <code class="command">manila type-key &lt;share_type&gt; unset &lt;key&gt;</code> to unset an extra
specification.</p><p>The public or private share type can be deleted with the
<code class="command">manila type-delete &lt;share_type&gt;</code> command.</p></div><div class="sect2 " id="share-type-access"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share type access</span> <a title="Permalink" class="permalink" href="#share-type-access">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>share-type-access</li></ul></div></div></div></div><p>You can manage access to a private share type for different projects.
Administrators can provide access, remove access, and retrieve
information about access for a specified private share.</p><p>Create a private type:</p><div class="verbatim-wrap"><pre class="screen">$ manila type-create my_type1 True --is_public False
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| required_extra_specs | driver_handles_share_servers : True  |
| Name                 | my_type1                             |
| Visibility           | private                              |
| is_default           | -                                    |
| ID                   | 06793be5-9a79-4516-89fe-61188cad4d6c |
| optional_extra_specs | snapshot_support : True              |
+----------------------+--------------------------------------+</pre></div><div id="id-1.4.10.9.16.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you run <code class="command">manila type-list</code> only public share types appear.
To see private share types, run <code class="command">manila type-list</code> with
<code class="literal">--all</code> optional argument.</p></div><p>Grant access to created private type for a demo and alt_demo projects
by providing their IDs:</p><div class="verbatim-wrap"><pre class="screen">$ manila type-access-add my_type1 d8f9af6915404114ae4f30668a4f5ba7
$ manila type-access-add my_type1 e4970f57f1824faab2701db61ee7efdf</pre></div><p>To view information about access for a private share, type <code class="literal">my_type1</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila type-access-list my_type1
+----------------------------------+
| Project_ID                       |
+----------------------------------+
| d8f9af6915404114ae4f30668a4f5ba7 |
| e4970f57f1824faab2701db61ee7efdf |
+----------------------------------+</pre></div><p>After granting access to the share, the target project
can see the share type in the list, and create private
shares.</p><p>To deny access for a specified project, use
<code class="command">manila type-access-remove &lt;share_type&gt; &lt;project_id&gt;</code> command.</p></div></div><div class="sect1 " id="shared-file-systems-snapshots"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share snapshots</span> <a title="Permalink" class="permalink" href="#shared-file-systems-snapshots">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-snapshots</li></ul></div></div></div></div><p>The Shared File Systems service provides a snapshot mechanism to help users
restore data by running the <code class="command">manila snapshot-create</code> command.</p><p>To export a snapshot, create a share from it, then mount the new share
to an instance. Copy files from the attached share into the archive.</p><p>To import a snapshot, create a new share with appropriate size, attach it to
instance, and then copy a file from the archive to the attached file
system.</p><div id="id-1.4.10.10.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You cannot delete a share while it has saved dependent snapshots.</p></div><p>Create a snapshot from the share:</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-create Share1 --name Snapshot1 --description "Snapshot of Share1"
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | creating                             |
| share_id    | aca648eb-8c03-4394-a5cc-755066b7eb66 |
| name        | Snapshot1                            |
| created_at  | 2015-09-25T05:27:38.862040           |
| share_proto | NFS                                  |
| id          | 962e8126-35c3-47bb-8c00-f0ee37f42ddd |
| size        | 1                                    |
| share_size  | 1                                    |
| description | Snapshot of Share1                   |
+-------------+--------------------------------------+</pre></div><p>Update snapshot name or description if needed:</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-rename Snapshot1 Snapshot_1 --description "Snapshot of Share1. Updated."</pre></div><p>Check that status of a snapshot is <code class="literal">available</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-show Snapshot1
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | available                            |
| share_id    | aca648eb-8c03-4394-a5cc-755066b7eb66 |
| name        | Snapshot1                            |
| created_at  | 2015-09-25T05:27:38.000000           |
| share_proto | NFS                                  |
| id          | 962e8126-35c3-47bb-8c00-f0ee37f42ddd |
| size        | 1                                    |
| share_size  | 1                                    |
| description | Snapshot of Share1                   |
+-------------+--------------------------------------+</pre></div><p>To restore your data from a snapshot, use <code class="command">manila create</code> with
key <code class="literal">--snapshot-id</code>. This creates a new share from an
existing snapshot. Create a share from a snapshot and check whether
it is available:</p><div class="verbatim-wrap"><pre class="screen">$ manila create nfs 1 --name Share2 --metadata source=snapshot --description "Share from a snapshot." --snapshot-id 962e8126-35c3-47bb-8c00-f0ee37f42ddd
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | None                                 |
| share_type_name             | default                              |
| description                 | Share from a snapshot.               |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| export_locations            | []                                   |
| share_server_id             | None                                 |
| host                        | None                                 |
| snapshot_id                 | 962e8126-35c3-47bb-8c00-f0ee37f42ddd |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | b6b0617c-ea51-4450-848e-e7cff69238c7 |
| size                        | 1                                    |
| name                        | Share2                               |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86 |
| created_at                  | 2015-09-25T06:25:50.240417           |
| export_location             | None                                 |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 20787a7ba11946adad976463b57d8a2f     |
| metadata                    | {u'source': u'snapshot'}             |
+-----------------------------+--------------------------------------+

$ manila show Share2
+-----------------------------+-------------------------------------------+
| Property                    | Value                                     |
+-----------------------------+-------------------------------------------+
| status                      | available                                 |
| share_type_name             | default                                   |
| description                 | Share from a snapshot.                    |
| availability_zone           | nova                                      |
| share_network_id            | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a      |
| export_locations            | 10.254.0.3:/shares/share-1dc2a471-3d47-...|
| share_server_id             | 41b7829d-7f6b-4c96-aea5-d106c2959961      |
| host                        | manila@generic1#GENERIC1                  |
| snapshot_id                 | 962e8126-35c3-47bb-8c00-f0ee37f42ddd      |
| is_public                   | False                                     |
| task_state                  | None                                      |
| snapshot_support            | True                                      |
| id                          | b6b0617c-ea51-4450-848e-e7cff69238c7      |
| size                        | 1                                         |
| name                        | Share2                                    |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86      |
| created_at                  | 2015-09-25T06:25:50.000000                |
| share_proto                 | NFS                                       |
| consistency_group_id        | None                                      |
| source_cgsnapshot_member_id | None                                      |
| project_id                  | 20787a7ba11946adad976463b57d8a2f          |
| metadata                    | {u'source': u'snapshot'}                  |
+-----------------------------+-------------------------------------------+</pre></div><p>You can soft-delete a snapshot using <code class="command">manila snapshot-delete
&lt;snapshot_name_or_ID&gt;</code>. If a snapshot is in busy state, and during
the delete an <code class="literal">error_deleting</code> status appeared, administrator can
force-delete it or explicitly reset the state.</p><p>Use <code class="command">snapshot-reset-state [--state &lt;state&gt;] &lt;snapshot&gt;</code> to update
the state of a snapshot explicitly. A valid value of a status are
<code class="literal">available</code>, <code class="literal">error</code>, <code class="literal">creating</code>, <code class="literal">deleting</code>, <code class="literal">error_deleting</code>.
If no state is provided, the <code class="literal">available</code> state will be used.</p><p>Use <code class="command">manila snapshot-force-delete &lt;snapshot&gt;</code> to force-delete
a specified share snapshot in any state.</p></div><div class="sect1 " id="shared-file-systems-security-services"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Security services</span> <a title="Permalink" class="permalink" href="#shared-file-systems-security-services">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-security-services</li></ul></div></div></div></div><p>A security service stores client configuration information used for
authentication and authorization (AuthN/AuthZ). For example, a share server
will be the client for an existing service such as LDAP, Kerberos, or
Microsoft Active Directory.</p><p>You can associate a share with one to three security service types:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">ldap</code>: LDAP.</p></li><li class="listitem "><p><code class="literal">kerberos</code>: Kerberos.</p></li><li class="listitem "><p><code class="literal">active_directory</code>: Microsoft Active Directory.</p></li></ul></div><p>You can configure a security service with these options:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A DNS IP address.</p></li><li class="listitem "><p>An IP address or host name.</p></li><li class="listitem "><p>A domain.</p></li><li class="listitem "><p>A user or group name.</p></li><li class="listitem "><p>The password for the user, if you specify a user name.</p></li></ul></div><p>You can add the security service to the
<a class="xref" href="#shared-file-systems-share-networks" title="8.11.1. Share networks">Section 8.11.1, “Share networks”</a>.</p><p>To create a security service, specify the security service type, a
description of a security service, DNS IP address used inside project's
network, security service IP address or host name, domain, security
service user or group used by project, and a password for the user. The
share name is optional.</p><p>Create a <code class="literal">ldap</code> security service:</p><div class="verbatim-wrap"><pre class="screen">$ manila security-service-create ldap --dns-ip 8.8.8.8 --server 10.254.0.3 --name my_ldap_security_service
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | new                                  |
| domain      | None                                 |
| password    | None                                 |
| name        | my_ldap_security_service             |
| dns_ip      | 8.8.8.8                              |
| created_at  | 2015-09-25T10:19:06.019527           |
| updated_at  | None                                 |
| server      | 10.254.0.3                           |
| user        | None                                 |
| project_id  | 20787a7ba11946adad976463b57d8a2f     |
| type        | ldap                                 |
| id          | 413479b2-0d20-4c58-a9d3-b129fa592d8e |
| description | None                                 |
+-------------+--------------------------------------+</pre></div><p>To create <code class="literal">kerberos</code> security service, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila security-service-create kerberos --server 10.254.0.3 --user demo --password secret --name my_kerberos_security_service --description "Kerberos security service"
+-------------+--------------------------------------+
| Property    | Value                                |
+-------------+--------------------------------------+
| status      | new                                  |
| domain      | None                                 |
| password    | secret                               |
| name        | my_kerberos_security_service         |
| dns_ip      | None                                 |
| created_at  | 2015-09-25T10:26:03.211849           |
| updated_at  | None                                 |
| server      | 10.254.0.3                           |
| user        | demo                                 |
| project_id  | 20787a7ba11946adad976463b57d8a2f     |
| type        | kerberos                             |
| id          | 7f46a447-2534-453d-924d-bd7c8e63bbec |
| description | Kerberos security service            |
+-------------+--------------------------------------+</pre></div><p>To see the list of created security service use
<code class="command">manila security-service-list</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila security-service-list
+--------------------------------------+------------------------------+--------+----------+
| id                                   | name                         | status | type     |
+--------------------------------------+------------------------------+--------+----------+
| 413479b2-0d20-4c58-a9d3-b129fa592d8e | my_ldap_security_service     | new    | ldap     |
| 7f46a447-2534-453d-924d-bd7c8e63bbec | my_kerberos_security_service | new    | kerberos |
+--------------------------------------+------------------------------+--------+----------+</pre></div><p>You can add a security service to the existing
<a class="xref" href="#shared-file-systems-share-networks" title="8.11.1. Share networks">Section 8.11.1, “Share networks”</a>, which is not
yet used (a <code class="literal">share network</code> not associated with a share).</p><p>Add a security service to the share network with
<code class="literal">share-network-security-service-add</code> specifying share network and
security service. The command returns information about the
security service. You can see view new attributes and <code class="literal">share_networks</code>
using the associated share network ID.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-network-security-service-add share_net2 my_ldap_security_service

$ manila security-service-show my_ldap_security_service
+----------------+-------------------------------------------+
| Property       | Value                                     |
+----------------+-------------------------------------------+
| status         | new                                       |
| domain         | None                                      |
| password       | None                                      |
| name           | my_ldap_security_service                  |
| dns_ip         | 8.8.8.8                                   |
| created_at     | 2015-09-25T10:19:06.000000                |
| updated_at     | None                                      |
| server         | 10.254.0.3                                |
| share_networks | [u'6d36c41f-d310-4aff-a0c2-ffd870e91cab'] |
| user           | None                                      |
| project_id     | 20787a7ba11946adad976463b57d8a2f          |
| type           | ldap                                      |
| id             | 413479b2-0d20-4c58-a9d3-b129fa592d8e      |
| description    | None                                      |
+----------------+-------------------------------------------+</pre></div><p>It is possible to see the list of security services associated
with a given share network. List security services for <code class="literal">share_net2</code>
share network with:</p><div class="verbatim-wrap"><pre class="screen">$ manila share-network-security-service-list share_net2
+--------------------------------------+--------------------------+--------+------+
| id                                   | name                     | status | type |
+--------------------------------------+--------------------------+--------+------+
| 413479b2-0d20-4c58-a9d3-b129fa592d8e | my_ldap_security_service | new    | ldap |
+--------------------------------------+--------------------------+--------+------+</pre></div><p>You also can dissociate a security service from the share network
and confirm that the security service now has an empty list of
share networks:</p><div class="verbatim-wrap"><pre class="screen">$ manila share-network-security-service-remove share_net2 my_ldap_security_service

$ manila security-service-show my_ldap_security_service
+----------------+--------------------------------------+
| Property       | Value                                |
+----------------+--------------------------------------+
| status         | new                                  |
| domain         | None                                 |
| password       | None                                 |
| name           | my_ldap_security_service             |
| dns_ip         | 8.8.8.8                              |
| created_at     | 2015-09-25T10:19:06.000000           |
| updated_at     | None                                 |
| server         | 10.254.0.3                           |
| share_networks | []                                   |
| user           | None                                 |
| project_id     | 20787a7ba11946adad976463b57d8a2f     |
| type           | ldap                                 |
| id             | 413479b2-0d20-4c58-a9d3-b129fa592d8e |
| description    | None                                 |
+----------------+--------------------------------------+</pre></div><p>The Shared File Systems service allows you to update a security service field
using <code class="command">manila security-service-update</code> command with optional
arguments such as <code class="literal">--dns-ip</code>, <code class="literal">--server</code>, <code class="literal">--domain</code>,
<code class="literal">--user</code>, <code class="literal">--password</code>, <code class="literal">--name</code>, or
<code class="literal">--description</code>.</p><p>To remove a security service not associated with any share networks
run:</p><div class="verbatim-wrap"><pre class="screen">$ manila security-service-delete my_ldap_security_service</pre></div></div><div class="sect1 " id="shared-file-systems-cgroups"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Consistency groups</span> <a title="Permalink" class="permalink" href="#shared-file-systems-cgroups">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-cgroups</li></ul></div></div></div></div><p>Consistency groups enable you to create snapshots from multiple file system
shares at the same point in time. For example, a database might place its
tables, logs, and configurations on separate shares. Store logs, tables,
and configurations at the same point in time to effectively restore a
database.</p><p>The Shared File System service allows you to create a snapshot of the
consistency group and restore all shares that were associated with a
consistency group.</p><div id="id-1.4.10.12.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>The <span class="bold"><strong>consistency groups and snapshots</strong></span> are an <span class="bold"><strong>experimental</strong></span>
Shared File Systems API in the Liberty release.
Contributors can change or remove the experimental part of the
Shared File Systems API in further releases without maintaining
backward compatibility. Experimental APIs have an
<code class="literal">X-OpenStack-Manila-API-Experimental: true</code> header in
their HTTP requests.</p></div><div class="sect2 " id="id-1.4.10.12.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Consistency groups</span> <a title="Permalink" class="permalink" href="#id-1.4.10.12.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.10.12.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Before using consistency groups, make sure the Shared File System driver
that you are running has consistency group support. You can check it in the
<code class="literal">manila-scheduler</code> service reports. The <code class="literal">consistency_group_support</code> can
have the following values:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">pool</code> or <code class="literal">host</code>. Consistency groups are supported. Specifies the
level of consistency groups support.</p></li><li class="listitem "><p><code class="literal">false</code>. Consistency groups are not supported.</p></li></ul></div></div><p>The <code class="command">manila cg-create</code> command creates a new consistency group.
With this command, you can specify a share network, and one or more share
types. In the example a consistency group <code class="literal">cgroup1</code> was created by
specifying two comma-separated share types:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-create --name cgroup1 --description "My first CG." --share-types my_type1,default --share-network my_share_net
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | creating                             |
| description          | My first CG.                         |
| source_cgsnapshot_id | None                                 |
| created_at           | 2015-09-29T15:01:12.102472           |
| share_network_id     | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a |
| share_server_id      | None                                 |
| host                 | None                                 |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| share_types          | a4218aa5-f16a-42b3-945d-113496d40558 |
|                      | c0086582-30a6-4060-b096-a42ec9d66b86 |
| id                   | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| name                 | cgroup1                              |
+----------------------+--------------------------------------+</pre></div><p>Check that consistency group status is <code class="literal">available</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-show cgroup1
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | available                            |
| description          | My first CG.                         |
| source_cgsnapshot_id | None                                 |
| created_at           | 2015-09-29T15:05:40.000000           |
| share_network_id     | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a |
| share_server_id      | None                                 |
| host                 | manila@generic1#GENERIC1             |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| share_types          | c0086582-30a6-4060-b096-a42ec9d66b86 |
|                      | a4218aa5-f16a-42b3-945d-113496d40558 |
| id                   | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| name                 | cgroup1                              |
+----------------------+--------------------------------------+</pre></div><p>To add a share to the consistency group, create a share by adding the
<code class="literal">--consistency-group</code> option where you specify the ID of the consistency
group in <code class="literal">available</code> status:</p><div class="verbatim-wrap"><pre class="screen">$ manila create nfs 1 --name "Share2" --description "My second share" \
--share-type default --share-network my_share_net --consistency-group cgroup1
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | None                                 |
| share_type_name             | default                              |
| description                 | My second share                      |
| availability_zone           | None                                 |
| share_network_id            | None                                 |
| export_locations            | []                                   |
| share_server_id             | None                                 |
| host                        | None                                 |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | 7bcd888b-681b-4836-ac9c-c3add4e62537 |
| size                        | 1                                    |
| name                        | Share2                               |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86 |
| created_at                  | 2015-09-29T15:09:24.156387           |
| export_location             | None                                 |
| share_proto                 | NFS                                  |
| consistency_group_id        | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 20787a7ba11946adad976463b57d8a2f     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</pre></div><p>Administrators can rename the consistency group, or change its
description using the <code class="command">manila cg-update</code> command. Delete the group
with the <code class="command">manila cg-delete</code> command.</p><p>As an administrator, you can also reset the state of a consistency group and
force delete a specified consistency group in any state. Use the
<code class="literal">policy.json</code> file to grant permissions for these actions to other roles.</p><p>Use <code class="command">manila cg-reset-state [--state &lt;state&gt;] &lt;consistency_group&gt;</code>
to update the state of a consistency group explicitly. A valid value of a
status are <code class="literal">available</code>, <code class="literal">error</code>, <code class="literal">creating</code>, <code class="literal">deleting</code>,
<code class="literal">error_deleting</code>. If no state is provided, <code class="literal">available</code> will be used.</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-reset-state cgroup1 --state error</pre></div><p>Use <code class="command">manila cg-delete &lt;consistency_group&gt; [&lt;consistency_group&gt; ...]</code>
to soft-delete one or more consistency groups.</p><div id="id-1.4.10.12.5.14" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>A consistency group can be deleted only if it has no dependent
<a class="xref" href="#shared-file-systems-cgsnapshots" title="8.8.2. Consistency group snapshots">Section 8.8.2, “Consistency group snapshots”</a>.</p></div><div class="verbatim-wrap"><pre class="screen">$ manila cg-delete cgroup1</pre></div><p>Use <code class="command">manila cg-delete --force &lt;consistency_group&gt;
[&lt;consistency_group&gt; ...]</code>
to force-delete a specified consistency group in any state.</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-delete --force cgroup1</pre></div></div><div class="sect2 " id="shared-file-systems-cgsnapshots"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Consistency group snapshots</span> <a title="Permalink" class="permalink" href="#shared-file-systems-cgsnapshots">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-cgsnapshots</li></ul></div></div></div></div><p>To create a snapshot, specify the ID or name of the consistency group.
After creating a consistency group snapshot, it is possible to generate
a new consistency group.</p><p>Create a snapshot of consistency group <code class="literal">cgroup1</code>:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-snapshot-create cgroup1 --name CG_snapshot1 --description "A snapshot of the first CG."
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | creating                             |
| name                 | CG_snapshot1                         |
| created_at           | 2015-09-29T15:26:16.839704           |
| consistency_group_id | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| id                   | 876ad24c-1efd-4607-a2b1-6a2c90034fa5 |
| description          | A snapshot of the first CG.          |
+----------------------+--------------------------------------+</pre></div><p>Check the status of created consistency group snapshot:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-snapshot-show CG_snapshot1
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| status               | available                            |
| name                 | CG_snapshot1                         |
| created_at           | 2015-09-29T15:26:22.000000           |
| consistency_group_id | 6fdd91bc-7a48-48b4-8e40-0f4f98d0ecd6 |
| project_id           | 20787a7ba11946adad976463b57d8a2f     |
| id                   | 876ad24c-1efd-4607-a2b1-6a2c90034fa5 |
| description          | A snapshot of the first CG.          |
+----------------------+--------------------------------------+</pre></div><p>Administrators can rename a consistency group snapshot, change its
description using the <code class="command">cg-snapshot-update</code> command, or delete
it with the <code class="command">cg-snapshot-delete</code> command.</p><p>A consistency group snapshot can have <code class="literal">members</code>. To add a member,
include the <code class="literal">--consistency-group</code> optional parameter in the
create share command. This ID must match the ID of the consistency group from
which the consistency group snapshot was created. Then, while restoring data,
and operating with consistency group snapshots, you can quickly
find which shares belong to a specified consistency group.</p><p>You created the share <code class="literal">Share2</code> in <code class="literal">cgroup1</code> consistency group. Since
you made a snapshot of it, you can see that the only member of the consistency
group snapshot is <code class="literal">Share2</code> share:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-snapshot-members CG_snapshot1
+--------------+------+----------------------------+----------------+--------------+--------------+
| Id           | Size | Created_at                 | Share_protocol | Share_id     | Share_type_id|
+--------------+------+----------------------------+----------------+--------------+--------------+
| 5c62af2b-... | 1    | 2015-09-29T15:26:22.000000 | NFS            | 7bcd888b-... | c0086582-... |
+--------------+------+----------------------------+----------------+--------------+--------------+</pre></div><p>After you create a consistency group snapshot, you can create a consistency
group from the new snapshot:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-create --source-cgsnapshot-id 876ad24c-1efd-4607-a2b1-6a2c90034fa5 --name cgroup2 --description "A consistency group from a CG snapshot."
+----------------------+-----------------------------------------+
| Property             | Value                                   |
+----------------------+-----------------------------------------+
| status               | creating                                |
| description          | A consistency group from a CG snapshot. |
| source_cgsnapshot_id | 876ad24c-1efd-4607-a2b1-6a2c90034fa5    |
| created_at           | 2015-09-29T15:47:47.937991              |
| share_network_id     | None                                    |
| share_server_id      | None                                    |
| host                 | manila@generic1#GENERIC1                |
| project_id           | 20787a7ba11946adad976463b57d8a2f        |
| share_types          | c0086582-30a6-4060-b096-a42ec9d66b86    |
|                      | a4218aa5-f16a-42b3-945d-113496d40558    |
| id                   | ffee08d9-c86c-45e5-861e-175c731daca2    |
| name                 | cgroup2                                 |
+----------------------+-----------------------------------------+</pre></div><p>Check the consistency group list. Two groups now appear:</p><div class="verbatim-wrap"><pre class="screen">$ manila cg-list
+-------------------+---------+-----------------------------------------+-----------+
| id                | name    | description                             | status    |
+-------------------+---------+-----------------------------------------+-----------+
| 6fdd91bc-7a48-... | cgroup1 | My first CG.                            | available |
| ffee08d9-c86c-... | cgroup2 | A consistency group from a CG snapshot. | available |
+-------------------+---------+-----------------------------------------+-----------+</pre></div><p>Check a list of the shares. New share with
<code class="literal">ba52454e-2ea3-47fa-a683-3176a01295e6</code> ID appeared after the
consistency group <code class="literal">cgroup2</code> was built from a snapshot with a member.</p><div class="verbatim-wrap"><pre class="screen">$ manila list
+------+-------+-----+------------+----------+----------+-----------+--------------------------+
| ID   | Name  | Size| Share Proto| Status   | Is Public| Share Type| Host                     |
+------+-------+-----+------------+----------+----------+-----------+--------------------------+
| 7bc..| Share2| 1   | NFS        | available| False    | c008658...| manila@generic1#GENERIC1 |
| ba5..| None  | 1   | NFS        | available| False    | c008658...| manila@generic1#GENERIC1 |
+------+-------+-----+------------+----------+----------+-----------+--------------------------+</pre></div><p>Print detailed information about new share:</p><div id="id-1.4.10.12.6.18" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Pay attention on the <code class="literal">source_cgsnapshot_member_id</code> and
<code class="literal">consistency_group_id</code> fields in a new share. It has
<code class="literal">source_cgsnapshot_member_id</code> that is equal to the ID of the consistency
group snapshot and <code class="literal">consistency_group_id</code> that is equal to the ID of
<code class="literal">cgroup2</code> created from a snapshot.</p></div><div class="verbatim-wrap"><pre class="screen">$ manila show ba52454e-2ea3-47fa-a683-3176a01295e6
+-----------------------------+---------------------------------------------------------------+
| Property                    | Value                                                         |
+-----------------------------+---------------------------------------------------------------+
| status                      | available                                                     |
| share_type_name             | default                                                       |
| description                 | None                                                          |
| availability_zone           | None                                                          |
| share_network_id            | None                                                          |
| export_locations            | 10.254.0.5:/shares/share-5acadf4d-f81a-4515-b5ce-3ab641ab4d1e |
| share_server_id             | None                                                          |
| host                        | manila@generic1#GENERIC1                                      |
| snapshot_id                 | None                                                          |
| is_public                   | False                                                         |
| task_state                  | None                                                          |
| snapshot_support            | True                                                          |
| id                          | ba52454e-2ea3-47fa-a683-3176a01295e6                          |
| size                        | 1                                                             |
| name                        | None                                                          |
| share_type                  | c0086582-30a6-4060-b096-a42ec9d66b86                          |
| created_at                  | 2015-09-29T15:47:48.000000                                    |
| share_proto                 | NFS                                                           |
| consistency_group_id        | ffee08d9-c86c-45e5-861e-175c731daca2                          |
| source_cgsnapshot_member_id | 5c62af2b-0870-4d00-b3fa-174831eb15ca                          |
| project_id                  | 20787a7ba11946adad976463b57d8a2f                              |
| metadata                    | {}                                                            |
+-----------------------------+---------------------------------------------------------------+</pre></div><p>As an administrator, you can also reset the state of a consistency group
snapshot with the <code class="command">cg-snapshot-reset-state</code> command, and force delete a specified
consistency group snapshot in any state using the <code class="command">cg-snapshot-delete</code> command
with the <code class="literal">--force</code> key. Use the <code class="literal">policy.json</code> file to grant permissions for
these actions to other roles.</p></div></div><div class="sect1 " id="id-1.4.10.13"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share replication</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Replication of data has a number of use cases in the cloud. One use case is
High Availability of the data in a shared file system, used for example, to
support a production database. Another use case is ensuring Data Protection;
i.e being prepared for a disaster by having a replication location that will be
ready to back up your primary data source.</p><p>The Shared File System service supports user facing APIs that allow users to
create shares that support replication, add and remove share replicas and
manage their snapshots and access rules. Three replication types are currently
supported and they vary in the semantics associated with the primary share and
the secondary copies.</p><div id="id-1.4.10.13.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p><span class="bold"><strong>Share replication</strong></span> is an <span class="bold"><strong>experimental</strong></span> Shared File Systems API in
the Mitaka release. Contributors can change or remove the experimental
part of the Shared File Systems API in further releases without maintaining
backward compatibility. Experimental APIs have an
<code class="literal">X-OpenStack-Manila-API-Experimental: true</code> header in their HTTP requests.</p></div><div class="sect2 " id="id-1.4.10.13.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Replication types supported</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Before using share replication, make sure the Shared File System driver that
you are running supports this feature. You can check it in the
<code class="literal">manila-scheduler</code> service reports. The <code class="literal">replication_type</code> capability
reported can have one of the following values:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.10.13.5.3.1"><span class="term ">writable</span></dt><dd><p>The driver supports creating <code class="literal">writable</code> share replicas. All share replicas
can be accorded read/write access and would be synchronously mirrored.</p></dd><dt id="id-1.4.10.13.5.3.2"><span class="term ">readable</span></dt><dd><p>The driver supports creating <code class="literal">read-only</code> share replicas. All secondary
share replicas can be accorded read access. Only the primary (or <code class="literal">active</code>
share replica) can be written into.</p></dd><dt id="id-1.4.10.13.5.3.3"><span class="term ">dr</span></dt><dd><p>The driver supports creating <code class="literal">dr</code> (abbreviated from Disaster Recovery)
share replicas. A secondary share replica is inaccessible until after a
<code class="literal">promotion</code>.</p></dd><dt id="id-1.4.10.13.5.3.4"><span class="term ">None</span></dt><dd><p>The driver does not support Share Replication.</p></dd></dl></div><div id="id-1.4.10.13.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The term <code class="literal">active</code> share replica refers to the <code class="literal">primary</code> share. In
<code class="literal">writable</code> style of replication, all share replicas are <code class="literal">active</code>, and
there could be no distinction of a <code class="literal">primary</code> share. In <code class="literal">readable</code> and
<code class="literal">dr</code> styles of replication, a <code class="literal">secondary</code> share replica may be referred
to as <code class="literal">passive</code>, <code class="literal">non-active</code> or simply, <code class="literal">replica</code>.</p></div></div><div class="sect2 " id="id-1.4.10.13.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Two new configuration options have been introduced to support Share
Replication.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.10.13.6.3.1"><span class="term ">replica_state_update_interval</span></dt><dd><p>Specify this option in the <code class="literal">DEFAULT</code> section of your <code class="literal">manila.conf</code>.
The Shared File Systems service requests periodic update of the
<code class="literal">replica_state</code> of all <code class="literal">non-active</code> share replicas. The update occurs with
respect to an interval corresponding to this option. If it is not specified,
it defaults to 300 seconds.</p></dd><dt id="id-1.4.10.13.6.3.2"><span class="term ">replication_domain</span></dt><dd><p>Specify this option in the backend stanza when using a multi-backend style
configuration. The value can be any ASCII string. Two backends that can
replicate between each other would have the same <code class="literal">replication_domain</code>.
This comes from the premise that the Shared File Systems service expects
Share Replication to be performed between symmetric backends. This option
is <span class="emphasis"><em>required</em></span> for using the Share Replication feature.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.10.13.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Health of a share replica</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Apart from the <code class="literal">status</code> attribute, share replicas have the
<code class="literal">replica_state</code> attribute to denote the state of data replication on the
storage backend. The <code class="literal">primary</code> share replica will have it's <code class="literal">replica_state</code>
attribute set to <code class="literal">active</code>. The <code class="literal">secondary</code> share replicas may have one of
the following as their <code class="literal">replica_state</code>:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.10.13.7.3.1"><span class="term ">in_sync</span></dt><dd><p>The share replica is up to date with the <code class="literal">active</code> share replica (possibly
within a backend-specific <code class="literal">recovery point objective</code>).</p></dd><dt id="id-1.4.10.13.7.3.2"><span class="term ">out_of_sync</span></dt><dd><p>The share replica is out of date (all new share replicas start out in
this <code class="literal">replica_state</code>).</p></dd><dt id="id-1.4.10.13.7.3.3"><span class="term ">error</span></dt><dd><p>When the scheduler fails to schedule this share replica or some potentially
irrecoverable error occurred with regard to updating data for this replica.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.10.13.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Promotion or failover</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For <code class="literal">readable</code> and <code class="literal">dr</code> types of replication, we refer to the task
of switching a <code class="literal">non-active</code> share replica with the <code class="literal">active</code> replica as
<code class="literal">promotion</code>. For the <code class="literal">writable</code> style of replication, promotion does
not make sense since all share replicas are <code class="literal">active</code> (or writable) at all
times.</p><p>The <code class="literal">status</code> attribute of the non-active replica being promoted will be
set to <code class="literal">replication_change</code> during its promotion. This has been classified as
a <code class="literal">busy</code> state and thus API interactions with the share are restricted
while one of its share replicas is in this state.</p></div><div class="sect2 " id="id-1.4.10.13.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.9.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share replication workflows</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following examples have been implemented with the ZFSonLinux driver that
is a reference implementation in the Shared File Systems service. It operates
in <code class="literal">driver_handles_share_servers=False</code> mode and supports the <code class="literal">readable</code>
type of replication. In the example, we assume a configuration of two
Availability Zones (configuration option: <code class="literal">storage_availability_zone</code>),
called <code class="literal">availability_zone_1</code> and <code class="literal">availability_zone_2</code>.</p><p>Multiple availability zones are not necessary to use the replication feature.
However, the use of an availability zone as a <code class="literal">failure domain</code> is encouraged.</p><p>Pay attention to the network configuration for the ZFS driver. Here, we assume
a configuration of <code class="literal">zfs_service_ip</code> and <code class="literal">zfs_share_export_ip</code> from two
separate networks. The service network is reachable from the host where the
<code class="literal">manila-share</code> service is running. The share export IP is from a network that
allows user access.</p><p>See <a class="link" href="http://docs.openstack.org/newton/config-reference/shared-file-systems/drivers/zfs-on-linux-driver.html" target="_blank">Configuring the ZFSonLinux driver</a>
for information on how to set up the ZFSonLinux driver.</p><div class="sect3 " id="id-1.4.10.13.9.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a share that supports replication</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Create a new share type and specify the <code class="literal">replication_type</code> as an extra-spec
within the share-type being used.</p><p>Use the <code class="command">manila type-create</code> command to create a new share type.
Specify the name and the value for the extra-spec
<code class="literal">driver_handles_share_servers</code>.</p><div class="verbatim-wrap"><pre class="screen">$ manila type-create readable_type_replication False
+----------------------+--------------------------------------+
| Property             | Value                                |
+----------------------+--------------------------------------+
| required_extra_specs | driver_handles_share_servers : False |
| Name                 | readable_type_replication            |
| Visibility           | public                               |
| is_default           | -                                    |
| ID                   | 3b3ee3f7-6e43-4aa1-859d-0b0511c43074 |
| optional_extra_specs | snapshot_support : True              |
+----------------------+--------------------------------------+</pre></div><p>Use the <code class="command">manila type-key</code> command to set an extra-spec to the
share type.</p><div class="verbatim-wrap"><pre class="screen">$ manila type-key readable_type_replication set replication_type=readable</pre></div><div id="id-1.4.10.13.9.6.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output. To verify the extra-spec, use the
<code class="command">manila extra-specs-list</code> command and specify the share type's name
or ID as a parameter.</p></div><p>Create a share with the share type</p><p>Use the <code class="command">manila create</code> command to create a share. Specify the share
protocol, size and the availability zone.</p><div class="verbatim-wrap"><pre class="screen">$ manila create NFS 1 --share_type readable_type_replication --name my_share --description "This share will have replicas" --az availability_zone_1
+-----------------------------+--------------------------------------+
| Property                    | Value                                |
+-----------------------------+--------------------------------------+
| status                      | creating                             |
| share_type_name             | readable_type_replication            |
| description                 | This share will have replicas        |
| availability_zone           | availability_zone_1                  |
| share_network_id            | None                                 |
| share_server_id             | None                                 |
| host                        |                                      |
| access_rules_status         | active                               |
| snapshot_id                 | None                                 |
| is_public                   | False                                |
| task_state                  | None                                 |
| snapshot_support            | True                                 |
| id                          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| size                        | 1                                    |
| name                        | my_share                             |
| share_type                  | 3b3ee3f7-6e43-4aa1-859d-0b0511c43074 |
| has_replicas                | False                                |
| replication_type            | readable                             |
| created_at                  | 2016-03-29T20:22:18.000000           |
| share_proto                 | NFS                                  |
| consistency_group_id        | None                                 |
| source_cgsnapshot_member_id | None                                 |
| project_id                  | 48a5ca76ac69405e99dc1c13c5195186     |
| metadata                    | {}                                   |
+-----------------------------+--------------------------------------+</pre></div><p>Use the <code class="command">manila show</code> command to retrieve details of the share.
Specify the share ID or name as a parameter.</p><div class="verbatim-wrap"><pre class="screen">$ manila show my_share
+-----------------------------+--------------------------------------------------------------------+
| Property                    | Value                                                              |
+-----------------------------+--------------------------------------------------------------------+
| status                      | available                                                          |
| share_type_name             | readable_type_replication                                          |
| description                 | This share will have replicas                                      |
| availability_zone           | availability_zone_1                                                |
| share_network_id            | None                                                               |
| export_locations            |                                                                    |
|                             | path =                                                             |
|                             |10.32.62.26:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28|
|                             | preferred = False                                                  |
|                             | is_admin_only = False                                              |
|                             | id = e1d754b5-ec06-42d2-afff-3e98c0013faf                          |
|                             | share_instance_id = 38efc042-50c2-4825-a6d8-cba2a8277b28           |
|                             | path =                                                             |
|                             |172.21.0.23:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28|
|                             | preferred = False                                                  |
|                             | is_admin_only = True                                               |
|                             | id = 6f843ecd-a7ea-4939-86de-e1e01d9e8672                          |
|                             | share_instance_id = 38efc042-50c2-4825-a6d8-cba2a8277b28           |
| share_server_id             | None                                                               |
| host                        | openstack4@zfsonlinux_1#alpha                                      |
| access_rules_status         | active                                                             |
| snapshot_id                 | None                                                               |
| is_public                   | False                                                              |
| task_state                  | None                                                               |
| snapshot_support            | True                                                               |
| id                          | e496ed61-8f2e-436b-b299-32c3e90991cc                               |
| size                        | 1                                                                  |
| name                        | my_share                                                           |
| share_type                  | 3b3ee3f7-6e43-4aa1-859d-0b0511c43074                               |
| has_replicas                | False                                                              |
| replication_type            | readable                                                           |
| created_at                  | 2016-03-29T20:22:18.000000                                         |
| share_proto                 | NFS                                                                |
| consistency_group_id        | None                                                               |
| source_cgsnapshot_member_id | None                                                               |
| project_id                  | 48a5ca76ac69405e99dc1c13c5195186                                   |
| metadata                    | {}                                                                 |
+-----------------------------+--------------------------------------------------------------------+</pre></div><div id="id-1.4.10.13.9.6.13" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When you create a share that supports replication, an <code class="literal">active</code> replica is
created for you. You can verify this with the
<code class="command">manila share-replica-list</code> command.</p></div></div><div class="sect3 " id="id-1.4.10.13.9.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating and promoting share replicas</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Create a share replica</p><p>Use the <code class="command">manila share-replica-create</code> command to create a share
replica. Specify the share ID or name as a parameter. You may
optionally provide the <code class="literal">availability_zone</code> and <code class="literal">share_network_id</code>. In the
example below, <code class="literal">share_network_id</code> is not used since the ZFSonLinux driver
does not support it.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-create my_share --az availability_zone_2
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | creating                             |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| availability_zone | availability_zone_2                  |
| created_at        | 2016-03-29T20:24:53.148992           |
| updated_at        | None                                 |
| share_network_id  | None                                 |
| share_server_id   | None                                 |
| host              |                                      |
| replica_state     | None                                 |
| id                | 78a5ef96-6c36-42e0-b50b-44efe7c1807e |
+-------------------+--------------------------------------+</pre></div><p>See details of the newly created share replica</p><p>Use the <code class="command">manila share-replica-show</code> command to see details
of the newly created share replica. Specify the share replica's ID as a
parameter.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-show 78a5ef96-6c36-42e0-b50b-44efe7c1807e
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | available                            |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| availability_zone | availability_zone_2                  |
| created_at        | 2016-03-29T20:24:53.000000           |
| updated_at        | 2016-03-29T20:24:58.000000           |
| share_network_id  | None                                 |
| share_server_id   | None                                 |
| host              | openstack4@zfsonlinux_2#beta         |
| replica_state     | in_sync                              |
| id                | 78a5ef96-6c36-42e0-b50b-44efe7c1807e |
+-------------------+--------------------------------------+</pre></div><p>See all replicas of the share</p><p>Use the <code class="command">manila share-replica-list</code> command to see all the replicas
of the share. Specify the share ID or name as an optional parameter.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-list --share-id my_share
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| ID                                   | Status    | Replica State | Share ID                             | Host                          | Availability Zone   | Updated At                 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| 38efc042-50c2-4825-a6d8-cba2a8277b28 | available | active        | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_1#alpha | availability_zone_1 | 2016-03-29T20:22:19.000000 |
| 78a5ef96-6c36-42e0-b50b-44efe7c1807e | available | in_sync       | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_2#beta  | availability_zone_2 | 2016-03-29T20:24:58.000000 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+</pre></div><p>Promote the secondary share replica to be the new active replica</p><p>Use the <code class="command">manila share-replica-promote</code> command to promote a
non-active share replica to become the <code class="literal">active</code> replica. Specify the
non-active replica's ID as a parameter.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-promote 78a5ef96-6c36-42e0-b50b-44efe7c1807e</pre></div><div id="id-1.4.10.13.9.7.14" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output.</p></div><p>The promotion may take time. During the promotion, the <code class="literal">replica_state</code>
attribute of the share replica being promoted will be set to
<code class="literal">replication_change</code>.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-list --share-id my_share
+--------------------------------------+-----------+--------------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| ID                                   | Status    |    Replica State   | Share ID                             | Host                          | Availability Zone   | Updated At                 |
+--------------------------------------+-----------+--------------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| 38efc042-50c2-4825-a6d8-cba2a8277b28 | available |       active       | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_1#alpha | availability_zone_1 | 2016-03-29T20:32:19.000000 |
| 78a5ef96-6c36-42e0-b50b-44efe7c1807e | available | replication_change | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_2#beta  | availability_zone_2 | 2016-03-29T20:32:19.000000 |
+--------------------------------------+-----------+--------------------+--------------------------------------+-------------------------------+---------------------+----------------------------+</pre></div><p>Once the promotion is complete, the <code class="literal">replica_state</code> will be set to
<code class="literal">active</code>.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-list --share-id my_share
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| ID                                   | Status    | Replica State | Share ID                             | Host                          | Availability Zone   | Updated At                 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+
| 38efc042-50c2-4825-a6d8-cba2a8277b28 | available | in_sync       | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_1#alpha | availability_zone_1 | 2016-03-29T20:32:19.000000 |
| 78a5ef96-6c36-42e0-b50b-44efe7c1807e | available | active        | e496ed61-8f2e-436b-b299-32c3e90991cc | openstack4@zfsonlinux_2#beta  | availability_zone_2 | 2016-03-29T20:32:19.000000 |
+--------------------------------------+-----------+---------------+--------------------------------------+-------------------------------+---------------------+----------------------------+</pre></div></div><div class="sect3 " id="id-1.4.10.13.9.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Access rules</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Create an IP access rule for the share</p><p>Use the <code class="command">manila access-allow</code> command to add an access rule.
Specify the share ID or name, protocol and the target as parameters.</p><div class="verbatim-wrap"><pre class="screen">$ manila access-allow my_share ip 0.0.0.0/0 --access-level rw
+--------------+--------------------------------------+
| Property     | Value                                |
+--------------+--------------------------------------+
| share_id     | e496ed61-8f2e-436b-b299-32c3e90991cc |
| access_type  | ip                                   |
| access_to    | 0.0.0.0/0                            |
| access_level | rw                                   |
| state        | new                                  |
| id           | 8b339cdc-c1e0-448f-bf6d-f068ee6e8f45 |
+--------------+--------------------------------------+</pre></div><div id="id-1.4.10.13.9.8.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Access rules are not meant to be different across the replicas of the share.
However, as per the type of replication, drivers may choose to modify the
access level prescribed. In the above example, even though read/write access
was requested for the share, the driver will provide read-only access to
the non-active replica to the same target, because of the semantics of
the replication type: <code class="literal">readable</code>. However, the target will have read/write
access to the (currently) non-active replica when it is promoted to
become the <code class="literal">active</code> replica.</p></div><p>The <code class="command">manila access-deny</code> command can be used to remove a previously
applied access rule.</p><p>List the export locations of the share</p><p>Use the <code class="command">manila share-export-locations-list</code> command to list the
export locations of a share.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-export-location-list my_share
+--------------------------------------+---------------------------------------------------------------------------+-----------+
| ID                                   | Path                                                                      | Preferred |
+--------------------------------------+---------------------------------------------------------------------------+-----------+
| 3ed3fbf5-2fa1-4dc0-8440-a0af72398cb6 | 10.32.62.21:/beta/subdir/manila_share_78a5ef96_6c36_42e0_b50b_44efe7c1807e| False     |
| 6f843ecd-a7ea-4939-86de-e1e01d9e8672 | 172.21.0.23:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28      | False     |
| e1d754b5-ec06-42d2-afff-3e98c0013faf | 10.32.62.26:/alpha/manila_share_38efc042_50c2_4825_a6d8_cba2a8277b28      | False     |
| f3c5585f-c2f7-4264-91a7-a4a1e754e686 | 172.21.0.29:/beta/subdir/manila_share_78a5ef96_6c36_42e0_b50b_44efe7c1807e| False     |
+--------------------------------------+---------------------------------------------------------------------------+-----------+</pre></div><p>Identify the export location corresponding to the share replica on the user
accessible network and you may mount it on the target node.</p><div id="id-1.4.10.13.9.8.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>As an administrator, you can list the export locations for a particular
share replica by using the
<code class="command">manila share-instance-export-location-list</code> command and
specifying the share replica's ID as a parameter.</p></div></div><div class="sect3 " id="id-1.4.10.13.9.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Snapshots</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Create a snapshot of the share</p><p>Use the <code class="command">manila snapshot-create</code> command to create a snapshot
of the share. Specify the share ID or name as a parameter.</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-create my_share --name "my_snapshot"
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | creating                             |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| description       | None                                 |
| created_at        | 2016-03-29T21:14:03.000000           |
| share_proto       | NFS                                  |
| provider_location | None                                 |
| id                | 06cdccaf-93a0-4e57-9a39-79fb1929c649 |
| size              | 1                                    |
| share_size        | 1                                    |
| name              | my_snapshot                          |
+-------------------+--------------------------------------+</pre></div><p>Show the details of the snapshot</p><p>Use the <code class="command">manila snapshot-show</code> to view details of a snapshot.
Specify the snapshot ID or name as a parameter.</p><div class="verbatim-wrap"><pre class="screen">$ manila snapshot-show my_snapshot
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | available                            |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| description       | None                                 |
| created_at        | 2016-03-29T21:14:03.000000           |
| share_proto       | NFS                                  |
| provider_location | None                                 |
| id                | 06cdccaf-93a0-4e57-9a39-79fb1929c649 |
| size              | 1                                    |
| share_size        | 1                                    |
| name              | my_snapshot                          |
+-------------------+--------------------------------------+</pre></div><div id="id-1.4.10.13.9.9.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">status</code> attribute of a snapshot will transition from <code class="literal">creating</code>
to <code class="literal">available</code> only when it is present on all the share replicas that have
their <code class="literal">replica_state</code> attribute set to <code class="literal">active</code> or <code class="literal">in_sync</code>.</p><p>Likewise, the <code class="literal">replica_state</code> attribute of a share replica will
transition from <code class="literal">out_of_sync</code> to <code class="literal">in_sync</code> only when all <code class="literal">available</code>
snapshots are present on it.</p></div></div><div class="sect3 " id="id-1.4.10.13.9.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Planned failovers</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrator, you can use the <code class="command">manila share-replica-resync</code>
command to attempt to sync data between <code class="literal">active</code> and <code class="literal">non-active</code> share
replicas of a share before promotion. This will ensure that share replicas have
the most up-to-date data and their relationships can be safely switched.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-resync 38efc042-50c2-4825-a6d8-cba2a8277b28</pre></div><div id="id-1.4.10.13.9.10.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output.</p></div></div><div class="sect3 " id="id-1.4.10.13.9.11"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Updating attributes</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.11">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If an error occurs while updating data or replication relationships (during
a <code class="literal">promotion</code>), the Shared File Systems service may not be able to determine
the consistency or health of a share replica. It may require administrator
intervention to make any fixes on the storage backend as necessary. In such a
situation, state correction within the Shared File Systems service is possible.</p><p>As an administrator, you can:</p><p>Reset the <code class="literal">status</code> attribute of a share replica</p><p>Use the <code class="command">manila share-replica-reset-state</code> command to reset
the <code class="literal">status</code> attribute. Specify the share replica's ID as a parameter
and use the <code class="literal">--state</code> option to specify the state intended.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-reset-state 38efc042-50c2-4825-a6d8-cba2a8277b28 --state=available</pre></div><div id="id-1.4.10.13.9.11.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output.</p></div><p>Reset the <code class="literal">replica_state</code> attribute</p><p>Use the <code class="command">manila share-replica-reset-replica-state</code> command to
reset the <code class="literal">replica_state</code> attribute. Specify the share replica's ID
and use the <code class="literal">--state</code> option to specify the state intended.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-reset-replica-state 38efc042-50c2-4825-a6d8-cba2a8277b28 --state=out_of_sync</pre></div><div id="id-1.4.10.13.9.11.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output.</p></div><p>Force delete a specified share replica in any state</p><p>Use the <code class="command">manila share-replica-delete</code> command with the
'--force' key to remove the share replica, regardless of the state it is in.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-show 9513de5d-0384-4528-89fb-957dd9b57680
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| status            | error                                |
| share_id          | e496ed61-8f2e-436b-b299-32c3e90991cc |
| availability_zone | availability_zone_1                  |
| created_at        | 2016-03-30T01:32:47.000000           |
| updated_at        | 2016-03-30T01:34:25.000000           |
| share_network_id  | None                                 |
| share_server_id   | None                                 |
| host              | openstack4@zfsonlinux_1#alpha        |
| replica_state     | out_of_sync                          |
| id                | 38efc042-50c2-4825-a6d8-cba2a8277b28 |
+-------------------+--------------------------------------+

$ manila share-replica-delete --force 38efc042-50c2-4825-a6d8-cba2a8277b28</pre></div><div id="id-1.4.10.13.9.11.15" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output.</p></div><p>Use the <code class="literal">policy.json</code> file to grant permissions for these actions to other
roles.</p></div><div class="sect3 " id="id-1.4.10.13.9.12"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.9.5.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deleting share replicas</span> <a title="Permalink" class="permalink" href="#id-1.4.10.13.9.12">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use the <code class="command">manila share-replica-delete</code> command with the share
replica's ID to delete a share replica.</p><div class="verbatim-wrap"><pre class="screen">$ manila share-replica-delete 38efc042-50c2-4825-a6d8-cba2a8277b28</pre></div><div id="id-1.4.10.13.9.12.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This command has no output.</p></div><div id="id-1.4.10.13.9.12.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You cannot delete the last <code class="literal">active</code> replica with this command. You should
use the <code class="command">manila delete</code> command to remove the share.</p></div></div></div></div><div class="sect1 " id="shared-file-systems-multi-backend"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Multi-storage configuration</span> <a title="Permalink" class="permalink" href="#shared-file-systems-multi-backend">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-multi-backend</li></ul></div></div></div></div><p>The Shared File Systems service can provide access to multiple file storage
back ends. In general, the workflow with multiple back ends looks similar
to the Block Storage service one, see <a class="xref" href="#multi-backend" title="7.2.4. Configure multiple-storage back ends">Section 7.2.4, “Configure multiple-storage back ends”</a>.</p><p>Using <code class="literal">manila.conf</code>, you can spawn multiple share services. To do it, you
should set the <code class="literal">enabled_share_backends</code> flag in the <code class="literal">manila.conf</code> file. This
flag defines the comma-separated names of the configuration stanzas for the
different back ends. One name is associated to one configuration group for a
back end.</p><p>The following example runs three configured share services:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
enabled_share_backends=backendEMC2,backendGeneric1,backendNetApp

[backendGeneric1]
share_driver=manila.share.drivers.generic.GenericShareDriver
share_backend_name=one_name_for_two_backends
service_instance_user=ubuntu_user
service_instance_password=ubuntu_user_password
service_image_name=ubuntu_image_name
path_to_private_key=/home/foouser/.ssh/id_rsa
path_to_public_key=/home/foouser/.ssh/id_rsa.pub

[backendEMC2]
share_driver=manila.share.drivers.emc.driver.EMCShareDriver
share_backend_name=backendEMC2
emc_share_backend=vnx
emc_nas_server=1.1.1.1
emc_nas_password=password
emc_nas_login=user
emc_nas_server_container=server_3
emc_nas_pool_name="Pool 2"

[backendNetApp]
share_driver = manila.share.drivers.netapp.common.NetAppDriver
driver_handles_share_servers = True
share_backend_name=backendNetApp
netapp_login=user
netapp_password=password
netapp_server_hostname=1.1.1.1
netapp_root_volume_aggregate=aggr01</pre></div><p>To spawn separate groups of share services, you can use separate configuration
files. If it is necessary to control each back end in a separate way, you
should provide a single configuration file per each back end.</p><div class="sect2 " id="shared-file-systems-scheduling"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scheduling</span> <a title="Permalink" class="permalink" href="#shared-file-systems-scheduling">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-scheduling</li></ul></div></div></div></div><p>The Shared File Systems service uses a scheduler to provide unified
access for a variety of different types of shared file systems. The
scheduler collects information from the active shared services, and
makes decisions such as what shared services will be used to create
a new share. To manage this process, the Shared File Systems service
provides Share types API.</p><p>A share type is a list from key-value pairs called extra-specs. The
scheduler uses required and un-scoped extra-specs to look up
the shared service most suitable for a new share with the specified share type.
For more information about extra-specs and their type, see <a class="link" href="http://docs.openstack.org/developer/manila/devref/capabilities_and_extra_specs.html" target="_blank">Capabilities
and Extra-Specs</a> section in developer documentation.</p><p>The general scheduler workflow:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Share services report information about their existing pool number, their
capacities, and their capabilities.</p></li><li class="step "><p>When a request on share creation arrives, the scheduler picks a service
and pool that best serves the request, using share type
filters and back end capabilities. If back end capabilities pass through,
all filters request the selected back end where the target pool resides.</p></li><li class="step "><p>The share driver receives a reply on the request status, and lets the
target pool serve the request as the scheduler instructs. The scoped
and un-scoped share types are available for the driver implementation
to use as needed.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.10.14.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage shares services</span> <a title="Permalink" class="permalink" href="#id-1.4.10.14.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Shared File Systems service provides API that allows to manage running
share services (<a class="link" href="http://developer.openstack.org/api-ref/shared-file-systems/" target="_blank">Share services API</a>).
Using the <code class="command">manila service-list</code> command, it is possible to get a list
of all kinds of running services. To select only share services, you can pick
items that have field <code class="literal">binary</code> equal to <code class="literal">manila-share</code>. Also, you can
enable or disable share services using raw API requests. Disabling means that
share services are excluded from the scheduler cycle and new shares will not
be placed on the disabled back end. However, shares from this service stay
available.</p></div></div><div class="sect1 " id="id-1.4.10.15"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.10.15">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Unlike the OpenStack Block Storage service, the Shared File Systems service
must connect to the Networking service. The share service requires the
option to self-manage share servers. For client authentication and
authorization, you can configure the Shared File Systems service to
work with different network authentication services, like LDAP, Kerberos
protocols, or Microsoft Active Directory.</p><div class="sect2 " id="shared-file-systems-share-networks"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Share networks</span> <a title="Permalink" class="permalink" href="#shared-file-systems-share-networks">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-share-networks</li></ul></div></div></div></div><p>Share network is an entity that encapsulates interaction with the OpenStack
Networking service. If the share driver that you selected runs in a mode
requiring Networking service interaction, specify the share network when
creating a new share network.</p><div class="sect3 " id="id-1.4.10.15.3.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.11.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How to create share network</span> <a title="Permalink" class="permalink" href="#id-1.4.10.15.3.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To list networks in a project, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack network list
+--------------+---------+--------------------+
| ID           | Name    | Subnets            |
+--------------+---------+--------------------+
| bee7411d-... | public  | 884a6564-0f11-...  |
|              |         | e6da81fa-5d5f-...  |
| 5ed5a854-... | private | 74dcfb5a-b4d7-...  |
|              |         | cc297be2-5213-...  |
+--------------+---------+--------------------+</pre></div><p>A share network stores network information that share servers can use where
shares are hosted. You can associate a share with a single share network.
When you create or update a share, you can optionally specify the ID of a share
network through which instances can access the share.</p><p>When you create a share network, you can specify only one type of network:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>OpenStack Networking (neutron). Specify a network ID and subnet ID.
In this case <code class="literal">manila.network.nova_network_plugin.NeutronNetworkPlugin</code>
will be used.</p></li><li class="listitem "><p>Legacy networking (nova-network). Specify a network ID.
In this case <code class="literal">manila.network.nova_network_plugin.NoveNetworkPlugin</code>
will be used.</p></li></ul></div><p>For more information about supported plug-ins for share networks, see
<a class="xref" href="#shared-file-systems-network-plugins" title="8.11.2. Network plug-ins">Section 8.11.2, “Network plug-ins”</a>.</p><p>A share network has these attributes:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The IP block in Classless Inter-Domain Routing (CIDR) notation from which to
allocate the network.</p></li><li class="listitem "><p>The IP version of the network.</p></li><li class="listitem "><p>The network type, which is <code class="literal">vlan</code>, <code class="literal">vxlan</code>, <code class="literal">gre</code>, or <code class="literal">flat</code>.</p></li></ul></div><p>If the network uses segmentation, a segmentation identifier. For example, VLAN,
VXLAN, and GRE networks use segmentation.</p><p>To create a share network with private network and subnetwork, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila share-network-create --neutron-net-id 5ed5a854-21dc-4ed3-870a-117b7064eb21 \
--neutron-subnet-id 74dcfb5a-b4d7-4855-86f5-a669729428dc --name my_share_net --description "My first share network"
+-------------------+--------------------------------------+
| Property          | Value                                |
+-------------------+--------------------------------------+
| name              | my_share_net                         |
| segmentation_id   | None                                 |
| created_at        | 2015-09-24T12:06:32.602174           |
| neutron_subnet_id | 74dcfb5a-b4d7-4855-86f5-a669729428dc |
| updated_at        | None                                 |
| network_type      | None                                 |
| neutron_net_id    | 5ed5a854-21dc-4ed3-870a-117b7064eb21 |
| ip_version        | None                                 |
| nova_net_id       | None                                 |
| cidr              | None                                 |
| project_id        | 20787a7ba11946adad976463b57d8a2f     |
| id                | 5c3cbabb-f4da-465f-bc7f-fadbe047b85a |
| description       | My first share network               |
+-------------------+--------------------------------------+</pre></div><p>The <code class="literal">segmentation_id</code>, <code class="literal">cidr</code>, <code class="literal">ip_version</code>, and <code class="literal">network_type</code>
share network attributes are automatically set to the values determined by the
network provider.</p><p>To check the network list, run:</p><div class="verbatim-wrap"><pre class="screen">$ manila share-network-list
+--------------------------------------+--------------+
| id                                   | name         |
+--------------------------------------+--------------+
| 5c3cbabb-f4da-465f-bc7f-fadbe047b85a | my_share_net |
+--------------------------------------+--------------+</pre></div><p>If you configured the generic driver with <code class="literal">driver_handles_share_servers =
True</code> (with the share servers) and already had previous operations in the Shared
File Systems service, you can see <code class="literal">manila_service_network</code> in the neutron
list of networks. This network was created by the generic driver for internal
use.</p><div class="verbatim-wrap"><pre class="screen">$ openstack network list
+--------------+------------------------+--------------------+
| ID           | Name                   | Subnets            |
+--------------+------------------------+--------------------+
| 3b5a629a-e...| manila_service_network | 4f366100-50...     |
| bee7411d-... | public                 | 884a6564-0f11-...  |
|              |                        | e6da81fa-5d5f-...  |
| 5ed5a854-... | private                | 74dcfb5a-b4d7-...  |
|              |                        | cc297be2-5213-...  |
+--------------+------------------------+--------------------+</pre></div><p>You also can see detailed information about the share network including
<code class="literal">network_type</code>, and <code class="literal">segmentation_id</code> fields:</p><div class="verbatim-wrap"><pre class="screen">$ openstack network show manila_service_network
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | UP                                   |
| availability_zone_hints   |                                      |
| availability_zones        | nova                                 |
| created_at                | 2016-12-13T09:31:30Z                 |
| description               |                                      |
| id                        | 3b5a629a-e7a1-46a3-afb2-ab666fb884bc |
| ipv4_address_scope        | None                                 |
| ipv6_address_scope        | None                                 |
| mtu                       | 1450                                 |
| name                      | manila_service_network               |
| port_security_enabled     | True                                 |
| project_id                | f6ac448a469b45e888050cf837b6e628     |
| provider:network_type     | vxlan                                |
| provider:physical_network | None                                 |
| provider:segmentation_id  | 73                                   |
| revision_number           | 7                                    |
| router:external           | Internal                             |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   | 682e3329-60b0-440f-8749-83ef53dd8544 |
| tags                      | []                                   |
| updated_at                | 2016-12-13T09:31:36Z                 |
+---------------------------+--------------------------------------+</pre></div><p>You also can add and remove the security services from the share network.
For more detail, see <a class="xref" href="#shared-file-systems-security-services" title="8.7. Security services">Section 8.7, “Security services”</a>.</p></div></div><div class="sect2 " id="shared-file-systems-network-plugins"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Network plug-ins</span> <a title="Permalink" class="permalink" href="#shared-file-systems-network-plugins">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>shared-file-systems-network-plugins</li></ul></div></div></div></div><p>The Shared File Systems service architecture defines an abstraction layer for
network resource provisioning and allowing administrators to choose from a
different options for how network resources are assigned to their projects’
networked storage. There are a set of network plug-ins that provide a variety
of integration approaches with the network services that are available with
OpenStack.</p><p>The Shared File Systems service may need a network resource provisioning if
share service with specified driver works in mode, when a share driver manages
lifecycle of share servers on its own. This behavior is defined by a flag
<code class="literal">driver_handles_share_servers</code> in share service configuration.  When
<code class="literal">driver_handles_share_servers</code> is set to <code class="literal">True</code>, a share driver will be
called to create share servers for shares using information provided within a
share network. This information will be provided to one of the enabled network
plug-ins that will handle reservation, creation and deletion of network
resources including IP addresses and network interfaces.</p><div class="sect3 " id="id-1.4.10.15.4.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.11.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What network plug-ins are available?</span> <a title="Permalink" class="permalink" href="#id-1.4.10.15.4.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are three different network plug-ins and five python classes in the
Shared File Systems service:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Network plug-in for using the OpenStack Networking service. It allows to use
any network segmentation that the Networking service supports. It is up to
each share driver to support at least one network segmentation type.</p><ol type="a" class="substeps "><li class="step "><p><code class="literal">manila.network.neutron.neutron_network_plugin.NeutronNetworkPlugin</code>.
This is a default network plug-in. It requires the <code class="literal">neutron_net_id</code> and
the <code class="literal">neutron_subnet_id</code> to be provided when defining the share network
that will be used for the creation of share servers. The user may define
any number of share networks corresponding to the various physical
network segments in a project environment.</p></li><li class="step "><p><code class="literal">manila.network.neutron.neutron_network_plugin.
NeutronSingleNetworkPlugin</code>. This is a simplification of the previous
case. It accepts values for <code class="literal">neutron_net_id</code> and <code class="literal">neutron_subnet_id</code>
from the <code class="literal">manila.conf</code> configuration file and uses one network for all
shares.</p></li></ol><p>When only a single network is needed, the NeutronSingleNetworkPlugin (1.b)
is a simple solution. Otherwise NeutronNetworkPlugin (1.a) should be chosen.</p></li><li class="step "><p>Network plug-in for working with OpenStack Networking from the Compute
service. It supports either flat networks or VLAN-segmented networks.</p><ol type="a" class="substeps "><li class="step "><p><code class="literal">manila.network.nova_network_plugin.NovaNetworkPlugin</code>. This plug-in
serves the networking needs when <code class="literal">Nova networking</code> is configured in
the cloud instead of Neutron. It requires a single parameter,
<code class="literal">nova_net_id</code>.</p></li><li class="step "><p><code class="literal">manila.network.nova_network_plugin.NovaSingleNetworkPlugin</code>. This
plug-in works the same way as
<code class="literal">manila.network.nova_network_plugin.NovaNetworkPlugin</code>, except it takes
<code class="literal">nova_net_id</code> from the Shared File Systems service configuration
file and creates the share servers using only one network.</p></li></ol><p>When only a single network is needed, the NovaSingleNetworkPlugin (2.b) is a
simple solution. Otherwise NovaNetworkPlugin (2.a) should be chosen.</p></li><li class="step "><p>Network plug-in for specifying networks independently from OpenStack
networking services.</p><ol type="a" class="substeps "><li class="step "><p><code class="literal">manila.network.standalone_network_plugin.StandaloneNetworkPlugin</code>.
This plug-in uses a pre-existing network that is available to the
manila-share host. This network may be handled either by OpenStack or be
created independently by any other means. The plug-in supports any type
of network - flat and segmented. As above, it is completely up to the
share driver to support the network type for which the network plug-in is
configured.</p></li></ol></li></ol></div></div><div id="id-1.4.10.15.4.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>These network plug-ins were introduced in the OpenStack Kilo release. In
the OpenStack Juno version, only NeutronNetworkPlugin is available.</p></div><p>More information about network plug-ins can be found in <a class="link" href="http://docs.openstack.org/developer/manila/adminref/network_plugins.html" target="_blank">Manila developer documentation</a></p></div></div></div><div class="sect1 " id="id-1.4.10.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">8.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot Shared File Systems service</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.10.16.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failures in Share File Systems service during a share creation</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.16.2.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.2.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>New shares can enter <code class="literal">error</code> state during the creation process.</p></div><div class="sect3 " id="id-1.4.10.16.2.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.2.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Make sure, that share services are running in debug mode. If the debug mode
is not set, you will not get any tips from logs how to fix your issue.</p></li><li class="step "><p>Find what share service holds a specified share. To do that, run command
<code class="command">manila show &lt;share_id_or_name&gt;</code> and find a share host in the
output. Host uniquely identifies what share service holds the broken share.</p></li><li class="step "><p>Look thought logs of this share service. Usually, it can be found at
<code class="literal">/etc/var/log/manila-share.log</code>. This log should contain kind of
traceback with extra information to help you to find the origin of issues.</p></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.10.16.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">No valid host was found</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.16.3.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.3.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If a share type contains invalid extra specs, the scheduler will not be
able to locate a valid host for the shares.</p></div><div class="sect3 " id="id-1.4.10.16.3.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.3.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To diagnose this issue, make sure that scheduler service is running in
debug mode. Try to create a new share and look for message <code class="literal">Failed to
schedule create_share: No valid host was found.</code> in
<code class="literal">/etc/var/log/manila-scheduler.log</code>.</p><p>To solve this issue look carefully through the list of extra specs in
the share type, and the list of share services reported capabilities.
Make sure that extra specs are pointed in the right way.</p></div></div><div class="sect2 " id="id-1.4.10.16.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.12.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Created share is unreachable</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.16.4.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.4.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By default, a new share does not have any active access rules.</p></div><div class="sect3 " id="id-1.4.10.16.4.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.4.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To provide access to new share, you need to create
appropriate access rule with the right value.
The value must defines access.</p></div></div><div class="sect2 " id="id-1.4.10.16.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.12.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Service becomes unavailable after upgrade</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.16.5.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.5.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>After upgrading the Shared File Systems service from version v1 to version
v2.x, you must update the service endpoint in the OpenStack Identity service.
Otherwise, the service may become unavailable.</p></div><div class="sect3 " id="id-1.4.10.16.5.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.5.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To get the service type related to the Shared File Systems service, run:</p><div class="verbatim-wrap"><pre class="screen"># openstack endpoint list

# openstack endpoint show &lt;share-service-type&gt;</pre></div><p>You will get the endpoints expected from running the Shared File Systems
service.</p></li><li class="step "><p>Make sure that these endpoints are updated. Otherwise, delete the outdated
endpoints and create new ones.</p></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.10.16.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">8.12.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Failures during management of internal resources</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.10.16.6.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.6.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Shared File System service manages internal resources effectively.
Administrators may need to manually adjust internal resources to
handle failures.</p></div><div class="sect3 " id="id-1.4.10.16.6.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">8.12.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.10.16.6.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Some drivers in the Shared File Systems service can create service entities,
like servers and networks. If it is necessary, you can log in to
project <code class="literal">service</code> and take manual control over it.</p></div></div></div></div><div class="chapter " id="networking"><div class="titlepage"><div><div><h1 class="title"><span class="number">9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking</span> <a title="Permalink" class="permalink" href="#networking">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>networking</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.11.4"><span class="number">9.1 </span><span class="name">Introduction to Networking</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.5"><span class="number">9.2 </span><span class="name">Networking architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.6"><span class="number">9.3 </span><span class="name">Plug-in configurations</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.7"><span class="number">9.4 </span><span class="name">Configure neutron agents</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.8"><span class="number">9.5 </span><span class="name">Configure Identity service for Networking</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.9"><span class="number">9.6 </span><span class="name">Advanced configuration options</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.10"><span class="number">9.7 </span><span class="name">Scalable and highly available DHCP agents</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.11"><span class="number">9.8 </span><span class="name">Use Networking</span></a></span></dt><dt><span class="sect1"><a href="#networking-adv-features"><span class="number">9.9 </span><span class="name">Advanced features through API extensions</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.11.13"><span class="number">9.10 </span><span class="name">Advanced operational features</span></a></span></dt><dt><span class="sect1"><a href="#authentication-and-authorization"><span class="number">9.11 </span><span class="name">Authentication and authorization</span></a></span></dt></dl></div></div><p>Learn OpenStack Networking concepts, architecture, and basic and
advanced <code class="literal">neutron</code> and <code class="literal">nova</code> command-line interface (CLI) commands.</p><div class="sect1 " id="id-1.4.11.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction to Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Networking service, code-named neutron, provides an API that lets
you define network connectivity and addressing in the cloud. The
Networking service enables operators to leverage different networking
technologies to power their cloud networking. The Networking service
also provides an API to configure and manage a variety of network
services ranging from L3 forwarding and NAT to load balancing, edge
firewalls, and IPsec VPN.</p><p>For a detailed description of the Networking API abstractions and their
attributes, see the <a class="link" href="http://developer.openstack.org/api-ref/networking/v2/" target="_blank">OpenStack Networking API v2.0
Reference</a>.</p><div id="id-1.4.11.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you use the Networking service, do not run the Compute
<code class="literal">nova-network</code> service (like you do in traditional Compute deployments).
When you configure networking, see the Compute-related topics in this
Networking section.</p></div><div class="sect2 " id="id-1.4.11.4.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking API</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Networking is a virtual network service that provides a powerful API to
define the network connectivity and IP addressing that devices from
other services, such as Compute, use.</p><p>The Compute API has a virtual server abstraction to describe computing
resources. Similarly, the Networking API has virtual network, subnet,
and port abstractions to describe networking resources.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Resource</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <span class="bold"><strong>Network</strong></span>
                  </p>
                </td><td>
                  <p>An isolated L2 segment, analogous to VLAN in the physical
networking world.</p>
                </td></tr><tr><td>
                  <p>
                    <span class="bold"><strong>Subnet</strong></span>
                  </p>
                </td><td>
                  <p>A block of v4 or v6 IP addresses and associated
configuration state.</p>
                </td></tr><tr><td>
                  <p>
                    <span class="bold"><strong>Port</strong></span>
                  </p>
                </td><td>
                  <p>A connection point for attaching a single device, such as
the NIC of a virtual server, to a virtual network. Also
describes the associated network configuration, such as
the MAC and IP addresses to be used on that port.</p>
                </td></tr></tbody></table></div><p>
          <span class="bold"><strong>Networking resources</strong></span>
        </p><p>To configure rich network topologies, you can create and configure
networks and subnets and instruct other OpenStack services like Compute
to attach virtual devices to ports on these networks.</p><p>In particular, Networking supports each project having multiple private
networks and enables projects to choose their own IP addressing scheme,
even if those IP addresses overlap with those that other projects use.</p><p>The Networking service:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Enables advanced cloud networking use cases, such as building
multi-tiered web applications and enabling migration of applications
to the cloud without changing IP addresses.</p></li><li class="listitem "><p>Offers flexibility for administrators to customize network
offerings.</p></li><li class="listitem "><p>Enables developers to extend the Networking API. Over time, the
extended functionality becomes part of the core Networking API.</p></li></ul></div></div><div class="sect2 " id="id-1.4.11.4.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure SSL support for networking API</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Networking supports SSL for the Networking API server. By
default, SSL is disabled but you can enable it in the <code class="literal">neutron.conf</code>
file.</p><p>Set these options to configure SSL:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.4.6.4.1"><span class="term ">
              <code class="literal">use_ssl = True</code>
            </span></dt><dd><p>Enables SSL on the networking API server.</p></dd><dt id="id-1.4.11.4.6.4.2"><span class="term ">
              <code class="literal">ssl_cert_file = PATH_TO_CERTFILE</code>
            </span></dt><dd><p>Certificate file that is used when you securely start the Networking
API server.</p></dd><dt id="id-1.4.11.4.6.4.3"><span class="term ">
              <code class="literal">ssl_key_file = PATH_TO_KEYFILE</code>
            </span></dt><dd><p>Private key file that is used when you securely start the Networking
API server.</p></dd><dt id="id-1.4.11.4.6.4.4"><span class="term ">
              <code class="literal">ssl_ca_file = PATH_TO_CAFILE</code>
            </span></dt><dd><p>Optional. CA certificate file that is used when you securely start
the Networking API server. This file verifies connecting clients.
Set this option when API clients must authenticate to the API server
by using SSL certificates that are signed by a trusted CA.</p></dd><dt id="id-1.4.11.4.6.4.5"><span class="term ">
              <code class="literal">tcp_keepidle = 600</code>
            </span></dt><dd><p>The value of TCP_KEEPIDLE, in seconds, for each server socket when
starting the API server. Not supported on OS X.</p></dd><dt id="id-1.4.11.4.6.4.6"><span class="term ">
              <code class="literal">retry_until_window = 30</code>
            </span></dt><dd><p>Number of seconds to keep retrying to listen.</p></dd><dt id="id-1.4.11.4.6.4.7"><span class="term ">
              <code class="literal">backlog = 4096</code>
            </span></dt><dd><p>Number of backlog requests with which to configure the socket.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.11.4.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Load-Balancer-as-a-Service (LBaaS) overview</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Load-Balancer-as-a-Service (LBaaS) enables Networking to distribute
incoming requests evenly among designated instances. This distribution
ensures that the workload is shared predictably among instances and
enables more effective use of system resources. Use one of these load
balancing methods to distribute incoming requests:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.4.7.3.1"><span class="term ">Round robin</span></dt><dd><p>Rotates requests evenly between multiple instances.</p></dd><dt id="id-1.4.11.4.7.3.2"><span class="term ">Source IP</span></dt><dd><p>Requests from a unique source IP address are consistently directed
to the same instance.</p></dd><dt id="id-1.4.11.4.7.3.3"><span class="term ">Least connections</span></dt><dd><p>Allocates requests to the instance with the least number of active
connections.</p></dd></dl></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Feature</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <span class="bold"><strong>Monitors</strong></span>
                  </p>
                </td><td>
                  <p>LBaaS provides availability monitoring with the
<code class="literal">ping</code>, TCP, HTTP and HTTPS GET methods.
Monitors are implemented to determine whether
pool members are available to handle requests.</p>
                </td></tr><tr><td>
                  <p>
                    <span class="bold"><strong>Management</strong></span>
                  </p>
                </td><td>
                  <p>LBaaS is managed using a variety of tool sets.
The REST API is available for programmatic
administration and scripting. Users perform
administrative management of load balancers
through either the CLI (<code class="literal">neutron</code>) or the
OpenStack Dashboard.</p>
                </td></tr><tr><td>
                  <p>
                    <span class="bold"><strong>Connection limits</strong></span>
                  </p>
                </td><td>
                  <p>Ingress traffic can be shaped with <span class="emphasis"><em>connection
limits</em></span>. This feature allows workload control,
and can also assist with mitigating DoS (Denial
of Service) attacks.</p>
                </td></tr><tr><td>
                  <p>
                    <span class="bold"><strong>Session persistence</strong></span>
                  </p>
                </td><td>
                  <p>LBaaS supports session persistence by ensuring
incoming requests are routed to the same instance
within a pool of multiple instances. LBaaS
supports routing decisions based on cookies and
source IP address.</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.11.4.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Firewall-as-a-Service (FWaaS) overview</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For information on Firewall-as-a-Service (FWaaS), please consult
        the <a class="link" href="http://docs.openstack.org/newton/networking-guide/fwaas.html" target="_blank">Networking
        Guide</a>. OpenSWAN packages are not present in SUSE Linux Enterprise Server 12 SP3.</p></div><div class="sect2 " id="id-1.4.11.4.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Allowed-address-pairs</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><code class="literal">Allowed-address-pairs</code> enables you to specify
mac_address and ip_address(cidr) pairs that pass through a port regardless
of subnet. This enables the use of protocols such as VRRP, which floats
an IP address between two instances to enable fast data plane failover.</p><div id="id-1.4.11.4.9.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Currently, only the ML2, Open vSwitch, and VMware NSX plug-ins
support the allowed-address-pairs extension.</p></div><p>
          <span class="bold"><strong>Basic allowed-address-pairs operations.</strong></span>
        </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a port with a specified allowed address pair:</p><div class="verbatim-wrap"><pre class="screen">$ neutron port-create net1 --allowed-address-pairs type=dict \
  list=true mac_address=MAC_ADDRESS,ip_address=IP_CIDR</pre></div></li><li class="listitem "><p>Update a port by adding allowed address pairs:</p><div class="verbatim-wrap"><pre class="screen">$ neutron port-update PORT_UUID --allowed-address-pairs type=dict \
list=true mac_address=MAC_ADDRESS,ip_address=IP_CIDR</pre></div></li></ul></div></div><div class="sect2 " id="id-1.4.11.4.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Virtual-Private-Network-as-a-Service (VPNaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.11.4.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The VPNaaS extension enables OpenStack projects to extend private networks
across the internet.</p><p>VPNaas is a <a class="xref" href="#term-service" title="service">service</a>. It is a parent object that associates a VPN
with a specific subnet and router. Only one VPN service object can be
created for each router and each subnet. However, each VPN service object
can have any number of IP security connections.</p><p>The Internet Key Exchange (IKE) policy specifies the authentication and
encryption algorithms to use during phase one and two negotiation of a VPN
connection. The IP security policy specifies the authentication and encryption
algorithm and encapsulation mode to use for the established VPN connection.
Note that you cannot update the IKE and IPSec parameters for live tunnels.</p><p>You can set parameters for site-to-site IPsec connections, including peer
CIDRs, MTU, authentication mode, peer address, DPD settings, and status.</p><p>The current implementation of the VPNaaS extension provides:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Site-to-site VPN that connects two private networks.</p></li><li class="listitem "><p>Multiple VPN connections per project.</p></li><li class="listitem "><p>IKEv1 policy support with 3des, aes-128, aes-256, or aes-192 encryption.</p></li><li class="listitem "><p>IPSec policy support with 3des, aes-128, aes-192, or aes-256 encryption,
sha1 authentication, ESP, AH, or AH-ESP transform protocol, and tunnel or
transport mode encapsulation.</p></li><li class="listitem "><p>
            Dead Peer Detection (DPD) with hold, clear, restart, disabled, or
            restart-by-peer actions.
           </p><p>
             OpenSWAN packages are not present in SUSE Linux Enterprise Server 12 SP3.</p></li></ul></div><p>The VPNaaS driver plugin can be configured in the neutron configuration file.
You can then enable the service.</p></div></div><div class="sect1 " id="id-1.4.11.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.11.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Before you deploy Networking, it is useful to understand the Networking
services and how they interact with the OpenStack components.</p><div class="sect2 " id="id-1.4.11.5.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Overview</span> <a title="Permalink" class="permalink" href="#id-1.4.11.5.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Networking is a standalone component in the OpenStack modular
architecture. It is positioned alongside OpenStack components such as
Compute, Image service, Identity, or Dashboard. Like those
components, a deployment of Networking often involves deploying several
services to a variety of hosts.</p><p>The Networking server uses the neutron-server daemon to expose the
Networking API and enable administration of the configured Networking
plug-in. Typically, the plug-in requires access to a database for
persistent storage (also similar to other OpenStack services).</p><p>If your deployment uses a controller host to run centralized Compute
components, you can deploy the Networking server to that same host.
However, Networking is entirely standalone and can be deployed to a
dedicated host. Depending on your configuration, Networking can also
include the following agents:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Agent</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p><span class="bold"><strong>plug-in agent</strong></span>
(<code class="literal">neutron-*-agent</code>)</p>
                </td><td>
                  <p>Runs on each hypervisor to perform
local vSwitch configuration. The agent that
runs, depends on the plug-in that you use.
Certain plug-ins do not require an agent.</p>
                </td></tr><tr><td>
                  <p><span class="bold"><strong>dhcp agent</strong></span>
(<code class="literal">neutron-dhcp-agent</code>)</p>
                </td><td>
                  <p>Provides DHCP services to project networks.
Required by certain plug-ins.</p>
                </td></tr><tr><td>
                  <p><span class="bold"><strong>l3 agent</strong></span>
(<code class="literal">neutron-l3-agent</code>)</p>
                </td><td>
                  <p>Provides L3/NAT forwarding to provide
external network access for VMs on project
networks. Required by certain plug-ins.</p>
                </td></tr><tr><td>
                  <p><span class="bold"><strong>metering agent</strong></span>
(<code class="literal">neutron-metering-agent</code>)</p>
                </td><td>
                  <p>Provides L3 traffic metering for project
networks.</p>
                </td></tr></tbody></table></div><p>These agents interact with the main neutron process through RPC (for
example, RabbitMQ or Qpid) or through the standard Networking API. In
addition, Networking integrates with OpenStack components in a number of
ways:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Networking relies on the Identity service (keystone) for the
authentication and authorization of all API requests.</p></li><li class="listitem "><p>Compute (nova) interacts with Networking through calls to its
standard API. As part of creating a VM, the <code class="literal">nova-compute</code> service
communicates with the Networking API to plug each virtual NIC on the
VM into a particular network.</p></li><li class="listitem "><p>The dashboard (horizon) integrates with the Networking API, enabling
administrators and project users to create and manage network services
through a web-based GUI.</p></li></ul></div></div><div class="sect2 " id="id-1.4.11.5.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VMware NSX integration</span> <a title="Permalink" class="permalink" href="#id-1.4.11.5.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStack Networking uses the NSX plug-in to integrate with an existing
VMware vCenter deployment. When installed on the network nodes, the NSX
plug-in enables a NSX controller to centrally manage configuration
settings and push them to managed network nodes. Network nodes are
considered managed when they are added as hypervisors to the NSX
controller.</p><p>The diagrams below depict some VMware NSX deployment examples. The first
diagram illustrates the traffic flow between VMs on separate Compute
nodes, and the second diagram between two VMs on a single compute node.
Note the placement of the VMware NSX plug-in and the neutron-server
service on the network node. The green arrow indicates the management
relationship between the NSX controller and the network node.</p><div class="figure" id="id-1.4.11.5.4.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/vmware_nsx_ex1.png" target="_blank"><img src="images/vmware_nsx_ex1.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 9.1: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.11.5.4.4">#</a></h6></div></div><div class="figure" id="id-1.4.11.5.4.5"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/vmware_nsx_ex2.png" target="_blank"><img src="images/vmware_nsx_ex2.png" width="" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 9.2: </span><span class="name"> </span><a title="Permalink" class="permalink" href="#id-1.4.11.5.4.5">#</a></h6></div></div></div></div><div class="sect1 " id="id-1.4.11.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Plug-in configurations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For configurations options, see <a class="link" href="http://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html" target="_blank">Networking configuration
options</a>
in Configuration Reference. These sections explain how to configure
specific plug-ins.</p><div class="sect2 " id="id-1.4.11.6.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Big Switch (Floodlight REST Proxy) plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.6.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Edit the <code class="literal">/etc/neutron/neutron.conf</code> file and add this line:</p><div class="verbatim-wrap highlight ini"><pre class="screen">core_plugin = bigswitch</pre></div></li><li class="step "><p>In the <code class="literal">/etc/neutron/neutron.conf</code> file, set the <code class="literal">service_plugins</code>
option:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_plugins = neutron.plugins.bigswitch.l3_router_plugin.L3RestProxy</pre></div></li><li class="step "><p>Edit the <code class="literal">/etc/neutron/plugins/bigswitch/restproxy.ini</code> file for the
plug-in and specify a comma-separated list of controller_ip:port pairs:</p><div class="verbatim-wrap highlight ini"><pre class="screen">server = CONTROLLER_IP:PORT</pre></div><p>For database configuration, see <a class="link" href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html" target="_blank">Install Networking
Services</a>
in the Installation Tutorials and Guides. (The link defaults to the Ubuntu
version.)</p></li><li class="step "><p>Restart the <code class="literal">neutron-server</code> to apply the settings:</p><div class="verbatim-wrap"><pre class="screen"># service neutron-server restart</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.11.6.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Brocade plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.6.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install the Brocade-modified Python netconf client (ncclient) library,
which is available at <a class="link" href="https://github.com/brocade/ncclient" target="_blank">https://github.com/brocade/ncclient</a>:</p><div class="verbatim-wrap"><pre class="screen">$ git clone https://github.com/brocade/ncclient</pre></div></li><li class="step "><p>As root, run this command:</p><div class="verbatim-wrap"><pre class="screen"># cd ncclient;python setup.py install</pre></div></li><li class="step "><p>Edit the <code class="literal">/etc/neutron/neutron.conf</code> file and set the following
option:</p><div class="verbatim-wrap highlight ini"><pre class="screen">core_plugin = brocade</pre></div></li><li class="step "><p>Edit the <code class="literal">/etc/neutron/plugins/brocade/brocade.ini</code> file for the
Brocade plug-in and specify the admin user name, password, and IP
address of the Brocade switch:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[SWITCH]
username = ADMIN
password = PASSWORD
address  = SWITCH_MGMT_IP_ADDRESS
ostype   = NOS</pre></div><p>For database configuration, see <a class="link" href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html" target="_blank">Install Networking
Services</a>
in any of the Installation Tutorials and Guides in the <a class="link" href="http://docs.openstack.org" target="_blank">OpenStack Documentation
index</a>. (The link defaults to the Ubuntu
version.)</p></li><li class="step "><p>Restart the <code class="literal">neutron-server</code> service to apply the settings:</p><div class="verbatim-wrap"><pre class="screen"># service neutron-server restart</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.11.6.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure NSX-mh plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.6.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The instructions in this section refer to the VMware NSX-mh platform,
formerly known as Nicira NVP.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install the NSX plug-in:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install neutron-plugin-vmware</pre></div></li><li class="step "><p>Edit the <code class="literal">/etc/neutron/neutron.conf</code> file and set this line:</p><div class="verbatim-wrap highlight ini"><pre class="screen">core_plugin = vmware</pre></div><p>Example <code class="literal">neutron.conf</code> file for NSX-mh integration:</p><div class="verbatim-wrap highlight ini"><pre class="screen">core_plugin = vmware
rabbit_host = 192.168.203.10
allow_overlapping_ips = True</pre></div></li><li class="step "><p>To configure the NSX-mh controller cluster for OpenStack Networking,
locate the <code class="literal">[default]</code> section in the
<code class="literal">/etc/neutron/plugins/vmware/nsx.ini</code> file and add the following
entries:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To establish and configure the connection with the controller cluster
you must set some parameters, including NSX-mh API endpoints, access
credentials, and optionally specify settings for HTTP timeouts,
redirects and retries in case of connection failures:</p><div class="verbatim-wrap highlight ini"><pre class="screen">nsx_user = ADMIN_USER_NAME
nsx_password = NSX_USER_PASSWORD
http_timeout = HTTP_REQUEST_TIMEOUT # (seconds) default 75 seconds
retries = HTTP_REQUEST_RETRIES # default 2
redirects = HTTP_REQUEST_MAX_REDIRECTS # default 2
nsx_controllers = API_ENDPOINT_LIST # comma-separated list</pre></div><p>To ensure correct operations, the <code class="literal">nsx_user</code> user must have
administrator credentials on the NSX-mh platform.</p><p>A controller API endpoint consists of the IP address and port for the
controller; if you omit the port, port 443 is used. If multiple API
endpoints are specified, it is up to the user to ensure that all
these endpoints belong to the same controller cluster. The OpenStack
Networking VMware NSX-mh plug-in does not perform this check, and
results might be unpredictable.</p><p>When you specify multiple API endpoints, the plug-in takes care of
load balancing requests on the various API endpoints.</p></li><li class="listitem "><p>The UUID of the NSX-mh transport zone that should be used by default
when a project creates a network. You can get this value from the
Transport Zones page for the NSX-mh manager:</p><p>Alternatively the transport zone identifier can be retrieved by query
the NSX-mh API: <code class="literal">/ws.v1/transport-zone</code></p><div class="verbatim-wrap highlight ini"><pre class="screen">default_tz_uuid = TRANSPORT_ZONE_UUID</pre></div></li><li class="listitem "><div class="verbatim-wrap highlight ini"><pre class="screen">default_l3_gw_service_uuid = GATEWAY_SERVICE_UUID</pre></div><div id="id-1.4.11.6.5.3.3.2.3.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Ubuntu packaging currently does not update the neutron init
script to point to the NSX-mh configuration file. Instead, you
must manually update <code class="literal">/etc/default/neutron-server</code> to add this
line:</p><div class="verbatim-wrap highlight ini"><pre class="screen">NEUTRON_PLUGIN_CONFIG = /etc/neutron/plugins/vmware/nsx.ini</pre></div></div><p>For database configuration, see <a class="link" href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html" target="_blank">Install Networking
Services</a>
in the Installation Tutorials and Guides.</p></li></ul></div></li><li class="step "><p>Restart <code class="literal">neutron-server</code> to apply settings:</p><div class="verbatim-wrap"><pre class="screen"># service neutron-server restart</pre></div><div id="id-1.4.11.6.5.3.4.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>The neutron NSX-mh plug-in does not implement initial
re-synchronization of Neutron resources. Therefore resources that
might already exist in the database when Neutron is switched to the
NSX-mh plug-in will not be created on the NSX-mh backend upon
restart.</p></div></li></ol></div></div><p>Example <code class="literal">nsx.ini</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
default_tz_uuid = d3afb164-b263-4aaa-a3e4-48e0e09bb33c
default_l3_gw_service_uuid=5c8622cc-240a-40a1-9693-e6a5fca4e3cf
nsx_user=admin
nsx_password=changeme
nsx_controllers=10.127.0.100,10.127.0.200:8888</pre></div><div id="id-1.4.11.6.5.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To debug <code class="literal">nsx.ini</code> configuration issues, run this command from the
host that runs neutron-server:</p></div><div class="verbatim-wrap"><pre class="screen"># neutron-check-nsx-config PATH_TO_NSX.INI</pre></div><p>This command tests whether <code class="literal">neutron-server</code> can log into all of the
NSX-mh controllers and the SQL server, and whether all UUID values
are correct.</p></div><div class="sect2 " id="id-1.4.11.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure PLUMgrid plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Edit the <code class="literal">/etc/neutron/neutron.conf</code> file and set this line:</p><div class="verbatim-wrap highlight ini"><pre class="screen">core_plugin = plumgrid</pre></div></li><li class="step "><p>Edit the [PLUMgridDirector] section in the
<code class="literal">/etc/neutron/plugins/plumgrid/plumgrid.ini</code> file and specify the IP
address, port, admin user name, and password of the PLUMgrid Director:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[PLUMgridDirector]
director_server = "PLUMgrid-director-ip-address"
director_server_port = "PLUMgrid-director-port"
username = "PLUMgrid-director-admin-username"
password = "PLUMgrid-director-admin-password"</pre></div><p>For database configuration, see <a class="link" href="http://docs.openstack.org/newton/install-guide-ubuntu/neutron-controller-install.html" target="_blank">Install Networking
Services</a>
in the Installation Tutorials and Guides.</p></li><li class="step "><p>Restart the <code class="literal">neutron-server</code> service to apply the settings:</p><div class="verbatim-wrap"><pre class="screen"># service neutron-server restart</pre></div></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.11.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure neutron agents</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Plug-ins typically have requirements for particular software that must
be run on each node that handles data packets. This includes any node
that runs nova-compute and nodes that run dedicated OpenStack Networking
service agents such as <code class="literal">neutron-dhcp-agent</code>, <code class="literal">neutron-l3-agent</code>,
<code class="literal">neutron-metering-agent</code> or <code class="literal">neutron-lbaasv2-agent</code>.</p><p>A data-forwarding node typically has a network interface with an IP
address on the management network and another interface on the data
network.</p><p>This section shows you how to install and configure a subset of the
available plug-ins, which might include the installation of switching
software (for example, <code class="literal">Open vSwitch</code>) and as agents used to communicate
with the <code class="literal">neutron-server</code> process running elsewhere in the data center.</p><div class="sect2 " id="id-1.4.11.7.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure data-forwarding nodes</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.11.7.5.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.4.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Node set up: NSX plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.5.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you use the NSX plug-in, you must also install Open vSwitch on each
data-forwarding node. However, you do not need to install an additional
agent on each node.</p><div id="id-1.4.11.7.5.2.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>It is critical that you run an Open vSwitch version that is
compatible with the current version of the NSX Controller software.
Do not use the Open vSwitch version that is installed by default on
Ubuntu. Instead, use the Open vSwitch version that is provided on
the VMware support portal for your NSX Controller version.</p></div><p>
            <span class="bold"><strong>To set up each node for the NSX plug-in</strong></span>
          </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Ensure that each data-forwarding node has an IP address on the
management network, and an IP address on the data network that is used
for tunneling data traffic. For full details on configuring your
forwarding node, see the <a class="link" href="http://pubs.vmware.com/NSX-62/index.jsp#com.vmware.nsx.admin.doc/GUID-B5C70003-8194-4EC3-AB36-54C848508818.html" target="_blank">NSX Administration Guide</a>.</p></li><li class="step "><p>Use the NSX Administrator Guide to add the node as a Hypervisor
by using the NSX Manager GUI. Even if your forwarding node has no
VMs and is only used for services agents like <code class="literal">neutron-dhcp-agent</code>
or <code class="literal">neutron-lbaas-agent</code>, it should still be added to NSX as a
Hypervisor.</p></li><li class="step "><p>After following the NSX Administrator Guide, use the page for this
Hypervisor in the NSX Manager GUI to confirm that the node is properly
connected to the NSX Controller Cluster and that the NSX Controller
Cluster can see the <code class="literal">br-int</code> integration bridge.</p></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.11.7.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure DHCP agent</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The DHCP service agent is compatible with all existing plug-ins and is
required for all deployments where VMs should automatically receive IP
addresses through DHCP.</p><p>
          <span class="bold"><strong>To install and configure the DHCP agent</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>You must configure the host running the neutron-dhcp-agent as a data
forwarding node according to the requirements for your plug-in.</p></li><li class="step "><p>Install the DHCP agent:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install neutron-dhcp-agent</pre></div></li><li class="step "><p>Update any options in the <code class="literal">/etc/neutron/dhcp_agent.ini</code> file
that depend on the plug-in in use. See the sub-sections.</p><div id="id-1.4.11.7.6.4.3.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>If you reboot a node that runs the DHCP agent, you must run the
<code class="command">neutron-ovs-cleanup</code> command before the <code class="literal">neutron-dhcp-agent</code>
service starts.</p><p>On Red Hat, SUSE, and Ubuntu based systems, the
<code class="literal">neutron-ovs-cleanup</code> service runs the <code class="command">neutron-ovs-cleanup</code>
command automatically. However, on Debian-based systems, you
must manually run this command or write your own system script
that runs on boot before the <code class="literal">neutron-dhcp-agent</code> service starts.</p></div></li></ol></div></div><p>Networking dhcp-agent can use
<a class="link" href="http://www.thekelleys.org.uk/dnsmasq/doc.html" target="_blank">dnsmasq</a> driver which
supports stateful and stateless DHCPv6 for subnets created with
<code class="literal">--ipv6_address_mode</code> set to <code class="literal">dhcpv6-stateful</code> or
<code class="literal">dhcpv6-stateless</code>.</p><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack subnet create --ip-version 6 --ipv6-ra-mode dhcpv6-stateful \
  --ipv6-address-mode dhcpv6-stateful --network NETWORK --subnet-range \
  CIDR SUBNET_NAME</pre></div><div class="verbatim-wrap"><pre class="screen">$ openstack subnet create --ip-version 6 --ipv6-ra-mode dhcpv6-stateless \
  --ipv6-address-mode dhcpv6-stateless --network NETWORK --subnet-range \
  CIDR SUBNET_NAME</pre></div><p>If no dnsmasq process for subnet's network is launched, Networking will
launch a new one on subnet's dhcp port in <code class="literal">qdhcp-XXX</code> namespace. If
previous dnsmasq process is already launched, restart dnsmasq with a new
configuration.</p><p>Networking will update dnsmasq process and restart it when subnet gets
updated.</p><div id="id-1.4.11.7.6.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For dhcp-agent to operate in IPv6 mode use at least dnsmasq v2.63.</p></div><p>After a certain, configured timeframe, networks uncouple from DHCP
agents when the agents are no longer in use. You can configure the DHCP
agent to automatically detach from a network when the agent is out of
service, or no longer needed.</p><p>This feature applies to all plug-ins that support DHCP scaling. For more
information, see the <a class="link" href="http://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#dhcp-agent" target="_blank">DHCP agent configuration
options</a>
listed in the OpenStack Configuration Reference.</p><div class="sect3 " id="id-1.4.11.7.6.14"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.4.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DHCP agent setup: OVS plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.6.14">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These DHCP agent options are required in the
<code class="literal">/etc/neutron/dhcp_agent.ini</code> file for the OVS plug-in:</p><div class="verbatim-wrap highlight bash"><pre class="screen">[DEFAULT]
enable_isolated_metadata = True
interface_driver = openvswitch</pre></div></div><div class="sect3 " id="id-1.4.11.7.6.15"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.4.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DHCP agent setup: NSX plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.6.15">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These DHCP agent options are required in the
<code class="literal">/etc/neutron/dhcp_agent.ini</code> file for the NSX plug-in:</p><div class="verbatim-wrap highlight bash"><pre class="screen">[DEFAULT]
enable_metadata_network = True
enable_isolated_metadata = True
interface_driver = openvswitch</pre></div></div><div class="sect3 " id="id-1.4.11.7.6.16"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.4.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DHCP agent setup: Linux-bridge plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.6.16">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These DHCP agent options are required in the
<code class="literal">/etc/neutron/dhcp_agent.ini</code> file for the Linux-bridge plug-in:</p><div class="verbatim-wrap highlight bash"><pre class="screen">[DEFAULT]
enabled_isolated_metadata = True
interface_driver = linuxbridge</pre></div></div></div><div class="sect2 " id="id-1.4.11.7.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure L3 agent</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Networking service has a widely used API extension to
allow administrators and projects to create routers to interconnect L2
networks, and floating IPs to make ports on private networks publicly
accessible.</p><p>Many plug-ins rely on the L3 service agent to implement the L3
functionality. However, the following plug-ins already have built-in L3
capabilities:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Big Switch/Floodlight plug-in, which supports both the open source
<a class="link" href="http://www.projectfloodlight.org/floodlight/" target="_blank">Floodlight</a>
controller and the proprietary Big Switch controller.</p><div id="id-1.4.11.7.7.4.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only the proprietary BigSwitch controller implements L3
functionality. When using Floodlight as your OpenFlow controller,
L3 functionality is not available.</p></div></li><li class="listitem "><p>IBM SDN-VE plug-in</p></li><li class="listitem "><p>MidoNet plug-in</p></li><li class="listitem "><p>NSX plug-in</p></li><li class="listitem "><p>PLUMgrid plug-in</p></li></ul></div><div id="id-1.4.11.7.7.5" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Do not configure or use <code class="literal">neutron-l3-agent</code> if you use one of these
plug-ins.</p></div><p>
          <span class="bold"><strong>To install the L3 agent for all other plug-ins</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install the <code class="literal">neutron-l3-agent</code> binary on the network node:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install neutron-l3-agent</pre></div></li><li class="step "><p>To uplink the node that runs <code class="literal">neutron-l3-agent</code> to the external network,
create a bridge named <code class="literal">br-ex</code> and attach the NIC for the external
network to this bridge.</p><p>For example, with Open vSwitch and NIC eth1 connected to the external
network, run:</p><div class="verbatim-wrap"><pre class="screen"># ovs-vsctl add-br br-ex
# ovs-vsctl add-port br-ex eth1</pre></div><p>When the <code class="literal">br-ex</code> port is added to the <code class="literal">eth1</code> interface, external
communication is interrupted. To avoid this, edit the
<code class="literal">/etc/network/interfaces</code> file to contain the following information:</p><div class="verbatim-wrap highlight ini"><pre class="screen">## External bridge
auto br-ex
iface br-ex inet static
address 192.27.117.101
netmask 255.255.240.0
gateway 192.27.127.254
dns-nameservers 8.8.8.8

## External network interface
auto eth1
iface eth1 inet manual
up ifconfig $IFACE 0.0.0.0 up
up ip link set $IFACE promisc on
down ip link set $IFACE promisc off
down ifconfig $IFACE down</pre></div><div id="id-1.4.11.7.7.7.2.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The external bridge configuration address is the external IP address.
This address and gateway should be configured in
<code class="literal">/etc/network/interfaces</code>.</p></div><p>After editing the configuration, restart <code class="literal">br-ex</code>:</p><div class="verbatim-wrap"><pre class="screen"># ifdown br-ex &amp;&amp; ifup br-ex</pre></div><p>Do not manually configure an IP address on the NIC connected to the
external network for the node running <code class="literal">neutron-l3-agent</code>. Rather, you
must have a range of IP addresses from the external network that can be
used by OpenStack Networking for routers that uplink to the external
network. This range must be large enough to have an IP address for each
router in the deployment, as well as each floating IP.</p></li><li class="step "><p>The <code class="literal">neutron-l3-agent</code> uses the Linux IP stack and iptables to perform L3
forwarding and NAT. In order to support multiple routers with
potentially overlapping IP addresses, <code class="literal">neutron-l3-agent</code> defaults to
using Linux network namespaces to provide isolated forwarding contexts.
As a result, the IP addresses of routers are not visible simply by running
the <code class="command">ip addr list</code> or <code class="command">ifconfig</code> command on the node.
Similarly, you cannot directly <code class="command">ping</code> fixed IPs.</p><p>To do either of these things, you must run the command within a
particular network namespace for the router. The namespace has the name
<code class="literal">qrouter-ROUTER_UUID</code>. These example commands run in the router
namespace with UUID 47af3868-0fa8-4447-85f6-1304de32153b:</p><div class="verbatim-wrap"><pre class="screen"># ip netns exec qrouter-47af3868-0fa8-4447-85f6-1304de32153b ip addr list</pre></div><div class="verbatim-wrap"><pre class="screen"># ip netns exec qrouter-47af3868-0fa8-4447-85f6-1304de32153b ping FIXED_IP</pre></div><div id="id-1.4.11.7.7.7.3.5" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>If you reboot a node that runs the L3 agent, you must run the
<code class="command">neutron-ovs-cleanup</code> command before the <code class="literal">neutron-l3-agent</code>
service starts.</p><p>On Red Hat, SUSE and Ubuntu based systems, the neutron-ovs-cleanup
service runs the <code class="command">neutron-ovs-cleanup</code> command
automatically. However, on Debian-based systems, you must manually
run this command or write your own system script that runs on boot
before the neutron-l3-agent service starts.</p></div></li></ol></div></div><p><span class="bold"><strong>How routers are assigned to L3 agents</strong></span>
By default, a router is assigned to the L3 agent with the least number
of routers (LeastRoutersScheduler). This can be changed by altering the
<code class="literal">router_scheduler_driver</code> setting in the configuration file.</p></div><div class="sect2 " id="id-1.4.11.7.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure metering agent</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Neutron Metering agent resides beside neutron-l3-agent.</p><p>
          <span class="bold"><strong>To install the metering agent and configure the node</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install the agent by running:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install neutron-metering-agent</pre></div></li><li class="step "><p>If you use one of the following plug-ins, you need to configure the
metering agent with these lines as well:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>An OVS-based plug-in such as OVS, NSX, NEC, BigSwitch/Floodlight:</p><div class="verbatim-wrap highlight ini"><pre class="screen">interface_driver = openvswitch</pre></div></li><li class="listitem "><p>A plug-in that uses LinuxBridge:</p><div class="verbatim-wrap highlight ini"><pre class="screen">interface_driver = linuxbridge</pre></div></li></ul></div></li><li class="step "><p>To use the reference implementation, you must set:</p><div class="verbatim-wrap highlight ini"><pre class="screen">driver = neutron.services.metering.drivers.iptables.iptables_driver
.IptablesMeteringDriver</pre></div></li><li class="step "><p>Set the <code class="literal">service_plugins</code> option in the <code class="literal">/etc/neutron/neutron.conf</code>
file on the host that runs <code class="literal">neutron-server</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_plugins = metering</pre></div><p>If this option is already defined, add <code class="literal">metering</code> to the list, using a
comma as separator. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_plugins = router,metering</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.11.7.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Load-Balancer-as-a-Service (LBaaS v2)</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For the back end, use either <a class="xref" href="#term-octavia" title="Octavia">Octavia</a> or <a class="xref" href="#term-haproxy" title="HAProxy">HAProxy</a>.
This example uses Octavia.</p><p>
          <span class="bold"><strong>To configure LBaaS V2</strong></span>
        </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install Octavia using your distribution's package manager.</p></li><li class="step "><p>Edit the <code class="literal">/etc/neutron/neutron_lbaas.conf</code> file and change
the <code class="literal">service_provider</code> parameter to enable Octavia:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_provider = LOADBALANCERV2:Octavia:neutron_lbaas.
drivers.octavia.driver.OctaviaDriver:default</pre></div></li><li class="step "><p>Edit the <code class="literal">/etc/neutron/neutron.conf</code> file and add the
<code class="literal">service_plugins</code> parameter to enable the load-balancing plug-in:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_plugins = neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2</pre></div><p>If this option is already defined, add the load-balancing plug-in to
the list using a comma as a separator. For example:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_plugins = [already defined plugins],neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2</pre></div></li><li class="step "><p>Create the required tables in the database:</p><div class="verbatim-wrap"><pre class="screen"># neutron-db-manage --subproject neutron-lbaas upgrade head</pre></div></li><li class="step "><p>Restart the <code class="literal">neutron-server</code> service.</p></li><li class="step "><p>Enable load balancing in the Project section of the dashboard.</p><div id="id-1.4.11.7.9.4.6.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Horizon panels are enabled only for LBaaSV1. LBaaSV2 panels are still
being developed.</p></div><p>By default, the <code class="literal">enable_lb</code> option is <code class="literal">True</code> in the <code class="literal">local_settings.py</code>
file.</p><div class="verbatim-wrap highlight python"><pre class="screen">OPENSTACK_NEUTRON_NETWORK = {
    'enable_lb': True,
    ...
}</pre></div><p>Apply the settings by restarting the web server. You can now view the
Load Balancer management options in the Project view in the dashboard.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.11.7.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.4.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic operations on agents</span> <a title="Permalink" class="permalink" href="#id-1.4.11.7.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This table shows examples of Networking commands that enable you to
complete basic operations on agents.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Operation</p>
                </th><th>
                  <p>Command</p>
                </th></tr></thead><tbody><tr><td>
                  <p>List all available agents.</p>
                </td><td>
                  <p>
                    <code class="literal">$ openstack network agent list</code>
                  </p>
                </td></tr><tr><td>
                  <p>Show information of a given agent.</p>
                </td><td>
                  <p>
                    <code class="literal">$ openstack network agent show AGENT_ID</code>
                  </p>
                </td></tr><tr><td>
                  <p>Update the admin status and description for a specified agent. The
command can be used to enable and disable agents by using
<code class="literal">--admin-state-up</code> parameter set to <code class="literal">False</code> or <code class="literal">True</code>.</p>
                </td><td>
                  <p>
                    <code class="literal">$ neutron agent-update --admin-state-up False AGENT_ID</code>
                  </p>
                </td></tr><tr><td>
                  <p>Delete a given agent. Consider disabling the agent before deletion.</p>
                </td><td>
                  <p>
                    <code class="literal">$ openstack network agent delete AGENT_ID</code>
                  </p>
                </td></tr></tbody></table></div><p>
          <span class="bold"><strong>Basic operations on Networking agents</strong></span>
        </p><p>See the <a class="link" href="http://docs.openstack.org/cli-reference/neutron.html" target="_blank">OpenStack Command-Line Interface
Reference</a>
for more information on Networking commands.</p></div></div><div class="sect1 " id="id-1.4.11.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Identity service for Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.11.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
        <span class="bold"><strong>To configure the Identity service for use with Networking</strong></span>
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the <code class="literal">get_id()</code> function</p><p>The <code class="literal">get_id()</code> function stores the ID of created objects, and removes
the need to copy and paste object IDs in later steps:</p><ol type="a" class="substeps "><li class="step "><p>Add the following function to your <code class="literal">.bashrc</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">function get_id () {
echo `"$@" | awk '/ id / { print $4 }'`
}</pre></div></li><li class="step "><p>Source the <code class="literal">.bashrc</code> file:</p><div class="verbatim-wrap"><pre class="screen">$ source .bashrc</pre></div></li></ol></li><li class="step "><p>Create the Networking service entry</p><p>Networking must be available in the Compute service catalog. Create the
service:</p><div class="verbatim-wrap"><pre class="screen">$ NEUTRON_SERVICE_ID=$(get_id openstack service create network \
  --name neutron --description 'OpenStack Networking Service')</pre></div></li><li class="step "><p>Create the Networking service endpoint entry</p><div id="id-1.4.11.8.3.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
           Cloud 8 does not support multiple regions, so for the
           following steps you should use the default
           <code class="literal">RegionOne</code> region.
          </p></div><p>The way that you create a Networking endpoint entry depends on whether
you are using the SQL or the template catalog driver:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>If you are using the <code class="literal">SQL driver</code>, run the following command with the
specified region (<code class="literal">$REGION</code>), IP address of the Networking server
(<code class="literal">$IP</code>), and service ID (<code class="literal">$NEUTRON_SERVICE_ID</code>, obtained in the
previous step).</p><div class="verbatim-wrap"><pre class="screen">$ openstack endpoint create $NEUTRON_SERVICE_ID --region $REGION \
  --publicurl 'http://$IP:9696/' --adminurl 'http://$IP:9696/' \
  --internalurl 'http://$IP:9696/'</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack endpoint create $NEUTRON_SERVICE_ID --region myregion \
  --publicurl "http://10.211.55.17:9696/" \
  --adminurl "http://10.211.55.17:9696/" \
  --internalurl "http://10.211.55.17:9696/"</pre></div></li><li class="listitem "><p>If you are using the <code class="literal">template driver</code>, specify the following
parameters in your Compute catalog template file
(<code class="literal">default_catalog.templates</code>), along with the region (<code class="literal">$REGION</code>)
and IP address of the Networking server (<code class="literal">$IP</code>).</p><div class="verbatim-wrap highlight bash"><pre class="screen">catalog.$REGION.network.publicURL = http://$IP:9696
catalog.$REGION.network.adminURL = http://$IP:9696
catalog.$REGION.network.internalURL = http://$IP:9696
catalog.$REGION.network.name = Network Service</pre></div><p>For example:</p><div class="verbatim-wrap highlight bash"><pre class="screen">catalog.$Region.network.publicURL = http://10.211.55.17:9696
catalog.$Region.network.adminURL = http://10.211.55.17:9696
catalog.$Region.network.internalURL = http://10.211.55.17:9696
catalog.$Region.network.name = Network Service</pre></div></li></ul></div></li><li class="step "><p>Create the Networking service user</p><p>You must provide admin user credentials that Compute and some internal
Networking components can use to access the Networking API. Create a
special <code class="literal">service</code> project and a <code class="literal">neutron</code> user within this project,
and assign an <code class="literal">admin</code> role to this role.</p><ol type="a" class="substeps "><li class="step "><p>Create the <code class="literal">admin</code> role:</p><div class="verbatim-wrap"><pre class="screen">$ ADMIN_ROLE=$(get_id openstack role create admin)</pre></div></li><li class="step "><p>Create the <code class="literal">neutron</code> user:</p><div class="verbatim-wrap"><pre class="screen">$ NEUTRON_USER=$(get_id openstack user create neutron \
  --password "$NEUTRON_PASSWORD" --email demo@example.com \
  --project service)</pre></div></li><li class="step "><p>Create the <code class="literal">service</code> project:</p><div class="verbatim-wrap"><pre class="screen">$ SERVICE_TENANT=$(get_id openstack project create service \
  --description "Services project" --domain default)</pre></div></li><li class="step "><p>Establish the relationship among the project, user, and role:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role add $ADMIN_ROLE --user $NEUTRON_USER \
  --project $SERVICE_TENANT</pre></div></li></ol></li></ol></div></div><p>For information about how to create service entries and users, see the <a class="link" href="http://docs.openstack.org/project-install-guide/newton/" target="_blank">Newton Installation
Tutorials and Guides</a>
for your distribution.</p><div class="sect2 " id="id-1.4.11.8.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute</span> <a title="Permalink" class="permalink" href="#id-1.4.11.8.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you use Networking, do not run the Compute <code class="literal">nova-network</code> service (like
you do in traditional Compute deployments). Instead, Compute delegates
most network-related decisions to Networking.</p><div id="id-1.4.11.8.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Uninstall <code class="literal">nova-network</code> and reboot any physical nodes that have been
running <code class="literal">nova-network</code> before using them to run Networking.
Inadvertently running the <code class="literal">nova-network</code> process while using
Networking can cause problems, as can stale iptables rules pushed
down by previously running <code class="literal">nova-network</code>.</p></div><p>Compute proxies project-facing API calls to manage security groups and
floating IPs to Networking APIs. However, operator-facing tools such
as <code class="literal">nova-manage</code>, are not proxied and should not be used.</p><div id="id-1.4.11.8.5.5" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>When you configure networking, you must use this guide. Do not rely
on Compute networking documentation or past experience with Compute.
If a <code class="command">nova</code> command or configuration option related to networking
is not mentioned in this guide, the command is probably not
supported for use with Networking. In particular, you cannot use CLI
tools like <code class="literal">nova-manage</code> and <code class="literal">nova</code> to manage networks or IP
addressing, including both fixed and floating IPs, with Networking.</p></div><p>To ensure that Compute works properly with Networking (rather than the
legacy <code class="literal">nova-network</code> mechanism), you must adjust settings in the
<code class="literal">nova.conf</code> configuration file.</p></div><div class="sect2 " id="id-1.4.11.8.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking API and credential configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.11.8.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Each time you provision or de-provision a VM in Compute, <code class="literal">nova-\*</code>
services communicate with Networking using the standard API. For this to
happen, you must configure the following items in the <code class="literal">nova.conf</code> file
(used by each <code class="literal">nova-compute</code> and <code class="literal">nova-api</code> instance).</p><div class="table" id="id-1.4.11.8.6.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.1: </span><span class="name">nova.conf API and credential settings prior to Mitaka </span><a title="Permalink" class="permalink" href="#id-1.4.11.8.6.3">#</a></h6></div><div class="table-contents"><table class="table" summary="nova.conf API and credential settings prior to Mitaka" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Attribute name</p>
                </th><th>
                  <p>Required</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <code class="literal">[DEFAULT] use_neutron</code>
                  </p>
                </td><td>
                  <p>Modify from the default to <code class="literal">True</code> to
indicate that Networking should be used rather than the traditional
nova-network networking model.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] url</code>
                  </p>
                </td><td>
                  <p>Update to the host name/IP and port of the neutron-server instance
for this deployment.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] auth_strategy</code>
                  </p>
                </td><td>
                  <p>Keep the default <code class="literal">keystone</code> value for all production deployments.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] admin_project_name</code>
                  </p>
                </td><td>
                  <p>Update to the name of the service tenant created in the above section on
Identity configuration.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] admin_username</code>
                  </p>
                </td><td>
                  <p>Update to the name of the user created in the above section on Identity
configuration.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] admin_password</code>
                  </p>
                </td><td>
                  <p>Update to the password of the user created in the above section on
Identity configuration.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] admin_auth_url</code>
                  </p>
                </td><td>
                  <p>Update to the Identity server IP and port. This is the Identity
(keystone) admin API server IP and port value, and not the Identity
service API IP and port.</p>
                </td></tr></tbody></table></div></div><div class="table" id="id-1.4.11.8.6.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.2: </span><span class="name">nova.conf API and credential settings in Newton </span><a title="Permalink" class="permalink" href="#id-1.4.11.8.6.4">#</a></h6></div><div class="table-contents"><table class="table" summary="nova.conf API and credential settings in Newton" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Attribute name</p>
                </th><th>
                  <p>Required</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <code class="literal">[DEFAULT] use_neutron</code>
                  </p>
                </td><td>
                  <p>Modify from the default to <code class="literal">True</code> to
indicate that Networking should be used rather than the traditional
nova-network networking model.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] url</code>
                  </p>
                </td><td>
                  <p>Update to the host name/IP and port of the neutron-server instance
for this deployment.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] auth_strategy</code>
                  </p>
                </td><td>
                  <p>Keep the default <code class="literal">keystone</code> value for all production deployments.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] project_name</code>
                  </p>
                </td><td>
                  <p>Update to the name of the service tenant created in the above section on
Identity configuration.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] username</code>
                  </p>
                </td><td>
                  <p>Update to the name of the user created in the above section on Identity
configuration.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] password</code>
                  </p>
                </td><td>
                  <p>Update to the password of the user created in the above section on
Identity configuration.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">[neutron] auth_url</code>
                  </p>
                </td><td>
                  <p>Update to the Identity server IP and port. This is the Identity
(keystone) admin API server IP and port value, and not the Identity
service API IP and port.</p>
                </td></tr></tbody></table></div></div></div><div class="sect2 " id="id-1.4.11.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure security groups</span> <a title="Permalink" class="permalink" href="#id-1.4.11.8.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Networking service provides security group functionality using a
mechanism that is more flexible and powerful than the security group
capabilities built into Compute. Therefore, if you use Networking, you
should always disable built-in security groups and proxy all security
group calls to the Networking API. If you do not, security policies
will conflict by being simultaneously applied by both services.</p><p>To proxy security groups to Networking, use the following configuration
values in the <code class="literal">nova.conf</code> file:</p><p>
          <span class="bold"><strong>nova.conf security group settings</strong></span>
        </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Item</p>
                </th><th>
                  <p>Configuration</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <code class="literal">firewall_driver</code>
                  </p>
                </td><td>
                  <p>Update to <code class="literal">nova.virt.firewall.NoopFirewallDriver</code>,
so that nova-compute does not perform
iptables-based filtering itself.</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.11.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure metadata</span> <a title="Permalink" class="permalink" href="#id-1.4.11.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Compute service allows VMs to query metadata associated with a VM by
making a web request to a special 169.254.169.254 address. Networking
supports proxying those requests to nova-api, even when the requests are
made from isolated networks, or from multiple networks that use
overlapping IP addresses.</p><p>To enable proxying the requests, you must update the following fields in
<code class="literal">[neutron]</code> section in the <code class="literal">nova.conf</code>.</p><p>
          <span class="bold"><strong>nova.conf metadata settings</strong></span>
        </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Item</p>
                </th><th>
                  <p>Configuration</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <code class="literal">service_metadata_proxy</code>
                  </p>
                </td><td>
                  <p>Update to <code class="literal">true</code>, otherwise nova-api
will not properly respond to requests
from the neutron-metadata-agent.</p>
                </td></tr><tr><td>
                  <p>
                    <code class="literal">metadata_proxy_shared_secret</code>
                  </p>
                </td><td>
                  <p>Update to a string "password" value.
You must also configure the same value in
the <code class="literal">metadata_agent.ini</code> file, to
authenticate requests made for metadata.</p>
                  <p>The default value of an empty string in
both files will allow metadata to
function, but will not be secure if any
non-trusted entities have access to the
metadata APIs exposed by nova-api.</p>
                </td></tr></tbody></table></div><div id="id-1.4.11.8.8.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>As a precaution, even when using <code class="literal">metadata_proxy_shared_secret</code>,
we recommend that you do not expose metadata using the same
nova-api instances that are used for projects. Instead, you should
run a dedicated set of nova-api instances for metadata that are
available only on your management network. Whether a given nova-api
instance exposes metadata APIs is determined by the value of
<code class="literal">enabled_apis</code> in its <code class="literal">nova.conf</code>.</p></div></div><div class="sect2 " id="id-1.4.11.8.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example nova.conf (for nova-compute and nova-api)</span> <a title="Permalink" class="permalink" href="#id-1.4.11.8.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Example values for the above settings, assuming a cloud controller node
running Compute and Networking with an IP address of 192.168.1.2:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
use_neutron = True
firewall_driver=nova.virt.firewall.NoopFirewallDriver

[neutron]
url=http://192.168.1.2:9696
auth_strategy=keystone
admin_tenant_name=service
admin_username=neutron
admin_password=password
admin_auth_url=http://192.168.1.2:35357/v2.0
service_metadata_proxy=true
metadata_proxy_shared_secret=foo</pre></div></div></div><div class="sect1 " id="id-1.4.11.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Advanced configuration options</span> <a title="Permalink" class="permalink" href="#id-1.4.11.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section describes advanced configuration options for various system
components. For example, configuration options where the default works
but that the user wants to customize options. After installing from
packages, <code class="literal">$NEUTRON_CONF_DIR</code> is <code class="literal">/etc/neutron</code>.</p><div class="sect2 " id="id-1.4.11.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">L3 metering agent</span> <a title="Permalink" class="permalink" href="#id-1.4.11.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can run an L3 metering agent that enables layer-3 traffic metering.
In general, you should launch the metering agent on all nodes that run
the L3 agent:</p><div class="verbatim-wrap"><pre class="screen">$ neutron-metering-agent --config-file NEUTRON_CONFIG_FILE \
  --config-file L3_METERING_CONFIG_FILE</pre></div><p>You must configure a driver that matches the plug-in that runs on the
service. The driver adds metering to the routing interface.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Option</p>
                </th><th>
                  <p>Value</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <span class="bold"><strong>Open vSwitch</strong></span>
                  </p>
                </td><td> </td></tr><tr><td>
                  <p>interface_driver
($NEUTRON_CONF_DIR/metering_agent.ini)</p>
                </td><td>
                  <p>openvswitch</p>
                </td></tr><tr><td>
                  <p>
                    <span class="bold"><strong>Linux Bridge</strong></span>
                  </p>
                </td><td> </td></tr><tr><td>
                  <p>interface_driver
($NEUTRON_CONF_DIR/metering_agent.ini)</p>
                </td><td>
                  <p>linuxbridge</p>
                </td></tr></tbody></table></div><div class="sect3 " id="id-1.4.11.9.3.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.6.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">L3 metering driver</span> <a title="Permalink" class="permalink" href="#id-1.4.11.9.3.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must configure any driver that implements the metering abstraction.
Currently the only available implementation uses iptables for metering.</p><div class="verbatim-wrap highlight ini"><pre class="screen">driver = neutron.services.metering.drivers.
iptables.iptables_driver.IptablesMeteringDriver</pre></div></div><div class="sect3 " id="id-1.4.11.9.3.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.6.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">L3 metering service driver</span> <a title="Permalink" class="permalink" href="#id-1.4.11.9.3.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable L3 metering, you must set the following option in the
<code class="literal">neutron.conf</code> file on the host that runs <code class="literal">neutron-server</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen">service_plugins = metering</pre></div></div></div></div><div class="sect1 " id="id-1.4.11.10"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scalable and highly available DHCP agents</span> <a title="Permalink" class="permalink" href="#id-1.4.11.10">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section is fully described at the <a class="link" href="http://docs.openstack.org/newton/networking-guide/config-dhcp-ha.html" target="_blank">High-availability for DHCP</a>
in the Networking Guide.</p></div><div class="sect1 " id="id-1.4.11.11"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can manage OpenStack Networking services by using the service
command. For example:</p><div class="verbatim-wrap"><pre class="screen"># service neutron-server stop
# service neutron-server status
# service neutron-server start
# service neutron-server restart</pre></div><p>Log files are in the <code class="literal">/var/log/neutron</code> directory.</p><p>Configuration files are in the <code class="literal">/etc/neutron</code> directory.</p><p>Administrators and projects can use OpenStack Networking to build
rich network topologies. Administrators can create network
connectivity on behalf of projects.</p><div class="sect2 " id="id-1.4.11.11.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Core Networking API features</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>After installing and configuring Networking (neutron), projects and
administrators can perform create-read-update-delete (CRUD) API networking
operations. This is performed using the Networking API directly with either
the <code class="command">neutron</code> command-line interface (CLI) or the <code class="command">openstack</code>
CLI. The <code class="command">neutron</code> CLI is a wrapper around the Networking API. Every
Networking API call has a corresponding <code class="command">neutron</code> command.</p><p>The <code class="command">openstack</code> CLI is a common interface for all OpenStack
projects, however, not every API operation has been implemented. For the
list of available commands, see <a class="link" href="http://docs.openstack.org/developer/python-openstackclient/command-list.html" target="_blank">Command List</a>.</p><p>The <code class="command">neutron</code> CLI includes a number of options. For details, see
<a class="link" href="http://docs.openstack.org/user-guide/cli-create-and-manage-networks.html" target="_blank">Create and manage networks</a>.</p><div class="sect3 " id="id-1.4.11.11.7.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.8.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic Networking operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.7.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To learn about advanced capabilities available through the <code class="command">neutron</code>
command-line interface (CLI), read the networking section <a class="link" href="http://docs.openstack.org/user-guide/cli-create-and-manage-networks.html" target="_blank">Create and manage
networks</a>
in the OpenStack End User Guide.</p><p>This table shows example <code class="command">openstack</code> commands that enable you to
complete basic network operations:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operation</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Creates a network.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack network create net1</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Creates a subnet that is
associated with net1.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack subnet create subnet1</code>
                      <code class="literal">--subnet-range 10.0.0.0/24</code>
                      <code class="literal">--network net1</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Lists ports for a
specified project.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port list</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Lists ports for a
specified project
and displays the <code class="literal">ID</code>,
<code class="literal">Fixed IP Addresses</code></p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port list -c ID</code>
                      <code class="literal">-c "Fixed IP Addresses</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Shows information for a
specified port.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port show PORT_ID</code>
                    </p>
                  </td></tr></tbody></table></div><p>
            <span class="bold"><strong>Basic Networking operations</strong></span>
          </p><div id="id-1.4.11.11.7.5.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">device_owner</code> field describes who owns the port. A port whose
<code class="literal">device_owner</code> begins with:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">network</code> is created by Networking.</p></li><li class="listitem "><p><code class="literal">compute</code> is created by Compute.</p></li></ul></div></div></div><div class="sect3 " id="id-1.4.11.11.7.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.8.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Administrative operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.7.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The administrator can run any <code class="command">openstack</code> command on behalf of
projects by specifying an Identity <code class="literal">project</code> in the command, as
follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack network create --project PROJECT_ID NETWORK_NAME</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack network create --project 5e4bbe24b67a4410bc4d9fae29ec394e net1</pre></div><div id="id-1.4.11.11.7.6.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To view all project IDs in Identity, run the following command as an
Identity service admin user:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project list</pre></div></div></div><div class="sect3 " id="id-1.4.11.11.7.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.8.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Advanced Networking operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.7.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This table shows example CLI commands that enable you to complete
advanced network operations:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operation</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Creates a network that
all projects can use.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack network create</code>
                      <code class="literal">--share public-net</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Creates a subnet with a
specified gateway IP address.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack subnet create subnet1</code>
                      <code class="literal">--gateway 10.0.0.254 --network net1</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Creates a subnet that has
no gateway IP address.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack subnet create subnet1</code>
                      <code class="literal">--no-gateway --network net1</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Creates a subnet with DHCP
disabled.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack subnet create subnet1</code>
                      <code class="literal">--network net1 --no-dhcp</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Specifies a set of host routes</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack subnet create subnet1</code>
                      <code class="literal">--network net1 --host-route</code>
                      <code class="literal">destination=40.0.1.0/24,</code>
                      <code class="literal">gateway=40.0.0.2</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Creates a subnet with a
specified set of dns name
servers.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack subnet create subnet1</code>
                      <code class="literal">--network net1 --dns-nameserver</code>
                      <code class="literal">8.8.4.4</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Displays all ports and
IPs allocated on a network.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port list --network NET_ID</code>
                    </p>
                  </td></tr></tbody></table></div><p>
            <span class="bold"><strong>Advanced Networking operations</strong></span>
          </p></div></div><div class="sect2 " id="id-1.4.11.11.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use Compute with Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.11.11.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.8.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic Compute and Networking operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.8.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This table shows example <code class="command">openstack</code> commands that enable you to
complete basic VM networking operations:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Action</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Checks available networks.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack network list</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Boots a VM with a single NIC on
a selected Networking network.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack server create --image</code>
                      <code class="literal">IMAGE --flavor FLAVOR --nic</code>
                      <code class="literal">net-id=NET_ID VM_NAME</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Searches for ports with a
<code class="literal">device_id</code> that matches the
Compute instance UUID. See :ref:
<code class="literal">Create and delete VMs</code></p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port list --server VM_ID</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Searches for ports, but shows
only the <code class="literal">mac_address</code> of
the port.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port list -c</code>
                      <code class="literal">"MAC Address" --server VM_ID</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Temporarily disables a port from
sending traffic.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack port set PORT_ID</code>
                      <code class="literal">--disable</code>
                    </p>
                  </td></tr></tbody></table></div><p>
            <span class="bold"><strong>Basic Compute and Networking operations</strong></span>
          </p><div id="id-1.4.11.11.8.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">device_id</code> can also be a logical router ID.</p></div><div id="id-1.4.11.11.8.2.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>When you boot a Compute VM, a port on the network that
corresponds to the VM NIC is automatically created and associated
with the default security group. You can configure security
group rules to enable
users to access the VM.</p></li></ul></div></div></div><div class="sect3 " id="id-1.4.11.11.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.8.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Advanced VM creation operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This table shows example <code class="command">openstack</code> commands that enable you to
complete advanced VM creation operations:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operation</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Boots a VM with multiple
NICs.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack server create --image</code>
                      <code class="literal">IMAGE --flavor FLAVOR --nic</code>
                      <code class="literal">net-id=NET_ID VM_NAME</code>
                      <code class="literal">net-id=NET2-ID VM_NAME</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Boots a VM with a specific IP
address. Note that you cannot
use the <code class="literal">--max</code> or <code class="literal">--min</code>
parameters in this case.</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack server create --image</code>
                      <code class="literal">IMAGE --flavor FLAVOR --nic</code>
                      <code class="literal">net-id=NET_ID VM_NAME</code>
                      <code class="literal">v4-fixed-ip=IP-ADDR VM_NAME</code>
                    </p>
                  </td></tr><tr><td>
                    <p>Boots a VM that connects to all
networks that are accessible to the
project who submits the request
(without the <code class="literal">--nic</code> option).</p>
                  </td><td>
                    <p>
                      <code class="literal">$ openstack server create --image</code>
                      <code class="literal">IMAGE --flavor FLAVOR</code>
                    </p>
                  </td></tr></tbody></table></div><p>
            <span class="bold"><strong>Advanced VM creation operations</strong></span>
          </p><div id="id-1.4.11.11.8.3.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Cloud images that distribution vendors offer usually have only one
active NIC configured. When you boot with multiple NICs, you must
configure additional interfaces on the image or the NICs are not
reachable.</p><p>The following Debian/Ubuntu-based example shows how to set up the
interfaces within the instance in the <code class="literal">/etc/network/interfaces</code>
file. You must apply this configuration to the image.</p><div class="verbatim-wrap highlight bash"><pre class="screen"># The loopback network interface
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet dhcp

auto eth1
iface eth1 inet dhcp</pre></div></div></div><div class="sect3 " id="id-1.4.11.11.8.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.8.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enable ping and SSH on VMs (security groups)</span> <a title="Permalink" class="permalink" href="#id-1.4.11.11.8.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You must configure security group rules depending on the type of plug-in
you are using. If you are using a plug-in that:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Implements Networking security groups, you can configure security
group rules directly by using the <code class="command">openstack security group rule create</code>
command. This example enables <code class="literal">ping</code> and <code class="literal">ssh</code> access to your VMs.</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create --protocol icmp \
    --ingress</pre></div><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create --protocol tcp \
    --egress --description "Sample Security Group"</pre></div></li><li class="listitem "><p>Does not implement Networking security groups, you can configure
security group rules by using the <code class="command">openstack security group rule
create</code> or <code class="command">euca-authorize</code> command. These <code class="command">openstack</code>
commands enable <code class="literal">ping</code> and <code class="literal">ssh</code> access to your VMs.</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create default --protocol icmp --dst-port -1:-1 --remote-ip 0.0.0.0/0
$ openstack security group rule create default --protocol tcp --dst-port 22:22 --remote-ip 0.0.0.0/0</pre></div></li></ul></div><div id="id-1.4.11.11.8.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If your plug-in implements Networking security groups, you can also
leverage Compute security groups by setting
<code class="literal">security_group_api = neutron</code> in the <code class="literal">nova.conf</code> file. After
you set this option, all Compute security group commands are proxied
to Networking.</p></div></div></div></div><div class="sect1 " id="networking-adv-features"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Advanced features through API extensions</span> <a title="Permalink" class="permalink" href="#networking-adv-features">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>networking-adv-features</li></ul></div></div></div></div><p>Several plug-ins implement API extensions that provide capabilities
similar to what was available in <code class="literal">nova-network</code>. These plug-ins are likely
to be of interest to the OpenStack community.</p><div class="sect2 " id="id-1.4.11.12.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provider networks</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Networks can be categorized as either project networks or provider
networks. Project networks are created by normal users and details about
how they are physically realized are hidden from those users. Provider
networks are created with administrative credentials, specifying the
details of how the network is physically realized, usually to match some
existing network in the data center.</p><p>Provider networks enable administrators to create networks that map
directly to the physical networks in the data center.
This is commonly used to give projects direct access to a public network
that can be used to reach the Internet. It might also be used to
integrate with VLANs in the network that already have a defined meaning
(for example, enable a VM from the marketing department to be placed
on the same VLAN as bare-metal marketing hosts in the same data center).</p><p>The provider extension allows administrators to explicitly manage the
relationship between Networking virtual networks and underlying physical
mechanisms such as VLANs and tunnels. When this extension is supported,
Networking client users with administrative privileges see additional
provider attributes on all virtual networks and are able to specify
these attributes in order to create provider networks.</p><p>The provider extension is supported by the Open vSwitch and Linux Bridge
plug-ins. Configuration of these plug-ins requires familiarity with this
extension.</p><div class="sect3 " id="id-1.4.11.12.3.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Terminology</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.3.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A number of terms are used in the provider extension and in the
configuration of plug-ins supporting the provider extension:</p><p>
            <span class="bold"><strong>Provider extension terminology</strong></span>
          </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Term</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>
                      <span class="bold"><strong>virtual network</strong></span>
                    </p>
                  </td><td>
                    <p>A Networking L2 network (identified by a UUID and
optional name) whose ports can be attached as vNICs
to Compute instances and to various Networking
agents. The Open vSwitch and Linux Bridge plug-ins
each support several different mechanisms to
realize virtual networks.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>physical network</strong></span>
                    </p>
                  </td><td>
                    <p>A network connecting virtualization hosts (such as
compute nodes) with each other and with other
network resources. Each physical network might
support multiple virtual networks. The provider
extension and the plug-in configurations identify
physical networks using simple string names.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>project network</strong></span>
                    </p>
                  </td><td>
                    <p>A virtual network that a project or an administrator
creates. The physical details of the network are not
exposed to the project.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>provider network</strong></span>
                    </p>
                  </td><td>
                    <p>A virtual network administratively created to map to
a specific network in the data center, typically to
enable direct access to non-OpenStack resources on
that network. Project can be given access to
provider networks.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>VLAN network</strong></span>
                    </p>
                  </td><td>
                    <p>A virtual network implemented as packets on a
specific physical network containing IEEE 802.1Q
headers with a specific VID field value. VLAN
networks sharing the same physical network are
isolated from each other at L2 and can even have
overlapping IP address spaces. Each distinct
physical network supporting VLAN networks is
treated as a separate VLAN trunk, with a distinct
space of VID values. Valid VID values are 1
through 4094.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>flat network</strong></span>
                    </p>
                  </td><td>
                    <p>A virtual network implemented as packets on a
specific physical network containing no IEEE 802.1Q
header. Each physical network can realize at most
one flat network.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>local network</strong></span>
                    </p>
                  </td><td>
                    <p>A virtual network that allows communication within
each host, but not across a network. Local networks
are intended mainly for single-node test scenarios,
but can have other uses.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>GRE network</strong></span>
                    </p>
                  </td><td>
                    <p>A virtual network implemented as network packets
encapsulated using GRE. GRE networks are also
referred to as <span class="emphasis"><em>tunnels</em></span>. GRE tunnel packets are
routed by the IP routing table for the host, so
GRE networks are not associated by Networking with
specific physical networks.</p>
                  </td></tr><tr><td>
                    <p>
                      <span class="bold"><strong>Virtual Extensible
LAN (VXLAN) network</strong></span>
                    </p>
                  </td><td>
                    <p>VXLAN is a proposed encapsulation protocol for
running an overlay network on existing Layer 3
infrastructure. An overlay network is a virtual
network that is built on top of existing network
Layer 2 and Layer 3 technologies to support elastic
compute architectures.</p>
                  </td></tr></tbody></table></div><p>The ML2, Open vSwitch, and Linux Bridge plug-ins support VLAN networks,
flat networks, and local networks. Only the ML2 and Open vSwitch
plug-ins currently support GRE and VXLAN networks, provided that the
required features exist in the hosts Linux kernel, Open vSwitch, and
iproute2 packages.</p></div><div class="sect3 " id="id-1.4.11.12.3.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provider attributes</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.3.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The provider extension extends the Networking network resource with
these attributes:</p><div class="table" id="id-1.4.11.12.3.7.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.3: </span><span class="name">Provider network attributes </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.3.7.3">#</a></h6></div><div class="table-contents"><table class="table" summary="Provider network attributes" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                    <p>Attribute name</p>
                  </th><th>
                    <p>Type</p>
                  </th><th>
                    <p>Default Value</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>provider: network_type</p>
                  </td><td>
                    <p>String</p>
                  </td><td>
                    <p>N/A</p>
                  </td><td>
                    <p>The physical mechanism by which the virtual network is implemented.
Possible values are <code class="literal">flat</code>, <code class="literal">vlan</code>, <code class="literal">local</code>, <code class="literal">gre</code>, and
<code class="literal">vxlan</code>, corresponding to flat networks, VLAN networks, local
networks, GRE networks, and VXLAN networks as defined above.
All types of provider networks can be created by administrators,
while project networks can be implemented as <code class="literal">vlan</code>, <code class="literal">gre</code>,
<code class="literal">vxlan</code>, or <code class="literal">local</code> network types depending on plug-in
configuration.</p>
                  </td></tr><tr><td>
                    <p>provider: physical_network</p>
                  </td><td>
                    <p>String</p>
                  </td><td>
                    <p>If a physical network named "default" has been configured and
if provider:network_type is <code class="literal">flat</code> or <code class="literal">vlan</code>, then "default"
is used.</p>
                  </td><td>
                    <p>The name of the physical network over which the virtual network
is implemented for flat and VLAN networks. Not applicable to the
<code class="literal">local</code> or <code class="literal">gre</code> network types.</p>
                  </td></tr><tr><td>
                    <p>provider:segmentation_id</p>
                  </td><td>
                    <p>Integer</p>
                  </td><td>
                    <p>N/A</p>
                  </td><td>
                    <p>For VLAN networks, the VLAN VID on the physical network that
realizes the virtual network. Valid VLAN VIDs are 1 through 4094.
For GRE networks, the tunnel ID. Valid tunnel IDs are any 32 bit
unsigned integer. Not applicable to the <code class="literal">flat</code> or <code class="literal">local</code>
network types.</p>
                  </td></tr></tbody></table></div></div><p>To view or set provider extended attributes, a client must be authorized
for the <code class="literal">extension:provider_network:view</code> and
<code class="literal">extension:provider_network:set</code> actions in the Networking policy
configuration. The default Networking configuration authorizes both
actions for users with the admin role. An authorized client or an
administrative user can view and set the provider extended attributes
through Networking API calls. See the section called
<a class="xref" href="#authentication-and-authorization" title="9.11. Authentication and authorization">Section 9.11, “Authentication and authorization”</a> for details on policy configuration.</p></div></div><div class="sect2 " id="l3-routing-and-nat"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">L3 routing and NAT</span> <a title="Permalink" class="permalink" href="#l3-routing-and-nat">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>l3-routing-and-nat</li></ul></div></div></div></div><p>The Networking API provides abstract L2 network segments that are
decoupled from the technology used to implement the L2 network.
Networking includes an API extension that provides abstract L3 routers
that API users can dynamically provision and configure. These Networking
routers can connect multiple L2 Networking networks and can also provide
a gateway that connects one or more private L2 networks to a shared
external network. For example, a public network for access to the
Internet. See the <a class="link" href="http://docs.openstack.org/newton/config-reference/" target="_blank">OpenStack Configuration Reference</a> for details on common
models of deploying Networking L3 routers.</p><p>The L3 router provides basic NAT capabilities on gateway ports that
uplink the router to external networks. This router SNATs all traffic by
default and supports floating IPs, which creates a static one-to-one
mapping from a public IP on the external network to a private IP on one
of the other subnets attached to the router. This allows a project to
selectively expose VMs on private networks to other hosts on the
external network (and often to all hosts on the Internet). You can
allocate and map floating IPs from one port to another, as needed.</p><div class="sect3 " id="id-1.4.11.12.4.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic L3 operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.4.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>External networks are visible to all users. However, the default policy
settings enable only administrative users to create, update, and delete
external networks.</p><p>This table shows example neutron commands that enable you to complete
basic L3 operations:</p><div class="table" id="id-1.4.11.12.4.4.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.4: </span><span class="name">Basic L3 Operations </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.4.4.4">#</a></h6></div><div class="table-contents"><table class="table" summary="Basic L3 Operations" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operation</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Creates external networks.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network create public --external
$ openstack subnet create --network public --subnet-range 172.16.1.0/24 public-subnet</pre></div>
                  </td></tr><tr><td>
                    <p>Lists external networks.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network list --external</pre></div>
                  </td></tr><tr><td>
                    <p>Creates an internal-only router that connects to multiple L2 networks privately.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network create net1
$ openstack subnet create --network net1 --subnet-range 10.0.0.0/24 subnet1
$ openstack network create net2
$ openstack subnet create --network net2 --subnet-range 10.0.1.0/24 subnet2
$ openstack router create router1
$ openstack router add subnet router1 SUBNET1_UUID
$ openstack router add subnet router1 SUBNET2_UUID</pre></div>
                    <p>An internal router port can have only one IPv4 subnet and multiple IPv6 subnets
that belong to the same network ID. When you call <code class="literal">router-interface-add</code> with an IPv6
subnet, this operation adds the interface to an existing internal port with the same
network ID. If a port with the same network ID does not exist, a new port is created.</p>
                  </td></tr><tr><td>
                    <p>Connects a router to an external network, which enables that router to
act as a NAT gateway for external connectivity.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack router set router1 --external-gateway EXT_NET_ID</pre></div>
                    <p>The router obtains an interface with the gateway_ip address of the
subnet and this interface is attached to a port on the L2 Networking
network associated with the subnet. The router also gets a gateway
interface to the specified external network. This provides SNAT
connectivity to the external network as well as support for floating
IPs allocated on that external networks. Commonly an external network
maps to a network in the provider.</p>
                  </td></tr><tr><td>
                    <p>Lists routers.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack router list</pre></div>
                  </td></tr><tr><td>
                    <p>Shows information for a specified router.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack router show ROUTER_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Shows all internal interfaces for a router.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack port list --router  ROUTER_ID
$ openstack port list --router  ROUTER_NAME</pre></div>
                  </td></tr><tr><td>
                    <p>Identifies the PORT_ID that represents the VM NIC to which the floating
IP should map.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack port list -c ID -c "Fixed IP Addresses" --server INSTANCE_ID</pre></div>
                    <p>This port must be on a Networking subnet that is attached to
a router uplinked to the external network used to create the floating
IP. Conceptually, this is because the router must be able to perform the
Destination NAT (DNAT) rewriting of packets from the floating IP address
(chosen from a subnet on the external network) to the internal fixed
IP (chosen from a private subnet that is behind the router).</p>
                  </td></tr><tr><td>
                    <p>Creates a floating IP address and associates it with a port.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip create EXT_NET_ID
$ openstack floating ip add port FLOATING_IP_ID --port-id INTERNAL_VM_PORT_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Creates a floating IP on a specific subnet in the external network.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip create EXT_NET_ID --subnet SUBNET_ID</pre></div>
                    <p>If there are multiple subnets in the external network, you can choose a specific
subnet based on quality and costs.</p>
                  </td></tr><tr><td>
                    <p>Creates a floating IP address and associates it with a port, in a single step.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip create --port INTERNAL_VM_PORT_ID EXT_NET_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Lists floating IPs</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip list</pre></div>
                  </td></tr><tr><td>
                    <p>Finds floating IP for a specified VM port.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip list --port INTERNAL_VM_PORT_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Disassociates a floating IP address.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip remove port FLOATING_IP_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Deletes the floating IP address.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack floating ip delete FLOATING_IP_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Clears the gateway.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack router unset --external-gateway router1</pre></div>
                  </td></tr><tr><td>
                    <p>Removes the interfaces from the router.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack router remove subnet router1 SUBNET_ID</pre></div>
                    <p>If this subnet ID is the last subnet on the port, this operation deletes the port itself.</p>
                  </td></tr><tr><td>
                    <p>Deletes the router.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack router delete router1</pre></div>
                  </td></tr></tbody></table></div></div></div></div><div class="sect2 " id="id-1.4.11.12.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Security groups</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Security groups and security group rules allow administrators and
projects to specify the type of traffic and direction
(ingress/egress) that is allowed to pass through a port. A security
group is a container for security group rules.</p><p>When a port is created in Networking it is associated with a security
group. If a security group is not specified the port is associated with
a 'default' security group. By default, this group drops all ingress
traffic and allows all egress. Rules can be added to this group in order
to change the behavior.</p><p>To use the Compute security group APIs or use Compute to orchestrate the
creation of ports for instances on specific security groups, you must
complete additional configuration. You must configure the
<code class="literal">/etc/nova/nova.conf</code> file and set the <code class="literal">security_group_api=neutron</code>
option on every node that runs nova-compute and nova-api. After you make
this change, restart nova-api and nova-compute to pick up this change.
Then, you can use both the Compute and OpenStack Network security group
APIs at the same time.</p><div id="id-1.4.11.12.5.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To use the Compute security group API with Networking, the
Networking plug-in must implement the security group API. The
following plug-ins currently implement this: ML2, Open vSwitch,
Linux Bridge, NEC, and VMware NSX.</p></li><li class="listitem "><p>You must configure the correct firewall driver in the
<code class="literal">securitygroup</code> section of the plug-in/agent configuration
file. Some plug-ins and agents, such as Linux Bridge Agent and
Open vSwitch Agent, use the no-operation driver as the default,
which results in non-working security groups.</p></li><li class="listitem "><p>When using the security group API through Compute, security
groups are applied to all ports on an instance. The reason for
this is that Compute security group APIs are instances based and
not port based as Networking.</p></li></ul></div></div><div class="sect3 " id="id-1.4.11.12.5.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic security group operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.5.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This table shows example neutron commands that enable you to complete
basic security group operations:</p><div class="table" id="id-1.4.11.12.5.6.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.5: </span><span class="name">Basic security group operations </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.5.6.3">#</a></h6></div><div class="table-contents"><table class="table" summary="Basic security group operations" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operation</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Creates a security group for our web servers.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack security group create webservers \
 --description "security group for webservers"</pre></div>
                  </td></tr><tr><td>
                    <p>Lists security groups.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack security group list</pre></div>
                  </td></tr><tr><td>
                    <p>Creates a security group rule to allow port 80 ingress.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create --ingress \
  --protocol tcp SECURITY_GROUP_UUID</pre></div>
                  </td></tr><tr><td>
                    <p>Lists security group rules.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack security group rule list</pre></div>
                  </td></tr><tr><td>
                    <p>Deletes a security group rule.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack security group rule delete SECURITY_GROUP_RULE_UUID</pre></div>
                  </td></tr><tr><td>
                    <p>Deletes a security group.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack security group delete SECURITY_GROUP_UUID</pre></div>
                  </td></tr><tr><td>
                    <p>Creates a port and associates two security groups.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack port create port1 --security-group SECURITY_GROUP_ID1 \
  --security-group SECURITY_GROUP_ID2 --network NETWORK_ID</pre></div>
                  </td></tr><tr><td>
                    <p>Removes security groups from a port.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack port set --no-security-group PORT_ID</pre></div>
                  </td></tr></tbody></table></div></div></div></div><div class="sect2 " id="id-1.4.11.12.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic Load-Balancer-as-a-Service operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.11.12.6.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The Load-Balancer-as-a-Service (LBaaS) API provisions and configures
load balancers. The reference implementation is based on the HAProxy
software load balancer.</p></div><p>This list shows example neutron commands that enable you to complete
basic LBaaS operations:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Creates a load balancer pool by using specific provider.</p><p><code class="literal">--provider</code> is an optional argument. If not used, the pool is
created with default provider for LBaaS service. You should configure
the default provider in the <code class="literal">[service_providers]</code> section of the
<code class="literal">neutron.conf</code> file. If no default provider is specified for LBaaS,
the <code class="literal">--provider</code> parameter is required for pool creation.</p><div class="verbatim-wrap"><pre class="screen">$ neutron lbaas-pool-create --lb-algorithm ROUND_ROBIN --name mypool \
  --protocol HTTP --subnet-id SUBNET_UUID --provider PROVIDER_NAME</pre></div></li><li class="listitem "><p>Associates two web servers with pool.</p><div class="verbatim-wrap"><pre class="screen">$ neutron lbaas-member-create --address  WEBSERVER1_IP --protocol-port 80 mypool
$ neutron lbaas-member-create --address  WEBSERVER2_IP --protocol-port 80 mypool</pre></div></li><li class="listitem "><p>Creates a health monitor that checks to make sure our instances are
still running on the specified protocol-port.</p><div class="verbatim-wrap"><pre class="screen">$ neutron lbaas-healthmonitor-create --delay 3 --type HTTP --max-retries 3 \
  --timeout 3</pre></div></li><li class="listitem "><p>Associates a health monitor with pool.</p><div class="verbatim-wrap"><pre class="screen">$ neutron lbaas-healthmonitor-associate HEALTHMONITOR_UUID mypool</pre></div></li><li class="listitem "><p>Creates a virtual IP (VIP) address that, when accessed through the
load balancer, directs the requests to one of the pool members.</p><div class="verbatim-wrap"><pre class="screen">$ neutron lbaas-vip-create --name myvip --protocol-port 80 --protocol \
  HTTP --subnet-id SUBNET_UUID mypool</pre></div></li></ul></div></div><div class="sect2 " id="id-1.4.11.12.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.9.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Plug-in specific extensions</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Each vendor can choose to implement additional API extensions to the
core API. This section describes the extensions for each plug-in.</p><div class="sect3 " id="id-1.4.11.12.7.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VMware NSX extensions</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These sections explain NSX plug-in extensions.</p><div class="sect4 " id="id-1.4.11.12.7.3.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">9.9.5.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VMware NSX QoS extension</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The VMware NSX QoS extension rate-limits network ports to guarantee a
specific amount of bandwidth for each port. This extension, by default,
is only accessible by a project with an admin role but is configurable
through the <code class="literal">policy.json</code> file. To use this extension, create a queue
and specify the min/max bandwidth rates (kbps) and optionally set the
QoS Marking and DSCP value (if your network fabric uses these values to
make forwarding decisions). Once created, you can associate a queue with
a network. Then, when ports are created on that network they are
automatically created and associated with the specific queue size that
was associated with the network. Because one size queue for a every port
on a network might not be optimal, a scaling factor from the nova flavor
<code class="literal">rxtx_factor</code> is passed in from Compute when creating the port to scale
the queue.</p><p>Lastly, if you want to set a specific baseline QoS policy for the amount
of bandwidth a single port can use (unless a network queue is specified
with the network a port is created on) a default queue can be created in
Networking which then causes ports created to be associated with a queue
of that size times the rxtx scaling factor. Note that after a network or
default queue is specified, queues are added to ports that are
subsequently created but are not added to existing ports.</p><div class="sect5 " id="id-1.4.11.12.7.3.3.4"><div class="titlepage"><div><div><h6 class="title"><span class="number">9.9.5.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic VMware NSX QoS operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.3.4">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This table shows example neutron commands that enable you to complete
basic queue operations:</p><div class="table" id="id-1.4.11.12.7.3.3.4.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.6: </span><span class="name">Basic VMware NSX QoS operations </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.3.4.3">#</a></h6></div><div class="table-contents"><table class="table" summary="Basic VMware NSX QoS operations" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                        <p>Operation</p>
                      </th><th>
                        <p>Command</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Creates QoS queue (admin-only).</p>
                      </td><td>
                        <div class="verbatim-wrap"><pre class="screen">$ neutron queue-create --min 10 --max 1000 myqueue</pre></div>
                      </td></tr><tr><td>
                        <p>Associates a queue with a network.</p>
                      </td><td>
                        <div class="verbatim-wrap"><pre class="screen">$ neutron net-create network --queue_id QUEUE_ID</pre></div>
                      </td></tr><tr><td>
                        <p>Creates a default system queue.</p>
                      </td><td>
                        <div class="verbatim-wrap"><pre class="screen">$ neutron queue-create --default True --min 10 --max 2000 default</pre></div>
                      </td></tr><tr><td>
                        <p>Lists QoS queues.</p>
                      </td><td>
                        <div class="verbatim-wrap"><pre class="screen">$ neutron queue-list</pre></div>
                      </td></tr><tr><td>
                        <p>Deletes a QoS queue.</p>
                      </td><td>
                        <div class="verbatim-wrap"><pre class="screen">$ neutron queue-delete QUEUE_ID_OR_NAME</pre></div>
                      </td></tr></tbody></table></div></div></div></div><div class="sect4 " id="id-1.4.11.12.7.3.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">9.9.5.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VMware NSX provider networks extension</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Provider networks can be implemented in different ways by the underlying
NSX platform.</p><p>The <span class="emphasis"><em>FLAT</em></span> and <span class="emphasis"><em>VLAN</em></span> network types use bridged transport connectors.
These network types enable the attachment of large number of ports. To
handle the increased scale, the NSX plug-in can back a single OpenStack
Network with a chain of NSX logical switches. You can specify the
maximum number of ports on each logical switch in this chain on the
<code class="literal">max_lp_per_bridged_ls</code> parameter, which has a default value of 5,000.</p><p>The recommended value for this parameter varies with the NSX version
running in the back-end, as shown in the following table.</p><p>
              <span class="bold"><strong>Recommended values for max_lp_per_bridged_ls</strong></span>
            </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                      <p>NSX version</p>
                    </th><th>
                      <p>Recommended Value</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>2.x</p>
                    </td><td>
                      <p>64</p>
                    </td></tr><tr><td>
                      <p>3.0.x</p>
                    </td><td>
                      <p>5,000</p>
                    </td></tr><tr><td>
                      <p>3.1.x</p>
                    </td><td>
                      <p>5,000</p>
                    </td></tr><tr><td>
                      <p>3.2.x</p>
                    </td><td>
                      <p>10,000</p>
                    </td></tr></tbody></table></div><p>In addition to these network types, the NSX plug-in also supports a
special <span class="emphasis"><em>l3_ext</em></span> network type, which maps external networks to specific
NSX gateway services as discussed in the next section.</p></div><div class="sect4 " id="id-1.4.11.12.7.3.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">9.9.5.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VMware NSX L3 extension</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>NSX exposes its L3 capabilities through gateway services which are
usually configured out of band from OpenStack. To use NSX with L3
capabilities, first create an L3 gateway service in the NSX Manager.
Next, in <code class="literal">/etc/neutron/plugins/vmware/nsx.ini</code> set
<code class="literal">default_l3_gw_service_uuid</code> to this value. By default, routers are
mapped to this gateway service.</p><div class="sect5 " id="id-1.4.11.12.7.3.5.3"><div class="titlepage"><div><div><h6 class="title"><span class="number">9.9.5.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VMware NSX L3 extension operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.5.3">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Create external network and map it to a specific NSX gateway service:</p><div class="verbatim-wrap"><pre class="screen">$ openstack network create public --external --provider-network-type l3_ext \
--provider-physical-network L3_GATEWAY_SERVICE_UUID</pre></div><p>Terminate traffic on a specific VLAN from a NSX gateway service:</p><div class="verbatim-wrap"><pre class="screen">$ openstack network create public --external --provider-network-type l3_ext \
--provider-physical-network L3_GATEWAY_SERVICE_UUID --provider-segment VLAN_ID</pre></div></div></div><div class="sect4 " id="id-1.4.11.12.7.3.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">9.9.5.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Operational status synchronization in the VMware NSX plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Starting with the Havana release, the VMware NSX plug-in provides an
asynchronous mechanism for retrieving the operational status for neutron
resources from the NSX back-end; this applies to <span class="emphasis"><em>network</em></span>, <span class="emphasis"><em>port</em></span>, and
<span class="emphasis"><em>router</em></span> resources.</p><p>The back-end is polled periodically and the status for every resource is
retrieved; then the status in the Networking database is updated only
for the resources for which a status change occurred. As operational
status is now retrieved asynchronously, performance for <code class="literal">GET</code>
operations is consistently improved.</p><p>Data to retrieve from the back-end are divided in chunks in order to
avoid expensive API requests; this is achieved leveraging NSX APIs
response paging capabilities. The minimum chunk size can be specified
using a configuration option; the actual chunk size is then determined
dynamically according to: total number of resources to retrieve,
interval between two synchronization task runs, minimum delay between
two subsequent requests to the NSX back-end.</p><p>The operational status synchronization can be tuned or disabled using
the configuration options reported in this table; it is however worth
noting that the default values work fine in most cases.</p><div class="table" id="id-1.4.11.12.7.3.6.6"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.7: </span><span class="name">Configuration options for tuning operational status synchronization in the NSX plug-in </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.7.3.6.6">#</a></h6></div><div class="table-contents"><table class="table" summary="Configuration options for tuning operational status synchronization in the NSX plug-in" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /></colgroup><thead><tr><th>
                      <p>Option name</p>
                    </th><th>
                      <p>Group</p>
                    </th><th>
                      <p>Default value</p>
                    </th><th>
                      <p>Type and constraints</p>
                    </th><th>
                      <p>Notes</p>
                    </th></tr></thead><tbody><tr><td>
                      <p>
                        <code class="literal">state_sync_interval</code>
                      </p>
                    </td><td>
                      <p>
                        <code class="literal">nsx_sync</code>
                      </p>
                    </td><td>
                      <p>10 seconds</p>
                    </td><td>
                      <p>Integer; no constraint.</p>
                    </td><td>
                      <p>Interval in seconds between two run of the synchronization task. If the
synchronization task takes more than <code class="literal">state_sync_interval</code> seconds to
execute, a new instance of the task is started as soon as the other is
completed. Setting the value for this option to 0 will disable the
synchronization task.</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">max_random_sync_delay</code>
                      </p>
                    </td><td>
                      <p>
                        <code class="literal">nsx_sync</code>
                      </p>
                    </td><td>
                      <p>0 seconds</p>
                    </td><td>
                      <p>Integer. Must not exceed <code class="literal">min_sync_req_delay</code></p>
                    </td><td>
                      <p>When different from zero, a random delay between 0 and
<code class="literal">max_random_sync_delay</code> will be added before processing the next
chunk.</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">min_sync_req_delay</code>
                      </p>
                    </td><td>
                      <p>
                        <code class="literal">nsx_sync</code>
                      </p>
                    </td><td>
                      <p>1 second</p>
                    </td><td>
                      <p>Integer. Must not exceed <code class="literal">state_sync_interval</code>.</p>
                    </td><td>
                      <p>The value of this option can be tuned according to the observed
load on the NSX controllers. Lower values will result in faster
synchronization, but might increase the load on the controller cluster.</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">min_chunk_size</code>
                      </p>
                    </td><td>
                      <p>
                        <code class="literal">nsx_sync</code>
                      </p>
                    </td><td>
                      <p>500 resources</p>
                    </td><td>
                      <p>Integer; no constraint.</p>
                    </td><td>
                      <p>Minimum number of resources to retrieve from the back-end for each
synchronization chunk. The expected number of synchronization chunks
is given by the ratio between <code class="literal">state_sync_interval</code> and
<code class="literal">min_sync_req_delay</code>. This size of a chunk might increase if the
total number of resources is such that more than <code class="literal">min_chunk_size</code>
resources must be fetched in one chunk with the current number of
chunks.</p>
                    </td></tr><tr><td>
                      <p>
                        <code class="literal">always_read_status</code>
                      </p>
                    </td><td>
                      <p>
                        <code class="literal">nsx_sync</code>
                      </p>
                    </td><td>
                      <p>False</p>
                    </td><td>
                      <p>Boolean; no constraint.</p>
                    </td><td>
                      <p>When this option is enabled, the operational status will always be
retrieved from the NSX back-end ad every <code class="literal">GET</code> request. In this
case it is advisable to disable the synchronization task.</p>
                    </td></tr></tbody></table></div></div><p>When running multiple OpenStack Networking server instances, the status
synchronization task should not run on every node; doing so sends
unnecessary traffic to the NSX back-end and performs unnecessary DB
operations. Set the <code class="literal">state_sync_interval</code> configuration option to a
non-zero value exclusively on a node designated for back-end status
synchronization.</p><p>The <code class="literal">fields=status</code> parameter in Networking API requests always
triggers an explicit query to the NSX back end, even when you enable
asynchronous state synchronization. For example, <code class="literal">GET
/v2.0/networks/NET_ID?fields=status&amp;fields=name</code>.</p></div></div><div class="sect3 " id="id-1.4.11.12.7.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Big Switch plug-in extensions</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section explains the Big Switch neutron plug-in-specific extension.</p><div class="sect4 " id="id-1.4.11.12.7.4.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">9.9.5.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Big Switch router rules</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.4.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Big Switch allows router rules to be added to each project router. These
rules can be used to enforce routing policies such as denying traffic
between subnets or traffic to external networks. By enforcing these at
the router level, network segmentation policies can be enforced across
many VMs that have differing security groups.</p><div class="sect5 " id="id-1.4.11.12.7.4.3.3"><div class="titlepage"><div><div><h6 class="title"><span class="number">9.9.5.2.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Router rule attributes</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.4.3.3">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Each project router has a set of router rules associated with it. Each
router rule has the attributes in this table. Router rules and their
attributes can be set using the <code class="command">openstack router set</code> command,
through the horizon interface or the Networking API.</p><div class="table" id="id-1.4.11.12.7.4.3.3.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.8: </span><span class="name">Big Switch Router rule attributes </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.7.4.3.3.3">#</a></h6></div><div class="table-contents"><table class="table" summary="Big Switch Router rule attributes" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                        <p>Attribute name</p>
                      </th><th>
                        <p>Required</p>
                      </th><th>
                        <p>Input type</p>
                      </th><th>
                        <p>Description</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>source</p>
                      </td><td>
                        <p>Yes</p>
                      </td><td>
                        <p>A valid CIDR or one of the keywords 'any' or 'external'</p>
                      </td><td>
                        <p>The network that a packet's source IP must match for the
rule to be applied.</p>
                      </td></tr><tr><td>
                        <p>destination</p>
                      </td><td>
                        <p>Yes</p>
                      </td><td>
                        <p>A valid CIDR or one of the keywords 'any' or 'external'</p>
                      </td><td>
                        <p>The network that a packet's destination IP must match for the rule to
be applied.</p>
                      </td></tr><tr><td>
                        <p>action</p>
                      </td><td>
                        <p>Yes</p>
                      </td><td>
                        <p>'permit' or 'deny'</p>
                      </td><td>
                        <p>Determines whether or not the matched packets will allowed to cross the
router.</p>
                      </td></tr><tr><td>
                        <p>nexthop</p>
                      </td><td>
                        <p>No</p>
                      </td><td>
                        <p>A plus-separated (+) list of next-hop IP addresses. For example,
<code class="literal">1.1.1.1+1.1.1.2</code>.</p>
                      </td><td>
                        <p>Overrides the default virtual router used to handle traffic for packets
that match the rule.</p>
                      </td></tr></tbody></table></div></div></div><div class="sect5 " id="id-1.4.11.12.7.4.3.4"><div class="titlepage"><div><div><h6 class="title"><span class="number">9.9.5.2.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Order of rule processing</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.4.3.4">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The order of router rules has no effect. Overlapping rules are evaluated
using longest prefix matching on the source and destination fields. The
source field is matched first so it always takes higher precedence over
the destination field. In other words, longest prefix matching is used
on the destination field only if there are multiple matching rules with
the same source.</p></div><div class="sect5 " id="id-1.4.11.12.7.4.3.5"><div class="titlepage"><div><div><h6 class="title"><span class="number">9.9.5.2.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Big Switch router rules operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.7.4.3.5">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Router rules are configured with a router update operation in OpenStack
Networking. The update overrides any previous rules so all rules must be
provided at the same time.</p><p>Update a router with rules to permit traffic by default but block
traffic from external networks to the 10.10.10.0/24 subnet:</p><div class="verbatim-wrap"><pre class="screen">$ neutron router-update ROUTER_UUID --router_rules type=dict list=true \
  source=any,destination=any,action=permit \
  source=external,destination=10.10.10.0/24,action=deny</pre></div><p>Specify alternate next-hop addresses for a specific subnet:</p><div class="verbatim-wrap"><pre class="screen">$ neutron router-update ROUTER_UUID --router_rules type=dict list=true  \
  source=any,destination=any,action=permit \
  source=10.10.10.0/24,destination=any,action=permit,nexthops=10.10.10.254+10.10.10.253</pre></div><p>Block traffic between two subnets while allowing everything else:</p><div class="verbatim-wrap"><pre class="screen">$ neutron router-update ROUTER_UUID --router_rules type=dict list=true \
  source=any,destination=any,action=permit \
  source=10.10.10.0/24,destination=10.20.20.20/24,action=deny</pre></div></div></div></div></div><div class="sect2 " id="id-1.4.11.12.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.9.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">L3 metering</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The L3 metering API extension enables administrators to configure IP
ranges and assign a specified label to them to be able to measure
traffic that goes through a virtual router.</p><p>The L3 metering extension is decoupled from the technology that
implements the measurement. Two abstractions have been added: One is the
metering label that can contain metering rules. Because a metering label
is associated with a project, all virtual routers in this project are
associated with this label.</p><div class="sect3 " id="id-1.4.11.12.8.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.9.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic L3 metering operations</span> <a title="Permalink" class="permalink" href="#id-1.4.11.12.8.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Only administrators can manage the L3 metering labels and rules.</p><p>This table shows example <code class="command">neutron</code> commands that enable you to
complete basic L3 metering operations:</p><div class="table" id="id-1.4.11.12.8.4.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 9.9: </span><span class="name">Basic L3 operations </span><a title="Permalink" class="permalink" href="#id-1.4.11.12.8.4.4">#</a></h6></div><div class="table-contents"><table class="table" summary="Basic L3 operations" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Operation</p>
                  </th><th>
                    <p>Command</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Creates a metering label.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label create LABEL1 \
  --description "DESCRIPTION_LABEL1"</pre></div>
                  </td></tr><tr><td>
                    <p>Lists metering labels.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label list</pre></div>
                  </td></tr><tr><td>
                    <p>Shows information for a specified label.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label show LABEL_UUID
$ openstack network meter label show LABEL1</pre></div>
                  </td></tr><tr><td>
                    <p>Deletes a metering label.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label delete LABEL_UUID
$ openstack network meter label delete LABEL1</pre></div>
                  </td></tr><tr><td>
                    <p>Creates a metering rule.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label rule create LABEL_UUID \
  --remote-ip-prefix CIDR \
  --direction DIRECTION --exclude</pre></div>
                    <p>For example:</p>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label rule create label1 \
  --remote-ip-prefix 10.0.0.0/24 --direction ingress
$ openstack network meter label rule create label1 \
  --remote-ip-prefix 20.0.0.0/24 --exclude</pre></div>
                  </td></tr><tr><td>
                    <p>Lists metering all label rules.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label rule list</pre></div>
                  </td></tr><tr><td>
                    <p>Shows information for a specified label rule.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label rule show RULE_UUID</pre></div>
                  </td></tr><tr><td>
                    <p>Deletes a metering label rule.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ openstack network meter label rule delete RULE_UUID</pre></div>
                  </td></tr><tr><td>
                    <p>Lists the value of created metering label rules.</p>
                  </td><td>
                    <div class="verbatim-wrap"><pre class="screen">$ ceilometer sample-list -m bandwidth -q resource=LABEL_UUID</pre></div>
                  </td></tr></tbody></table></div></div></div></div></div><div class="sect1 " id="id-1.4.11.13"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Advanced operational features</span> <a title="Permalink" class="permalink" href="#id-1.4.11.13">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.11.13.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging settings</span> <a title="Permalink" class="permalink" href="#id-1.4.11.13.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Networking components use Python logging module to do logging. Logging
configuration can be provided in <code class="literal">neutron.conf</code> or as command-line
options. Command options override ones in <code class="literal">neutron.conf</code>.</p><p>To configure logging for Networking components, use one of these
methods:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Provide logging settings in a logging configuration file.</p><p>See <a class="link" href="http://docs.python.org/howto/logging.html" target="_blank">Python logging
how-to</a> to learn more
about logging.</p></li><li class="listitem "><p>Provide logging setting in <code class="literal">neutron.conf</code>.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
# Default log level is WARNING
# Show debugging output in logs (sets DEBUG log level output)
# debug = False

# log_date_format = %Y-%m-%d %H:%M:%S

# use_syslog = False
# syslog_log_facility = LOG_USER

# if use_syslog is False, we can set log_file and log_dir.
# if use_syslog is False and we do not set log_file,
# the log will be printed to stdout.
# log_file =
# log_dir =</pre></div></li></ul></div></div><div class="sect2 " id="id-1.4.11.13.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">9.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notifications</span> <a title="Permalink" class="permalink" href="#id-1.4.11.13.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Notifications can be sent when Networking resources such as network,
subnet and port are created, updated or deleted.</p><div class="sect3 " id="id-1.4.11.13.3.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.10.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notification options</span> <a title="Permalink" class="permalink" href="#id-1.4.11.13.3.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To support DHCP agent, <code class="literal">rpc_notifier</code> driver must be set. To set up the
notification, edit notification options in <code class="literal">neutron.conf</code>:</p><div class="verbatim-wrap highlight ini"><pre class="screen"># Driver or drivers to handle sending notifications. (multi
# valued)
# notification_driver=messagingv2

# AMQP topic used for OpenStack notifications. (list value)
# Deprecated group/name - [rpc_notifier2]/topics
notification_topics = notifications</pre></div></div><div class="sect3 " id="id-1.4.11.13.3.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">9.10.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setting cases</span> <a title="Permalink" class="permalink" href="#id-1.4.11.13.3.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.11.13.3.4.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">9.10.2.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging and RPC</span> <a title="Permalink" class="permalink" href="#id-1.4.11.13.3.4.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>These options configure the Networking server to send notifications
through logging and RPC. The logging options are described in OpenStack
Configuration Reference. RPC notifications go to <code class="literal">notifications.info</code>
queue bound to a topic exchange defined by <code class="literal">control_exchange</code> in
<code class="literal">neutron.conf</code>.</p><p>
              <span class="bold"><strong>Notification System Options</strong></span>
            </p><p>A notification can be sent when a network, subnet, or port is created,
updated or deleted. The notification system options are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1"><span class="term ">
                      <code class="literal">notification_driver</code>
                    </span></dt><dd><p>Defines the driver or drivers to handle the sending of a notification.
The six available options are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1.2.2.1.1.1"><span class="term ">
                                <code class="literal">messaging</code>
                              </span></dt><dd><p>Send notifications using the 1.0 message format.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1.2.2.2.1.1"><span class="term ">
                                <code class="literal">messagingv2</code>
                              </span></dt><dd><p>Send notifications using the 2.0 message format (with a message
envelope).</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1.2.2.3.1.1"><span class="term ">
                                <code class="literal">routing</code>
                              </span></dt><dd><p>Configurable routing notifier (by priority or event_type).</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1.2.2.4.1.1"><span class="term ">
                                <code class="literal">log</code>
                              </span></dt><dd><p>Publish notifications using Python logging infrastructure.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1.2.2.5.1.1"><span class="term ">
                                <code class="literal">test</code>
                              </span></dt><dd><p>Store notifications in memory for test verification.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.1.1.1.2.2.6.1.1"><span class="term ">
                                <code class="literal">noop</code>
                              </span></dt><dd><p>Disable sending notifications entirely.</p></dd></dl></div></li></ul></div></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.2.1.1"><span class="term ">
                      <code class="literal">default_notification_level</code>
                    </span></dt><dd><p>Is used to form topic names or to set a logging level.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.3.1.1"><span class="term ">
                      <code class="literal">default_publisher_id</code>
                    </span></dt><dd><p>Is a part of the notification payload.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.4.1.1"><span class="term ">
                      <code class="literal">notification_topics</code>
                    </span></dt><dd><p>AMQP topic used for OpenStack notifications. They can be comma-separated
values. The actual topic names will be the values of
<code class="literal">default_notification_level</code>.</p></dd></dl></div></li><li class="listitem "><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.11.13.3.4.2.5.5.1.1"><span class="term ">
                      <code class="literal">control_exchange</code>
                    </span></dt><dd><p>This is an option defined in oslo.messaging. It is the default exchange
under which topics are scoped. May be overridden by an exchange name
specified in the <code class="literal">transport_url</code> option. It is a string value.</p></dd></dl></div></li></ul></div><p>Below is a sample <code class="literal">neutron.conf</code> configuration file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">notification_driver = messagingv2

default_notification_level = INFO

host = myhost.com
default_publisher_id = $host

notification_topics = notifications

control_exchange = openstack</pre></div></div></div></div></div><div class="sect1 " id="authentication-and-authorization"><div class="titlepage"><div><div><h2 class="title"><span class="number">9.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Authentication and authorization</span> <a title="Permalink" class="permalink" href="#authentication-and-authorization">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>authentication-and-authorization</li></ul></div></div></div></div><p>Networking uses the Identity service as the default authentication
service. When the Identity service is enabled, users who submit requests
to the Networking service must provide an authentication token in
<code class="literal">X-Auth-Token</code> request header. Users obtain this token by
authenticating with the Identity service endpoint. For more information
about authentication with the Identity service, see <a class="link" href="http://developer.openstack.org/api-ref/identity/v2/" target="_blank">OpenStack Identity
service API v2.0
Reference</a>.
When the Identity service is enabled, it is not mandatory to specify the
project ID for resources in create requests because the project ID is
derived from the authentication token.</p><p>The default authorization settings only allow administrative users
to create resources on behalf of a different project. Networking uses
information received from Identity to authorize user requests.
Networking handles two kind of authorization policies:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Operation-based</strong></span> policies specify access criteria for specific
operations, possibly with fine-grained control over specific
attributes.</p></li><li class="listitem "><p><span class="bold"><strong>Resource-based</strong></span> policies specify whether access to specific
resource is granted or not according to the permissions configured
for the resource (currently available only for the network resource).
The actual authorization policies enforced in Networking might vary
from deployment to deployment.</p></li></ul></div><p>The policy engine reads entries from the <code class="literal">policy.json</code> file. The
actual location of this file might vary from distribution to
distribution. Entries can be updated while the system is running, and no
service restart is required. Every time the policy file is updated, the
policies are automatically reloaded. Currently the only way of updating
such policies is to edit the policy file. In this section, the terms
<span class="emphasis"><em>policy</em></span> and <span class="emphasis"><em>rule</em></span> refer to objects that are specified in the same way
in the policy file. There are no syntax differences between a rule and a
policy. A policy is something that is matched directly from the
Networking policy engine. A rule is an element in a policy, which is
evaluated. For instance in <code class="literal">"create_subnet":
"rule:admin_or_network_owner"</code>, <span class="emphasis"><em>create_subnet</em></span> is a
policy, and <span class="emphasis"><em>admin_or_network_owner</em></span> is a rule.</p><p>Policies are triggered by the Networking policy engine whenever one of
them matches a Networking API operation or a specific attribute being
used in a given operation. For instance the <code class="literal">create_subnet</code> policy is
triggered every time a <code class="literal">POST /v2.0/subnets</code> request is sent to the
Networking server; on the other hand <code class="literal">create_network:shared</code> is
triggered every time the <span class="emphasis"><em>shared</em></span> attribute is explicitly specified (and
set to a value different from its default) in a <code class="literal">POST /v2.0/networks</code>
request. It is also worth mentioning that policies can also be related
to specific API extensions; for instance
<code class="literal">extension:provider_network:set</code> is triggered if the attributes
defined by the Provider Network extensions are specified in an API
request.</p><p>An authorization policy can be composed by one or more rules. If more
rules are specified then the evaluation policy succeeds if any of the
rules evaluates successfully; if an API operation matches multiple
policies, then all the policies must evaluate successfully. Also,
authorization rules are recursive. Once a rule is matched, the rule(s)
can be resolved to another rule, until a terminal rule is reached.</p><p>The Networking policy engine currently defines the following kinds of
terminal rules:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Role-based rules</strong></span> evaluate successfully if the user who submits
the request has the specified role. For instance <code class="literal">"role:admin"</code> is
successful if the user who submits the request is an administrator.</p></li><li class="listitem "><p><span class="bold"><strong>Field-based rules</strong></span> evaluate successfully if a field of the
resource specified in the current request matches a specific value.
For instance <code class="literal">"field:networks:shared=True"</code> is successful if the
<code class="literal">shared</code> attribute of the <code class="literal">network</code> resource is set to true.</p></li><li class="listitem "><p><span class="bold"><strong>Generic rules</strong></span> compare an attribute in the resource with an
attribute extracted from the user's security credentials and
evaluates successfully if the comparison is successful. For instance
<code class="literal">"tenant_id:%(tenant_id)s"</code> is successful if the project identifier
in the resource is equal to the project identifier of the user
submitting the request.</p></li></ul></div><p>This extract is from the default <code class="literal">policy.json</code> file:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A rule that evaluates successfully if the current user is an
administrator or the owner of the resource specified in the request
(project identifier is equal).</p><div class="verbatim-wrap highlight json"><pre class="screen">{
 "admin_or_owner": [
     [
         "role:admin"
     ],
     [
         "tenant_id:%(tenant_id)s"
     ]
 ],
 "admin_or_network_owner": [
     [
         "role:admin"
     ],
     [
         "tenant_id:%(network_tenant_id)s"
     ]
 ],
 "admin_only": [
     [
         "role:admin"
 ]
 ],
 "regular_user": [],
 "shared": [
     [
         "field:networks:shared=True"
     ]
 ],
 "default": [
     [</pre></div></li><li class="listitem "><p>The default policy that is always evaluated if an API operation does
not match any of the policies in <code class="literal">policy.json</code>.</p><div class="verbatim-wrap highlight json"><pre class="screen">        "rule:admin_or_owner"
    ]
],
"create_subnet": [
    [
        "rule:admin_or_network_owner"
    ]
],
"get_subnet": [
    [
        "rule:admin_or_owner"
    ],
    [
        "rule:shared"
    ]
],
"update_subnet": [
    [
        "rule:admin_or_network_owner"
    ]
],
"delete_subnet": [
    [
        "rule:admin_or_network_owner"
    ]
],
"create_network": [],
"get_network": [
    [
        "rule:admin_or_owner"
    ],</pre></div></li><li class="listitem "><p>This policy evaluates successfully if either <span class="emphasis"><em>admin_or_owner</em></span>, or
<span class="emphasis"><em>shared</em></span> evaluates successfully.</p><div class="verbatim-wrap highlight json"><pre class="screen">    [
        "rule:shared"
    ]
],
"create_network:shared": [
    [
        "rule:admin_only"
    ]</pre></div></li><li class="listitem "><p>This policy restricts the ability to manipulate the <span class="emphasis"><em>shared</em></span>
attribute for a network to administrators only.</p><div class="verbatim-wrap highlight json"><pre class="screen">],
"update_network": [
    [
        "rule:admin_or_owner"
    ]
],
"delete_network": [
    [
        "rule:admin_or_owner"
    ]
],
"create_port": [],
"create_port:mac_address": [
    [
        "rule:admin_or_network_owner"
    ]
],
"create_port:fixed_ips": [</pre></div></li><li class="listitem "><p>This policy restricts the ability to manipulate the <span class="emphasis"><em>mac_address</em></span>
attribute for a port only to administrators and the owner of the
network where the port is attached.</p><div class="verbatim-wrap highlight json"><pre class="screen">     [
         "rule:admin_or_network_owner"
     ]
 ],
 "get_port": [
     [
         "rule:admin_or_owner"
     ]
 ],
 "update_port": [
     [
         "rule:admin_or_owner"
     ]
 ],
  "delete_port": [
     [
         "rule:admin_or_owner"
     ]
 ]
}</pre></div></li></ul></div><p>In some cases, some operations are restricted to administrators only.
This example shows you how to modify a policy file to permit project to
define networks, see their resources, and permit administrative users to
perform all other operations:</p><div class="verbatim-wrap highlight ini"><pre class="screen">{
        "admin_or_owner": [["role:admin"], ["tenant_id:%(tenant_id)s"]],
        "admin_only": [["role:admin"]], "regular_user": [],
        "default": [["rule:admin_only"]],
        "create_subnet": [["rule:admin_only"]],
        "get_subnet": [["rule:admin_or_owner"]],
        "update_subnet": [["rule:admin_only"]],
        "delete_subnet": [["rule:admin_only"]],
        "create_network": [],
        "get_network": [["rule:admin_or_owner"]],
        "create_network:shared": [["rule:admin_only"]],
        "update_network": [["rule:admin_or_owner"]],
        "delete_network": [["rule:admin_or_owner"]],
        "create_port": [["rule:admin_only"]],
        "get_port": [["rule:admin_or_owner"]],
        "update_port": [["rule:admin_only"]],
        "delete_port": [["rule:admin_only"]]
}</pre></div></div></div><div class="chapter " id="id-1.4.12"><div class="titlepage"><div><div><h1 class="title"><span class="number">10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry</span> <a title="Permalink" class="permalink" href="#id-1.4.12">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#telemetry-system-architecture"><span class="number">10.1 </span><span class="name">System architecture</span></a></span></dt><dt><span class="sect1"><a href="#telemetry-data-collection"><span class="number">10.2 </span><span class="name">Data collection</span></a></span></dt><dt><span class="sect1"><a href="#data-collection-and-processing"><span class="number">10.3 </span><span class="name">Data collection, processing, and pipelines</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.12"><span class="number">10.4 </span><span class="name">Data retrieval</span></a></span></dt><dt><span class="sect1"><a href="#telemetry-alarms"><span class="number">10.5 </span><span class="name">Alarms</span></a></span></dt><dt><span class="sect1"><a href="#telemetry-measurements"><span class="number">10.6 </span><span class="name">Measurements</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.15"><span class="number">10.7 </span><span class="name">Events</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.16"><span class="number">10.8 </span><span class="name">Troubleshoot Telemetry</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.12.17"><span class="number">10.9 </span><span class="name">Telemetry best practices</span></a></span></dt></dl></div></div><p>Even in the cloud industry, providers must use a multi-step process
for billing. The required steps to bill for usage in a cloud
environment are metering, rating, and billing. Because the provider's
requirements may be far too specific for a shared solution, rating
and billing solutions cannot be designed in a common module that
satisfies all. Providing users with measurements on cloud services is
required to meet the <code class="literal">measured service</code> definition of cloud computing.</p><p>The Telemetry service was originally designed to support billing
systems for OpenStack cloud resources. This project only covers the
metering portion of the required processing for billing. This service
collects information about the system and stores it in the form of
samples in order to provide data about anything that can be billed.</p><p>In addition to system measurements, the Telemetry service also
captures event notifications triggered when various actions are
executed in the OpenStack system. This data is captured as Events and
stored alongside metering data.</p><p>The list of meters is continuously growing, which makes it possible
to use the data collected by Telemetry for different purposes, other
than billing. For example, the autoscaling feature in the
Orchestration service can be triggered by alarms this module sets and
then gets notified within Telemetry.</p><p>The sections in this document contain information about the
architecture and usage of Telemetry. The first section contains a
brief summary about the system architecture used in a typical
OpenStack deployment. The second section describes the data
collection mechanisms. You can also read about alarming to understand
how alarm definitions can be posted to Telemetry and what actions can
happen if an alarm is raised. The last section contains a
troubleshooting guide, which mentions error situations and possible
solutions to the problems.</p><p>You can retrieve the collected samples in three different ways: with
the REST API, with the command-line interface, or with the Metering
tab on an OpenStack dashboard.</p><div class="sect1 " id="telemetry-system-architecture"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System architecture</span> <a title="Permalink" class="permalink" href="#telemetry-system-architecture">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-system-architecture</li></ul></div></div></div></div><p>The Telemetry service uses an agent-based architecture. Several modules
combine their responsibilities to collect data, store samples in a
database, or provide an API service for handling incoming requests.</p><p>The Telemetry service is built from the following agents and services:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.9.4.1"><span class="term ">ceilometer-api</span></dt><dd><p>Presents aggregated metering data to consumers (such as billing
engines and analytics tools).</p></dd><dt id="id-1.4.12.9.4.2"><span class="term ">ceilometer-polling</span></dt><dd><p>Polls for different kinds of meter data by using the polling
plug-ins (pollsters) registered in different namespaces. It provides a
single polling interface across different namespaces.</p></dd><dt id="id-1.4.12.9.4.3"><span class="term ">ceilometer-agent-central</span></dt><dd><p>Polls the public RESTful APIs of other OpenStack services such as
Compute service and Image service, in order to keep tabs on resource
existence, by using the polling plug-ins (pollsters) registered in
the central polling namespace.</p></dd><dt id="id-1.4.12.9.4.4"><span class="term ">ceilometer-agent-compute</span></dt><dd><p>Polls the local hypervisor or libvirt daemon to acquire performance
data for the local instances, messages and emits the data as AMQP
messages, by using the polling plug-ins (pollsters) registered in
the compute polling namespace.</p></dd><dt id="id-1.4.12.9.4.5"><span class="term ">ceilometer-agent-ipmi</span></dt><dd><p>Polls the local node with IPMI support, in order to acquire IPMI
sensor data and Intel Node Manager data, by using the polling
plug-ins (pollsters) registered in the IPMI polling namespace.</p></dd><dt id="id-1.4.12.9.4.6"><span class="term ">ceilometer-agent-notification</span></dt><dd><p>Consumes AMQP messages from other OpenStack services.</p></dd><dt id="id-1.4.12.9.4.7"><span class="term ">ceilometer-collector</span></dt><dd><p>Consumes AMQP notifications from the agents, then dispatches these
data to the appropriate data store.</p></dd><dt id="id-1.4.12.9.4.8"><span class="term ">ceilometer-alarm-evaluator</span></dt><dd><p>Determines when alarms fire due to the associated statistic trend
crossing a threshold over a sliding time window.</p></dd><dt id="id-1.4.12.9.4.9"><span class="term ">ceilometer-alarm-notifier</span></dt><dd><p>Initiates alarm actions, for example calling out to a webhook with a
description of the alarm state transition.</p><div id="id-1.4.12.9.4.9.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The <code class="literal">ceilometer-polling</code> service is available since the Kilo release.
It is intended to replace <code class="literal">ceilometer-agent-central</code>,
<code class="literal">ceilometer-agent-compute</code>, and <code class="literal">ceilometer-agent-ipmi</code>.</p></li><li class="step "><p>The <code class="literal">ceilometer-alarm-evaluator</code> and <code class="literal">ceilometer-alarm-notifier</code>
services are removed in Mitaka release.</p></li></ol></div></div></div></dd></dl></div><p>Except for the <code class="literal">ceilometer-agent-compute</code> and the <code class="literal">ceilometer-agent-ipmi</code>
services, all the other services are placed on one or more controller
nodes.</p><p>The Telemetry architecture highly depends on the AMQP service both for
consuming notifications coming from OpenStack services and internal
communication.</p><div class="sect2 " id="telemetry-supported-databases"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported databases</span> <a title="Permalink" class="permalink" href="#telemetry-supported-databases">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-supported-databases</li></ul></div></div></div></div><p>The other key external component of Telemetry is the database, where
events, samples, alarm definitions, and alarms are stored.</p><div id="id-1.4.12.9.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Multiple database back ends can be configured in order to store
events, samples, and alarms separately. We recommend Gnocchi for
time-series storage.</p></div><p>The list of supported database back ends:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://gnocchi.xyz/" target="_blank">Gnocchi</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://www.elastic.co/" target="_blank">ElasticSearch (events only)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://www.mongodb.org/" target="_blank">MongoDB</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://www.mysql.com/" target="_blank">MySQL</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://www.postgresql.org/" target="_blank">PostgreSQL</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://hbase.apache.org/" target="_blank">HBase</a>
            </p></li></ul></div></div><div class="sect2 " id="telemetry-supported-hypervisors"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported hypervisors</span> <a title="Permalink" class="permalink" href="#telemetry-supported-hypervisors">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-supported-hypervisors</li></ul></div></div></div></div><p>The Telemetry service collects information about the virtual machines,
which requires close connection to the hypervisor that runs on the
compute hosts.</p><p>The following is a list of supported hypervisors.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The following hypervisors are supported via <a class="link" href="http://libvirt.org/" target="_blank">libvirt</a></p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <a class="link" href="http://www.linux-kvm.org/page/Main_Page" target="_blank">Kernel-based Virtual Machine (KVM)</a>
                </p></li><li class="listitem "><p>
                  <a class="link" href="http://wiki.qemu.org/Main_Page" target="_blank">Quick Emulator (QEMU)</a>
                </p></li><li class="listitem "><p>
                  <a class="link" href="https://linuxcontainers.org/" target="_blank">Linux Containers (LXC)</a>
                </p></li><li class="listitem "><p>
                  <a class="link" href="http://user-mode-linux.sourceforge.net/" target="_blank">User-mode Linux (UML)</a>
                </p></li></ul></div><div id="id-1.4.12.9.8.4.1.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For details about hypervisor support in libvirt please check the
<a class="link" href="http://libvirt.org/hvsupport.html" target="_blank">Libvirt API support matrix</a>.</p></div></li><li class="listitem "><p>
              <a class="link" href="http://www.xenproject.org/help/documentation.html" target="_blank">XEN</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://www.vmware.com/products/vsphere-hypervisor/support.html" target="_blank">VMware vSphere</a>
            </p></li></ul></div></div><div class="sect2 " id="id-1.4.12.9.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported networking services</span> <a title="Permalink" class="permalink" href="#id-1.4.12.9.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Telemetry is able to retrieve information from OpenStack Networking and
external networking services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>OpenStack Networking:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Basic network meters</p></li><li class="listitem "><p>Firewall-as-a-Service (FWaaS) meters</p></li><li class="listitem "><p>Load-Balancer-as-a-Service (LBaaS) meters</p></li><li class="listitem "><p>VPN-as-a-Service (VPNaaS) meters</p></li></ul></div></li><li class="listitem "><p>SDN controller meters:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <a class="link" href="https://www.opendaylight.org/" target="_blank">OpenDaylight</a>
                </p></li><li class="listitem "><p>
                  <a class="link" href="http://www.opencontrail.org/" target="_blank">OpenContrail</a>
                </p></li></ul></div></li></ul></div></div><div class="sect2 " id="telemetry-users-roles-projects"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Users, roles, and projects</span> <a title="Permalink" class="permalink" href="#telemetry-users-roles-projects">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-users-roles-projects</li></ul></div></div></div></div><p>This service of OpenStack uses OpenStack Identity for authenticating and
authorizing users. The required configuration options are listed in the
<a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry.html" target="_blank">Telemetry
section</a>
in the OpenStack Configuration Reference.</p><p>The system uses two roles:<code class="literal">admin</code> and <code class="literal">non-admin</code>. The authorization
happens before processing each API request. The amount of returned data
depends on the role the requestor owns.</p><p>The creation of alarm definitions also highly depends on the role of the
user, who initiated the action. Further details about <a class="xref" href="#telemetry-alarms" title="10.5. Alarms">Section 10.5, “Alarms”</a>
handling can be found in this guide.</p></div></div><div class="sect1 " id="telemetry-data-collection"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data collection</span> <a title="Permalink" class="permalink" href="#telemetry-data-collection">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-data-collection</li></ul></div></div></div></div><p>The main responsibility of Telemetry in OpenStack is to collect
information about the system that can be used by billing systems or
interpreted by analytic tooling. Telemetry in OpenStack originally focused
on the counters used for billing, and the recorded range is
continuously growing wider.</p><p>Collected data can be stored in the form of samples or events in the
supported databases, which are listed
in <a class="xref" href="#telemetry-supported-databases" title="10.1.1. Supported databases">Section 10.1.1, “Supported databases”</a>.</p><p>Samples can have various sources. Sample sources depend on, and adapt to,
the needs and configuration of Telemetry. The Telemetry service requires
multiple methods to collect data samples.</p><p>The available data collection mechanisms are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.10.6.1"><span class="term ">Notifications</span></dt><dd><p>Processing notifications from other OpenStack services, by consuming
messages from the configured message queue system.</p></dd><dt id="id-1.4.12.10.6.2"><span class="term ">Polling</span></dt><dd><p>Retrieve information directly from the hypervisor or from the host
machine using SNMP, or by using the APIs of other OpenStack
services.</p></dd><dt id="id-1.4.12.10.6.3"><span class="term ">RESTful API</span></dt><dd><p>Pushing samples via the RESTful API of Telemetry.</p></dd></dl></div><div class="sect2 " id="id-1.4.12.10.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notifications</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>All OpenStack services send notifications about the executed operations
or system state. Several notifications carry information that can be
metered. For example, CPU time of a VM instance created by OpenStack
Compute service.</p><p>The notification agent works alongside, but separately, from the
Telemetry service. The agent is responsible for consuming notifications.
This component is responsible for consuming from the message bus and
transforming notifications into events and measurement samples.</p><p>Since the Liberty release, the notification agent is responsible
for all data processing such as transformations and publishing. After
processing, the data is sent via AMQP to the collector service or any
external service. These external services persist the data in
configured databases.</p><p>The different OpenStack services emit several notifications about the
various types of events that happen in the system during normal
operation. Not all these notifications are consumed by the Telemetry
service, as the intention is only to capture the billable events and
notifications that can be used for monitoring or profiling purposes. The
notification agent filters by the event type. Each notification
message contains the event type. The following table contains the event
types by each OpenStack service that Telemetry transforms into samples.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                  <p>OpenStack service</p>
                </th><th>
                  <p>Event types</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td>
                  <p>OpenStack Compute</p>
                </td><td>
                  <p>scheduler.run_instance.scheduled</p>
                  <p>scheduler.select_destinations</p>
                  <p>compute.instance.*</p>
                </td><td>
                  <p>For a more detailed list of Compute notifications please
check the <a class="link" href="https://wiki.openstack.org/wiki/SystemUsageData" target="_blank">System Usage Data wiki page</a>.</p>
                </td></tr><tr><td>
                  <p>Bare metal service</p>
                </td><td>
                  <p>hardware.ipmi.*</p>
                </td><td> </td></tr><tr><td>
                  <p>OpenStack Image</p>
                </td><td>
                  <p>image.update</p>
                  <p>image.upload</p>
                  <p>image.delete</p>
                  <p>image.send</p>
                </td><td>
                  <p>The required configuration for Image service can be  * - service found in
<a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton" target="_blank">Configure the Image service for Telemetry</a>
section in the Installation Tutorials and Guides.</p>
                </td></tr><tr><td>
                  <p>OpenStack Networking</p>
                </td><td>
                  <p>floatingip.create.end</p>
                  <p>floatingip.update.*</p>
                  <p>floatingip.exists</p>
                  <p>network.create.end</p>
                  <p>network.update.*</p>
                  <p>network.exists</p>
                  <p>port.create.end</p>
                  <p>port.update.*</p>
                  <p>port.exists</p>
                  <p>router.create.end</p>
                  <p>router.update.*</p>
                  <p>router.exists</p>
                  <p>subnet.create.end</p>
                  <p>subnet.update.*</p>
                  <p>subnet.exists</p>
                  <p>l3.meter</p>
                </td><td> </td></tr><tr><td>
                  <p>Orchestration service</p>
                </td><td>
                  <p>orchestration.stack.create.end</p>
                  <p>orchestration.stack.update.end</p>
                  <p>orchestration.stack.delete.end</p>
                  <p>orchestration.stack.resume.end</p>
                  <p>orchestration.stack.suspend.end</p>
                </td><td> </td></tr><tr><td>
                  <p>OpenStack Block Storage</p>
                </td><td>
                  <p>volume.exists</p>
                  <p>volume.create.*</p>
                  <p>volume.delete.*</p>
                  <p>volume.update.*</p>
                  <p>volume.resize.*</p>
                  <p>volume.attach.*</p>
                  <p>volume.detach.*</p>
                  <p>snapshot.exists</p>
                  <p>snapshot.create.*</p>
                  <p>snapshot.delete.*</p>
                  <p>snapshot.update.*</p>
                  <p>volume.backup.create.*</p>
                  <p>volume.backup.delete.*</p>
                  <p>volume.backup.restore.*</p>
                </td><td>
                  <p>The required configuration for Block Storage service can be found in the
<a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/cinder/install-cinder-ubuntu.html" target="_blank">Add the Block Storage service agent for Telemetry section</a>
in the Installation Tutorials and Guides.</p>
                </td></tr></tbody></table></div><div id="id-1.4.12.10.7.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Some services require additional configuration to emit the
notifications using the correct control exchange on the message
queue and so forth. These configuration needs are referred in the
above table for each OpenStack service that needs it.</p></div><p>Specific notifications from the Compute service are important for
administrators and users. Configuring <code class="literal">nova_notifications</code> in the
<code class="literal">nova.conf</code> file allows administrators to respond to events
rapidly. For more information on configuring notifications for the
compute service, see
<a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/nova/install-nova-ubuntu.html" target="_blank">Telemetry services</a> in the
Installation Tutorials and Guides.</p><div id="id-1.4.12.10.7.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When the <code class="literal">store_events</code> option is set to <code class="literal">True</code> in
<code class="literal">ceilometer.conf</code>, Prior to the Kilo release, the notification agent
needed database access in order to work properly.</p></div><div class="sect3 " id="id-1.4.12.10.7.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute agent</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.7.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This agent is responsible for collecting resource usage data of VM
instances on individual compute nodes within an OpenStack deployment.
This mechanism requires a closer interaction with the hypervisor,
therefore a separate agent type fulfills the collection of the related
meters, which is placed on the host machines to retrieve this
information locally.</p><p>A Compute agent instance has to be installed on each and every compute
node, installation instructions can be found in the <a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/nova/install-nova-ubuntu.html" target="_blank">Install the Compute
agent for Telemetry</a>
section in the Installation Tutorials and Guides.</p><p>Just like the central agent, this component also does not need a direct
database connection. The samples are sent via AMQP to the notification agent.</p><p>The list of supported hypervisors can be found in
<a class="xref" href="#telemetry-supported-hypervisors" title="10.1.2. Supported hypervisors">Section 10.1.2, “Supported hypervisors”</a>. The Compute agent uses the API of the
hypervisor installed on the compute hosts. Therefore, the supported meters may
be different in case of each virtualization back end, as each inspection tool
provides a different set of meters.</p><p>The list of collected meters can be found in <a class="xref" href="#telemetry-compute-meters" title="10.6.1. OpenStack Compute">Section 10.6.1, “OpenStack Compute”</a>.
The support column provides the information about which meter is available for
each hypervisor supported by the Telemetry service.</p><div id="id-1.4.12.10.7.10.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Telemetry supports Libvirt, which hides the hypervisor under it.</p></div></div><div class="sect3 " id="id-1.4.12.10.7.11"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Middleware for the OpenStack Object Storage service</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.7.11">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A subset of Object Store statistics requires additional middleware to
be installed behind the proxy of Object Store. This additional component
emits notifications containing data-flow-oriented meters, namely the
<code class="literal">storage.objects.(incoming|outgoing).bytes values</code>. The list of these
meters are listed in <a class="xref" href="#telemetry-object-storage-meter" title="10.6.7. OpenStack Object Storage">Section 10.6.7, “OpenStack Object Storage”</a>, marked with
<code class="literal">notification</code> as origin.</p><p>The instructions on how to install this middleware can be found in
<a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/configure_services/swift/install-swift-ubuntu.html" target="_blank">Configure the Object Storage service for Telemetry</a>
section in the Installation Tutorials and Guides.</p></div><div class="sect3 " id="id-1.4.12.10.7.12"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry middleware</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.7.12">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Telemetry provides HTTP request and API endpoint counting
capability in OpenStack. This is achieved by
storing a sample for each event marked as <code class="literal">audit.http.request</code>,
<code class="literal">audit.http.response</code>, <code class="literal">http.request</code> or <code class="literal">http.response</code>.</p><p>It is recommended that these notifications be consumed as events rather
than samples to better index the appropriate values and avoid massive
load on the Metering database. If preferred, Telemetry can consume these
events as samples if the services are configured to emit <code class="literal">http.*</code>
notifications.</p></div></div><div class="sect2 " id="id-1.4.12.10.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Polling</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service is intended to store a complex picture of the
infrastructure. This goal requires additional information than what is
provided by the events and notifications published by each service. Some
information is not emitted directly, like resource usage of the VM
instances.</p><p>Therefore Telemetry uses another method to gather this data by polling
the infrastructure including the APIs of the different OpenStack
services and other assets, like hypervisors. The latter case requires
closer interaction with the compute hosts. To solve this issue,
Telemetry uses an agent based architecture to fulfill the requirements
against the data collection.</p><p>There are three types of agents supporting the polling mechanism, the
<code class="literal">compute agent</code>, the <code class="literal">central agent</code>, and the <code class="literal">IPMI agent</code>. Under
the hood, all the types of polling agents are the same
<code class="literal">ceilometer-polling</code> agent, except that they load different polling
plug-ins (pollsters) from different namespaces to gather data. The following
subsections give further information regarding the architectural and
configuration details of these components.</p><p>Running <code class="command">ceilometer-agent-compute</code> is exactly the same as:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer-polling --polling-namespaces compute</pre></div><p>Running <code class="command">ceilometer-agent-central</code> is exactly the same as:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer-polling --polling-namespaces central</pre></div><p>Running <code class="command">ceilometer-agent-ipmi</code> is exactly the same as:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer-polling --polling-namespaces ipmi</pre></div><p>In addition to loading all the polling plug-ins registered in the
specified namespaces, the <code class="literal">ceilometer-polling</code> agent can also specify the
polling plug-ins to be loaded by using the <code class="literal">pollster-list</code> option:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer-polling --polling-namespaces central \
        --pollster-list image image.size storage.*</pre></div><div id="id-1.4.12.10.8.13" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>HA deployment is NOT supported if the <code class="literal">pollster-list</code> option is
used.</p></div><div id="id-1.4.12.10.8.14" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">ceilometer-polling</code> service is available since Kilo release.</p></div><div class="sect3 " id="id-1.4.12.10.8.15"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Central agent</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.8.15">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This agent is responsible for polling public REST APIs to retrieve additional
information on OpenStack resources not already surfaced via notifications,
and also for polling hardware resources over SNMP.</p><p>The following services can be polled with this agent:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>OpenStack Networking</p></li><li class="listitem "><p>OpenStack Object Storage</p></li><li class="listitem "><p>OpenStack Block Storage</p></li><li class="listitem "><p>Hardware resources via SNMP</p></li><li class="listitem "><p>Energy consumption meters via <a class="link" href="https://launchpad.net/kwapi" target="_blank">Kwapi</a>
framework</p></li></ul></div><p>To install and configure this service use the <a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/install-base-ubuntu.html" target="_blank">Add the Telemetry service</a>
section in the Installation Tutorials and Guides.</p><p>The central agent does not need direct database connection. The samples
collected by this agent are sent via AMQP to the notification agent to be
processed.</p><div id="id-1.4.12.10.8.15.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Prior to the Liberty release, data from the polling agents was processed
locally and published accordingly rather than by the notification agent.</p></div></div><div class="sect3 " id="telemetry-ipmi-agent"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">IPMI agent</span> <a title="Permalink" class="permalink" href="#telemetry-ipmi-agent">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-ipmi-agent</li></ul></div></div></div></div><p>This agent is responsible for collecting IPMI sensor data and Intel Node
Manager data on individual compute nodes within an OpenStack deployment.
This agent requires an IPMI capable node with the ipmitool utility installed,
which is commonly used for IPMI control on various Linux distributions.</p><p>An IPMI agent instance could be installed on each and every compute node
with IPMI support, except when the node is managed by the Bare metal
service and the <code class="literal">conductor.send_sensor_data</code> option is set to <code class="literal">true</code>
in the Bare metal service. It is no harm to install this agent on a
compute node without IPMI or Intel Node Manager support, as the agent
checks for the hardware and if none is available, returns empty data. It
is suggested that you install the IPMI agent only on an IPMI capable
node for performance reasons.</p><p>Just like the central agent, this component also does not need direct
database access. The samples are sent via AMQP to the notification agent.</p><p>The list of collected meters can be found in
<a class="xref" href="#telemetry-bare-metal-service" title="10.6.2. Bare metal service">Section 10.6.2, “Bare metal service”</a>.</p><div id="id-1.4.12.10.8.16.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Do not deploy both the IPMI agent and the Bare metal service on one
compute node. If <code class="literal">conductor.send_sensor_data</code> is set, this
misconfiguration causes duplicated IPMI sensor samples.</p></div></div></div><div class="sect2 " id="ha-deploy-services"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Support for HA deployment</span> <a title="Permalink" class="permalink" href="#ha-deploy-services">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>ha-deploy-services</li></ul></div></div></div></div><p>Both the polling agents and notification agents can run in an HA deployment,
which means that multiple instances of these services can run in
parallel with workload partitioning among these running instances.</p><p>The <a class="link" href="https://pypi.python.org/pypi/tooz" target="_blank">Tooz</a> library provides the
coordination within the groups of service instances. It provides an API
above several back ends that can be used for building distributed
applications.</p><p>Tooz supports <a class="link" href="http://docs.openstack.org/developer/tooz/drivers.html" target="_blank">various
drivers</a>
including the following back end solutions:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><a class="link" href="http://zookeeper.apache.org/" target="_blank">Zookeeper</a>. Recommended solution by
the Tooz project.</p></li><li class="listitem "><p><a class="link" href="http://redis.io/" target="_blank">Redis</a>. Recommended solution by the Tooz
project.</p></li><li class="listitem "><p><a class="link" href="http://memcached.org/" target="_blank">Memcached</a>. Recommended for testing.</p></li></ul></div><p>You must configure a supported Tooz driver for the HA deployment of the
Telemetry services.</p><p>For information about the required configuration options that have to be
set in the <code class="literal">ceilometer.conf</code> configuration file for both the central
and Compute agents, see the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">Coordination section</a>
in the OpenStack Configuration Reference.</p><div class="sect3 " id="id-1.4.12.10.9.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notification agent HA deployment</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.9.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the Kilo release, workload partitioning support was added to the
notification agent. This is particularly useful as the pipeline processing
is handled exclusively by the notification agent now which may result
in a larger amount of load.</p><p>To enable workload partitioning by notification agent, the <code class="literal">backend_url</code>
option must be set in the <code class="literal">ceilometer.conf</code> configuration file.
Additionally, <code class="literal">workload_partitioning</code> should be enabled in the
<a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">Notification section</a> in the OpenStack Configuration Reference.</p><div id="id-1.4.12.10.9.8.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>In Liberty, the notification agent creates multiple queues to divide the
workload across all active agents. The number of queues can be controlled by
the <code class="literal">pipeline_processing_queues</code> option in the <code class="literal">ceilometer.conf</code>
configuration file. A larger value will result in better distribution of
tasks but will also require more memory and longer startup time. It is
recommended to have a value approximately three times the number of active
notification agents. At a minimum, the value should be equal to the number
of active agents.</p></div></div><div class="sect3 " id="id-1.4.12.10.9.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Polling agent HA deployment</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.9.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.12.10.9.9.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Without the <code class="literal">backend_url</code> option being set only one instance of
both the central and Compute agent service is able to run and
function correctly.</p></div><p>The availability check of the instances is provided by heartbeat
messages. When the connection with an instance is lost, the workload
will be reassigned within the remained instances in the next polling
cycle.</p><div id="id-1.4.12.10.9.9.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p><code class="literal">Memcached</code> uses a <code class="literal">timeout</code> value, which should always be set
to a value that is higher than the <code class="literal">heartbeat</code> value set for
Telemetry.</p></div><p>For backward compatibility and supporting existing deployments, the
central agent configuration also supports using different configuration
files for groups of service instances of this type that are running in
parallel. For enabling this configuration set a value for the
<code class="literal">partitioning_group_prefix</code> option in the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">polling section</a>
in the OpenStack Configuration Reference.</p><div id="id-1.4.12.10.9.9.6" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>For each sub-group of the central agent pool with the same
<code class="literal">partitioning_group_prefix</code> a disjoint subset of meters must be
polled, otherwise samples may be missing or duplicated. The list of
meters to poll can be set in the <code class="literal">/etc/ceilometer/pipeline.yaml</code>
configuration file. For more information about pipelines see
<a class="xref" href="#data-collection-and-processing" title="10.3. Data collection, processing, and pipelines">Section 10.3, “Data collection, processing, and pipelines”</a>.</p></div><p>To enable the Compute agent to run multiple instances simultaneously
with workload partitioning, the <code class="literal">workload_partitioning</code> option has to
be set to <code class="literal">True</code> under the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">Compute section</a>
in the <code class="literal">ceilometer.conf</code> configuration file.</p></div></div><div class="sect2 " id="id-1.4.12.10.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Send samples to Telemetry</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>While most parts of the data collection in the Telemetry service are
automated, Telemetry provides the possibility to submit samples via the
REST API to allow users to send custom samples into this service.</p><p>This option makes it possible to send any kind of samples without the
need of writing extra code lines or making configuration changes.</p><p>The samples that can be sent to Telemetry are not limited to the actual
existing meters. There is a possibility to provide data for any new,
customer defined counter by filling out all the required fields of the
POST request.</p><p>If the sample corresponds to an existing meter, then the fields like
<code class="literal">meter-type</code> and meter name should be matched accordingly.</p><p>The required fields for sending a sample using the command-line client
are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>ID of the corresponding resource. (<code class="literal">--resource-id</code>)</p></li><li class="listitem "><p>Name of meter. (<code class="literal">--meter-name</code>)</p></li><li class="listitem "><p>Type of meter. (<code class="literal">--meter-type</code>)</p><p>Predefined meter types:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Gauge</p></li><li class="listitem "><p>Delta</p></li><li class="listitem "><p>Cumulative</p></li></ul></div></li><li class="listitem "><p>Unit of meter. (<code class="literal">--meter-unit</code>)</p></li><li class="listitem "><p>Volume of sample. (<code class="literal">--sample-volume</code>)</p></li></ul></div><p>To send samples to Telemetry using the command-line client, the
following command should be invoked:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer sample-create -r 37128ad6-daaa-4d22-9509-b7e1c6b08697 \
  -m memory.usage --meter-type gauge --meter-unit MB --sample-volume 48
+-------------------+--------------------------------------------+
| Property          | Value                                      |
+-------------------+--------------------------------------------+
| message_id        | 6118820c-2137-11e4-a429-08002715c7fb       |
| name              | memory.usage                               |
| project_id        | e34eaa91d52a4402b4cb8bc9bbd308c1           |
| resource_id       | 37128ad6-daaa-4d22-9509-b7e1c6b08697       |
| resource_metadata | {}                                         |
| source            | e34eaa91d52a4402b4cb8bc9bbd308c1:openstack |
| timestamp         | 2014-08-11T09:10:46.358926                 |
| type              | gauge                                      |
| unit              | MB                                         |
| user_id           | 679b0499e7a34ccb9d90b64208401f8e           |
| volume            | 48.0                                       |
+-------------------+--------------------------------------------+</pre></div><div class="sect3 " id="id-1.4.12.10.10.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Meter definitions</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.10.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service collects a subset of the meters by filtering
notifications emitted by other OpenStack services. Starting with the Liberty
release, you can find the meter definitions in a separate configuration file,
called <code class="literal">ceilometer/meter/data/meter.yaml</code>. This enables
operators/administrators to add new meters to Telemetry project by updating
the <code class="literal">meter.yaml</code> file without any need for additional code changes.</p><div id="id-1.4.12.10.10.10.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">meter.yaml</code> file should be modified with care. Unless intended
do not remove any existing meter definitions from the file. Also, the
collected meters can differ in some cases from what is referenced in the
documentation.</p></div><p>A standard meter definition looks like:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
metric:
  - name: 'meter name'
    event_type: 'event name'
    type: 'type of meter eg: gauge, cumulative or delta'
    unit: 'name of unit eg: MB'
    volume: 'path to a measurable value eg: $.payload.size'
    resource_id: 'path to resource id eg: $.payload.id'
    project_id: 'path to project id eg: $.payload.owner'</pre></div><p>The definition above shows a simple meter definition with some fields,
from which <code class="literal">name</code>, <code class="literal">event_type</code>, <code class="literal">type</code>, <code class="literal">unit</code>, and <code class="literal">volume</code>
are required. If there is a match on the event type, samples are generated
for the meter.</p><p>If you take a look at the <code class="literal">meter.yaml</code> file, it contains the sample
definitions for all the meters that Telemetry is collecting from
notifications. The value of each field is specified by using JSON path in
order to find the right value from the notification message. In order to be
able to specify the right field you need to be aware of the format of the
consumed notification. The values that need to be searched in the notification
message are set with a JSON path starting with <code class="literal">$.</code> For instance, if you need
the <code class="literal">size</code> information from the payload you can define it like
<code class="literal">$.payload.size</code>.</p><p>A notification message may contain multiple meters. You can use <code class="literal">*</code> in
the meter definition to capture all the meters and generate samples
respectively. You can use wild cards as shown in the following example:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
metric:
  - name: $.payload.measurements.[*].metric.[*].name
    event_type: 'event_name.*'
    type: 'delta'
    unit: $.payload.measurements.[*].metric.[*].unit
    volume: payload.measurements.[*].result
    resource_id: $.payload.target
    user_id: $.payload.initiator.id
    project_id: $.payload.initiator.project_id</pre></div><p>In the above example, the <code class="literal">name</code> field is a JSON path with matching
a list of meter names defined in the notification message.</p><p>You can even use complex operations on JSON paths. In the following example,
<code class="literal">volume</code> and <code class="literal">resource_id</code> fields perform an arithmetic
and string concatenation:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
metric:
- name: 'compute.node.cpu.idle.percent'
  event_type: 'compute.metrics.update'
  type: 'gauge'
  unit: 'percent'
  volume: payload.metrics[?(@.name='cpu.idle.percent')].value * 100
  resource_id: $.payload.host + "_" + $.payload.nodename</pre></div><p>You can use the <code class="literal">timedelta</code> plug-in to evaluate the difference in seconds
between two <code class="literal">datetime</code> fields from one notification.</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
metric:
- name: 'compute.instance.booting.time'
  event_type: 'compute.instance.create.end'
 type: 'gauge'
 unit: 'sec'
 volume:
   fields: [$.payload.created_at, $.payload.launched_at]
   plugin: 'timedelta'
 project_id: $.payload.tenant_id
 resource_id: $.payload.instance_id</pre></div><p>You will find some existence meters in the <code class="literal">meter.yaml</code>. These
meters have a <code class="literal">volume</code> as <code class="literal">1</code> and are at the bottom of the yaml file
with a note suggesting that these will be removed in Mitaka release.</p><p>For example, the meter definition for existence meters is as follows:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
metric:
  - name: 'meter name'
    type: 'delta'
    unit: 'volume'
    volume: 1
    event_type:
        - 'event type'
    resource_id: $.payload.volume_id
    user_id: $.payload.user_id
    project_id: $.payload.tenant_id</pre></div><p>These meters are not loaded by default. To load these meters, flip
the <code class="literal">disable_non_metric_meters</code> option in the <code class="literal">ceilometer.conf</code>
file.</p></div></div><div class="sect2 " id="id-1.4.12.10.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Block Storage audit script setup to get notifications</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you want to collect OpenStack Block Storage notification on demand,
you can use <code class="command">cinder-volume-usage-audit</code> from OpenStack Block Storage.
This script becomes available when you install OpenStack Block Storage,
so you can use it without any specific settings and you don't need to
authenticate to access the data. To use it, you must run this command in
the following format:</p><div class="verbatim-wrap"><pre class="screen">$ cinder-volume-usage-audit \
  --start_time='YYYY-MM-DD HH:MM:SS' --end_time='YYYY-MM-DD HH:MM:SS' --send_actions</pre></div><p>This script outputs what volumes or snapshots were created, deleted, or
exists in a given period of time and some information about these
volumes or snapshots. Information about the existence and size of
volumes and snapshots is store in the Telemetry service. This data is
also stored as an event which is the recommended usage as it provides
better indexing of data.</p><p>Using this script via cron you can get notifications periodically, for
example, every 5 minutes:</p><div class="verbatim-wrap"><pre class="screen">*/5 * * * * /path/to/cinder-volume-usage-audit --send_actions</pre></div></div><div class="sect2 " id="telemetry-storing-samples"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storing samples</span> <a title="Permalink" class="permalink" href="#telemetry-storing-samples">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-storing-samples</li></ul></div></div></div></div><p>The Telemetry service has a separate service that is responsible for
persisting the data that comes from the pollsters or is received as
notifications. The data can be stored in a file or a database back end,
for which the list of supported databases can be found in
<a class="xref" href="#telemetry-supported-databases" title="10.1.1. Supported databases">Section 10.1.1, “Supported databases”</a>. The data can also be sent to an external
data store by using an HTTP dispatcher.</p><p>The <code class="literal">ceilometer-collector</code> service receives the data as messages from the
message bus of the configured AMQP service. It sends these datapoints
without any modification to the configured target. The service has to
run on a host machine from which it has access to the configured
dispatcher.</p><div id="id-1.4.12.10.12.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Multiple dispatchers can be configured for Telemetry at one time.</p></div><p>Multiple <code class="literal">ceilometer-collector</code> processes can be run at a time. It is also
supported to start multiple worker threads per collector process. The
<code class="literal">collector_workers</code> configuration option has to be modified in the
<a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">Collector section</a>
of the <code class="literal">ceilometer.conf</code> configuration file.</p><div class="sect3 " id="id-1.4.12.10.12.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Database dispatcher</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.12.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When the database dispatcher is configured as data store, you have the
option to set a <code class="literal">time_to_live</code> option (ttl) for samples. By default
the time to live value for samples is set to -1, which means that they
are kept in the database forever.</p><p>The time to live value is specified in seconds. Each sample has a time
stamp, and the <code class="literal">ttl</code> value indicates that a sample will be deleted
from the database when the number of seconds has elapsed since that
sample reading was stamped. For example, if the time to live is set to
600, all samples older than 600 seconds will be purged from the
database.</p><p>Certain databases support native TTL expiration. In cases where this is
not possible, a command-line script, which you can use for this purpose
is <code class="literal">ceilometer-expirer</code>. You can run it in a cron job, which helps to keep
your database in a consistent state.</p><p>The level of support differs in case of the configured back end:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                    <p>Database</p>
                  </th><th>
                    <p>TTL value support</p>
                  </th><th>
                    <p>Note</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>MongoDB</p>
                  </td><td>
                    <p>Yes</p>
                  </td><td>
                    <p>MongoDB has native TTL support for deleting samples
that are older than the configured ttl value.</p>
                  </td></tr><tr><td>
                    <p>SQL-based back ends</p>
                  </td><td>
                    <p>Yes</p>
                  </td><td>
                    <p><code class="literal">ceilometer-expirer</code> has to be used for deleting
samples and its related data from the database.</p>
                  </td></tr><tr><td>
                    <p>HBase</p>
                  </td><td>
                    <p>No</p>
                  </td><td>
                    <p>Telemetry's HBase support does not include native TTL
nor <code class="literal">ceilometer-expirer</code> support.</p>
                  </td></tr><tr><td>
                    <p>DB2 NoSQL</p>
                  </td><td>
                    <p>No</p>
                  </td><td>
                    <p>DB2 NoSQL does not have native TTL
nor <code class="literal">ceilometer-expirer</code> support.</p>
                  </td></tr></tbody></table></div></div><div class="sect3 " id="id-1.4.12.10.12.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">HTTP dispatcher</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.12.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service supports sending samples to an external HTTP
target. The samples are sent without any modification. To set this
option as the collector's target, the <code class="literal">dispatcher</code> has to be changed
to <code class="literal">http</code> in the <code class="literal">ceilometer.conf</code> configuration file. For the list
of options that you need to set, see the see the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">dispatcher_http
section</a>
in the OpenStack Configuration Reference.</p></div><div class="sect3 " id="id-1.4.12.10.12.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.2.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">File dispatcher</span> <a title="Permalink" class="permalink" href="#id-1.4.12.10.12.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can store samples in a file by setting the <code class="literal">dispatcher</code> option in the
<code class="literal">ceilometer.conf</code> file. For the list of configuration options,
see the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">dispatcher_file section</a>
in the OpenStack Configuration Reference.</p></div></div></div><div class="sect1 " id="data-collection-and-processing"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data collection, processing, and pipelines</span> <a title="Permalink" class="permalink" href="#data-collection-and-processing">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>data-collection-and-processing</li></ul></div></div></div></div><p>The mechanism by which data is collected and processed is called a
pipeline. Pipelines, at the configuration level, describe a coupling
between sources of data and the corresponding sinks for transformation
and publication of data.</p><p>A source is a producer of data: <code class="literal">samples</code> or <code class="literal">events</code>. In effect, it is a
set of pollsters or notification handlers emitting datapoints for a set
of matching meters and event types.</p><p>Each source configuration encapsulates name matching, polling interval
determination, optional resource enumeration or discovery, and mapping
to one or more sinks for publication.</p><p>Data gathered can be used for different purposes, which can impact how
frequently it needs to be published. Typically, a meter published for
billing purposes needs to be updated every 30 minutes while the same
meter may be needed for performance tuning every minute.</p><div id="id-1.4.12.11.6" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Rapid polling cadences should be avoided, as it results in a huge
amount of data in a short time frame, which may negatively affect
the performance of both Telemetry and the underlying database back
end. We strongly recommend you do not use small granularity
values like 10 seconds.</p></div><p>A sink, on the other hand, is a consumer of data, providing logic for
the transformation and publication of data emitted from related sources.</p><p>In effect, a sink describes a chain of handlers. The chain starts with
zero or more transformers and ends with one or more publishers. The
first transformer in the chain is passed data from the corresponding
source, takes some action such as deriving rate of change, performing
unit conversion, or aggregating, before passing the modified data to the
next step that is described in <a class="xref" href="#telemetry-publishers" title="10.4.3. Publishers">Section 10.4.3, “Publishers”</a>.</p><div class="sect2 " id="telemetry-pipeline-configuration"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Pipeline configuration</span> <a title="Permalink" class="permalink" href="#telemetry-pipeline-configuration">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-pipeline-configuration</li></ul></div></div></div></div><p>The pipeline configuration is, by default stored in separate configuration
files called <code class="literal">pipeline.yaml</code> and <code class="literal">event_pipeline.yaml</code> next to
the <code class="literal">ceilometer.conf</code> file. The meter pipeline and event pipeline
configuration files can be set by the <code class="literal">pipeline_cfg_file</code> and
<code class="literal">event_pipeline_cfg_file</code> options listed in the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry/telemetry-config-options.html" target="_blank">Description of
configuration options for api table</a>
section in the OpenStack Configuration Reference respectively. Multiple
pipelines can be defined in one pipeline configuration file.</p><p>The meter pipeline definition looks like:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
sources:
  - name: 'source name'
    interval: 'how often should the samples be injected into the pipeline'
    meters:
      - 'meter filter'
    resources:
      - 'list of resource URLs'
    sinks
      - 'sink name'
sinks:
  - name: 'sink name'
    transformers: 'definition of transformers'
    publishers:
      - 'list of publishers'</pre></div><p>The interval parameter in the sources section should be defined in
seconds. It determines the polling cadence of sample injection into the
pipeline, where samples are produced under the direct control of an
agent.</p><p>There are several ways to define the list of meters for a pipeline
source. The list of valid meters can be found in <a class="xref" href="#telemetry-measurements" title="10.6. Measurements">Section 10.6, “Measurements”</a>.
There is a possibility to define all the meters, or just included or excluded
meters, with which a source should operate:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To include all meters, use the <code class="literal">*</code> wildcard symbol. It is highly
advisable to select only the meters that you intend on using to avoid
flooding the metering database with unused data.</p></li><li class="listitem "><p>To define the list of meters, use either of the following:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To define the list of included meters, use the <code class="literal">meter_name</code>
syntax.</p></li><li class="listitem "><p>To define the list of excluded meters, use the <code class="literal">!meter_name</code>
syntax.</p></li><li class="listitem "><p>For meters, which have variants identified by a complex name
field, use the wildcard symbol to select all, for example,
for <code class="literal">instance:m1.tiny</code>, use <code class="literal">instance:\*</code>.</p></li></ul></div></li></ul></div><div id="id-1.4.12.11.9.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The OpenStack Telemetry service does not have any duplication check
between pipelines, and if you add a meter to multiple pipelines then it is
assumed the duplication is intentional and may be stored multiple
times according to the specified sinks.</p></div><p>The above definition methods can be used in the following combinations:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Use only the wildcard symbol.</p></li><li class="listitem "><p>Use the list of included meters.</p></li><li class="listitem "><p>Use the list of excluded meters.</p></li><li class="listitem "><p>Use wildcard symbol with the list of excluded meters.</p></li></ul></div><div id="id-1.4.12.11.9.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>At least one of the above variations should be included in the
meters section. Included and excluded meters cannot co-exist in the
same pipeline. Wildcard and included meters cannot co-exist in the
same pipeline definition section.</p></div><p>The optional resources section of a pipeline source allows a static list
of resource URLs to be configured for polling.</p><p>The transformers section of a pipeline sink provides the possibility to
add a list of transformer definitions. The available transformers are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Name of transformer</p>
                </th><th>
                  <p>Reference name for configuration</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Accumulator</p>
                </td><td>
                  <p>accumulator</p>
                </td></tr><tr><td>
                  <p>Aggregator</p>
                </td><td>
                  <p>aggregator</p>
                </td></tr><tr><td>
                  <p>Arithmetic</p>
                </td><td>
                  <p>arithmetic</p>
                </td></tr><tr><td>
                  <p>Rate of change</p>
                </td><td>
                  <p>rate_of_change</p>
                </td></tr><tr><td>
                  <p>Unit conversion</p>
                </td><td>
                  <p>unit_conversion</p>
                </td></tr><tr><td>
                  <p>Delta</p>
                </td><td>
                  <p>delta</p>
                </td></tr></tbody></table></div><p>The publishers section contains the list of publishers, where the
samples data should be sent after the possible transformations.</p><p>Similarly, the event pipeline definition looks like:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">---
sources:
  - name: 'source name'
    events:
      - 'event filter'
    sinks
      - 'sink name'
sinks:
  - name: 'sink name'
    publishers:
      - 'list of publishers'</pre></div><p>The event filter uses the same filtering logic as the meter pipeline.</p><div class="sect3 " id="telemetry-transformers"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.3.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Transformers</span> <a title="Permalink" class="permalink" href="#telemetry-transformers">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-transformers</li></ul></div></div></div></div><p>The definition of transformers can contain the following fields:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.11.9.19.3.1"><span class="term ">name</span></dt><dd><p>Name of the transformer.</p></dd><dt id="id-1.4.12.11.9.19.3.2"><span class="term ">parameters</span></dt><dd><p>Parameters of the transformer.</p></dd></dl></div><p>The parameters section can contain transformer specific fields, like
source and target fields with different subfields in case of the rate of
change, which depends on the implementation of the transformer.</p><p>In the case of the transformer that creates the <code class="literal">cpu_util</code> meter, the
definition looks like:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "rate_of_change"
      parameters:
          target:
              name: "cpu_util"
              unit: "%"
              type: "gauge"
              scale: "100.0 / (10**9 * (resource_metadata.cpu_number or 1))"</pre></div><p>The rate of change the transformer generates is the <code class="literal">cpu_util</code> meter
from the sample values of the <code class="literal">cpu</code> counter, which represents
cumulative CPU time in nanoseconds. The transformer definition above
defines a scale factor (for nanoseconds and multiple CPUs), which is
applied before the transformation derives a sequence of gauge samples
with unit <code class="literal">%</code>, from sequential values of the <code class="literal">cpu</code> meter.</p><p>The definition for the disk I/O rate, which is also generated by the
rate of change transformer:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "rate_of_change"
      parameters:
          source:
              map_from:
                  name: "disk\\.(read|write)\\.(bytes|requests)"
                  unit: "(B|request)"
          target:
              map_to:
                  name: "disk.\\1.\\2.rate"
                  unit: "\\1/s"
              type: "gauge"</pre></div></div><div class="sect3 " id="id-1.4.12.11.9.20"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.3.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Unit conversion transformer</span> <a title="Permalink" class="permalink" href="#id-1.4.12.11.9.20">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Transformer to apply a unit conversion. It takes the volume of the meter
and multiplies it with the given <code class="literal">scale</code> expression. Also supports
<code class="literal">map_from</code> and <code class="literal">map_to</code> like the rate of change transformer.</p><p>Sample configuration:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "unit_conversion"
      parameters:
          target:
              name: "disk.kilobytes"
              unit: "KB"
              scale: "volume * 1.0 / 1024.0"</pre></div><p>With <code class="literal">map_from</code> and <code class="literal">map_to</code>:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "unit_conversion"
      parameters:
          source:
              map_from:
                  name: "disk\\.(read|write)\\.bytes"
          target:
              map_to:
                  name: "disk.\\1.kilobytes"
              scale: "volume * 1.0 / 1024.0"
              unit: "KB"</pre></div></div><div class="sect3 " id="id-1.4.12.11.9.21"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.3.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Aggregator transformer</span> <a title="Permalink" class="permalink" href="#id-1.4.12.11.9.21">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A transformer that sums up the incoming samples until enough samples
have come in or a timeout has been reached.</p><p>Timeout can be specified with the <code class="literal">retention_time</code> option. If you want
to flush the aggregation, after a set number of samples have been
aggregated, specify the size parameter.</p><p>The volume of the created sample is the sum of the volumes of samples
that came into the transformer. Samples can be aggregated by the
attributes <code class="literal">project_id</code>, <code class="literal">user_id</code> and <code class="literal">resource_metadata</code>. To aggregate
by the chosen attributes, specify them in the configuration and set which
value of the attribute to take for the new sample (first to take the
first sample's attribute, last to take the last sample's attribute, and
drop to discard the attribute).</p><p>To aggregate 60s worth of samples by <code class="literal">resource_metadata</code> and keep the
<code class="literal">resource_metadata</code> of the latest received sample:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "aggregator"
      parameters:
          retention_time: 60
          resource_metadata: last</pre></div><p>To aggregate each 15 samples by <code class="literal">user_id</code> and <code class="literal">resource_metadata</code> and keep
the <code class="literal">user_id</code> of the first received sample and drop the
<code class="literal">resource_metadata</code>:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "aggregator"
      parameters:
          size: 15
          user_id: first
          resource_metadata: drop</pre></div></div><div class="sect3 " id="id-1.4.12.11.9.22"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.3.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accumulator transformer</span> <a title="Permalink" class="permalink" href="#id-1.4.12.11.9.22">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This transformer simply caches the samples until enough samples have
arrived and then flushes them all down the pipeline at once:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "accumulator"
      parameters:
          size: 15</pre></div></div><div class="sect3 " id="id-1.4.12.11.9.23"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.3.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Multi meter arithmetic transformer</span> <a title="Permalink" class="permalink" href="#id-1.4.12.11.9.23">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This transformer enables us to perform arithmetic calculations over one
or more meters and/or their metadata, for example:</p><div class="verbatim-wrap highlight json"><pre class="screen">memory_util = 100 * memory.usage / memory</pre></div><p>A new sample is created with the properties described in the <code class="literal">target</code>
section of the transformer's configuration. The sample's
volume is the result of the provided expression. The calculation is
performed on samples from the same resource.</p><div id="id-1.4.12.11.9.23.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The calculation is limited to meters with the same interval.</p></div><p>Example configuration:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "arithmetic"
      parameters:
        target:
          name: "memory_util"
          unit: "%"
          type: "gauge"
          expr: "100 * $(memory.usage) / $(memory)"</pre></div><p>To demonstrate the use of metadata, the following implementation of a
novel meter shows average CPU time per core:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "arithmetic"
      parameters:
        target:
          name: "avg_cpu_per_core"
          unit: "ns"
          type: "cumulative"
          expr: "$(cpu) / ($(cpu).resource_metadata.cpu_number or 1)"</pre></div><div id="id-1.4.12.11.9.23.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Expression evaluation gracefully handles NaNs and exceptions. In
such a case it does not create a new sample but only logs a warning.</p></div></div><div class="sect3 " id="id-1.4.12.11.9.24"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.3.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delta transformer</span> <a title="Permalink" class="permalink" href="#id-1.4.12.11.9.24">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This transformer calculates the change between two sample datapoints of a
resource. It can be configured to capture only the positive growth deltas.</p><p>Example configuration:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">transformers:
    - name: "delta"
      parameters:
        target:
            name: "cpu.delta"
        growth_only: True</pre></div></div></div></div><div class="sect1 " id="id-1.4.12.12"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data retrieval</span> <a title="Permalink" class="permalink" href="#id-1.4.12.12">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service offers several mechanisms from which the persisted
data can be accessed. As described in <a class="xref" href="#telemetry-system-architecture" title="10.1. System architecture">Section 10.1, “System architecture”</a> and
in <a class="xref" href="#telemetry-data-collection" title="10.2. Data collection">Section 10.2, “Data collection”</a>, the collected information can be stored in
one or more database back ends, which are hidden by the Telemetry RESTful API.</p><div id="id-1.4.12.12.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>It is highly recommended not to access the database directly and
read or modify any data in it. The API layer hides all the changes
in the actual database schema and provides a standard interface to
expose the samples, alarms and so forth.</p></div><div class="sect2 " id="id-1.4.12.12.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry v2 API</span> <a title="Permalink" class="permalink" href="#id-1.4.12.12.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service provides a RESTful API, from which the collected
samples and all the related information can be retrieved, like the list
of meters, alarm definitions and so forth.</p><p>The Telemetry API URL can be retrieved from the service catalog provided
by OpenStack Identity, which is populated during the installation
process. The API access needs a valid token and proper permission to
retrieve data, as described in <a class="xref" href="#telemetry-users-roles-projects" title="10.1.4. Users, roles, and projects">Section 10.1.4, “Users, roles, and projects”</a>.</p><p>Further information about the available API endpoints can be found in
the <a class="link" href="http://developer.openstack.org/api-ref-telemetry-v2.html" target="_blank">Telemetry API Reference</a>.</p><div class="sect3 " id="sec-query"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.4.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Query</span> <a title="Permalink" class="permalink" href="#sec-query">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>sec-query</li></ul></div></div></div></div><p>The API provides some additional functionalities, like querying the
collected data set. For the samples and alarms API endpoints, both
simple and complex query styles are available, whereas for the other
endpoints only simple queries are supported.</p><p>After validating the query parameters, the processing is done on the
database side in the case of most database back ends in order to achieve
better performance.</p><p>
            <span class="bold"><strong>Simple query</strong></span>
          </p><p>Many of the API endpoints accept a query filter argument, which should
be a list of data structures that consist of the following items:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">field</code>
              </p></li><li class="listitem "><p>
                <code class="literal">op</code>
              </p></li><li class="listitem "><p>
                <code class="literal">value</code>
              </p></li><li class="listitem "><p>
                <code class="literal">type</code>
              </p></li></ul></div><p>Regardless of the endpoint on which the filter is applied on, it will
always target the fields of the <a class="link" href="http://docs.openstack.org/developer/ceilometer/webapi/v2.html#Sample" target="_blank">Sample type</a>.</p><p>Several fields of the API endpoints accept shorter names than the ones
defined in the reference. The API will do the transformation internally
and return the output with the fields that are listed in the <a class="link" href="http://docs.openstack.org/developer/ceilometer/webapi/v2.html" target="_blank">API reference</a>.
The fields are the following:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">project_id</code>: project</p></li><li class="listitem "><p><code class="literal">resource_id</code>: resource</p></li><li class="listitem "><p><code class="literal">user_id</code>: user</p></li></ul></div><p>When a filter argument contains multiple constraints of the above form,
a logical <code class="literal">AND</code> relation between them is implied.</p><p>
            <span class="bold"><strong>Complex query</strong></span>
          </p><p>The filter expressions of the complex query feature operate on the
fields of <code class="literal">Sample</code>, <code class="literal">Alarm</code> and <code class="literal">AlarmChange</code> types. The following
comparison operators are supported:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">=</code>
              </p></li><li class="listitem "><p>
                <code class="literal">!=</code>
              </p></li><li class="listitem "><p>
                <code class="literal">&lt;</code>
              </p></li><li class="listitem "><p>
                <code class="literal">&lt;=</code>
              </p></li><li class="listitem "><p>
                <code class="literal">&gt;</code>
              </p></li><li class="listitem "><p>
                <code class="literal">&gt;=</code>
              </p></li></ul></div><p>The following logical operators can be used:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">and</code>
              </p></li><li class="listitem "><p>
                <code class="literal">or</code>
              </p></li><li class="listitem "><p>
                <code class="literal">not</code>
              </p></li></ul></div><div id="id-1.4.12.12.4.5.16" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">not</code> operator has different behavior in MongoDB and in the
SQLAlchemy-based database engines. If the <code class="literal">not</code> operator is
applied on a non existent metadata field then the result depends on
the database engine. In case of MongoDB, it will return every sample
as the <code class="literal">not</code> operator is evaluated true for every sample where the
given field does not exist. On the other hand the SQL-based database
engine will return an empty result because of the underlying
<code class="literal">join</code> operation.</p></div><p>Complex query supports specifying a list of <code class="literal">orderby</code> expressions.
This means that the result of the query can be ordered based on the
field names provided in this list. When multiple keys are defined for
the ordering, these will be applied sequentially in the order of the
specification. The second expression will be applied on the groups for
which the values of the first expression are the same. The ordering can
be ascending or descending.</p><p>The number of returned items can be bounded using the <code class="literal">limit</code> option.</p><p>The <code class="literal">filter</code>, <code class="literal">orderby</code> and <code class="literal">limit</code> fields are optional.</p><div id="id-1.4.12.12.4.5.20" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>As opposed to the simple query, complex query is available via a
separate API endpoint. For more information see the <a class="link" href="http://docs.openstack.org/developer/ceilometer/webapi/v2.html#v2-web-api" target="_blank">Telemetry v2 Web API
Reference</a>.</p></div></div><div class="sect3 " id="id-1.4.12.12.4.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.4.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Statistics</span> <a title="Permalink" class="permalink" href="#id-1.4.12.12.4.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The sample data can be used in various ways for several purposes, like
billing or profiling. In external systems the data is often used in the
form of aggregated statistics. The Telemetry API provides several
built-in functions to make some basic calculations available without any
additional coding.</p><p>Telemetry supports the following statistics and aggregation functions:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.4.6.4.1"><span class="term ">
                <code class="literal">avg</code>
              </span></dt><dd><p>Average of the sample volumes over each period.</p></dd><dt id="id-1.4.12.12.4.6.4.2"><span class="term ">
                <code class="literal">cardinality</code>
              </span></dt><dd><p>Count of distinct values in each period identified by a key
specified as the parameter of this aggregate function. The supported
parameter values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                      <code class="literal">project_id</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">resource_id</code>
                    </p></li><li class="listitem "><p>
                      <code class="literal">user_id</code>
                    </p></li></ul></div></dd></dl></div><div id="id-1.4.12.12.4.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">aggregate.param</code> option is required.</p></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.4.6.6.1"><span class="term ">
                <code class="literal">count</code>
              </span></dt><dd><p>Number of samples in each period.</p></dd><dt id="id-1.4.12.12.4.6.6.2"><span class="term ">
                <code class="literal">max</code>
              </span></dt><dd><p>Maximum of the sample volumes in each period.</p></dd><dt id="id-1.4.12.12.4.6.6.3"><span class="term ">
                <code class="literal">min</code>
              </span></dt><dd><p>Minimum of the sample volumes in each period.</p></dd><dt id="id-1.4.12.12.4.6.6.4"><span class="term ">
                <code class="literal">stddev</code>
              </span></dt><dd><p>Standard deviation of the sample volumes in each period.</p></dd><dt id="id-1.4.12.12.4.6.6.5"><span class="term ">
                <code class="literal">sum</code>
              </span></dt><dd><p>Sum of the sample volumes over each period.</p></dd></dl></div><p>The simple query and the statistics functionality can be used together
in a single API request.</p></div></div><div class="sect2 " id="id-1.4.12.12.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry command-line client and SDK</span> <a title="Permalink" class="permalink" href="#id-1.4.12.12.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service provides a command-line client, with which the
collected data is available just as the alarm definition and retrieval
options. The client uses the Telemetry RESTful API in order to execute
the requested operations.</p><p>To be able to use the <code class="command">ceilometer</code> command, the
python-ceilometerclient package needs to be installed and configured
properly. For details about the installation process, see the <a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/" target="_blank">Telemetry
chapter</a>
in the Installation Tutorials and Guides.</p><div id="id-1.4.12.12.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The Telemetry service captures the user-visible resource usage data.
Therefore the database will not contain any data without the
existence of these resources, like VM images in the OpenStack Image
service.</p></div><p>Similarly to other OpenStack command-line clients, the <code class="literal">ceilometer</code>
client uses OpenStack Identity for authentication. The proper
credentials and <code class="literal">--auth_url</code> parameter have to be defined via command
line parameters or environment variables.</p><p>This section provides some examples without the aim of completeness.
These commands can be used for instance for validating an installation
of Telemetry.</p><p>To retrieve the list of collected meters, the following command should
be used:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer meter-list
+------------------------+------------+------+------------------------------------------+----------------------------------+----------------------------------+
| Name                   | Type       | Unit | Resource ID                              | User ID                          | Project ID                       |
+------------------------+------------+------+------------------------------------------+----------------------------------+----------------------------------+
| cpu                    | cumulative | ns   | bb52e52b-1e42-4751-b3ac-45c52d83ba07     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu                    | cumulative | ns   | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_util               | gauge      | %    | bb52e52b-1e42-4751-b3ac-45c52d83ba07     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_util               | gauge      | %    | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b     | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | bb52e52b-1e42-4751-b3ac-45c52d83ba07-hdd | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | bb52e52b-1e42-4751-b3ac-45c52d83ba07-vda | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b-hdd | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.device.read.bytes | cumulative | B    | c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b-vda | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| ...                                                                                                                                                         |
+------------------------+------------+------+------------------------------------------+----------------------------------+----------------------------------+</pre></div><p>The <code class="command">ceilometer</code> command was run with <code class="literal">admin</code> rights, which means
that all the data is accessible in the database. For more information
about access right see <a class="xref" href="#telemetry-users-roles-projects" title="10.1.4. Users, roles, and projects">Section 10.1.4, “Users, roles, and projects”</a>. As it can be seen
in the above example, there are two VM instances existing in the system, as
there are VM instance related meters on the top of the result list. The
existence of these meters does not indicate that these instances are running at
the time of the request. The result contains the currently collected meters per
resource, in an ascending order based on the name of the meter.</p><p>Samples are collected for each meter that is present in the list of
meters, except in case of instances that are not running or deleted from
the OpenStack Compute database. If an instance no longer exists and
there is a <code class="literal">time_to_live</code> value set in the <code class="literal">ceilometer.conf</code>
configuration file, then a group of samples are deleted in each
expiration cycle. When the last sample is deleted for a meter, the
database can be cleaned up by running ceilometer-expirer and the meter
will not be present in the list above anymore. For more information
about the expiration procedure see <a class="xref" href="#telemetry-storing-samples" title="10.2.6. Storing samples">Section 10.2.6, “Storing samples”</a>.</p><p>The Telemetry API supports simple query on the meter endpoint. The query
functionality has the following syntax:</p><div class="verbatim-wrap"><pre class="screen">--query &lt;field1&gt;&lt;operator1&gt;&lt;value1&gt;;...;&lt;field_n&gt;&lt;operator_n&gt;&lt;value_n&gt;</pre></div><p>The following command needs to be invoked to request the meters of one
VM instance:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer meter-list --query resource=bb52e52b-1e42-4751-b3ac-45c52d83ba07
+-------------------------+------------+-----------+--------------------------------------+----------------------------------+----------------------------------+
| Name                    | Type       | Unit      | Resource ID                          | User ID                          | Project ID                       |
+-------------------------+------------+-----------+--------------------------------------+----------------------------------+----------------------------------+
| cpu                     | cumulative | ns        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_util                | gauge      | %         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| cpu_l3_cache            | gauge      | B         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.ephemeral.size     | gauge      | GB        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.bytes         | cumulative | B         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.bytes.rate    | gauge      | B/s       | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.requests      | cumulative | request   | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.read.requests.rate | gauge      | request/s | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.root.size          | gauge      | GB        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.bytes        | cumulative | B         | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.bytes.rate   | gauge      | B/s       | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.requests     | cumulative | request   | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| disk.write.requests.rate| gauge      | request/s | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| instance                | gauge      | instance  | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| instance:m1.tiny        | gauge      | instance  | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| memory                  | gauge      | MB        | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
| vcpus                   | gauge      | vcpu      | bb52e52b-1e42-4751-b3ac-45c52d83ba07 | b6e62aad26174382bc3781c12fe413c8 | cbfa8e3dfab64a27a87c8e24ecd5c60f |
+-------------------------+------------+-----------+--------------------------------------+----------------------------------+----------------------------------+</pre></div><p>As it was described above, the whole set of samples can be retrieved
that are stored for a meter or filtering the result set by using one of
the available query types. The request for all the samples of the
<code class="literal">cpu</code> meter without any additional filtering looks like the following:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer sample-list --meter cpu
+--------------------------------------+-------+------------+------------+------+---------------------+
| Resource ID                          | Meter | Type       | Volume     | Unit | Timestamp           |
+--------------------------------------+-------+------------+------------+------+---------------------+
| c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b | cpu   | cumulative | 5.4863e+11 | ns   | 2014-08-31T11:17:03 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu   | cumulative | 5.7848e+11 | ns   | 2014-08-31T11:17:03 |
| c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b | cpu   | cumulative | 5.4811e+11 | ns   | 2014-08-31T11:07:05 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu   | cumulative | 5.7797e+11 | ns   | 2014-08-31T11:07:05 |
| c8d2e153-a48f-4cec-9e93-86e7ac6d4b0b | cpu   | cumulative | 5.3589e+11 | ns   | 2014-08-31T10:27:19 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu   | cumulative | 5.6397e+11 | ns   | 2014-08-31T10:27:19 |
| ...                                                                                                 |
+--------------------------------------+-------+------------+------------+------+---------------------+</pre></div><p>The result set of the request contains the samples for both instances
ordered by the timestamp field in the default descending order.</p><p>The simple query makes it possible to retrieve only a subset of the
collected samples. The following command can be executed to request the
<code class="literal">cpu</code> samples of only one of the VM instances:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer sample-list --meter cpu --query resource=bb52e52b-1e42-4751-
  b3ac-45c52d83ba07
+--------------------------------------+------+------------+------------+------+---------------------+
| Resource ID                          | Name | Type       | Volume     | Unit | Timestamp           |
+--------------------------------------+------+------------+------------+------+---------------------+
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.7906e+11 | ns   | 2014-08-31T11:27:08 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.7848e+11 | ns   | 2014-08-31T11:17:03 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.7797e+11 | ns   | 2014-08-31T11:07:05 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.6397e+11 | ns   | 2014-08-31T10:27:19 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.6207e+11 | ns   | 2014-08-31T10:17:03 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu  | cumulative | 5.3831e+11 | ns   | 2014-08-31T08:41:57 |
| ...                                                                                                |
+--------------------------------------+------+------------+------------+------+---------------------+</pre></div><p>As it can be seen on the output above, the result set contains samples
for only one instance of the two.</p><p>The <code class="command">ceilometer query-samples</code> command is used to execute rich
queries. This command accepts the following parameters:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.5.22.1"><span class="term ">
              <code class="literal">--filter</code>
            </span></dt><dd><p>Contains the filter expression for the query in the form of:
<code class="literal">{complex_op: [{simple_op: {field_name: value}}]}</code>.</p></dd><dt id="id-1.4.12.12.5.22.2"><span class="term ">
              <code class="literal">--orderby</code>
            </span></dt><dd><p>Contains the list of <code class="literal">orderby</code> expressions in the form of:
<code class="literal">[{field_name: direction}, {field_name: direction}]</code>.</p></dd><dt id="id-1.4.12.12.5.22.3"><span class="term ">
              <code class="literal">--limit</code>
            </span></dt><dd><p>Specifies the maximum number of samples to return.</p></dd></dl></div><p>For more information about complex queries see
<a class="xref" href="#sec-query" title="10.4.1.1. Query">Section 10.4.1.1, “Query”</a>.</p><p>As the complex query functionality provides the possibility of using
complex operators, it is possible to retrieve a subset of samples for a
given VM instance. To request for the first six samples for the <code class="literal">cpu</code>
and <code class="literal">disk.read.bytes</code> meters, the following command should be invoked:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer query-samples --filter '{"and": \
  [{"=":{"resource":"bb52e52b-1e42-4751-b3ac-45c52d83ba07"}},{"or":[{"=":{"counter_name":"cpu"}}, \
  {"=":{"counter_name":"disk.read.bytes"}}]}]}' --orderby '[{"timestamp":"asc"}]' --limit 6
+--------------------------------------+-----------------+------------+------------+------+---------------------+
| Resource ID                          | Meter           | Type       | Volume     | Unit | Timestamp           |
+--------------------------------------+-----------------+------------+------------+------+---------------------+
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | disk.read.bytes | cumulative | 385334.0   | B    | 2014-08-30T13:00:46 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu             | cumulative | 1.2132e+11 | ns   | 2014-08-30T13:00:47 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu             | cumulative | 1.4295e+11 | ns   | 2014-08-30T13:10:51 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | disk.read.bytes | cumulative | 601438.0   | B    | 2014-08-30T13:10:51 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | disk.read.bytes | cumulative | 601438.0   | B    | 2014-08-30T13:20:33 |
| bb52e52b-1e42-4751-b3ac-45c52d83ba07 | cpu             | cumulative | 1.4795e+11 | ns   | 2014-08-30T13:20:34 |
+--------------------------------------+-----------------+------------+------------+------+---------------------+</pre></div><p>Ceilometer also captures data as events, which represents the state of a
resource. Refer to <code class="literal">/telemetry-events</code> for more information regarding
Events.</p><p>To retrieve a list of recent events that occurred in the system, the
following command can be executed:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer event-list
+--------------------------------------+---------------+----------------------------+-----------------------------------------------------------------+
| Message ID                           | Event Type    | Generated                  | Traits                                                          |
+--------------------------------------+---------------+----------------------------+-----------------------------------------------------------------+
| dfdb87b6-92c6-4d40-b9b5-ba308f304c13 | image.create  | 2015-09-24T22:17:39.498888 | +---------+--------+-----------------+                          |
|                                      |               |                            | |   name  |  type  |      value      |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
|                                      |               |                            | | service | string | image.localhost |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
| 84054bc6-2ae6-4b93-b5e7-06964f151cef | image.prepare | 2015-09-24T22:17:39.594192 | +---------+--------+-----------------+                          |
|                                      |               |                            | |   name  |  type  |      value      |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
|                                      |               |                            | | service | string | image.localhost |                          |
|                                      |               |                            | +---------+--------+-----------------+                          |
| 2ec99c2c-08ee-4079-bf80-27d4a073ded6 | image.update  | 2015-09-24T22:17:39.578336 | +-------------+--------+--------------------------------------+ |
|                                      |               |                            | |     name    |  type  |                value                 | |
|                                      |               |                            | +-------------+--------+--------------------------------------+ |
|                                      |               |                            | |  created_at | string |         2015-09-24T22:17:39Z         | |
|                                      |               |                            | |     name    | string |    cirros-0.3.4-x86_64-uec-kernel    | |
|                                      |               |                            | |  project_id | string |   56ffddea5b4f423496444ea36c31be23   | |
|                                      |               |                            | | resource_id | string | 86eb8273-edd7-4483-a07c-002ff1c5657d | |
|                                      |               |                            | |   service   | string |           image.localhost            | |
|                                      |               |                            | |    status   | string |                saving                | |
|                                      |               |                            | |   user_id   | string |   56ffddea5b4f423496444ea36c31be23   | |
|                                      |               |                            | +-------------+--------+--------------------------------------+ |
+--------------------------------------+---------------+----------------------------+-----------------------------------------------------------------+</pre></div><div id="id-1.4.12.12.5.29" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>In Liberty, the data returned corresponds to the role and user. Non-admin
users will only return events that are scoped to them. Admin users will
return all events related to the project they administer as well as
all unscoped events.</p></div><p>Similar to querying meters, additional filter parameters can be given to
retrieve specific events:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer event-list -q 'event_type=compute.instance.exists; \
  instance_type=m1.tiny'
+--------------------------------------+-------------------------+----------------------------+----------------------------------------------------------------------------------+
| Message ID                           | Event Type              | Generated                  | Traits                                                                           |
+--------------------------------------+-------------------------+----------------------------+----------------------------------------------------------------------------------+
| 134a2ab3-6051-496c-b82f-10a3c367439a | compute.instance.exists | 2015-09-25T03:00:02.152041 | +------------------------+----------+------------------------------------------+ |
|                                      |                         |                            | |          name          |   type   |                  value                   | |
|                                      |                         |                            | +------------------------+----------+------------------------------------------+ |
|                                      |                         |                            | | audit_period_beginning | datetime |           2015-09-25T02:00:00            | |
|                                      |                         |                            | |  audit_period_ending   | datetime |           2015-09-25T03:00:00            | |
|                                      |                         |                            | |        disk_gb         | integer  |                    1                     | |
|                                      |                         |                            | |      ephemeral_gb      | integer  |                    0                     | |
|                                      |                         |                            | |          host          |  string  |          localhost.localdomain           | |
|                                      |                         |                            | |      instance_id       |  string  |   2115f189-c7f1-4228-97bc-d742600839f2   | |
|                                      |                         |                            | |     instance_type      |  string  |                 m1.tiny                  | |
|                                      |                         |                            | |    instance_type_id    | integer  |                    2                     | |
|                                      |                         |                            | |      launched_at       | datetime |           2015-09-24T22:24:56            | |
|                                      |                         |                            | |       memory_mb        | integer  |                   512                    | |
|                                      |                         |                            | |       project_id       |  string  |     56ffddea5b4f423496444ea36c31be23     | |
|                                      |                         |                            | |       request_id       |  string  | req-c6292b21-bf98-4a1d-b40c-cebba4d09a67 | |
|                                      |                         |                            | |        root_gb         | integer  |                    1                     | |
|                                      |                         |                            | |        service         |  string  |                 compute                  | |
|                                      |                         |                            | |         state          |  string  |                  active                  | |
|                                      |                         |                            | |       tenant_id        |  string  |     56ffddea5b4f423496444ea36c31be23     | |
|                                      |                         |                            | |        user_id         |  string  |     0b3d725756f94923b9d0c4db864d06a9     | |
|                                      |                         |                            | |         vcpus          | integer  |                    1                     | |
|                                      |                         |                            | +------------------------+----------+------------------------------------------+ |
+--------------------------------------+-------------------------+----------------------------+----------------------------------------------------------------------------------+</pre></div><div id="id-1.4.12.12.5.32" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>As of the Liberty release, the number of items returned will be
restricted to the value defined by <code class="literal">default_api_return_limit</code> in the
<code class="literal">ceilometer.conf</code> configuration file. Alternatively, the value can
be set per query by passing the <code class="literal">limit</code> option in the request.</p></div><div class="sect3 " id="id-1.4.12.12.5.33"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.4.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry Python bindings</span> <a title="Permalink" class="permalink" href="#id-1.4.12.12.5.33">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The command-line client library provides python bindings in order to use
the Telemetry Python API directly from python programs.</p><p>The first step in setting up the client is to create a client instance
with the proper credentials:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; import ceilometerclient.client
&gt;&gt;&gt; cclient = ceilometerclient.client.get_client(VERSION, username=USERNAME, password=PASSWORD, tenant_name=PROJECT_NAME, auth_url=AUTH_URL)</pre></div><p>The <code class="literal">VERSION</code> parameter can be <code class="literal">1</code> or <code class="literal">2</code>, specifying the API
version to be used.</p><p>The method calls look like the following:</p><div class="verbatim-wrap highlight python"><pre class="screen">&gt;&gt;&gt; cclient.meters.list()
 [&lt;Meter ...&gt;, ...]

&gt;&gt;&gt; cclient.samples.list()
 [&lt;Sample ...&gt;, ...]</pre></div><p>For further details about the python-ceilometerclient package, see the
<a class="link" href="http://docs.openstack.org/developer/python-ceilometerclient/" target="_blank">Python bindings to the OpenStack Ceilometer
API</a>
reference.</p></div></div><div class="sect2 " id="telemetry-publishers"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Publishers</span> <a title="Permalink" class="permalink" href="#telemetry-publishers">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-publishers</li></ul></div></div></div></div><p>The Telemetry service provides several transport methods to forward the
data collected to the <code class="literal">ceilometer-collector</code> service or to an external
system. The consumers of this data are widely different, like monitoring
systems, for which data loss is acceptable and billing systems, which
require reliable data transportation. Telemetry provides methods to
fulfill the requirements of both kind of systems, as it is described
below.</p><p>The publisher component makes it possible to persist the data into
storage through the message bus or to send it to one or more external
consumers. One chain can contain multiple publishers.</p><p>To solve the above mentioned problem, the notion of multi-publisher can
be configured for each datapoint within the Telemetry service, allowing
the same technical meter or event to be published multiple times to
multiple destinations, each potentially using a different transport.</p><p>Publishers can be specified in the <code class="literal">publishers</code> section for each
pipeline (for further details about pipelines see
<a class="xref" href="#data-collection-and-processing" title="10.3. Data collection, processing, and pipelines">Section 10.3, “Data collection, processing, and pipelines”</a>) that is defined in
the <a class="link" href="https://git.openstack.org/cgit/openstack/ceilometer/plain/etc/ceilometer/pipeline.yaml" target="_blank">pipeline.yaml</a>
file.</p><p>The following publisher types are supported:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.6.7.1"><span class="term ">direct</span></dt><dd><p>It can be specified in the form of <code class="literal">direct://?dispatcher=http</code>. The
dispatcher's options include database, file, http, and gnocchi. For
more details on dispatcher, see <a class="xref" href="#telemetry-storing-samples" title="10.2.6. Storing samples">Section 10.2.6, “Storing samples”</a>.
It emits data in the configured dispatcher directly, default configuration
(the form is <code class="literal">direct://</code>) is database dispatcher.
In the Mitaka release, this method can only emit data to the database
dispatcher, and the form is <code class="literal">direct://</code>.</p></dd><dt id="id-1.4.12.12.6.7.2"><span class="term ">notifier</span></dt><dd><p>It can be specified in the form of
<code class="literal">notifier://?option1=value1&amp;option2=value2</code>. It emits data over
AMQP using oslo.messaging. This is the recommended method of
publishing.</p></dd><dt id="id-1.4.12.12.6.7.3"><span class="term ">rpc</span></dt><dd><p>It can be specified in the form of
<code class="literal">rpc://?option1=value1&amp;option2=value2</code>. It emits metering data
over lossy AMQP. This method is synchronous and may experience
performance issues. This publisher is deprecated in Liberty in favor of
the notifier publisher.</p></dd><dt id="id-1.4.12.12.6.7.4"><span class="term ">udp</span></dt><dd><p>It can be specified in the form of <code class="literal">udp://&lt;host&gt;:&lt;port&gt;/</code>. It emits
metering data for over UDP.</p></dd><dt id="id-1.4.12.12.6.7.5"><span class="term ">file</span></dt><dd><p>It can be specified in the form of
<code class="literal">file://path?option1=value1&amp;option2=value2</code>. This publisher
records metering data into a file.</p></dd></dl></div><div id="id-1.4.12.12.6.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If a file name and location is not specified, this publisher
does not log any meters, instead it logs a warning message in
the configured log file for Telemetry.</p></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.6.9.1"><span class="term ">kafka</span></dt><dd><p>It can be specified in the form of:
<code class="literal">kafka://kafka_broker_ip: kafka_broker_port?topic=kafka_topic
&amp;option1=value1</code>.</p><p>This publisher sends metering data to a kafka broker.</p></dd></dl></div><div id="id-1.4.12.12.6.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If the topic parameter is missing, this publisher brings out
metering data under a topic name, <code class="literal">ceilometer</code>. When the port
number is not specified, this publisher uses 9092 as the
broker's port.</p></div><p>The following options are available for <code class="literal">rpc</code> and <code class="literal">notifier</code>. The
policy option can be used by <code class="literal">kafka</code> publisher:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.6.12.1"><span class="term ">
              <code class="literal">per_meter_topic</code>
            </span></dt><dd><p>The value of it is 1. It is used for publishing the samples on
additional <code class="literal">metering_topic.sample_name</code> topic queue besides the
default <code class="literal">metering_topic</code> queue.</p></dd><dt id="id-1.4.12.12.6.12.2"><span class="term ">
              <code class="literal">policy</code>
            </span></dt><dd><p>It is used for configuring the behavior for the case, when the
publisher fails to send the samples, where the possible predefined
values are the following:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.6.12.2.2.2.1"><span class="term ">default</span></dt><dd><p>Used for waiting and blocking until the samples have been sent.</p></dd><dt id="id-1.4.12.12.6.12.2.2.2.2"><span class="term ">drop</span></dt><dd><p>Used for dropping the samples which are failed to be sent.</p></dd><dt id="id-1.4.12.12.6.12.2.2.2.3"><span class="term ">queue</span></dt><dd><p>Used for creating an in-memory queue and retrying to send the
samples on the queue on the next samples publishing period (the
queue length can be configured with <code class="literal">max_queue_length</code>, where
1024 is the default value).</p></dd></dl></div></dd></dl></div><p>The following option is additionally available for the <code class="literal">notifier</code> publisher:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.6.14.1"><span class="term ">
              <code class="literal">topic</code>
            </span></dt><dd><p>The topic name of queue to publish to. Setting this will override the
default topic defined by <code class="literal">metering_topic</code> and <code class="literal">event_topic</code> options.
This option can be used to support multiple consumers. Support for this
feature was added in Kilo.</p></dd></dl></div><p>The following options are available for the <code class="literal">file</code> publisher:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.12.6.16.1"><span class="term ">
              <code class="literal">max_bytes</code>
            </span></dt><dd><p>When this option is greater than zero, it will cause a rollover.
When the size is about to be exceeded, the file is closed and a new
file is silently opened for output. If its value is zero, rollover
never occurs.</p></dd><dt id="id-1.4.12.12.6.16.2"><span class="term ">
              <code class="literal">backup_count</code>
            </span></dt><dd><p>If this value is non-zero, an extension will be appended to the
filename of the old log, as '.1', '.2', and so forth until the
specified value is reached. The file that is written and contains
the newest data is always the one that is specified without any
extensions.</p></dd></dl></div><p>The default publisher is <code class="literal">notifier</code>, without any additional options
specified. A sample <code class="literal">publishers</code> section in the
<code class="literal">/etc/ceilometer/pipeline.yaml</code> looks like the following:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">publishers:
    - udp://10.0.0.2:1234
    - rpc://?per_meter_topic=1 (deprecated in Liberty)
    - notifier://?policy=drop&amp;max_queue_length=512&amp;topic=custom_target
    - direct://?dispatcher=http</pre></div></div></div><div class="sect1 " id="telemetry-alarms"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarms</span> <a title="Permalink" class="permalink" href="#telemetry-alarms">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-alarms</li></ul></div></div></div></div><p>Alarms provide user-oriented Monitoring-as-a-Service for resources
running on OpenStack. This type of monitoring ensures you can
automatically scale in or out a group of instances through the
Orchestration service, but you can also use alarms for general-purpose
awareness of your cloud resources' health.</p><p>These alarms follow a tri-state model:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.13.4.1"><span class="term ">ok</span></dt><dd><p>The rule governing the alarm has been evaluated as <code class="literal">False</code>.</p></dd><dt id="id-1.4.12.13.4.2"><span class="term ">alarm</span></dt><dd><p>The rule governing the alarm have been evaluated as <code class="literal">True</code>.</p></dd><dt id="id-1.4.12.13.4.3"><span class="term ">insufficient data</span></dt><dd><p>There are not enough datapoints available in the evaluation periods
to meaningfully determine the alarm state.</p></dd></dl></div><div class="sect2 " id="id-1.4.12.13.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm definitions</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The definition of an alarm provides the rules that govern when a state
transition should occur, and the actions to be taken thereon. The
nature of these rules depend on the alarm type.</p><div class="sect3 " id="id-1.4.12.13.5.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Threshold rule alarms</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.5.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For conventional threshold-oriented alarms, state transitions are
governed by:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>A static threshold value with a comparison operator such as greater
than or less than.</p></li><li class="listitem "><p>A statistic selection to aggregate the data.</p></li><li class="listitem "><p>A sliding time window to indicate how far back into the recent past
you want to look.</p></li></ul></div></div><div class="sect3 " id="id-1.4.12.13.5.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Combination rule alarms</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.5.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service also supports the concept of a meta-alarm, which
aggregates over the current state of a set of underlying basic alarms
combined via a logical operator (AND or OR).</p></div></div><div class="sect2 " id="id-1.4.12.13.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm dimensioning</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A key associated concept is the notion of <span class="emphasis"><em>dimensioning</em></span> which
defines the set of matching meters that feed into an alarm
evaluation. Recall that meters are per-resource-instance, so in the
simplest case an alarm might be defined over a particular meter
applied to all resources visible to a particular user. More useful
however would be the option to explicitly select which specific
resources you are interested in alarming on.</p><p>At one extreme you might have narrowly dimensioned alarms where this
selection would have only a single target (identified by resource
ID). At the other extreme, you could have widely dimensioned alarms
where this selection identifies many resources over which the
statistic is aggregated. For example all instances booted from a
particular image or all instances with matching user metadata (the
latter is how the Orchestration service identifies autoscaling
groups).</p></div><div class="sect2 " id="id-1.4.12.13.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm evaluation</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Alarms are evaluated by the <code class="literal">alarm-evaluator</code> service on a periodic
basis, defaulting to once every minute.</p><div class="sect3 " id="id-1.4.12.13.7.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm actions</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.7.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Any state transition of individual alarm (to <code class="literal">ok</code>, <code class="literal">alarm</code>, or
<code class="literal">insufficient data</code>) may have one or more actions associated with
it. These actions effectively send a signal to a consumer that the
state transition has occurred, and provide some additional context.
This includes the new and previous states, with some reason data
describing the disposition with respect to the threshold, the number
of datapoints involved and most recent of these. State transitions
are detected by the <code class="literal">alarm-evaluator</code>, whereas the
<code class="literal">alarm-notifier</code> effects the actual notification action.</p><p>
            <span class="bold"><strong>Webhooks</strong></span>
          </p><p>These are the <span class="emphasis"><em>de facto</em></span> notification type used by Telemetry alarming
and simply involve an HTTP POST request being sent to an endpoint,
with a request body containing a description of the state transition
encoded as a JSON fragment.</p><p>
            <span class="bold"><strong>Log actions</strong></span>
          </p><p>These are a lightweight alternative to webhooks, whereby the state
transition is simply logged by the <code class="literal">alarm-notifier</code>, and are
intended primarily for testing purposes.</p></div><div class="sect3 " id="id-1.4.12.13.7.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Workload partitioning</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.7.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The alarm evaluation process uses the same mechanism for workload
partitioning as the central and compute agents. The
<a class="link" href="https://pypi.python.org/pypi/tooz" target="_blank">Tooz</a> library provides the
coordination within the groups of service instances. For further
information about this approach, see the section called
<a class="xref" href="#ha-deploy-services" title="10.2.3. Support for HA deployment">Section 10.2.3, “Support for HA deployment”</a>.</p><p>To use this workload partitioning solution set the
<code class="literal">evaluation_service</code> option to <code class="literal">default</code>. For more
information, see the alarm section in the
<a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry.html" target="_blank">OpenStack Configuration Reference</a>.</p></div></div><div class="sect2 " id="id-1.4.12.13.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using alarms</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.12.13.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm creation</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.8.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An example of creating a threshold-oriented alarm, based on an upper
bound on the CPU utilization for a particular instance:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-threshold-create --name cpu_hi \
  --description 'instance running hot' \
  --meter-name cpu_util --threshold 70.0 \
  --comparison-operator gt --statistic avg \
  --period 600 --evaluation-periods 3 \
  --alarm-action 'log://' \
  --query resource_id=INSTANCE_ID</pre></div><p>This creates an alarm that will fire when the average CPU utilization
for an individual instance exceeds 70% for three consecutive 10
minute periods. The notification in this case is simply a log message,
though it could alternatively be a webhook URL.</p><div id="id-1.4.12.13.8.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Alarm names must be unique for the alarms associated with an
individual project. Administrator can limit the maximum
resulting actions for three different states, and the
ability for a normal user to create <code class="literal">log://</code> and <code class="literal">test://</code>
notifiers is disabled. This prevents unintentional
consumption of disk and memory resources by the
Telemetry service.</p></div><p>The sliding time window over which the alarm is evaluated is 30
minutes in this example. This window is not clamped to wall-clock
time boundaries, rather it's anchored on the current time for each
evaluation cycle, and continually creeps forward as each evaluation
cycle rolls around (by default, this occurs every minute).</p><p>The period length is set to 600s in this case to reflect the
out-of-the-box default cadence for collection of the associated
meter. This period matching illustrates an important general
principal to keep in mind for alarms:</p><div id="id-1.4.12.13.8.2.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The alarm period should be a whole number multiple (1 or more)
of the interval configured in the pipeline corresponding to the
target meter.</p></div><p>Otherwise the alarm will tend to flit in and out of the
<code class="literal">insufficient data</code> state due to the mismatch between the actual
frequency of datapoints in the metering store and the statistics
queries used to compare against the alarm threshold. If a shorter
alarm period is needed, then the corresponding interval should be
adjusted in the <code class="literal">pipeline.yaml</code> file.</p><p>Other notable alarm attributes that may be set on creation, or via a
subsequent update, include:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.13.8.2.11.1"><span class="term ">state</span></dt><dd><p>The initial alarm state (defaults to <code class="literal">insufficient data</code>).</p></dd><dt id="id-1.4.12.13.8.2.11.2"><span class="term ">description</span></dt><dd><p>A free-text description of the alarm (defaults to a synopsis of the
alarm rule).</p></dd><dt id="id-1.4.12.13.8.2.11.3"><span class="term ">enabled</span></dt><dd><p>True if evaluation and actioning is to be enabled for this alarm
(defaults to <code class="literal">True</code>).</p></dd><dt id="id-1.4.12.13.8.2.11.4"><span class="term ">repeat-actions</span></dt><dd><p>True if actions should be repeatedly notified while the alarm
remains in the target state (defaults to <code class="literal">False</code>).</p></dd><dt id="id-1.4.12.13.8.2.11.5"><span class="term ">ok-action</span></dt><dd><p>An action to invoke when the alarm state transitions to <code class="literal">ok</code>.</p></dd><dt id="id-1.4.12.13.8.2.11.6"><span class="term ">insufficient-data-action</span></dt><dd><p>An action to invoke when the alarm state transitions to
<code class="literal">insufficient data</code>.</p></dd><dt id="id-1.4.12.13.8.2.11.7"><span class="term ">time-constraint</span></dt><dd><p>Used to restrict evaluation of the alarm to certain times of the
day or days of the week (expressed as <code class="literal">cron</code> expression with an
optional timezone).</p></dd></dl></div><p>An example of creating a combination alarm, based on the combined
state of two underlying alarms:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-combination-create --name meta \
  --alarm_ids ALARM_ID1 \
  --alarm_ids ALARM_ID2 \
  --operator or \
  --alarm-action 'http://example.org/notify'</pre></div><p>This creates an alarm that will fire when either one of two underlying
alarms transition into the alarm state. The notification in this case
is a webhook call. Any number of underlying alarms can be combined in
this way, using either <code class="literal">and</code> or <code class="literal">or</code>.</p></div><div class="sect3 " id="id-1.4.12.13.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm retrieval</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can display all your alarms via (some attributes are omitted for
brevity):</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-list
+----------+--------+-------------------+---------------------------------+
| Alarm ID | Name   | State             | Alarm condition                 |
+----------+--------+-------------------+---------------------------------+
| ALARM_ID | cpu_hi | insufficient data | cpu_util &gt; 70.0 during 3 x 600s |
+----------+--------+-------------------+---------------------------------+</pre></div><p>In this case, the state is reported as <code class="literal">insufficient data</code> which
could indicate that:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>meters have not yet been gathered about this instance over the
evaluation window into the recent past (for example a brand-new
instance)</p></li><li class="listitem "><p><span class="emphasis"><em>or</em></span>, that the identified instance is not visible to the
user/project owning the alarm</p></li><li class="listitem "><p><span class="emphasis"><em>or</em></span>, simply that an alarm evaluation cycle hasn't kicked off since
the alarm was created (by default, alarms are evaluated once per
minute).</p></li></ul></div><div id="id-1.4.12.13.8.3.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The visibility of alarms depends on the role and project
associated with the user issuing the query:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>admin users see <span class="emphasis"><em>all</em></span> alarms, regardless of the owner</p></li><li class="listitem "><p>non-admin users see only the alarms associated with their project
(as per the normal project segregation in OpenStack)</p></li></ul></div></div></div><div class="sect3 " id="id-1.4.12.13.8.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm update</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.8.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Once the state of the alarm has settled down, we might decide that we
set that bar too low with 70%, in which case the threshold (or most
any other alarm attribute) can be updated thusly:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-update --threshold 75 ALARM_ID</pre></div><p>The change will take effect from the next evaluation cycle, which by
default occurs every minute.</p><p>Most alarm attributes can be changed in this way, but there is also
a convenient short-cut for getting and setting the alarm state:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-state-get ALARM_ID
$ ceilometer alarm-state-set --state ok -a ALARM_ID</pre></div><p>Over time the state of the alarm may change often, especially if the
threshold is chosen to be close to the trending value of the
statistic. You can follow the history of an alarm over its lifecycle
via the audit API:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-history ALARM_ID
+------------------+-----------+---------------------------------------+
| Type             | Timestamp | Detail                                |
+------------------+-----------+---------------------------------------+
| creation         | time0     | name: cpu_hi                          |
|                  |           | description: instance running hot     |
|                  |           | type: threshold                       |
|                  |           | rule: cpu_util &gt; 70.0 during 3 x 600s |
| state transition | time1     | state: ok                             |
| rule change      | time2     | rule: cpu_util &gt; 75.0 during 3 x 600s |
+------------------+-----------+---------------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.12.13.8.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.5.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Alarm deletion</span> <a title="Permalink" class="permalink" href="#id-1.4.12.13.8.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An alarm that is no longer required can be disabled so that it is no
longer actively evaluated:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-update --enabled False -a ALARM_ID</pre></div><p>or even deleted permanently (an irreversible step):</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer alarm-delete ALARM_ID</pre></div><div id="id-1.4.12.13.8.5.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>By default, alarm history is retained for deleted alarms.</p></div></div></div></div><div class="sect1 " id="telemetry-measurements"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Measurements</span> <a title="Permalink" class="permalink" href="#telemetry-measurements">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-measurements</li></ul></div></div></div></div><p>The Telemetry service collects meters within an OpenStack deployment.
This section provides a brief summary about meters format and origin and
also contains the list of available meters.</p><p>Telemetry collects meters by polling the infrastructure elements and
also by consuming the notifications emitted by other OpenStack services.
For more information about the polling mechanism and notifications see
<a class="xref" href="#telemetry-data-collection" title="10.2. Data collection">Section 10.2, “Data collection”</a>. There are several meters which are collected
by polling and by consuming. The origin for each meter is listed in the tables
below.</p><div id="id-1.4.12.14.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You may need to configure Telemetry or other OpenStack services in
order to be able to collect all the samples you need. For further
information about configuration requirements see the <a class="link" href="http://docs.openstack.org/project-install-guide/telemetry/newton/" target="_blank">Telemetry chapter</a>
in the Installation Tutorials and Guides. Also check the <a class="link" href="http://docs.openstack.org/developer/ceilometer/install/manual.html" target="_blank">Telemetry manual
installation</a>
description.</p></div><p>Telemetry uses the following meter types:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                <p>Type</p>
              </th><th>
                <p>Description</p>
              </th></tr></thead><tbody><tr><td>
                <p>Cumulative</p>
              </td><td>
                <p>Increasing over time (instance hours)</p>
              </td></tr><tr><td>
                <p>Delta</p>
              </td><td>
                <p>Changing over time (bandwidth)</p>
              </td></tr><tr><td>
                <p>Gauge</p>
              </td><td>
                <p>Discrete items (floating IPs, image uploads) and fluctuating
values (disk I/O)</p>
              </td></tr></tbody></table></div><p>Telemetry provides the possibility to store metadata for samples. This
metadata can be extended for OpenStack Compute and OpenStack Object
Storage.</p><p>In order to add additional metadata information to OpenStack Compute you
have two options to choose from. The first one is to specify them when
you boot up a new instance. The additional information will be stored
with the sample in the form of <code class="literal">resource_metadata.user_metadata.*</code>.
The new field should be defined by using the prefix <code class="literal">metering.</code>. The
modified boot command look like the following:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server create --property metering.custom_metadata=a_value my_vm</pre></div><p>The other option is to set the <code class="literal">reserved_metadata_keys</code> to the list of
metadata keys that you would like to be included in
<code class="literal">resource_metadata</code> of the instance related samples that are collected
for OpenStack Compute. This option is included in the <code class="literal">DEFAULT</code>
section of the <code class="literal">ceilometer.conf</code> configuration file.</p><p>You might also specify headers whose values will be stored along with
the sample data of OpenStack Object Storage. The additional information
is also stored under <code class="literal">resource_metadata</code>. The format of the new field
is <code class="literal">resource_metadata.http_header_$name</code>, where <code class="literal">$name</code> is the name of
the header with <code class="literal">-</code> replaced by <code class="literal">_</code>.</p><p>For specifying the new header, you need to set <code class="literal">metadata_headers</code> option
under the <code class="literal">[filter:ceilometer]</code> section in <code class="literal">proxy-server.conf</code> under the
<code class="literal">swift</code> folder. You can use this additional data for instance to distinguish
external and internal users.</p><p>Measurements are grouped by services which are polled by
Telemetry or emit notifications that this service consumes.</p><div id="id-1.4.12.14.14" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The Telemetry service supports storing notifications as events. This
functionality was added later, therefore the list of meters still
contains existence type and other event related items. The proper
way of using Telemetry is to configure it to use the event store and
turn off the collection of the event related meters. For further
information about events see <a class="link" href="http://docs.openstack.org/developer/ceilometer/events.html" target="_blank">Events section</a>
in the Telemetry documentation. For further information about how to
turn on and off meters see <a class="xref" href="#telemetry-pipeline-configuration" title="10.3.1. Pipeline configuration">Section 10.3.1, “Pipeline configuration”</a>. Please
also note that currently no migration is available to move the already
existing event type samples to the event store.</p></div><div class="sect2 " id="telemetry-compute-meters"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Compute</span> <a title="Permalink" class="permalink" href="#telemetry-compute-meters">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-compute-meters</li></ul></div></div></div></div><p>The following meters are collected for OpenStack Compute:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /><col class="c7" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Support</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="7">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>instance</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>instance</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification,
Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Existence of
instance</p>
                </td></tr><tr><td>
                  <p>instance:&lt;type&gt;</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>instance</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification,
Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Existence of
instance &lt;type&gt;
(OpenStack types)</p>
                </td></tr><tr><td>
                  <p>memory</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>MB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Volume of RAM
allocated to the
instance</p>
                </td></tr><tr><td>
                  <p>memory.usage</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>MB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>vSphere</p>
                </td><td>
                  <p>Volume of RAM
used by the
instance from the
amount of its
allocated memory</p>
                </td></tr><tr><td>
                  <p>cpu</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>CPU time used</p>
                </td></tr><tr><td>
                  <p>cpu_util</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>vSphere</p>
                </td><td>
                  <p>Average CPU
utilization</p>
                </td></tr><tr><td>
                  <p>vcpus</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>vcpu</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of virtual
CPUs allocated to
the instance</p>
                </td></tr><tr><td>
                  <p>disk.read.requests</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of read
requests</p>
                </td></tr><tr><td>
                  <p>disk.read.requests.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>request/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
read requests</p>
                </td></tr><tr><td>
                  <p>disk.write.requests</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of write
requests</p>
                </td></tr><tr><td>
                  <p>disk.write.requests.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>request/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
write requests</p>
                </td></tr><tr><td>
                  <p>disk.read.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Volume of reads</p>
                </td></tr><tr><td>
                  <p>disk.read.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
reads</p>
                </td></tr><tr><td>
                  <p>disk.write.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt </p>
                </td><td>
                  <p>Volume of writes</p>
                </td></tr><tr><td>
                  <p>disk.write.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
writes</p>
                </td></tr><tr><td>
                  <p>disk.root.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>GB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Size of root disk</p>
                </td></tr><tr><td>
                  <p>disk.ephemeral.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>GB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Size of ephemeral
disk</p>
                </td></tr><tr><td>
                  <p>network.incoming.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of
incoming bytes</p>
                </td></tr><tr><td>
                  <p>network.incoming.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
incoming bytes</p>
                </td></tr><tr><td>
                  <p>network.outgoing.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of
outgoing bytes</p>
                </td></tr><tr><td>
                  <p>network.outgoing.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
outgoing bytes</p>
                </td></tr><tr><td>
                  <p>network.incoming.packets</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of
incoming packets</p>
                </td></tr><tr><td>
                  <p>network.incoming.packets.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>packet/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
incoming packets</p>
                </td></tr><tr><td>
                  <p>network.outgoing.packets</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of
outgoing packets</p>
                </td></tr><tr><td>
                  <p>network.outgoing.packets.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>packet/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
outgoing packets</p>
                </td></tr><tr><td colspan="7">
                  <p>
                    <span class="bold"><strong>Meters added or hypervisor support changed in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>instance</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>instance</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification,
Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Existence of
instance</p>
                </td></tr><tr><td>
                  <p>instance:&lt;type&gt;</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>instance</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification,
Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Existence of
instance &lt;type&gt;
(OpenStack types)</p>
                </td></tr><tr><td>
                  <p>memory.usage</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>MB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>vSphere,
XenAPI</p>
                </td><td>
                  <p>Volume of RAM
used by the
instance from the
amount of its
allocated memory</p>
                </td></tr><tr><td>
                  <p>cpu_util</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>vSphere,
XenAPI</p>
                </td><td>
                  <p>Average CPU
utilization</p>
                </td></tr><tr><td>
                  <p>disk.read.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Average rate of
reads</p>
                </td></tr><tr><td>
                  <p>disk.write.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Average rate of
writes</p>
                </td></tr><tr><td>
                  <p>disk.device.read.requests</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of read
requests</p>
                </td></tr><tr><td>
                  <p>disk.device.read.requests.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>request/s</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
read requests</p>
                </td></tr><tr><td>
                  <p>disk.device.write.requests</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Number of write
requests</p>
                </td></tr><tr><td>
                  <p>disk.device.write.requests.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>request/s</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
write requests</p>
                </td></tr><tr><td>
                  <p>disk.device.read.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Volume of reads</p>
                </td></tr><tr><td>
                  <p>disk.device.read.bytes
.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
reads</p>
                </td></tr><tr><td>
                  <p>disk.device.write.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Volume of writes</p>
                </td></tr><tr><td>
                  <p>disk.device.write.bytes
.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt, vSphere</p>
                </td><td>
                  <p>Average rate of
writes</p>
                </td></tr><tr><td>
                  <p>network.incoming.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Average rate of
incoming bytes</p>
                </td></tr><tr><td>
                  <p>network.outgoing.bytes.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Average rate of
outgoing bytes</p>
                </td></tr><tr><td>
                  <p>network.incoming.packets.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>packet/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Average rate of
incoming packets</p>
                </td></tr><tr><td>
                  <p>network.outgoing.packets.rate</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>packet/s</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Average rate of
outgoing packets</p>
                </td></tr><tr><td colspan="7">
                  <p>
                    <span class="bold"><strong>Meters added or hypervisor support changed in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>memory.usage</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>MB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Volume of RAM
used by the instance from the
amount of its
allocated memory</p>
                </td></tr><tr><td>
                  <p>memory.resident</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>MB</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Volume of RAM used by the instance on the physical machine</p>
                </td></tr><tr><td>
                  <p>disk.capacity</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>The amount of disk that the instance can see</p>
                </td></tr><tr><td>
                  <p>disk.allocation</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>The amount of disk occupied by
the instance on the host machine</p>
                </td></tr><tr><td>
                  <p>disk.usage</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>The physical size in bytes of
the image container on the host</p>
                </td></tr><tr><td>
                  <p>disk.device.capacity</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>The amount of disk per device
that the instance can see</p>
                </td></tr><tr><td>
                  <p>disk.device.allocation</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>The amount of disk per device
occupied by the
instance on the host machine</p>
                </td></tr><tr><td>
                  <p>disk.device.usage</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>The physical size in bytes of
the image container on the host per device</p>
                </td></tr><tr><td colspan="7">
                  <p>
                    <span class="bold"><strong>Meters deprecated in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>instance:&lt;type&gt;</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>instance</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Notification,
Pollster</p>
                </td><td>
                  <p>Libvirt,
vSphere,
XenAPI</p>
                </td><td>
                  <p>Existence of
instance &lt;type&gt;
(OpenStack types)</p>
                </td></tr><tr><td colspan="7">
                  <p>
                    <span class="bold"><strong>Meters added in the Liberty release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>cpu.delta</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>CPU time used since previous datapoint</p>
                </td></tr><tr><td colspan="7">
                  <p>
                    <span class="bold"><strong>Meters added in the Newton release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>cpu_l3_cache</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>L3 cache used by the instance</p>
                </td></tr><tr><td>
                  <p>memory.bandwidth.total</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Total system bandwidth from one level of cache</p>
                </td></tr><tr><td>
                  <p>memory.bandwidth.local</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B/s</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>Bandwidth of memory traffic for a memory controller</p>
                </td></tr><tr><td>
                  <p>perf.cpu.cycles</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>cycle</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>the number of cpu cycles one instruction needs</p>
                </td></tr><tr><td>
                  <p>perf.instructions</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>instruction</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>the count of instructions</p>
                </td></tr><tr><td>
                  <p>perf.cache.references</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>count</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>the count of cache hits</p>
                </td></tr><tr><td>
                  <p>perf.cache.misses</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>count</p>
                </td><td>
                  <p>instance
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Libvirt</p>
                </td><td>
                  <p>the count of cache misses</p>
                </td></tr></tbody></table></div><div id="id-1.4.12.14.15.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>The <code class="literal">instance:&lt;type&gt;</code> meter can be replaced by using extra parameters in
both the samples and statistics queries. Sample queries look like:</p></li></ul></div></div><div class="verbatim-wrap"><pre class="screen">statistics:

  ceilometer statistics -m instance -g resource_metadata.instance_type

samples:

  ceilometer sample-list -m instance -q metadata.instance_type=&lt;value&gt;</pre></div></div><p>The Telemetry service supports to create new meters by using
transformers. For more details about transformers see
<a class="xref" href="#telemetry-transformers" title="10.3.1.1. Transformers">Section 10.3.1.1, “Transformers”</a>. Among the meters gathered from libvirt there are a few ones which are generated from other meters. The list of
meters that are created by using the <code class="literal">rate_of_change</code> transformer from the
above table is the following:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>cpu_util</p></li><li class="listitem "><p>disk.read.requests.rate</p></li><li class="listitem "><p>disk.write.requests.rate</p></li><li class="listitem "><p>disk.read.bytes.rate</p></li><li class="listitem "><p>disk.write.bytes.rate</p></li><li class="listitem "><p>disk.device.read.requests.rate</p></li><li class="listitem "><p>disk.device.write.requests.rate</p></li><li class="listitem "><p>disk.device.read.bytes.rate</p></li><li class="listitem "><p>disk.device.write.bytes.rate</p></li><li class="listitem "><p>network.incoming.bytes.rate</p></li><li class="listitem "><p>network.outgoing.bytes.rate</p></li><li class="listitem "><p>network.incoming.packets.rate</p></li><li class="listitem "><p>network.outgoing.packets.rate</p></li></ul></div><div id="id-1.4.12.14.15.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To enable the libvirt <code class="literal">memory.usage</code> support, you need to install
libvirt version 1.1.1+, QEMU version 1.5+, and you also need to
prepare suitable balloon driver in the image. It is applicable
particularly for Windows guests, most modern Linux distributions
already have it built in. Telemetry is not able to fetch the
<code class="literal">memory.usage</code> samples without the image balloon driver.</p></div><p>OpenStack Compute is capable of collecting <code class="literal">CPU</code> related meters from
the compute host machines. In order to use that you need to set the
<code class="literal">compute_monitors</code> option to <code class="literal">ComputeDriverCPUMonitor</code> in the
<code class="literal">nova.conf</code> configuration file. For further information see the
Compute configuration section in the <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/config-options.html" target="_blank">Compute chapter</a>
of the OpenStack Configuration Reference.</p><p>The following host machine related meters are collected for OpenStack
Compute:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.frequency</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>MHz</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU frequency</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.kernel.time</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU kernel
time</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.idle.time</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU idle time</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.user.time</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU user mode
time</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.iowait.time</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU I/O wait
time</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.kernel.percent</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU kernel
percentage</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.idle.percent</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU idle
percentage</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.user.percent</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU user mode
percentage</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.iowait.percent</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU I/O wait
percentage</p>
                </td></tr><tr><td>
                  <p>compute.node.cpu.percent</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>CPU
utilization</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="telemetry-bare-metal-service"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Bare metal service</span> <a title="Permalink" class="permalink" href="#telemetry-bare-metal-service">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-bare-metal-service</li></ul></div></div></div></div><p>Telemetry captures notifications that are emitted by the Bare metal
service. The source of the notifications are IPMI sensors that collect
data from the host machine.</p><div id="id-1.4.12.14.16.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The sensor data is not available in the Bare metal service by
default. To enable the meters and configure this module to emit
notifications about the measured values see the <a class="link" href="http://docs.openstack.org/project-install-guide/baremetal/newton" target="_blank">Installation
Guide</a>
for the Bare metal service.</p></div><p>The following meters are recorded for the Bare metal service:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.fan</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>RPM</p>
                </td><td>
                  <p>fan
sensor</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Fan rounds per
minute (RPM)</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.temperature</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>C</p>
                </td><td>
                  <p>temperature
sensor</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Temperature reading from sensor</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.current</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>W</p>
                </td><td>
                  <p>current
sensor</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Current reading
from sensor</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.voltage</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>V</p>
                </td><td>
                  <p>voltage
sensor</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Voltage reading
from sensor</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.17"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">IPMI based meters</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.17">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Another way of gathering IPMI based data is to use IPMI sensors
independently from the Bare metal service's components. Same meters as
<a class="xref" href="#telemetry-bare-metal-service" title="10.6.2. Bare metal service">Section 10.6.2, “Bare metal service”</a> could be fetched except that origin is
<code class="literal">Pollster</code> instead of <code class="literal">Notification</code>.</p><p>You need to deploy the ceilometer-agent-ipmi on each IPMI-capable node
in order to poll local sensor data. For further information about the
IPMI agent see <a class="xref" href="#telemetry-ipmi-agent" title="10.2.2.2. IPMI agent">Section 10.2.2.2, “IPMI agent”</a>.</p><div id="id-1.4.12.14.17.4" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>To avoid duplication of metering data and unnecessary load on the
IPMI interface, do not deploy the IPMI agent on nodes that are
managed by the Bare metal service and keep the
<code class="literal">conductor.send_sensor_data</code> option set to <code class="literal">False</code> in the
<code class="literal">ironic.conf</code> configuration file.</p></div><p>Besides generic IPMI sensor data, the following Intel Node Manager
meters are recorded from capable platform:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.power</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>W</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Current power
of the system</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.temperature</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>C</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Current temperature of the
system</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.inlet_temperature</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>C</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Inlet temperature of the system</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.outlet_temperature</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>C</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Outlet temperature of the system</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.airflow</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>CFM</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Volumetric airflow of the system, expressed as
1/10th of CFM</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.cups</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>CUPS</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CUPS(Compute Usage Per Second)
index data of the
system</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.cpu_util</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CPU CUPS utilization of the
system</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.mem_util</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Memory CUPS
utilization of
the system</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.io_util</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>IO CUPS
utilization of
the system</p>
                </td></tr></tbody></table></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th colspan="2">
                  <p>Meters renamed in the Kilo release</p>
                </th></tr></thead><tbody><tr><td>
                  <p>
                    <span class="bold"><strong>Original Name</strong></span>
                  </p>
                </td><td>
                  <p>
                    <span class="bold"><strong>New Name</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.temperature</p>
                </td><td>
                  <p>hardware.ipmi.node.inlet_temperature</p>
                </td></tr><tr><td>
                  <p>hardware.ipmi.node.inlet_temperature</p>
                </td><td>
                  <p>hardware.ipmi.node.temperature</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.18"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SNMP based meters</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.18">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Telemetry supports gathering SNMP based generic host meters. In order to
be able to collect this data you need to run snmpd on each target host.</p><p>The following meters are available about the host machines by using
SNMP:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>hardware.cpu.load.1min</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>process</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CPU load in the
past 1 minute</p>
                </td></tr><tr><td>
                  <p>hardware.cpu.load.5min</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>process</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CPU load in the
past 5 minutes</p>
                </td></tr><tr><td>
                  <p>hardware.cpu.load.15min</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>process</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CPU load in the
past 15 minutes</p>
                </td></tr><tr><td>
                  <p>hardware.disk.size.total</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total disk size</p>
                </td></tr><tr><td>
                  <p>hardware.disk.size.used</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>disk ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Used disk size</p>
                </td></tr><tr><td>
                  <p>hardware.memory.total</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total physical
memory size</p>
                </td></tr><tr><td>
                  <p>hardware.memory.used</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Used physical memory size</p>
                </td></tr><tr><td>
                  <p>hardware.memory.buffer</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Physical memory
buffer size</p>
                </td></tr><tr><td>
                  <p>hardware.memory.cached</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Cached physical
memory size</p>
                </td></tr><tr><td>
                  <p>hardware.memory.swap.total</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total swap space
size</p>
                </td></tr><tr><td>
                  <p>hardware.memory.swap.avail</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>KB</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Available swap
space size</p>
                </td></tr><tr><td>
                  <p>hardware.network.incoming.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Bytes received
by network interface</p>
                </td></tr><tr><td>
                  <p>hardware.network.outgoing.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Bytes sent by network interface</p>
                </td></tr><tr><td>
                  <p>hardware.network.outgoing.errors</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>interface
ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Sending error of network interface</p>
                </td></tr><tr><td>
                  <p>hardware.network.ip.incoming.datagrams</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>datagrams</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of received datagrams</p>
                </td></tr><tr><td>
                  <p>hardware.network.ip.outgoing.datagrams</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>datagrams</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of sent
datagrams</p>
                </td></tr><tr><td>
                  <p>hardware.system_stats.io.incoming.blocks</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>blocks</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Aggregated number of blocks received to block
device</p>
                </td></tr><tr><td>
                  <p>hardware.system_stats.io.outgoing.blocks</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>blocks</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Aggregated number of blocks sent to block device</p>
                </td></tr><tr><td>
                  <p>hardware.system_stats.cpu.idle</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CPU idle percentage</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Mitaka release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>hardware.cpu.util</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>%</p>
                </td><td>
                  <p>host ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>cpu usage
percentage</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.19"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Image service</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.19">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for OpenStack Image service:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>image</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>image</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of the
image</p>
                </td></tr><tr><td>
                  <p>image.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>image</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Size of the uploaded image</p>
                </td></tr><tr><td>
                  <p>image.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>image</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of updates on the image</p>
                </td></tr><tr><td>
                  <p>image.upload</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>image</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of uploads on the image</p>
                </td></tr><tr><td>
                  <p>image.delete</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>image</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of deletes on the image</p>
                </td></tr><tr><td>
                  <p>image.download</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Image is downloaded</p>
                </td></tr><tr><td>
                  <p>image.serve</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>image ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Image is served
out</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.20"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Block Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.20">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for OpenStack Block Storage:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>volume</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of the
volume</p>
                </td></tr><tr><td>
                  <p>volume.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>GB</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Size of the volume</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>snapshot</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>snapshot</p>
                </td><td>
                  <p>snapshot
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of the
snapshot</p>
                </td></tr><tr><td>
                  <p>snapshot.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>GB</p>
                </td><td>
                  <p>snapshot
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Size of the snapshot</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>volume.create.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation of the
volume</p>
                </td></tr><tr><td>
                  <p>volume.delete.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Deletion of the
volume</p>
                </td></tr><tr><td>
                  <p>volume.update.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update the name
or description
of the volume</p>
                </td></tr><tr><td>
                  <p>volume.resize.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update the size
of the volume</p>
                </td></tr><tr><td>
                  <p>volume.attach.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Attaching the volume to an instance</p>
                </td></tr><tr><td>
                  <p>volume.detach.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>volume ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Detaching the volume from an instance</p>
                </td></tr><tr><td>
                  <p>snapshot.create.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>snapshot</p>
                </td><td>
                  <p>snapshot
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation of the
snapshot</p>
                </td></tr><tr><td>
                  <p>snapshot.delete.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>snapshot</p>
                </td><td>
                  <p>snapshot
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Deletion of the
snapshot</p>
                </td></tr><tr><td>
                  <p>volume.backup.create.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>backup ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation of the
volume backup</p>
                </td></tr><tr><td>
                  <p>volume.backup.delete.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>backup ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Deletion of the
volume backup</p>
                </td></tr><tr><td>
                  <p>volume.backup.restore.(start|end)</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>volume</p>
                </td><td>
                  <p>backup ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Restoration of
the volume backup</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="telemetry-object-storage-meter"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Object Storage</span> <a title="Permalink" class="permalink" href="#telemetry-object-storage-meter">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>telemetry-object-storage-meter</li></ul></div></div></div></div><p>The following meters are collected for OpenStack Object Storage:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>storage.objects</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>object</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of objects</p>
                </td></tr><tr><td>
                  <p>storage.objects.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total size of stored objects</p>
                </td></tr><tr><td>
                  <p>storage.objects.containers</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>container</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of containers</p>
                </td></tr><tr><td>
                  <p>storage.objects.incoming.bytes</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of incoming bytes</p>
                </td></tr><tr><td>
                  <p>storage.objects.outgoing.bytes</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of outgoing bytes</p>
                </td></tr><tr><td>
                  <p>storage.api.request</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of API requests against
OpenStack Object Storage</p>
                </td></tr><tr><td>
                  <p>storage.containers.objects</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>object</p>
                </td><td>
                  <p>storage ID/container</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of objects in container</p>
                </td></tr><tr><td>
                  <p>storage.containers.objects.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID/container</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total size of stored objects in container</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>meters deprecated in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td colspan="6">
                  <p>storage.objects.in| Delta | B     | storage ID | Notific| Number of incomcoming.bytes       |       |       |            | ation   | ing bytes</p>
                </td></tr><tr><td>
                  <p>storage.objects.outgoing.bytes</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of outgoing bytes</p>
                </td></tr><tr><td>
                  <p>storage.api.request</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of API requests against
OpenStack Object Storage</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.22"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ceph Object Storage</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.22">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In order to gather meters from Ceph, you have to install and configure
the Ceph Object Gateway (radosgw) as it is described in the <a class="link" href="http://docs.ceph.com/docs/master/radosgw/" target="_blank">Installation
Manual</a>. You have to enable
<a class="link" href="http://ceph.com/docs/master/man/8/radosgw/#usage-logging" target="_blank">usage logging</a> in
order to get the related meters from Ceph. You will also need an
<code class="literal">admin</code> user with <code class="literal">users</code>, <code class="literal">buckets</code>, <code class="literal">metadata</code> and <code class="literal">usage</code><code class="literal">caps</code> configured.</p><p>In order to access Ceph from Telemetry, you need to specify a
<code class="literal">service group</code> for <code class="literal">radosgw</code> in the <code class="literal">ceilometer.conf</code>
configuration file along with <code class="literal">access_key</code> and <code class="literal">secret_key</code> of the
<code class="literal">admin</code> user mentioned above.</p><p>The following meters are collected for Ceph Object Storage:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>radosgw.objects</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>object</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of objects</p>
                </td></tr><tr><td>
                  <p>radosgw.objects.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total size of stored objects</p>
                </td></tr><tr><td>
                  <p>radosgw.objects.containers</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>container</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of containers</p>
                </td></tr><tr><td>
                  <p>radosgw.api.request</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>request</p>
                </td><td>
                  <p>storage ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of API requests against
Ceph Object Gateway (radosgw)</p>
                </td></tr><tr><td>
                  <p>radosgw.containers.objects</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>object</p>
                </td><td>
                  <p>storage ID/container</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of objects in container</p>
                </td></tr><tr><td>
                  <p>radosgw.containers.objects.size</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>storage ID/container</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total size of stored objects in
container</p>
                </td></tr></tbody></table></div><div id="id-1.4.12.14.22.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">usage</code> related information may not be updated right after an
upload or download, because the Ceph Object Gateway needs time to
update the usage properties. For instance, the default configuration
needs approximately 30 minutes to generate the usage logs.</p></div></div><div class="sect2 " id="id-1.4.12.14.23"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Identity</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.23">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for OpenStack Identity:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>identity.authenticate.success</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>user</p>
                </td><td>
                  <p>user ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>User successfully authenticated</p>
                </td></tr><tr><td>
                  <p>identity.authenticate.pending</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>user</p>
                </td><td>
                  <p>user ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>User pending authentication</p>
                </td></tr><tr><td>
                  <p>identity.authenticate.failure</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>user</p>
                </td><td>
                  <p>user ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>User failed to
authenticate</p>
                </td></tr><tr><td>
                  <p>identity.user.created</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>user</p>
                </td><td>
                  <p>user ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>User is created</p>
                </td></tr><tr><td>
                  <p>identity.user.deleted</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>user</p>
                </td><td>
                  <p>user ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>User is deleted</p>
                </td></tr><tr><td>
                  <p>identity.user.updated</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>user</p>
                </td><td>
                  <p>user ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>User is updated</p>
                </td></tr><tr><td>
                  <p>identity.group.created</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>group</p>
                </td><td>
                  <p>group ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Group is created</p>
                </td></tr><tr><td>
                  <p>identity.group.deleted</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>group</p>
                </td><td>
                  <p>group ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Group is deleted</p>
                </td></tr><tr><td>
                  <p>identity.group.updated</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>group</p>
                </td><td>
                  <p>group ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Group is updated</p>
                </td></tr><tr><td>
                  <p>identity.role.created</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>role</p>
                </td><td>
                  <p>role ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Role is created</p>
                </td></tr><tr><td>
                  <p>identity.role.deleted</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>role</p>
                </td><td>
                  <p>role ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Role is deleted</p>
                </td></tr><tr><td>
                  <p>identity.role.updated</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>role</p>
                </td><td>
                  <p>role ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Role is updated</p>
                </td></tr><tr><td>
                  <p>identity.project.created</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>project</p>
                </td><td>
                  <p>project ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Project is created</p>
                </td></tr><tr><td>
                  <p>identity.project.deleted</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>project</p>
                </td><td>
                  <p>project ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Project is deleted</p>
                </td></tr><tr><td>
                  <p>identity.project.updated</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>project</p>
                </td><td>
                  <p>project ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Project is updated</p>
                </td></tr><tr><td>
                  <p>identity.trust.created</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>trust</p>
                </td><td>
                  <p>trust ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Trust is created</p>
                </td></tr><tr><td>
                  <p>identity.trust.deleted</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>trust</p>
                </td><td>
                  <p>trust ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Trust is deleted</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>identity.role_assignment.created</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>role_assignment</p>
                </td><td>
                  <p>role ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Role is added to
an actor on a
target</p>
                </td></tr><tr><td>
                  <p>identity.role_assignment.deleted</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>role_assignment</p>
                </td><td>
                  <p>role ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Role is removed
from an actor
on a target</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>All meters thoroughly deprecated in the liberty release</strong></span>
                  </p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.24"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Networking</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.24">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for OpenStack Networking:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>network</p>
                </td><td>
                  <p>network ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of network</p>
                </td></tr><tr><td>
                  <p>network.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>network</p>
                </td><td>
                  <p>network ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation requests for this network</p>
                </td></tr><tr><td>
                  <p>network.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>network</p>
                </td><td>
                  <p>network ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update requests
for this network</p>
                </td></tr><tr><td>
                  <p>subnet</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>subnet</p>
                </td><td>
                  <p>subnet ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of subnet</p>
                </td></tr><tr><td>
                  <p>subnet.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>subnet</p>
                </td><td>
                  <p>subnet ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation requests for this subnet</p>
                </td></tr><tr><td>
                  <p>subnet.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>subnet</p>
                </td><td>
                  <p>subnet ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update requests
for this subnet</p>
                </td></tr><tr><td>
                  <p>port</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>port</p>
                </td><td>
                  <p>port ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of port</p>
                </td></tr><tr><td>
                  <p>port.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>port</p>
                </td><td>
                  <p>port ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation requests for this port</p>
                </td></tr><tr><td>
                  <p>port.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>port</p>
                </td><td>
                  <p>port ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update requests
for this port</p>
                </td></tr><tr><td>
                  <p>router</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>router</p>
                </td><td>
                  <p>router ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of router</p>
                </td></tr><tr><td>
                  <p>router.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>router</p>
                </td><td>
                  <p>router ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation requests for this router</p>
                </td></tr><tr><td>
                  <p>router.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>router</p>
                </td><td>
                  <p>router ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update requests
for this router</p>
                </td></tr><tr><td>
                  <p>ip.floating</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>ip</p>
                </td><td>
                  <p>ip ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of IP</p>
                </td></tr><tr><td>
                  <p>ip.floating.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ip</p>
                </td><td>
                  <p>ip ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Creation requests for this IP</p>
                </td></tr><tr><td>
                  <p>ip.floating.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ip</p>
                </td><td>
                  <p>ip ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Update requests
for this IP</p>
                </td></tr><tr><td>
                  <p>bandwidth</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>label ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Bytes through this l3 metering
label</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.25"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">SDN controllers</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.25">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for SDN:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>switch</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>switch</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Existence of switch</p>
                </td></tr><tr><td>
                  <p>switch.port</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>port</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Existence of port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.packets</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Packets received on port</p>
                </td></tr><tr><td>
                  <p>switch.port.transmit.packets</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Packets transmitted on port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Bytes received
on port</p>
                </td></tr><tr><td>
                  <p>switch.port.transmit.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Bytes transmitted on port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.drops</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Drops received
on port</p>
                </td></tr><tr><td>
                  <p>switch.port.transmit.drops</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Drops transmitted on port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.errors</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Errors received
on port</p>
                </td></tr><tr><td>
                  <p>switch.port.transmit.errors</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Errors transmitted on port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.frame_error</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Frame alignment
errors received on port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.overrun_error</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Overrun errors
received on port</p>
                </td></tr><tr><td>
                  <p>switch.port.receive.crc_error</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>CRC errors received on port</p>
                </td></tr><tr><td>
                  <p>switch.port.collision.count</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>count</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Collisions on port</p>
                </td></tr><tr><td>
                  <p>switch.table</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>table</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Duration of table</p>
                </td></tr><tr><td>
                  <p>switch.table.active.entries</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>entry</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Active entries
in table</p>
                </td></tr><tr><td>
                  <p>switch.table.lookup.packets</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Lookup packets
for table</p>
                </td></tr><tr><td>
                  <p>switch.table.matched.packets</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Packets matches
for table</p>
                </td></tr><tr><td>
                  <p>switch.flow</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>flow</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Duration of flow</p>
                </td></tr><tr><td>
                  <p>switch.flow.duration.seconds</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>s</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Duration of flow
in seconds</p>
                </td></tr><tr><td>
                  <p>switch.flow.duration.nanoseconds</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>ns</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Duration of flow
in nanoseconds</p>
                </td></tr><tr><td>
                  <p>switch.flow.packets</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>packet</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Packets received</p>
                </td></tr><tr><td>
                  <p>switch.flow.bytes</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>switch ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Bytes received</p>
                </td></tr></tbody></table></div><p>These meters are available for OpenFlow based switches. In order to
enable these meters, each driver needs to be properly configured.</p></div><div class="sect2 " id="id-1.4.12.14.26"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Load-Balancer-as-a-Service (LBaaS v1)</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.26">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for LBaaS v1:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network.services.lb.pool</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>pool</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB pool</p>
                </td></tr><tr><td>
                  <p>network.services.lb.vip</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>vip</p>
                </td><td>
                  <p>vip ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB VIP</p>
                </td></tr><tr><td>
                  <p>network.services.lb.member</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>member</p>
                </td><td>
                  <p>member ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB member</p>
                </td></tr><tr><td>
                  <p>network.services.lb.health_monitor</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>health_monitor</p>
                </td><td>
                  <p>monitor ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB health probe</p>
                </td></tr><tr><td>
                  <p>network.services.lb.total.connections</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>connection</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total connections on a LB</p>
                </td></tr><tr><td>
                  <p>network.services.lb.active.connections</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>connection</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Active connections on a LB</p>
                </td></tr><tr><td>
                  <p>network.services.lb.incoming.bytes</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of incoming Bytes</p>
                </td></tr><tr><td>
                  <p>network.services.lb.outgoing.bytes</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of outgoing Bytes</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network.services.lb.pool.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>pool</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB pool was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.pool.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>pool</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB pool was updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.vip.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>vip</p>
                </td><td>
                  <p>vip ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB VIP was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.vip.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>vip</p>
                </td><td>
                  <p>vip ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB VIP was updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.member.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>member</p>
                </td><td>
                  <p>member ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB member was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.member.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>member</p>
                </td><td>
                  <p>member ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB member was updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.health_monitor.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>health_monitor</p>
                </td><td>
                  <p>monitor ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB health probe
was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.health_monitor.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>health_monitor</p>
                </td><td>
                  <p>monitor ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB health probe
was updated</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.27"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Load-Balancer-as-a-Service (LBaaS v2)</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.27">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for LBaaS v2. They are added in Mitaka
release:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td>
                  <p>network.services.lb.pool</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>pool</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB pool</p>
                </td></tr><tr><td>
                  <p>network.services.lb.listener</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>listener</p>
                </td><td>
                  <p>listener
ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB listener</p>
                </td></tr><tr><td>
                  <p>network.services.lb.member</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>member</p>
                </td><td>
                  <p>member ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB member</p>
                </td></tr><tr><td>
                  <p>network.services.lb.health_monitor</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>health_monitor</p>
                </td><td>
                  <p>monitor ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB health probe</p>
                </td></tr><tr><td>
                  <p>network.services.lb.loadbalancer</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>loadbalancer</p>
                </td><td>
                  <p>loadbalancer ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
LB loadbalancer</p>
                </td></tr><tr><td>
                  <p>network.services.lb.total.connections</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>connection</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Total connections on a LB</p>
                </td></tr><tr><td>
                  <p>network.services.lb.active.connections</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>connection</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Active connections on a LB</p>
                </td></tr><tr><td>
                  <p>network.services.lb.incoming.bytes</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of incoming Bytes</p>
                </td></tr><tr><td>
                  <p>network.services.lb.outgoing.bytes</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>B</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Number of outgoing Bytes</p>
                </td></tr><tr><td>
                  <p>network.services.lb.pool.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>pool</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB pool was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.pool.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>pool</p>
                </td><td>
                  <p>pool ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB pool was updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.listener.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>listener</p>
                </td><td>
                  <p>listener
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB listener was
created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.listener.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>listener</p>
                </td><td>
                  <p>listener
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB listener was
updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.member.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>member</p>
                </td><td>
                  <p>member ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB member was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.member.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>member</p>
                </td><td>
                  <p>member ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB member was updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.healthmonitor.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>health_monitor</p>
                </td><td>
                  <p>monitor ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB health probe
was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.healthmonitor.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>health_monitor</p>
                </td><td>
                  <p>monitor ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB health probe
was updated</p>
                </td></tr><tr><td>
                  <p>network.services.lb.loadbalancer.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>loadbalancer</p>
                </td><td>
                  <p>loadbalancer ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB loadbalancer
was created</p>
                </td></tr><tr><td>
                  <p>network.services.lb.loadbalancer.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>loadbalancer</p>
                </td><td>
                  <p>loadbalancer ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>LB loadbalancer
was updated</p>
                </td></tr></tbody></table></div><div id="id-1.4.12.14.27.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The above meters are experimental and may generate a large load against the
Neutron APIs. The future enhancement will be implemented when Neutron
supports the new APIs.</p></div></div><div class="sect2 " id="id-1.4.12.14.28"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">VPN-as-a-Service (VPNaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.28">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for VPNaaS:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network.services.vpn</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>vpnservice</p>
                </td><td>
                  <p>vpn ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
VPN</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.connections</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>ipsec_site_connection</p>
                </td><td>
                  <p>connection
ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of an
IPSec connection</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network.services.vpn.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>vpnservice</p>
                </td><td>
                  <p>vpn ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>VPN was created</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>vpnservice</p>
                </td><td>
                  <p>vpn ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>VPN was updated</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.connections.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ipsec_site_connection</p>
                </td><td>
                  <p>connection
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>IPSec connection
was created</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.connections.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ipsec_site_connection</p>
                </td><td>
                  <p>connection
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>IPSec connection
was updated</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.ipsecpolicy</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>ipsecpolicy</p>
                </td><td>
                  <p>ipsecpolicy
ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of an
IPSec policy</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.ipsecpolicy.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ipsecpolicy</p>
                </td><td>
                  <p>ipsecpolicy
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>IPSec policy was
created</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.ipsecpolicy.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ipsecpolicy</p>
                </td><td>
                  <p>ipsecpolicy
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>IPSec policy was
updated</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.ikepolicy</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>ikepolicy</p>
                </td><td>
                  <p>ikepolicy
ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of an
Ike policy</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.ikepolicy.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ikepolicy</p>
                </td><td>
                  <p>ikepolicy
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Ike policy was
created</p>
                </td></tr><tr><td>
                  <p>network.services.vpn.ikepolicy.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>ikepolicy</p>
                </td><td>
                  <p>ikepolicy
ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Ike policy was
updated</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.29"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Firewall-as-a-Service (FWaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.29">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for FWaaS:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network.services.firewall</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>firewall</p>
                </td><td>
                  <p>firewall ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
firewall</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.policy</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>firewall_policy</p>
                </td><td>
                  <p>firewall ID</p>
                </td><td>
                  <p>Notification, Pollster</p>
                </td><td>
                  <p>Existence of a
firewall policy</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>network.services.firewall.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>firewall</p>
                </td><td>
                  <p>firewall ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Firewall was created</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>firewall</p>
                </td><td>
                  <p>firewall ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Firewall was updated</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.policy.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>firewall_policy</p>
                </td><td>
                  <p>policy ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Firewall policy
was created</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.policy.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>firewall_policy</p>
                </td><td>
                  <p>policy ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Firewall policy
was updated</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.rule</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>firewall_rule</p>
                </td><td>
                  <p>rule ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Existence of a
firewall rule</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.rule.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>firewall_rule</p>
                </td><td>
                  <p>rule ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Firewall rule was created</p>
                </td></tr><tr><td>
                  <p>network.services.firewall.rule.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>firewall_rule</p>
                </td><td>
                  <p>rule ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Firewall rule was updated</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.30"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration service</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.30">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for the Orchestration service:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>stack.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>stack</p>
                </td><td>
                  <p>stack ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Stack was successfully created</p>
                </td></tr><tr><td>
                  <p>stack.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>stack</p>
                </td><td>
                  <p>stack ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Stack was successfully updated</p>
                </td></tr><tr><td>
                  <p>stack.delete</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>stack</p>
                </td><td>
                  <p>stack ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Stack was successfully deleted</p>
                </td></tr><tr><td>
                  <p>stack.resume</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>stack</p>
                </td><td>
                  <p>stack ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Stack was successfully resumed</p>
                </td></tr><tr><td>
                  <p>stack.suspend</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>stack</p>
                </td><td>
                  <p>stack ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Stack was successfully suspended</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>All meters thoroughly deprecated in the Liberty release</strong></span>
                  </p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.31"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.17 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data processing service for OpenStack</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.31">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for the Data processing service for
OpenStack:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Juno release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>cluster.create</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>cluster</p>
                </td><td>
                  <p>cluster ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Cluster was
successfully
created</p>
                </td></tr><tr><td>
                  <p>cluster.update</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>cluster</p>
                </td><td>
                  <p>cluster ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Cluster was
successfully
updated</p>
                </td></tr><tr><td>
                  <p>cluster.delete</p>
                </td><td>
                  <p>Delta</p>
                </td><td>
                  <p>cluster</p>
                </td><td>
                  <p>cluster ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Cluster was
successfully
deleted</p>
                </td></tr><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>All meters thoroughly deprecated in the Liberty release</strong></span>
                  </p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.12.14.32"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.18 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Key Value Store module</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.32">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following meters are collected for the Key Value Store module:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Kilo release</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>magnetodb.table.create</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>table</p>
                </td><td>
                  <p>table ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Table was successfully created</p>
                </td></tr><tr><td>
                  <p>magnetodb.table.delete</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>table</p>
                </td><td>
                  <p>table ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Table was successfully deleted</p>
                </td></tr><tr><td>
                  <p>magnetodb.table.index.count</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>index</p>
                </td><td>
                  <p>table ID</p>
                </td><td>
                  <p>Notification</p>
                </td><td>
                  <p>Number of indices
created in a
table</p>
                </td></tr></tbody></table></div><div id="id-1.4.12.14.32.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The the Key Value Store meters are not supported in the Newton release and
later.</p></div></div><div class="sect2 " id="id-1.4.12.14.33"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.6.19 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Energy</span> <a title="Permalink" class="permalink" href="#id-1.4.12.14.33">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following energy related meters are available:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /><col class="c5" /><col class="c6" /></colgroup><thead><tr><th>
                  <p>Name</p>
                </th><th>
                  <p>Type</p>
                </th><th>
                  <p>Unit</p>
                </th><th>
                  <p>Resource</p>
                </th><th>
                  <p>Origin</p>
                </th><th>
                  <p>Note</p>
                </th></tr></thead><tbody><tr><td colspan="6">
                  <p>
                    <span class="bold"><strong>Meters added in the Icehouse release or earlier</strong></span>
                  </p>
                </td></tr><tr><td>
                  <p>energy</p>
                </td><td>
                  <p>Cumulative</p>
                </td><td>
                  <p>kWh</p>
                </td><td>
                  <p>probe ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Amount of energy</p>
                </td></tr><tr><td>
                  <p>power</p>
                </td><td>
                  <p>Gauge</p>
                </td><td>
                  <p>W</p>
                </td><td>
                  <p>probe ID</p>
                </td><td>
                  <p>Pollster</p>
                </td><td>
                  <p>Power consumption</p>
                </td></tr></tbody></table></div></div></div><div class="sect1 " id="id-1.4.12.15"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Events</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In addition to meters, the Telemetry service collects events triggered
within an OpenStack environment. This section provides a brief summary
of the events format in the Telemetry service.</p><p>While a sample represents a single, numeric datapoint within a
time-series, an event is a broader concept that represents the state of
a resource at a point in time. The state may be described using various
data types including non-numeric data such as an instance's flavor. In
general, events represent any action made in the OpenStack system.</p><div class="sect2 " id="id-1.4.12.15.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Event configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable the creation and storage of events in the Telemetry service
<code class="literal">store_events</code> option needs to be set to <code class="literal">True</code>. For further configuration
options, see the event section in the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry.html" target="_blank">OpenStack Configuration Reference</a>.</p><div id="id-1.4.12.15.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>It is advisable to set <code class="literal">disable_non_metric_meters</code> to <code class="literal">True</code>
when enabling events in the Telemetry service. The Telemetry service
historically represented events as metering data, which may create
duplication of data if both events and non-metric meters are
enabled.</p></div></div><div class="sect2 " id="id-1.4.12.15.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Event structure</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Events captured by the Telemetry service are represented by five key
attributes:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.15.5.3.1"><span class="term ">event_type</span></dt><dd><p>A dotted string defining what event occurred such as
<code class="literal">"compute.instance.resize.start"</code>.</p></dd><dt id="id-1.4.12.15.5.3.2"><span class="term ">message_id</span></dt><dd><p>A UUID for the event.</p></dd><dt id="id-1.4.12.15.5.3.3"><span class="term ">generated</span></dt><dd><p>A timestamp of when the event occurred in the system.</p></dd><dt id="id-1.4.12.15.5.3.4"><span class="term ">traits</span></dt><dd><p>A flat mapping of key-value pairs which describe the event. The
event's traits contain most of the details of the event. Traits are
typed, and can be strings, integers, floats, or datetimes.</p></dd><dt id="id-1.4.12.15.5.3.5"><span class="term ">raw</span></dt><dd><p>Mainly for auditing purpose, the full event message can be stored
(unindexed) for future evaluation.</p></dd></dl></div></div><div class="sect2 " id="id-1.4.12.15.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Event indexing</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The general philosophy of notifications in OpenStack is to emit any and
all data someone might need, and let the consumer filter out what they
are not interested in. In order to make processing simpler and more
efficient, the notifications are stored and processed within Ceilometer
as events. The notification payload, which can be an arbitrarily complex
JSON data structure, is converted to a flat set of key-value pairs. This
conversion is specified by a config file.</p><div id="id-1.4.12.15.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The event format is meant for efficient processing and querying.
Storage of complete notifications for auditing purposes can be
enabled by configuring <code class="literal">store_raw</code> option.</p></div><div class="sect3 " id="id-1.4.12.15.6.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.7.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Event conversion</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15.6.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The conversion from notifications to events is driven by a configuration
file defined by the <code class="literal">definitions_cfg_file</code> in the <code class="literal">ceilometer.conf</code>
configuration file.</p><p>This includes descriptions of how to map fields in the notification body
to Traits, and optional plug-ins for doing any programmatic translations
(splitting a string, forcing case).</p><p>The mapping of notifications to events is defined per event_type, which
can be wildcarded. Traits are added to events if the corresponding
fields in the notification exist and are non-null.</p><div id="id-1.4.12.15.6.4.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The default definition file included with the Telemetry service
contains a list of known notifications and useful traits. The
mappings provided can be modified to include more or less data
according to user requirements.</p></div><p>If the definitions file is not present, a warning will be logged, but an
empty set of definitions will be assumed. By default, any notifications
that do not have a corresponding event definition in the definitions
file will be converted to events with a set of minimal traits. This can
be changed by setting the option <code class="literal">drop_unmatched_notifications</code> in the
<code class="literal">ceilometer.conf</code> file. If this is set to <code class="literal">True</code>, any unmapped
notifications will be dropped.</p><p>The basic set of traits (all are TEXT type) that will be added to all
events if the notification has the relevant data are: service
(notification's publisher), tenant_id, and request_id. These do not
have to be specified in the event definition, they are automatically
added, but their definitions can be overridden for a given event_type.</p></div><div class="sect3 " id="id-1.4.12.15.6.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.7.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Event definitions format</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15.6.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The event definitions file is in YAML format. It consists of a list of
event definitions, which are mappings. Order is significant, the list of
definitions is scanned in reverse order to find a definition which
matches the notification's event_type. That definition will be used to
generate the event. The reverse ordering is done because it is common to
want to have a more general wildcarded definition (such as
<code class="literal">compute.instance.*</code>) with a set of traits common to all of those
events, with a few more specific event definitions afterwards that have
all of the above traits, plus a few more.</p><p>Each event definition is a mapping with two keys:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.15.6.5.4.1"><span class="term ">event_type</span></dt><dd><p>This is a list (or a string, which will be taken as a 1 element
list) of event_types this definition will handle. These can be
wildcarded with unix shell glob syntax. An exclusion listing
(starting with a <code class="literal">!</code>) will exclude any types listed from matching.
If only exclusions are listed, the definition will match anything
not matching the exclusions.</p></dd><dt id="id-1.4.12.15.6.5.4.2"><span class="term ">traits</span></dt><dd><p>This is a mapping, the keys are the trait names, and the values are
trait definitions.</p></dd></dl></div><p>Each trait definition is a mapping with the following keys:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.12.15.6.5.6.1"><span class="term ">fields</span></dt><dd><p>A path specification for the field(s) in the notification you wish
to extract for this trait. Specifications can be written to match
multiple possible fields. By default the value will be the first
such field. The paths can be specified with a dot syntax
(<code class="literal">payload.host</code>). Square bracket syntax (<code class="literal">payload[host]</code>) is
also supported. In either case, if the key for the field you are
looking for contains special characters, like <code class="literal">.</code>, it will need to
be quoted (with double or single quotes):
<code class="literal">payload.image_meta.’org.openstack__1__architecture’</code>. The syntax
used for the field specification is a variant of
<a class="link" href="https://github.com/kennknowles/python-jsonpath-rw" target="_blank">JSONPath</a></p></dd><dt id="id-1.4.12.15.6.5.6.2"><span class="term ">type</span></dt><dd><p>(Optional) The data type for this trait. Valid options are:
<code class="literal">text</code>, <code class="literal">int</code>, <code class="literal">float</code>, and <code class="literal">datetime</code>. Defaults to <code class="literal">text</code>
if not specified.</p></dd><dt id="id-1.4.12.15.6.5.6.3"><span class="term ">plugin</span></dt><dd><p>(Optional) Used to execute simple programmatic conversions on the
value in a notification field.</p></dd></dl></div></div><div class="sect3 " id="id-1.4.12.15.6.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">10.7.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Event delivery to external sinks</span> <a title="Permalink" class="permalink" href="#id-1.4.12.15.6.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can configure the Telemetry service to deliver the events
into external sinks. These sinks are configurable in the
<code class="literal">/etc/ceilometer/event_pipeline.yaml</code> file.</p></div></div></div><div class="sect1 " id="id-1.4.12.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot Telemetry</span> <a title="Permalink" class="permalink" href="#id-1.4.12.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.12.16.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logging in Telemetry</span> <a title="Permalink" class="permalink" href="#id-1.4.12.16.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Telemetry service has similar log settings as the other OpenStack
services. Multiple options are available to change the target of
logging, the format of the log entries and the log levels.</p><p>The log settings can be changed in <code class="literal">ceilometer.conf</code>. The list of
configuration options are listed in the logging configuration options
table in the <a class="link" href="http://docs.openstack.org/newton/config-reference/telemetry.html" target="_blank">Telemetry
section</a>
in the OpenStack Configuration Reference.</p><p>By default <code class="literal">stderr</code> is used as standard output for the log messages.
It can be changed to either a log file or syslog. The <code class="literal">debug</code> and
<code class="literal">verbose</code> options are also set to false in the default settings, the
default log levels of the corresponding modules can be found in the
table referred above.</p></div><div class="sect2 " id="id-1.4.12.16.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Recommended order of starting services</span> <a title="Permalink" class="permalink" href="#id-1.4.12.16.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As it can be seen in <a class="link" href="https://bugs.launchpad.net/devstack/+bug/1355809" target="_blank">Bug
1355809</a>, the wrong
ordering of service startup can result in data loss.</p><p>When the services are started for the first time or in line with the
message queue service restart, it takes time while the
<code class="literal">ceilometer-collector</code> service establishes the connection and joins or
rejoins to the configured exchanges. Therefore, if the
<code class="literal">ceilometer-agent-compute</code>, <code class="literal">ceilometer-agent-central</code>, and the
<code class="literal">ceilometer-agent-notification</code> services are started before
the <code class="literal">ceilometer-collector</code> service, the <code class="literal">ceilometer-collector</code> service
may lose some messages while connecting to the message queue service.</p><p>The possibility of this issue to happen is higher, when the polling
interval is set to a relatively short period. In order to avoid this
situation, the recommended order of service startup is to start or
restart the <code class="literal">ceilometer-collector</code> service after the message queue. All
the other Telemetry services should be started or restarted after and
the <code class="literal">ceilometer-agent-compute</code> should be the last in the sequence, as this
component emits metering messages in order to send the samples to the
collector.</p></div><div class="sect2 " id="id-1.4.12.16.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notification agent</span> <a title="Permalink" class="permalink" href="#id-1.4.12.16.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the Icehouse release of OpenStack a new service was introduced to be
responsible for consuming notifications that are coming from other
OpenStack services.</p><p>If the <code class="literal">ceilometer-agent-notification</code> service is not installed and
started, samples originating from notifications will not be generated.
In case of the lack of notification based samples, the state of this
service and the log file of Telemetry should be checked first.</p><p>For the list of meters that are originated from notifications, see the
<a class="link" href="http://docs.openstack.org/developer/ceilometer/measurements.html" target="_blank">Telemetry Measurements
Reference</a>.</p></div><div class="sect2 " id="id-1.4.12.16.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Recommended auth_url to be used</span> <a title="Permalink" class="permalink" href="#id-1.4.12.16.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When using the Telemetry command-line client, the credentials and the
<code class="literal">os_auth_url</code> have to be set in order for the client to authenticate
against OpenStack Identity. For further details
about the credentials that have to be provided see the <a class="link" href="http://docs.openstack.org/developer/python-ceilometerclient/" target="_blank">Telemetry Python
API</a>.</p><p>The service catalog provided by OpenStack Identity contains the
URLs that are available for authentication. The URLs have
different <code class="literal">port</code>s, based on whether the type of the given URL is
<code class="literal">public</code>, <code class="literal">internal</code> or <code class="literal">admin</code>.</p><p>OpenStack Identity is about to change API version from v2 to v3. The
<code class="literal">adminURL</code> endpoint (which is available via the port: <code class="literal">35357</code>)
supports only the v3 version, while the other two supports both.</p><p>The Telemetry command line client is not adapted to the v3 version of
the OpenStack Identity API. If the <code class="literal">adminURL</code> is used as
<code class="literal">os_auth_url</code>, the <code class="command">ceilometer</code> command results in the following
error message:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer meter-list
  Unable to determine the Keystone version to authenticate with \
  using the given auth_url: http://10.0.2.15:35357/v2.0</pre></div><p>Therefore when specifying the <code class="literal">os_auth_url</code> parameter on the command
line or by using environment variable, use the <code class="literal">internalURL</code> or
<code class="literal">publicURL</code>.</p><p>For more details check the bug report <a class="link" href="https://bugs.launchpad.net/python-ceilometerclient/+bug/1351841" target="_blank">Bug
1351841</a>.</p></div></div><div class="sect1 " id="id-1.4.12.17"><div class="titlepage"><div><div><h2 class="title"><span class="number">10.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Telemetry best practices</span> <a title="Permalink" class="permalink" href="#id-1.4.12.17">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following are some suggested best practices to follow when deploying
and configuring the Telemetry service. The best practices are divided
into data collection and storage.</p><div class="sect2 " id="id-1.4.12.17.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data collection</span> <a title="Permalink" class="permalink" href="#id-1.4.12.17.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The Telemetry service collects a continuously growing set of data. Not
all the data will be relevant for an administrator to monitor.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Based on your needs, you can edit the <code class="literal">pipeline.yaml</code> configuration
file to include a selected number of meters while disregarding the
rest.</p></li><li class="listitem "><p>By default, Telemetry service polls the service APIs every 10
minutes. You can change the polling interval on a per meter basis by
editing the <code class="literal">pipeline.yaml</code> configuration file.</p><div id="id-1.4.12.17.3.2.1.2.2.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>If the polling interval is too short, it will likely cause
increase of stored data and the stress on the service APIs.</p></div></li><li class="listitem "><p>Expand the configuration to have greater control over different meter
intervals.</p><div id="id-1.4.12.17.3.2.1.2.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more information, see the
<a class="xref" href="#telemetry-pipeline-configuration" title="10.3.1. Pipeline configuration">Section 10.3.1, “Pipeline configuration”</a>.</p></div></li></ul></div></li><li class="step "><p>If you are using the Kilo version of Telemetry, you can delay or adjust
polling requests by enabling the jitter support. This adds a random
delay on how the polling agents send requests to the service APIs. To
enable jitter, set <code class="literal">shuffle_time_before_polling_task</code> in the
<code class="literal">ceilometer.conf</code> configuration file to an integer greater
than 0.</p></li><li class="step "><p>If you are using Juno or later releases, based on the number of
resources that will be polled, you can add additional central and
compute agents as necessary. The agents are designed to scale
horizontally.</p><div id="id-1.4.12.17.3.2.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more information see, <a class="xref" href="#ha-deploy-services" title="10.2.3. Support for HA deployment">Section 10.2.3, “Support for HA deployment”</a>.</p></div></li><li class="step "><p>If you are using Juno or later releases, use the <code class="literal">notifier://</code>
publisher rather than <code class="literal">rpc://</code> as there is a certain level of overhead
that comes with RPC.</p><div id="id-1.4.12.17.3.2.4.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more information on RPC overhead, see <a class="link" href="https://www.rabbitmq.com/tutorials/tutorial-six-python.html" target="_blank">RPC overhead
info</a>.</p></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.12.17.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">10.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data storage</span> <a title="Permalink" class="permalink" href="#id-1.4.12.17.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>We recommend that you avoid open-ended queries. In order to get better
performance you can use reasonable time ranges and/or other query
constraints for retrieving measurements.</p><p>For example, this open-ended query might return an unpredictable amount
of data:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer sample-list --meter cpu -q 'resource_id=INSTANCE_ID_1'</pre></div><p>Whereas, this well-formed query returns a more reasonable amount of
data, hence better performance:</p><div class="verbatim-wrap"><pre class="screen">$ ceilometer sample-list --meter cpu -q 'resource_id=INSTANCE_ID_1;timestamp &gt; 2015-05-01T00:00:00;timestamp &lt; 2015-06-01T00:00:00'</pre></div><div id="id-1.4.12.17.4.2.1.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>As of the Liberty release, the number of items returned will be
restricted to the value defined by <code class="literal">default_api_return_limit</code> in the
<code class="literal">ceilometer.conf</code> configuration file. Alternatively, the value can
be set per query by passing <code class="literal">limit</code> option in request.</p></div></li><li class="step "><p>You can install the API behind <code class="literal">mod_wsgi</code>, as it provides more
settings to tweak, like <code class="literal">threads</code> and <code class="literal">processes</code> in case of
<code class="literal">WSGIDaemon</code>.</p><div id="id-1.4.12.17.4.2.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more information on how to configure <code class="literal">mod_wsgi</code>, see the
<a class="link" href="http://docs.openstack.org/developer/ceilometer/install/mod_wsgi.html" target="_blank">Telemetry Install Documentation</a>.</p></div></li><li class="step "><p>The collection service provided by the Telemetry project is not intended
to be an archival service. Set a Time to Live (TTL) value to expire data
and minimize the database size. If you would like to keep your data for
longer time period, you may consider storing it in a data warehouse
outside of Telemetry.</p><div id="id-1.4.12.17.4.2.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more information on how to set the TTL, see
<a class="xref" href="#telemetry-storing-samples" title="10.2.6. Storing samples">Section 10.2.6, “Storing samples”</a>.</p></div></li><li class="step "><p>We recommend that you do not use SQLAlchemy back end prior to the Juno
release, as it previously contained extraneous relationships to handle
deprecated data models. This resulted in extremely poor query
performance.</p></li><li class="step "><p>We recommend that you do not run MongoDB on the same node as the
controller. Keep it on a separate node optimized for fast storage for
better performance. Also it is advisable for the MongoDB node to have a
lot of memory.</p><div id="id-1.4.12.17.4.2.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For more information on how much memory you need, see <a class="link" href="http://docs.mongodb.org/manual/faq/diagnostics/#how-do-i-calculate-how-much-ram-i-need-for-my-application" target="_blank">MongoDB
FAQ</a>.</p></div></li><li class="step "><p>Use replica sets in MongoDB. Replica sets provide high availability
through automatic failover. If your primary node fails, MongoDB will
elect a secondary node to replace the primary node, and your cluster
will remain functional.</p><p>For more information on replica sets, see the <a class="link" href="http://docs.mongodb.org/manual/tutorial/deploy-replica-set/" target="_blank">MongoDB replica sets
docs</a>.</p></li><li class="step "><p>Use sharding in MongoDB. Sharding helps in storing data records across
multiple machines and is the MongoDB’s approach to meet the demands of
data growth.</p><p>For more information on sharding, see the <a class="link" href="http://docs.mongodb.org/manual/sharding/" target="_blank">MongoDB sharding
docs</a>.</p></li></ol></div></div></div></div></div><div class="chapter " id="id-1.4.13"><div class="titlepage"><div><div><h1 class="title"><span class="number">11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Database</span> <a title="Permalink" class="permalink" href="#id-1.4.13">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.13.4"><span class="number">11.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.13.5"><span class="number">11.2 </span><span class="name">Create a data store</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.13.6"><span class="number">11.3 </span><span class="name">Configure a cluster</span></a></span></dt></dl></div></div><p>The Database service provides database management features.</p><div class="sect1 " id="id-1.4.13.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction</span> <a title="Permalink" class="permalink" href="#id-1.4.13.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Database service provides scalable and reliable cloud
provisioning functionality for both relational and non-relational
database engines. Users can quickly and easily use database features
without the burden of handling complex administrative tasks. Cloud
users and database administrators can provision and manage multiple
database instances as needed.</p><p>The Database service provides resource isolation at high performance
levels, and automates complex administrative tasks such as deployment,
configuration, patching, backups, restores, and monitoring.</p><p>You can modify various cluster characteristics by editing the
<code class="literal">/etc/trove/trove.conf</code> file. A comprehensive list of the Database
service configuration options is described in the <a class="link" href="http://docs.openstack.org/newton/config-reference/database.html" target="_blank">Database service</a>
chapter in the <span class="emphasis"><em>Configuration Reference</em></span>.</p></div><div class="sect1 " id="id-1.4.13.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a data store</span> <a title="Permalink" class="permalink" href="#id-1.4.13.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An administrative user can create data stores for a variety of
databases.</p><p>This section assumes you do not yet have a MySQL data store, and shows
you how to create a MySQL data store and populate it with a MySQL 5.5
data store version.</p><p>
        <span class="bold"><strong>To create a data store</strong></span>
      </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
            <span class="bold"><strong>Create a trove image</strong></span>
          </p><p>Create an image for the type of database you want to use, for
example, MySQL, MongoDB, Cassandra.</p><p>This image must have the trove guest agent installed, and it must
have the <code class="literal">trove-guestagent.conf</code> file configured to connect to
your OpenStack environment. To configure <code class="literal">trove-guestagent.conf</code>,
add the following lines to <code class="literal">trove-guestagent.conf</code> on the guest
instance you are using to build your image:</p><div class="verbatim-wrap highlight ini"><pre class="screen">rabbit_host = controller
rabbit_password = RABBIT_PASS
nova_proxy_admin_user = admin
nova_proxy_admin_pass = ADMIN_PASS
nova_proxy_admin_tenant_name = service
trove_auth_url = http://controller:35357/v2.0</pre></div><p>This example assumes you have created a MySQL 5.5 image called
<code class="literal">mysql-5.5.qcow2</code>.</p><div id="id-1.4.13.5.5.1.6" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>If you have a guest image that was created with an OpenStack version
before Kilo, modify the guest agent init script for the guest image to
read the configuration files from the directory <code class="literal">/etc/trove/conf.d</code>.</p><p>For a backwards compatibility with pre-Kilo guest instances, set the
database service configuration options <code class="literal">injected_config_location</code> to
<code class="literal">/etc/trove</code> and <code class="literal">guest_info</code> to <code class="literal">/etc/guest_info</code>.</p></div></li><li class="step "><p>
            <span class="bold"><strong>Register image with Image service</strong></span>
          </p><p>You need to register your guest image with the Image service.</p><p>In this example, you use the <code class="command">openstack image create</code>
command to register a <code class="literal">mysql-5.5.qcow2</code> image.</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create mysql-5.5 --disk-format qcow2 --container-format bare --public &lt; mysql-5.5.qcow2
+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | 133eae9fb1c98f45894a4e60d8736619                     |
| container_format | bare                                                 |
| created_at       | 2016-12-21T12:10:02Z                                 |
| disk_format      | qcow2                                                |
| file             | /v2/images/d1afb4f0-2360-4400-8d97-846b1ab6af52/file |
| id               | d1afb4f0-2360-4400-8d97-846b1ab6af52                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | mysql-5.5                                            |
| owner            | 5669caad86a04256994cdf755df4d3c1                     |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 13200896                                             |
| status           | active                                               |
| tags             |                                                      |
| updated_at       | 2016-12-21T12:10:03Z                                 |
| virtual_size     | None                                                 |
| visibility       | public                                               |
+------------------+------------------------------------------------------+</pre></div></li><li class="step "><p>
            <span class="bold"><strong>Create the data store</strong></span>
          </p><p>Create the data store that will house the new image. To do this, use
the <code class="command">trove-manage</code><code class="command">datastore_update</code> command.</p><p>This example uses the following arguments:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                    <p>Argument</p>
                  </th><th>
                    <p>Description</p>
                  </th><th>
                    <p>In this example:</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>config file</p>
                  </td><td>
                    <p>The configuration file to use.</p>
                  </td><td>
                    <p>
                      <code class="literal">--config-file=/etc/trove/trove.conf</code>
                    </p>
                  </td></tr><tr><td>
                    <p>name</p>
                  </td><td>
                    <p>Name you want to use for this data store.</p>
                  </td><td>
                    <p>
                      <code class="literal">mysql</code>
                    </p>
                  </td></tr><tr><td>
                    <p>default version</p>
                  </td><td>
                    <p>You can attach multiple versions/images to a data store. For
example, you might have a MySQL 5.5 version and a MySQL 5.6
version. You can designate one version as the default, which
the system uses if a user does not explicitly request a
specific version.</p>
                  </td><td>
                    <p>
                      <code class="literal">""</code>
                    </p>
                    <p>At this point, you do not yet have a default version, so pass
in an empty string.</p>
                  </td></tr></tbody></table></div><p>Example:</p><div class="verbatim-wrap"><pre class="screen">$ trove-manage --config-file=/etc/trove/trove.conf datastore_update mysql ""</pre></div></li><li class="step "><p>
            <span class="bold"><strong>Add a version to the new data store</strong></span>
          </p><p>Now that you have a MySQL data store, you can add a version to it,
using the <code class="command">trove-manage</code><code class="command">datastore_version_update</code>
command. The version indicates which guest image to use.</p><p>This example uses the following arguments:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                    <p>Argument</p>
                  </th><th>
                    <p>Description</p>
                  </th><th>
                    <p>In this example:</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>config file</p>
                  </td><td>
                    <p>The configuration file to use.</p>
                  </td><td>
                    <p>
                      <code class="literal">--config-file=/etc/trove/trove.conf</code>
                    </p>
                  </td></tr><tr><td>
                    <p>data store</p>
                  </td><td>
                    <p>The name of the data store you just created via
<code class="literal">trove-manage</code><code class="command">datastore_update</code>.</p>
                  </td><td>
                    <p>
                      <code class="literal">mysql</code>
                    </p>
                  </td></tr><tr><td>
                    <p>version name</p>
                  </td><td>
                    <p>The name of the version you are adding to the data store.</p>
                  </td><td>
                    <p>
                      <code class="literal">mysql-5.5</code>
                    </p>
                  </td></tr><tr><td>
                    <p>data store manager</p>
                  </td><td>
                    <p>Which data store manager to use for this version. Typically,
the data store manager is identified by one of the following
strings, depending on the database:</p>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>cassandra</p></li><li class="listitem "><p>couchbase</p></li><li class="listitem "><p>couchdb</p></li><li class="listitem "><p>db2</p></li><li class="listitem "><p>mariadb</p></li><li class="listitem "><p>mongodb</p></li><li class="listitem "><p>mysql</p></li><li class="listitem "><p>percona</p></li><li class="listitem "><p>postgresql</p></li><li class="listitem "><p>pxc</p></li><li class="listitem "><p>redis</p></li><li class="listitem "><p>vertica</p></li></ul></div>
                  </td><td>
                    <p>
                      <code class="literal">mysql</code>
                    </p>
                  </td></tr><tr><td>
                    <p>glance ID</p>
                  </td><td>
                    <p>The ID of the guest image you just added to the Image
service. You can get this ID by using the glance
<code class="command">image-show</code> IMAGE_NAME command.</p>
                  </td><td>
                    <p>bb75f870-0c33-4907-8467-1367f8cb15b6</p>
                  </td></tr><tr><td>
                    <p>packages</p>
                  </td><td>
                    <p>If you want to put additional packages on each guest that
you create with this data store version, you can list the
package names here.</p>
                  </td><td>
                    <p>
                      <code class="literal">""</code>
                    </p>
                    <p>In this example, the guest image already contains all the
required packages, so leave this argument empty.</p>
                  </td></tr><tr><td>
                    <p>active</p>
                  </td><td>
                    <div class="variablelist "><dl class="variablelist"><dt id="id-1.4.13.5.5.4.4.1.5.7.2.1.1"><span class="term ">Set this to either 1 or 0:</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">1</code> = active</p></li><li class="listitem "><p><code class="literal">0</code> = disabled</p></li></ul></div></dd></dl></div>
                  </td><td>
                    <p>1</p>
                  </td></tr></tbody></table></div><p>Example:</p><div class="verbatim-wrap"><pre class="screen">$ trove-manage --config-file=/etc/trove/trove.conf datastore_version_update mysql mysql-5.5 mysql GLANCE_ID "" 1</pre></div><p><span class="bold"><strong>Optional.</strong></span> Set your new version as the default version. To do
this, use the <code class="command">trove-manage</code><code class="command">datastore_update</code>
command again, this time specifying the version you just created.</p><div class="verbatim-wrap"><pre class="screen">$ trove-manage --config-file=/etc/trove/trove.conf datastore_update mysql mysql-5.5</pre></div></li><li class="step "><p>
            <span class="bold"><strong>Load validation rules for configuration groups</strong></span>
          </p><div id="id-1.4.13.5.5.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
              <span class="bold"><strong>Applies only to MySQL and Percona data stores</strong></span>
            </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>If you just created a MySQL or Percona data store, then you need
to load the appropriate validation rules, as described in this
step.</p></li><li class="listitem "><p>If you just created a different data store, skip this step.</p></li></ul></div></div><p><span class="bold"><strong>Background.</strong></span> You can manage database configuration tasks by using
configuration groups. Configuration groups let you set configuration
parameters, in bulk, on one or more databases.</p><p>When you set up a configuration group using the trove
<code class="command">configuration-create</code> command, this command compares the configuration
values you are setting against a list of valid configuration values
that are stored in the <code class="literal">validation-rules.json</code> file.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /></colgroup><thead><tr><th>
                    <p>Operating System</p>
                  </th><th>
                    <p>Location of <code class="literal">validation-rules.json</code></p>
                  </th><th>
                    <p>Notes</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Ubuntu 14.04</p>
                  </td><td>
                    <p>
                      <code class="literal">/usr/lib/python2.7/dist-packages/trove/templates/DATASTORE_NAME</code>
                    </p>
                  </td><td>
                    <p>DATASTORE_NAME is the name of either the MySQL data store or
the Percona data store. This is typically either <code class="literal">mysql</code>
or <code class="literal">percona</code>.</p>
                  </td></tr><tr><td>
                    <p>RHEL 7, CentOS 7, Fedora 20, and Fedora 21</p>
                  </td><td>
                    <p>
                      <code class="literal">/usr/lib/python2.7/site-packages/trove/templates/DATASTORE_NAME</code>
                    </p>
                  </td><td>
                    <p>DATASTORE_NAME is the name of either the MySQL data store or
the Percona data store. This is typically either <code class="literal">mysql</code> or <code class="literal">percona</code>.</p>
                  </td></tr></tbody></table></div><p>Therefore, as part of creating a data store, you need to load the
<code class="literal">validation-rules.json</code> file, using the <code class="command">trove-manage</code><code class="command">db_load_datastore_config_parameters</code> command. This command
takes the following arguments:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Data store name</p></li><li class="listitem "><p>Data store version</p></li><li class="listitem "><p>Full path to the <code class="literal">validation-rules.json</code> file</p></li></ul></div><p>This example loads the <code class="literal">validation-rules.json</code> file for a MySQL
database on Ubuntu 14.04:</p><div class="verbatim-wrap"><pre class="screen">$ trove-manage db_load_datastore_config_parameters mysql mysql-5.5 /usr/lib/python2.7/dist-packages/trove/templates/mysql/validation-rules.json</pre></div></li><li class="step "><p>
            <span class="bold"><strong>Validate data store</strong></span>
          </p><p>To validate your new data store and version, start by listing the
data stores on your system:</p><div class="verbatim-wrap"><pre class="screen">$ trove datastore-list
+--------------------------------------+--------------+
|                  id                  |     name     |
+--------------------------------------+--------------+
| 10000000-0000-0000-0000-000000000001 | Legacy MySQL |
| e5dc1da3-f080-4589-a4c2-eff7928f969a |    mysql     |
+--------------------------------------+--------------+</pre></div><p>Take the ID of the MySQL data store and pass it in with the
<code class="command">datastore-version-list</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ trove datastore-version-list DATASTORE_ID
+--------------------------------------+-----------+
|                  id                  |    name   |
+--------------------------------------+-----------+
| 36a6306b-efd8-4d83-9b75-8b30dd756381 | mysql-5.5 |
+--------------------------------------+-----------+</pre></div></li></ol></div></div><div class="sect2 " id="id-1.4.13.5.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">11.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Data store classifications</span> <a title="Permalink" class="permalink" href="#id-1.4.13.5.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Database service supports a variety of both relational and
non-relational database engines, but to a varying degree of support for
each <a class="xref" href="#term-data-store" title="data store">data store</a>. The Database service project has defined
several classifications that indicate the quality of support for each
data store. Data stores also implement different extensions.
An extension is called a <a class="xref" href="#term-strategy" title="strategy">strategy</a> and is classified similar to
data stores.</p><p>Valid classifications for a data store and a strategy are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Experimental</p></li><li class="listitem "><p>Technical preview</p></li><li class="listitem "><p>Stable</p></li></ul></div><p>Each classification builds on the previous one. This means that a data store
that meets the <code class="literal">technical preview</code> requirements must also meet all the
requirements for <code class="literal">experimental</code>, and a data store that meets the <code class="literal">stable</code>
requirements must also meet all the requirements for <code class="literal">technical preview</code>.</p><p>
          <span class="bold"><strong>Requirements</strong></span>
        </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Experimental</p><p>A data store is considered to be <code class="literal">experimental</code> if it meets these criteria:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>It implements a basic subset of the Database service API including
<code class="literal">create</code> and <code class="literal">delete</code>.</p></li><li class="listitem "><p>It has guest agent elements that allow guest agent creation.</p></li><li class="listitem "><p>It has a definition of supported operating systems.</p></li><li class="listitem "><p>It meets the other
<a class="link" href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements" target="_blank">Documented Technical Requirements</a>.</p></li></ul></div><p>A strategy is considered <code class="literal">experimental</code> if:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>It meets the
<a class="link" href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements" target="_blank">Documented Technical Requirements</a>.</p></li></ul></div></li><li class="listitem "><p>Technical preview</p><p>A data store is considered to be a <code class="literal">technical preview</code> if it meets the
requirements of <code class="literal">experimental</code> and further:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>It implements APIs required to plant and start the capabilities of the
data store as defined in the
<a class="link" href="https://wiki.openstack.org/wiki/Trove/DatastoreCompatibilityMatrix" target="_blank">Datastore Compatibility Matrix</a>.</p><div id="id-1.4.13.5.6.7.2.3.1.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>It is not required that the data store implements all features like
resize, backup, replication, or clustering to meet this classification.</p></div></li><li class="listitem "><p>It provides a mechanism for building a guest image that allows you to
exercise its capabilities.</p></li><li class="listitem "><p>It meets the other
<a class="link" href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements" target="_blank">Documented Technical Requirements</a>.</p></li></ul></div><div id="id-1.4.13.5.6.7.2.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>A strategy is not normally considered to be <code class="literal">technical
preview</code>.</p></div></li><li class="listitem "><p>Stable</p><p>A data store or a strategy is considered <code class="literal">stable</code> if:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>It meets the requirements of <code class="literal">technical preview</code>.</p></li><li class="listitem "><p>It meets the other
<a class="link" href="https://specs.openstack.org/openstack/trove-specs/specs/kilo/experimental-datastores.html#requirements" target="_blank">Documented Technical Requirements</a>.</p></li></ul></div></li></ul></div><p>
          <span class="bold"><strong>Initial Classifications</strong></span>
        </p><p>The following table shows the current classification assignments for the
different data stores.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Classification</p>
                </th><th>
                  <p>Data store</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Stable</p>
                </td><td>
                  <p>MySQL</p>
                </td></tr><tr><td>
                  <p>Technical Preview</p>
                </td><td>
                  <p>Cassandra, MongoDB</p>
                </td></tr><tr><td>
                  <p>Experimental</p>
                </td><td>
                  <p>All others</p>
                </td></tr></tbody></table></div></div><div class="sect2 " id="id-1.4.13.5.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">11.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Redis data store replication</span> <a title="Permalink" class="permalink" href="#id-1.4.13.5.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Replication strategies are available for Redis with
several commands located in the Redis data store
manager:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <code class="command">create</code>
            </p></li><li class="listitem "><p>
              <code class="command">detach-replica</code>
            </p></li><li class="listitem "><p>
              <code class="command">eject-replica-source</code>
            </p></li><li class="listitem "><p>
              <code class="command">promote-to-replica-source</code>
            </p></li></ul></div><p>Additional arguments for the <code class="command">create</code> command
include <code class="command">--replica_of</code> and
<code class="command">--replica_count</code>.</p></div><div class="sect2 " id="id-1.4.13.5.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">11.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Redis integration and unit tests</span> <a title="Permalink" class="permalink" href="#id-1.4.13.5.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Unit tests and integration tests are also available for
Redis.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install redstack:</p><div class="verbatim-wrap"><pre class="screen">$ ./redstack install

.. note::

   Redstack is a development script used for integration
   testing and Database service development installations.
   Do not use Redstack in a production environment. For
   more information, see `the Database service
   developer docs &lt;http://docs.openstack.org/developer/trove/dev/install.html#running-redstack-to-install-trove&gt;`_</pre></div></li><li class="step "><p>Start Redis:</p><div class="verbatim-wrap"><pre class="screen">$ ./redstack kick-start redis</pre></div></li><li class="step "><p>Run integration tests:</p><div class="verbatim-wrap"><pre class="screen">$ ./redstack int-tests --group=replication</pre></div><p>You can run <code class="command">--group=redis_supported</code>
instead of <code class="command">--group=replication</code> if needed.</p></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.13.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure a cluster</span> <a title="Permalink" class="permalink" href="#id-1.4.13.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>An administrative user can configure various characteristics of a
MongoDB cluster.</p><p>
        <span class="bold"><strong>Query routers and config servers</strong></span>
      </p><p><span class="bold"><strong>Background.</strong></span> Each cluster includes at least one query router and
one config server. Query routers and config servers count against your
quota. When you delete a cluster, the system deletes the associated
query router(s) and config server(s).</p><p><span class="bold"><strong>Configuration.</strong></span> By default, the system creates one query router and
one config server per cluster. You can change this by editing
the <code class="literal">/etc/trove/trove.conf</code> file. These settings are in the
<code class="literal">mongodb</code> section of the file:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                <p>Setting</p>
              </th><th>
                <p>Valid values are:</p>
              </th></tr></thead><tbody><tr><td>
                <p>num_config_servers_per_cluster</p>
              </td><td>
                <p>1 or 3</p>
              </td></tr><tr><td>
                <p>num_query_routers_per_cluster</p>
              </td><td>
                <p>1 or 3</p>
              </td></tr></tbody></table></div></div></div><div class="chapter " id="id-1.4.14"><div class="titlepage"><div><div><h1 class="title"><span class="number">12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Bare Metal</span> <a title="Permalink" class="permalink" href="#id-1.4.14">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.14.4"><span class="number">12.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.5"><span class="number">12.2 </span><span class="name">System architecture</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.6"><span class="number">12.3 </span><span class="name">Bare Metal deployment</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.7"><span class="number">12.4 </span><span class="name">Use Bare Metal</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.14.8"><span class="number">12.5 </span><span class="name">Troubleshooting</span></a></span></dt></dl></div></div><p>The Bare Metal service provides physical hardware management features.</p><div class="sect1 " id="id-1.4.14.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction</span> <a title="Permalink" class="permalink" href="#id-1.4.14.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Bare Metal service provides physical hardware as opposed to
virtual machines. It also provides several reference drivers, which
leverage common technologies like PXE and IPMI, to cover a wide range
of hardware. The pluggable driver architecture also allows
vendor-specific drivers to be added for improved performance or
functionality not provided by reference drivers. The Bare Metal
service makes physical servers as easy to provision as virtual
machines in a cloud, which in turn will open up new avenues for
enterprises and service providers.</p></div><div class="sect1 " id="id-1.4.14.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.14.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Bare Metal service is composed of the following components:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>An admin-only RESTful API service, by which privileged users, such
as operators and other services within the cloud control
plane, may interact with the managed bare-metal servers.</p></li><li class="step "><p>A conductor service, which conducts all activity related to
bare-metal deployments. Functionality is exposed via the API
service. The Bare Metal service conductor and API service
communicate via RPC.</p></li><li class="step "><p>Various drivers that support heterogeneous hardware, which enable
features specific to unique hardware platforms and leverage
divergent capabilities via a common API.</p></li><li class="step "><p>A message queue, which is a central hub for passing messages, such
as RabbitMQ. It should use the same implementation as that of the
Compute service.</p></li><li class="step "><p>A database for storing information about the resources. Among other
things, this includes the state of the conductors, nodes (physical
servers), and drivers.</p></li></ol></div></div><p>When a user requests to boot an instance, the request is passed to the
Compute service via the Compute service API and scheduler. The Compute
service hands over this request to the Bare Metal service, where the
request passes from the Bare Metal service API, to the conductor which
will invoke a driver to successfully provision a physical server for
the user.</p></div><div class="sect1 " id="id-1.4.14.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Bare Metal deployment</span> <a title="Permalink" class="permalink" href="#id-1.4.14.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>PXE deploy process</p></li><li class="step "><p>Agent deploy process</p></li></ol></div></div></div><div class="sect1 " id="id-1.4.14.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use Bare Metal</span> <a title="Permalink" class="permalink" href="#id-1.4.14.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Install the Bare Metal service.</p></li><li class="step "><p>Setup the Bare Metal driver in the compute node's <code class="literal">nova.conf</code> file.</p></li><li class="step "><p>Setup TFTP folder and prepare PXE boot loader file.</p></li><li class="step "><p>Prepare the bare metal flavor.</p></li><li class="step "><p>Register the nodes with correct drivers.</p></li><li class="step "><p>Configure the driver information.</p></li><li class="step "><p>Register the ports information.</p></li><li class="step "><p>Use the <code class="command">openstack server create</code> command to
kick off the bare metal provision.</p></li><li class="step "><p>Check nodes' provision state and power state.</p></li></ol></div></div><div class="sect2 " id="id-1.4.14.7.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">12.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use multitenancy with Bare Metal service</span> <a title="Permalink" class="permalink" href="#id-1.4.14.7.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.14.7.3.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">12.4.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Use multitenancy with Bare Metal service</span> <a title="Permalink" class="permalink" href="#id-1.4.14.7.3.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Multitenancy allows creating a dedicated project network that extends the
current Bare Metal (ironic) service capabilities of providing <code class="literal">flat</code>
networks. Multitenancy works in conjunction with Networking (neutron)
service to allow provisioning of a bare metal server onto the project network.
Therefore, multiple projects can get isolated instances after deployment.</p><p>Bare Metal service provides the <code class="literal">local_link_connection</code> information to the
Networking service ML2 driver. The ML2 driver uses that information to plug the
specified port to the project network.</p><div class="table" id="id-1.4.14.7.3.2.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 12.1: </span><span class="name">local_link_connection fields </span><a title="Permalink" class="permalink" href="#id-1.4.14.7.3.2.4">#</a></h6></div><div class="table-contents"><table class="table" summary="local_link_connection fields" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                    <p>Field</p>
                  </th><th>
                    <p>Description</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>
                      <code class="literal">switch_id</code>
                    </p>
                  </td><td>
                    <p>Required. Identifies a switch and can be an LLDP-based MAC address or
an OpenFlow-based <code class="literal">datapath_id</code>.</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">port_id</code>
                    </p>
                  </td><td>
                    <p>Required. Port ID on the switch, for example, Gig0/1.</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">switch_info</code>
                    </p>
                  </td><td>
                    <p>Optional. Used to distinguish different switch models or other
vendor specific-identifier.</p>
                  </td></tr></tbody></table></div></div><div class="sect4 " id="id-1.4.14.7.3.2.5"><div class="titlepage"><div><div><h5 class="title"><span class="number">12.4.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Networking service ML2 driver</span> <a title="Permalink" class="permalink" href="#id-1.4.14.7.3.2.5">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To enable the Networking service ML2 driver, edit the
<code class="literal">/etc/neutron/plugins/ml2/ml2_conf.ini</code> file:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Add the name of your ML2 driver.</p></li><li class="step "><p>Add the vendor ML2 plugin configuration options.</p></li></ol></div></div><div class="verbatim-wrap highlight ini"><pre class="screen">[ml2]
...
mechanism_drivers = my_mechanism_driver

[my_vendor]
param_1 = ...
param_2 = ...
param_3 = ...</pre></div><p>For more details, see
<a class="link" href="http://docs.openstack.org/newton/networking-guide/config-ml2.html#mechanism-drivers" target="_blank">Networking service mechanism drivers</a>.</p></div><div class="sect4 " id="id-1.4.14.7.3.2.6"><div class="titlepage"><div><div><h5 class="title"><span class="number">12.4.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Bare Metal service</span> <a title="Permalink" class="permalink" href="#id-1.4.14.7.3.2.6">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>After you configure the Networking service ML2 driver, configure Bare Metal
service:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Edit the <code class="literal">/etc/ironic/ironic.conf</code> for the <code class="literal">ironic-conductor</code> service.
Set the <code class="literal">network_interface</code> node field to a valid network driver that is
used to switch, clean, and provision networks.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[DEFAULT]
...
enabled_network_interfaces=flat,neutron

[neutron]
...
cleaning_network_uuid=$UUID
provisioning_network_uuid=$UUID</pre></div><div id="id-1.4.14.7.3.2.6.3.1.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>The <code class="literal">cleaning_network_uuid</code> and <code class="literal">provisioning_network_uuid</code>
parameters are required for the <code class="literal">neutron</code> network interface. If they are
not set, <code class="literal">ironic-conductor</code> fails to start.</p></div></li><li class="step "><p>Set <code class="literal">neutron</code> to use Networking service ML2 driver:</p><div class="verbatim-wrap"><pre class="screen">$ ironic node-create -n $NAME --network-interface neutron --driver agent_ipmitool</pre></div></li><li class="step "><p>Create a port with appropriate <code class="literal">local_link_connection</code> information. Set
the <code class="literal">pxe_enabled</code> port attribute to <code class="literal">True</code> to create network ports for
for the <code class="literal">pxe_enabled</code> ports only:</p><div class="verbatim-wrap"><pre class="screen">$ ironic --ironic-api-version latest port-create -a $HW_MAC_ADDRESS \
  -n $NODE_UUID -l switch_id=$SWITCH_MAC_ADDRESS \
  -l switch_info=$SWITCH_HOSTNAME -l port_id=$SWITCH_PORT --pxe-enabled true</pre></div></li></ol></div></div></div></div></div></div><div class="sect1 " id="id-1.4.14.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">12.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="#id-1.4.14.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.14.8.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">12.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">No valid host found error</span> <a title="Permalink" class="permalink" href="#id-1.4.14.8.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect3 bridgehead"><h4 class="title" id="id-1.4.14.8.2.3"><span class="name">Problem</span><a title="Permalink" class="permalink" href="#id-1.4.14.8.2.3">#</a></h4></div><p>Sometimes <code class="literal">/var/log/nova/nova-conductor.log</code> contains the following error:</p><div class="verbatim-wrap"><pre class="screen">NoValidHost: No valid host was found. There are not enough hosts available.</pre></div><p>The message <code class="literal">No valid host was found</code> means that the Compute service
scheduler could not find a bare metal node suitable for booting the new
instance.</p><p>This means there will be some mismatch between resources that the Compute
service expects to find and resources that Bare Metal service advertised to
the Compute service.</p><div xmlns:dm="urn:x-suse:ns:docmanager" class="sect3 bridgehead"><h4 class="title" id="id-1.4.14.8.2.8"><span class="name">Solution</span><a title="Permalink" class="permalink" href="#id-1.4.14.8.2.8">#</a></h4></div><p>If you get this message, check the following:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Introspection should have succeeded for you before, or you should have
entered the required bare-metal node properties manually.
For each node in the <code class="command">ironic node-list</code> command, use:</p><div class="verbatim-wrap"><pre class="screen">$ ironic node-show &lt;IRONIC-NODE-UUID&gt;</pre></div><p>and make sure that <code class="literal">properties</code> JSON field has valid values for keys
<code class="literal">cpus</code>, <code class="literal">cpu_arch</code>, <code class="literal">memory_mb</code> and <code class="literal">local_gb</code>.</p></li><li class="step "><p>The flavor in the Compute service that you are using does not exceed the
bare-metal node properties above for a required number of nodes. Use:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor show FLAVOR</pre></div></li><li class="step "><p>Make sure that enough nodes are in <code class="literal">available</code> state according to the
<code class="command">ironic node-list</code> command. Nodes in <code class="literal">manageable</code> state usually
mean they have failed introspection.</p></li><li class="step "><p>Make sure nodes you are going to deploy to are not in maintenance mode.
Use the <code class="command">ironic node-list</code> command to check. A node automatically
going to maintenance mode usually means the incorrect credentials for
this node. Check them and then remove maintenance mode:</p><div class="verbatim-wrap"><pre class="screen">$ ironic node-set-maintenance &lt;IRONIC-NODE-UUID&gt; off</pre></div></li><li class="step "><p>It takes some time for nodes information to propagate from the Bare Metal
service to the Compute service after introspection. Our tooling usually
accounts for it, but if you did some steps manually there may be a period
of time when nodes are not available to the Compute service yet. Check that
the <code class="command">openstack hypervisor stats show</code> command correctly shows total
amount of resources in your system.</p></li></ol></div></div></div></div></div><div class="chapter " id="id-1.4.15"><div class="titlepage"><div><div><h1 class="title"><span class="number">13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration</span> <a title="Permalink" class="permalink" href="#id-1.4.15">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.15.4"><span class="number">13.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.15.5"><span class="number">13.2 </span><span class="name">Orchestration authorization model</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.15.6"><span class="number">13.3 </span><span class="name">Stack domain users</span></a></span></dt></dl></div></div><p>Orchestration is an orchestration engine that provides the
possibility to launch multiple composite cloud applications based on
templates in the form of text files that can be treated like code. A
native Heat Orchestration Template (HOT) format is evolving, but it
also endeavors to provide compatibility with the AWS CloudFormation
template format, so that many existing CloudFormation templates can
be launched on OpenStack.</p><div class="sect1 " id="id-1.4.15.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction</span> <a title="Permalink" class="permalink" href="#id-1.4.15.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack Orchestration service, a tool for orchestrating clouds,
automatically configures and deploys resources in stacks. The deployments can
be simple, such as deploying WordPress on Ubuntu with an SQL back end, or
complex, such as starting a server group that auto scales by
starting and stopping using real-time CPU loading information from the
Telemetry service.</p><p>Orchestration stacks are defined with templates, which are non-procedural
documents. Templates describe tasks in terms of resources, parameters, inputs,
constraints, and dependencies. When the Orchestration service was originally
introduced, it worked with AWS CloudFormation templates, which are in the JSON
format.</p><p>The Orchestration service also runs Heat Orchestration Template (HOT)
templates that are written in YAML. YAML is a terse notation that loosely
follows structural conventions (colons, returns, indentation) that are similar
to Python or Ruby. Therefore, it is easier to write, parse, grep, generate
with tools, and maintain source-code management systems.</p><p>Orchestration can be accessed through a CLI and RESTful queries.
The Orchestration service provides both an OpenStack-native REST API and a
CloudFormation-compatible Query API. The Orchestration service is also
integrated with the OpenStack dashboard to perform stack functions through
a web interface.</p><p>For more information about using the Orchestration service through the
command line, see the <a class="link" href="http://docs.openstack.org/cli-reference/heat.html" target="_blank">OpenStack Command-Line Interface Reference</a>.</p></div><div class="sect1 " id="id-1.4.15.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration authorization model</span> <a title="Permalink" class="permalink" href="#id-1.4.15.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Orchestration authorization model defines the
authorization process for requests during deferred operations.
A common example is an auto-scaling group update. During
the auto-scaling update operation, the Orchestration service
requests resources of other components (such as servers from
Compute or networks from Networking) to extend or reduce the
capacity of an auto-scaling group.</p><p>The Orchestration service provides the following authorization models:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Password authorization</p></li><li class="listitem "><p>OpenStack Identity trusts authorization</p></li></ul></div><div class="sect2 " id="id-1.4.15.5.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Password authorization</span> <a title="Permalink" class="permalink" href="#id-1.4.15.5.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Orchestration service supports password authorization.
Password authorization requires that a user pass a
username and password to the Orchestration service. Encrypted
password are stored in the database, and used for deferred
operations.</p><p>Password authorization involves the following steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>A user requests stack creation, by providing a token and
username and password. The Dashboard or
python-heatclient requests the token on the user's behalf.</p></li><li class="step "><p>If the stack contains any resources that require deferred
operations, then the orchestration engine fails its validation
checks if the user did not provide a valid username/password.</p></li><li class="step "><p>The username/password are encrypted and stored in the Orchestration
database.</p></li><li class="step "><p>Orchestration creates a stack.</p></li><li class="step "><p>Later, the Orchestration service retrieves the credentials and
requests another token on behalf of the user. The token is not
limited in scope and provides access to all the roles of the stack
owner.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.15.5.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Identity trusts authorization</span> <a title="Permalink" class="permalink" href="#id-1.4.15.5.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A trust is an OpenStack Identity extension that enables delegation,
and optionally impersonation through the OpenStack Identity service.
The key terminology is <span class="emphasis"><em>trustor</em></span> (the user delegating) and
<span class="emphasis"><em>trustee</em></span> (the user being delegated to).</p><p>To create a trust, the <span class="emphasis"><em>trustor</em></span> (in this case, the user creating the
stack in the Orchestration service) provides the OpenStack Identity service
with the following information:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The ID of the <span class="emphasis"><em>trustee</em></span> (who you want to delegate to, in this case,
the Orchestration service user).</p></li><li class="listitem "><p>The roles to be delegated. Configure roles through
the <code class="literal">heat.conf</code> file. Ensure the configuration contains whatever
roles are required to perform the deferred operations on the
user's behalf. For example, launching an OpenStack Compute
instance in response to an auto-scaling event.</p></li><li class="listitem "><p>Whether to enable impersonation.</p></li></ul></div><p>The OpenStack Identity service provides a <span class="emphasis"><em>trust id</em></span>,
which is consumed by <span class="emphasis"><em>only</em></span> the trustee to obtain a
<span class="emphasis"><em>trust scoped token</em></span>. This token is limited in scope,
such that the trustee has limited access to those
roles delegated. In addition, the trustee has effective impersonation
of the trustor user if it was selected when creating the trust.
For more information, see <a class="xref" href="#cha-identity" title="Chapter 3. Identity management">Chapter 3, <em>Identity management</em></a>.</p><p>Trusts authorization involves the following steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>A user creates a stack through an API request (only the token is
required).</p></li><li class="step "><p>The Orchestration service uses the token to create a trust
between the stack owner (trustor) and the Orchestration
service user (trustee). The service delegates a special role (or roles)
as defined in the <span class="emphasis"><em>trusts_delegated_roles</em></span> list in the
Orchestration configuration file. By default, the Orchestration
service sets all the roles from trustor available for trustee.
Deployers might modify this list to reflect a local RBAC policy.
For example, to ensure that the heat process can access only
those services that are expected while impersonating a stack owner.</p></li><li class="step "><p>Orchestration stores the encrypted <span class="emphasis"><em>trust id</em></span> in the Orchestration
database.</p></li><li class="step "><p>When a deferred operation is required, the Orchestration service
retrieves the <span class="emphasis"><em>trust id</em></span> and requests a trust scoped token which
enables the service user to impersonate the stack owner during
the deferred operation. Impersonation is helpful, for example,
so the service user can launch Compute instances on
behalf of the stack owner in response to an auto-scaling event.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.15.5.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Authorization model configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.15.5.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Initially, the password authorization model was the
default authorization model. Since the Kilo release, the
Identity trusts authorization model is enabled for the Orchestration
service by default.</p><p>To enable the password authorization model, change the following
parameter in the <code class="literal">heat.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">deferred_auth_method=password</pre></div><p>To enable the trusts authorization model, change the following
parameter in the <code class="literal">heat.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">deferred_auth_method=trusts</pre></div><p>To specify the trustor roles that it delegates to trustee during
authorization, specify the <code class="literal">trusts_delegated_roles</code> parameter
in the <code class="literal">heat.conf</code> file. If <code class="literal">trusts_delegated_roles</code> is not
defined, then all the trustor roles are delegated to trustee.</p><div id="id-1.4.15.5.7.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The trustor delegated roles must be pre-configured in the
OpenStack Identity service before using them in the Orchestration service.</p></div></div></div><div class="sect1 " id="id-1.4.15.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">13.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Stack domain users</span> <a title="Permalink" class="permalink" href="#id-1.4.15.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Stack domain users allow the Orchestration service to
authorize and start the following operations within booted virtual
machines:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Provide metadata to agents inside instances. Agents poll for changes
and apply the configuration that is expressed in the metadata to the
instance.</p></li><li class="listitem "><p>Detect when an action is complete. Typically, software configuration
on a virtual machine after it is booted. Compute moves
the VM state to "Active" as soon as it creates it, not when the
Orchestration service has fully configured it.</p></li><li class="listitem "><p>Provide application level status or meters from inside the instance.
For example, allow auto-scaling actions to be performed in response
to some measure of performance or quality of service.</p></li></ul></div><p>The Orchestration service provides APIs that enable all of these
operations, but all of those APIs require authentication.
For example, credentials to access the instance that the agent
is running upon. The heat-cfntools agents use signed requests,
which require an ec2 key pair created through Identity.
The key pair is then used to sign requests to the Orchestration
CloudFormation and CloudWatch compatible APIs, which are
authenticated through signature validation. Signature validation
uses the Identity ec2tokens extension.</p><p>Stack domain users encapsulate all stack-defined users (users who are
created as a result of data that is contained in an
Orchestration template) in a separate domain.
The separate domain is created specifically to contain data
related to the Orchestration stacks only. A user is created, which is
the <span class="emphasis"><em>domain admin</em></span>, and Orchestration uses the <span class="emphasis"><em>domain admin</em></span> to manage
the lifecycle of the users in the stack <span class="emphasis"><em>user domain</em></span>.</p><div class="sect2 " id="id-1.4.15.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Stack domain users configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.15.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To configure stack domain user, the Orchestration service completes the
following tasks:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>A special OpenStack Identity service domain is created. For
example, a domain that is called <code class="literal">heat</code> and the ID is set with the
<code class="literal">stack_user_domain</code> option in the <code class="literal">heat.conf</code> file.</p></li><li class="step "><p>A user with sufficient permissions to create and delete projects
and users in the <code class="literal">heat</code> domain is created.</p></li><li class="step "><p>The username and password for the domain admin user is set in the
<code class="literal">heat.conf</code> file (<code class="literal">stack_domain_admin</code> and
<code class="literal">stack_domain_admin_password</code>). This user administers
<span class="emphasis"><em>stack domain users</em></span> on behalf of stack owners, so they no longer
need to be administrators themselves. The risk of this escalation path
is limited because the <code class="literal">heat_domain_admin</code> is only given
administrative permission for the <code class="literal">heat</code> domain.</p></li></ol></div></div><p>To set up stack domain users, complete the following steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the domain:</p><p><code class="literal">$OS_TOKEN</code> refers to a token. For example, the service admin
token or some other valid token for a user with sufficient roles
to create users and domains. <code class="literal">$KS_ENDPOINT_V3</code> refers to the v3
OpenStack Identity endpoint (for example,
<code class="literal">http://keystone_address:5000/v3</code> where <span class="emphasis"><em>keystone_address</em></span> is
the IP address or resolvable name for the Identity
service).</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-token $OS_TOKEN --os-url=$KS_ENDPOINT_V3 --os-\
  identity-api-version=3 domain create heat --description "Owns \
  users and projects created by heat"</pre></div><p>The domain ID is returned by this command, and is referred to as
<code class="literal">$HEAT_DOMAIN_ID</code> below.</p></li><li class="step "><p>Create the user:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-token $OS_TOKEN --os-url=$KS_ENDPOINT_V3 --os-\
  identity-api-version=3 user create --password $PASSWORD --domain \
  $HEAT_DOMAIN_ID heat_domain_admin --description "Manages users \
  and projects created by heat"</pre></div><p>The user ID is returned by this command and is referred to as
<code class="literal">$DOMAIN_ADMIN_ID</code> below.</p></li><li class="step "><p>Make the user a domain admin:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-token $OS_TOKEN --os-url=$KS_ENDPOINT_V3 --os-\
  identity-api-version=3 role add --user $DOMAIN_ADMIN_ID --domain \
  $HEAT_DOMAIN_ID admin</pre></div><p>Then you must add the domain ID, username and password from these
steps to the <code class="literal">heat.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">stack_domain_admin_password = password
stack_domain_admin = heat_domain_admin
stack_user_domain = domain id returned from domain create above</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.15.6.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">13.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Usage workflow</span> <a title="Permalink" class="permalink" href="#id-1.4.15.6.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following steps are run during stack creation:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Orchestration creates a new <span class="emphasis"><em>stack domain project</em></span> in the <code class="literal">heat</code>
domain if the stack contains any resources that require creation
of a <span class="emphasis"><em>stack domain user</em></span>.</p></li><li class="step "><p>For any resources that require a user, the Orchestration service creates
the user in the <span class="emphasis"><em>stack domain project</em></span>. The <span class="emphasis"><em>stack domain project</em></span> is
associated with the Orchestration stack in the Orchestration
database, but is separate and unrelated (from an authentication
perspective) to the stack owners project. The users who are created
in the stack domain are still assigned the <code class="literal">heat_stack_user</code> role, so
the API surface they can access is limited through
the <code class="literal">policy.json</code> file.
For more  information, see <a class="xref" href="#cha-identity" title="Chapter 3. Identity management">Chapter 3, <em>Identity management</em></a>.</p></li><li class="step "><p>When API requests are processed, the Orchestration service performs
an internal lookup, and allows stack details for a given stack to be
retrieved. Details are retrieved from the database for
both the stack owner's project (the default
API path to the stack) and the stack domain project, subject to the
<code class="literal">policy.json</code> restrictions.</p></li></ol></div></div><p>This means there are now two paths that
can result in the same data being retrieved through the Orchestration API.
The following example is for resource-metadata:</p><div class="verbatim-wrap"><pre class="screen">GET v1/​{stack_owner_project_id}​/stacks/​{stack_name}​/\
​{stack_id}​/resources/​{resource_name}​/metadata</pre></div><p>or:</p><div class="verbatim-wrap"><pre class="screen">GET v1/​{stack_domain_project_id}​/stacks/​{stack_name}​/​\
{stack_id}​/resources/​{resource_name}​/metadata</pre></div><p>The stack owner uses the former (via <code class="literal">openstack stack resource metadata
STACK RESOURCE</code>), and any agents in the instance
use the latter.</p></div></div></div><div class="chapter " id="osadm-os-cli"><div class="titlepage"><div><div><h1 class="title"><span class="number">14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack command-line clients</span> <a title="Permalink" class="permalink" href="#osadm-os-cli">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>osadm-os-cli</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.16.3"><span class="number">14.1 </span><span class="name">Command-line client overview</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.4"><span class="number">14.2 </span><span class="name">Install the OpenStack command-line clients</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.5"><span class="number">14.3 </span><span class="name">Discover the version number for a client</span></a></span></dt><dt><span class="sect1"><a href="#sec-rcfile"><span class="number">14.4 </span><span class="name">Set environment variables using the OpenStack RC file</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.7"><span class="number">14.5 </span><span class="name">Manage projects, users, and roles</span></a></span></dt><dt><span class="sect1"><a href="#osadm-security-group"><span class="number">14.6 </span><span class="name">Manage project security</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.9"><span class="number">14.7 </span><span class="name">Manage services</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.10"><span class="number">14.8 </span><span class="name">Manage images</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.11"><span class="number">14.9 </span><span class="name">Manage volumes</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.12"><span class="number">14.10 </span><span class="name">Manage shares</span></a></span></dt><dt><span class="sect1"><a href="#osadm-manage-flavors-cmd"><span class="number">14.11 </span><span class="name">Manage flavors</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.14"><span class="number">14.12 </span><span class="name">Manage the OpenStack environment</span></a></span></dt><dt><span class="sect1"><a href="#manage-quotas"><span class="number">14.13 </span><span class="name">Manage quotas</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.16"><span class="number">14.14 </span><span class="name">Analyze log files</span></a></span></dt><dt><span class="sect1"><a href="#id-1.4.16.17"><span class="number">14.15 </span><span class="name">Manage Block Storage scheduling</span></a></span></dt></dl></div></div><div class="sect1 " id="id-1.4.16.3"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Command-line client overview</span> <a title="Permalink" class="permalink" href="#id-1.4.16.3">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>OpenStackClient project provides a unified command-line client, which
enables you to access the project API through easy-to-use commands.
Also, most OpenStack project provides a command-line client for each service.
For example, the Compute service provides a <code class="literal">nova</code> command-line client.</p><p>You can run the commands from the command line, or include the
commands within scripts to automate tasks. If you provide OpenStack
credentials, such as your user name and password, you can run these
commands on any computer.</p><p>Internally, each command uses cURL command-line tools, which embed API
requests. OpenStack APIs are RESTful APIs, and use the HTTP
protocol. They include methods, URIs, media types, and response codes.</p><p>OpenStack APIs are open-source Python clients, and can run on Linux or
Mac OS X systems. On some client commands, you can specify a debug
parameter to show the underlying API request for the command. This is
a good way to become familiar with the OpenStack API calls.</p><p>As a cloud end user, you can use the OpenStack Dashboard to provision
your own resources within the limits set by administrators. You can
modify the examples provided in this section to create other types and
sizes of server instances.</p><div class="sect2 " id="id-1.4.16.3.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Unified command-line client</span> <a title="Permalink" class="permalink" href="#id-1.4.16.3.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can use the unified <code class="literal">openstack</code> command (<span class="bold"><strong>python-openstackclient</strong></span>)
for the most of OpenStack services.
For more information, see <a class="link" href="http://docs.openstack.org/developer/python-openstackclient/" target="_blank">OpenStackClient document</a>.</p></div><div class="sect2 " id="id-1.4.16.3.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Individual command-line clients</span> <a title="Permalink" class="permalink" href="#id-1.4.16.3.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Unless the unified OpenStack Client (<span class="bold"><strong>python-openstackclient</strong></span>) is used,
the following table lists the command-line client for each OpenStack
service with its package name and description.</p><div class="table" id="id-1.4.16.3.8.3"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 14.1: </span><span class="name">OpenStack services and clients </span><a title="Permalink" class="permalink" href="#id-1.4.16.3.8.3">#</a></h6></div><div class="table-contents"><table class="table" summary="OpenStack services and clients" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                  <p>Service</p>
                </th><th>
                  <p>Client</p>
                </th><th>
                  <p>Package</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Application Catalog service</p>
                </td><td>
                  <p>murano</p>
                </td><td>
                  <p>python-muranoclient</p>
                </td><td>
                  <p>Creates and manages applications.</p>
                </td></tr><tr><td>
                  <p>Bare Metal service</p>
                </td><td>
                  <p>ironic</p>
                </td><td>
                  <p>python-ironicclient</p>
                </td><td>
                  <p>manages and provisions physical machines.</p>
                </td></tr><tr><td>
                  <p>Block Storage service</p>
                </td><td>
                  <p>cinder</p>
                </td><td>
                  <p>python-cinderclient</p>
                </td><td>
                  <p>Creates and manages volumes.</p>
                </td></tr><tr><td>
                  <p>Clustering service</p>
                </td><td>
                  <p>senlin</p>
                </td><td>
                  <p>python-senlinclient</p>
                </td><td>
                  <p>Creates and manages clustering services.</p>
                </td></tr><tr><td>
                  <p>Compute service</p>
                </td><td>
                  <p>nova</p>
                </td><td>
                  <p>python-novaclient</p>
                </td><td>
                  <p>Creates and manages images, instances, and flavors.</p>
                </td></tr><tr><td>
                  <p>Container Infrastructure Management service</p>
                </td><td>
                  <p>magnum</p>
                </td><td>
                  <p>python-magnumclient</p>
                </td><td>
                  <p>Creates and manages containers.</p>
                </td></tr><tr><td>
                  <p>Data Processing service</p>
                </td><td>
                  <p>sahara</p>
                </td><td>
                  <p>python-saharaclient</p>
                </td><td>
                  <p>Creates and manages Hadoop clusters on OpenStack.</p>
                </td></tr><tr><td>
                  <p>Database service</p>
                </td><td>
                  <p>trove</p>
                </td><td>
                  <p>python-troveclient</p>
                </td><td>
                  <p>Creates and manages databases.</p>
                </td></tr><tr><td>
                  <p>Deployment service</p>
                </td><td>
                  <p>fuel</p>
                </td><td>
                  <p>python-fuelclient</p>
                </td><td>
                  <p>Plans deployments.</p>
                </td></tr><tr><td>
                  <p>DNS service</p>
                </td><td>
                  <p>designate</p>
                </td><td>
                  <p>python-designateclient</p>
                </td><td>
                  <p>Creates and manages self service authoritative DNS.</p>
                </td></tr><tr><td>
                  <p>Image service</p>
                </td><td>
                  <p>glance</p>
                </td><td>
                  <p>python-glanceclient</p>
                </td><td>
                  <p>Creates and manages images.</p>
                </td></tr><tr><td>
                  <p>Key Manager service</p>
                </td><td>
                  <p>barbican</p>
                </td><td>
                  <p>python-barbicanclient</p>
                </td><td>
                  <p>Creates and manages keys.</p>
                </td></tr><tr><td>
                  <p>Monitoring</p>
                </td><td>
                  <p>monasca</p>
                </td><td>
                  <p>python-monascaclient</p>
                </td><td>
                  <p>Monitoring solution.</p>
                </td></tr><tr><td>
                  <p>Networking service</p>
                </td><td>
                  <p>neutron</p>
                </td><td>
                  <p>python-neutronclient</p>
                </td><td>
                  <p>Configures networks for guest servers.</p>
                </td></tr><tr><td>
                  <p>Object Storage service</p>
                </td><td>
                  <p>swift</p>
                </td><td>
                  <p>python-swiftclient</p>
                </td><td>
                  <p>Gathers statistics, lists items, updates metadata, and uploads,
downloads, and deletes files stored by the Object Storage service.
Gains access to an Object Storage installation for ad hoc processing.</p>
                </td></tr><tr><td>
                  <p>Orchestration service</p>
                </td><td>
                  <p>heat</p>
                </td><td>
                  <p>python-heatclient</p>
                </td><td>
                  <p>Launches stacks from templates, views details of running stacks
including events and resources, and updates and deletes stacks.</p>
                </td></tr><tr><td>
                  <p>Rating service</p>
                </td><td>
                  <p>cloudkitty</p>
                </td><td>
                  <p>python-cloudkittyclient</p>
                </td><td>
                  <p>Rating service.</p>
                </td></tr><tr><td>
                  <p>Shared File Systems service</p>
                </td><td>
                  <p>manila</p>
                </td><td>
                  <p>python-manilaclient</p>
                </td><td>
                  <p>Creates and manages shared file systems.</p>
                </td></tr><tr><td>
                  <p>Telemetry service</p>
                </td><td>
                  <p>ceilometer</p>
                </td><td>
                  <p>python-ceilometerclient</p>
                </td><td>
                  <p>Creates and collects measurements across OpenStack.</p>
                </td></tr><tr><td>
                  <p>Telemetry v3</p>
                </td><td>
                  <p>gnocchi</p>
                </td><td>
                  <p>python-gnocchiclient</p>
                </td><td>
                  <p>Creates and collects measurements across OpenStack.</p>
                </td></tr><tr><td>
                  <p>Workflow service</p>
                </td><td>
                  <p>mistral</p>
                </td><td>
                  <p>python-mistralclient</p>
                </td><td>
                  <p>Workflow service for OpenStack cloud.</p>
                </td></tr></tbody></table></div></div></div></div><div class="sect1 " id="id-1.4.16.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the OpenStack command-line clients</span> <a title="Permalink" class="permalink" href="#id-1.4.16.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Install the prerequisite software and the Python package for each
OpenStack client.</p><div class="sect2 " id="id-1.4.16.4.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the prerequisite software</span> <a title="Permalink" class="permalink" href="#id-1.4.16.4.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Most Linux distributions include packaged versions of the command-line
clients that you can install directly, see <a class="xref" href="#installing-from-packages" title="14.2.2.2. Installing from packages">Section 14.2.2.2, “Installing from packages”</a>.</p><p>If you need to install the source package for the command-line package,
the following table lists the software needed to run the
command-line clients, and provides installation instructions as needed.</p><div class="table" id="id-1.4.16.4.3.4"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 14.2: </span><span class="name">OpenStack command-line clients prerequisites </span><a title="Permalink" class="permalink" href="#id-1.4.16.4.3.4">#</a></h6></div><div class="table-contents"><table class="table" summary="OpenStack command-line clients prerequisites" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Prerequisite</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Python 2.7 or later</p>
                </td><td>
                  <p>Supports Python 2.7, 3.4, and 3.5.</p>
                </td></tr><tr><td>
                  <p>setuptools package</p>
                </td><td>
                  <p>Installed by default on Mac OS X.</p>
                  <p>Many Linux distributions provide packages to make setuptools
easy to install. Search your package manager for setuptools to
find an installation package.
If you cannot find one, download the setuptools package
directly from <a class="link" href="https://pypi.python.org/pypi/setuptools" target="_blank">https://pypi.python.org/pypi/setuptools</a>.</p>
                  <p>The recommended way to install setuptools on Microsoft Windows
is to follow the documentation provided on the setuptools website
(<a class="link" href="https://pypi.python.org/pypi/setuptools" target="_blank">https://pypi.python.org/pypi/setuptools</a>).</p>
                  <p>Another option is to use the unofficial binary installer
maintained by Christoph Gohlke
(<a class="link" href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#setuptools" target="_blank">http://www.lfd.uci.edu/~gohlke/pythonlibs/#setuptools</a>).</p>
                </td></tr><tr><td>
                  <p>pip package</p>
                </td><td>
                  <p>To install the clients on a Linux, Mac OS X, or Microsoft Windows
system, use pip. It is easy to use, ensures that you get the latest
version of the clients from the <a class="link" href="https://pypi.python.org/" target="_blank">Python Package Index</a>, and lets you update or remove
the packages later on.</p>
                  <p>Since the installation process compiles source files, this requires
the related Python development package for your operating system
and distribution.</p>
                  <p>Install pip through the package manager for your system:</p>
                  <p>
                    <span class="bold"><strong>MacOS</strong></span>
                  </p>
                  <div class="verbatim-wrap"><pre class="screen"># easy_install pip</pre></div>
                  <p>
                    <span class="bold"><strong>Microsoft Windows</strong></span>
                  </p>
                  <p>Ensure that the <code class="literal">C:\Python27\Scripts</code> directory is defined in the
<code class="literal">PATH</code> environment variable, and use the <code class="literal">easy_install</code> command
from the setuptools package:</p>
                  <div class="verbatim-wrap"><pre class="screen">C:\&gt;easy_install pip</pre></div>
                  <p>Another option is to use the unofficial binary installer provided by
Christoph Gohlke (<a class="link" href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip" target="_blank">http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip</a>).</p>
                  <p>
                    <span class="bold"><strong>Ubuntu or Debian</strong></span>
                  </p>
                  <div class="verbatim-wrap"><pre class="screen"># apt install python-dev python-pip</pre></div>
                  <p>Note that extra dependencies may be required, per operating system,
depending on the package being installed, such as is the case with
Tempest.</p>
                  <p>
                    <span class="bold"><strong>Red Hat Enterprise Linux, CentOS, or Fedora</strong></span>
                  </p>
                  <p>A packaged version enables you to use yum to install the package:</p>
                  <div class="verbatim-wrap"><pre class="screen"># yum install python-devel python-pip</pre></div>
                  <p>There are also packaged versions of the clients available in
<a class="link" href="https://www.rdoproject.org/" target="_blank">RDO</a> that enable yum to install
the clients as described in <a class="xref" href="#installing-from-packages" title="14.2.2.2. Installing from packages">Section 14.2.2.2, “Installing from packages”</a>.</p>
                  <p>
                    <span class="bold"><strong>SUSE Linux Enterprise Server</strong></span>
                  </p>
                  <p>A packaged version available in <a class="link" href="https://build.opensuse.org/package/show?package=python-pip&amp;project=Cloud:OpenStack:Master" target="_blank">the Open Build Service</a>
enables you to use YaST or zypper to install the package.</p>
                  <p>First, add the Open Build Service repository:</p>
                  <div class="verbatim-wrap"><pre class="screen"># zypper addrepo -f obs://Cloud:OpenStack:Mitaka/SLE_12_SP1 Mitaka</pre></div>
                  <p>Then install pip and use it to manage client installation:</p>
                  <div class="verbatim-wrap"><pre class="screen"># zypper install python-devel python-pip</pre></div>
                  <p>There are also packaged versions of the clients available that enable
zypper to install the clients as described in <a class="xref" href="#installing-from-packages" title="14.2.2.2. Installing from packages">Section 14.2.2.2, “Installing from packages”</a>.</p>
                  <p>
                    <span class="bold"><strong>openSUSE</strong></span>
                  </p>
                  <p>You can install pip and use it to manage client installation:</p>
                  <div class="verbatim-wrap"><pre class="screen"># zypper install python-devel python-pip</pre></div>
                  <p>There are also packaged versions of the clients available that enable
zypper to install the clients as described in <a class="xref" href="#installing-from-packages" title="14.2.2.2. Installing from packages">Section 14.2.2.2, “Installing from packages”</a>.</p>
                </td></tr></tbody></table></div></div></div><div class="sect2 " id="id-1.4.16.4.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the OpenStack client</span> <a title="Permalink" class="permalink" href="#id-1.4.16.4.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following example shows the command for installing the OpenStack client
with <code class="literal">pip</code>, which supports multiple services.</p><div class="verbatim-wrap"><pre class="screen"># pip install python-openstackclient</pre></div><p>The following individual clients are deprecated in favor of a common client.
Instead of installing and learning all these clients, we recommend
installing and using the OpenStack client. You may need to install an
individual project's client because coverage is not yet sufficient in the
OpenStack client. If you need to install an individual client's project,
replace the <code class="literal">PROJECT</code> name in this <code class="literal">pip install</code> command using the
list below.</p><div class="verbatim-wrap"><pre class="screen"># pip install python-PROJECTclient</pre></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">barbican</code> - Key Manager Service API</p></li><li class="listitem "><p><code class="literal">ceilometer</code> - Telemetry API</p></li><li class="listitem "><p><code class="literal">cinder</code> - Block Storage API and extensions</p></li><li class="listitem "><p><code class="literal">cloudkitty</code> - Rating service API</p></li><li class="listitem "><p><code class="literal">designate</code> - DNS service API</p></li><li class="listitem "><p><code class="literal">fuel</code> - Deployment service API</p></li><li class="listitem "><p><code class="literal">glance</code> - Image service API</p></li><li class="listitem "><p><code class="literal">gnocchi</code> - Telemetry API v3</p></li><li class="listitem "><p><code class="literal">heat</code> - Orchestration API</p></li><li class="listitem "><p><code class="literal">magnum</code> - Container Infrastructure Management service API</p></li><li class="listitem "><p><code class="literal">manila</code> - Shared file systems API</p></li><li class="listitem "><p><code class="literal">mistral</code> - Workflow service API</p></li><li class="listitem "><p><code class="literal">monasca</code> - Monitoring API</p></li><li class="listitem "><p><code class="literal">murano</code> - Application catalog API</p></li><li class="listitem "><p><code class="literal">neutron</code> - Networking API</p></li><li class="listitem "><p><code class="literal">nova</code> - Compute API and extensions</p></li><li class="listitem "><p><code class="literal">sahara</code> - Data Processing API</p></li><li class="listitem "><p><code class="literal">senlin</code> - Clustering service API</p></li><li class="listitem "><p><code class="literal">swift</code> - Object Storage API</p></li><li class="listitem "><p><code class="literal">trove</code> - Database service API</p></li></ul></div><div class="sect3 " id="id-1.4.16.4.4.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.2.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing with pip</span> <a title="Permalink" class="permalink" href="#id-1.4.16.4.4.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use pip to install the OpenStack clients on a Linux, Mac OS X, or
Microsoft Windows system. It is easy to use and ensures that you get the
latest version of the client from the <a class="link" href="https://pypi.python.org/pypi" target="_blank">Python Package
Index</a>. Also, pip enables you to update
or remove a package.</p><p>Install each client separately by using the following command:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>For Mac OS X or Linux:</p><div class="verbatim-wrap"><pre class="screen"># pip install python-PROJECTclient</pre></div></li><li class="listitem "><p>For Microsoft Windows:</p><div class="verbatim-wrap"><pre class="screen">C:\&gt;pip install python-PROJECTclient</pre></div></li></ul></div></div><div class="sect3 " id="installing-from-packages"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.2.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing from packages</span> <a title="Permalink" class="permalink" href="#installing-from-packages">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>installing-from-packages</li></ul></div></div></div></div><p>RDO, openSUSE, SUSE Linux Enterprise, Debian, and Ubuntu have client packages
that can be installed without <code class="literal">pip</code>.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>On Red Hat Enterprise Linux, CentOS, or Fedora, use <code class="literal">yum</code> to install
the clients from the packaged versions available in
<a class="link" href="https://www.rdoproject.org/" target="_blank">RDO</a>:</p><div class="verbatim-wrap"><pre class="screen"># yum install python-PROJECTclient</pre></div></li><li class="listitem "><p>For Ubuntu or Debian, use <code class="literal">apt-get</code> to install the clients from the
packaged versions:</p><div class="verbatim-wrap"><pre class="screen"># apt-get install python-PROJECTclient</pre></div></li><li class="listitem "><p>For openSUSE, use <code class="literal">zypper</code> to install the clients from the distribution
packages service:</p><div class="verbatim-wrap"><pre class="screen"># zypper install python-PROJECTclient</pre></div></li><li class="listitem "><p>For SUSE Linux Enterprise Server, use <code class="literal">zypper</code> to install the clients from
the distribution packages in the Open Build Service. First, add the Open
Build Service repository:</p><div class="verbatim-wrap"><pre class="screen"># zypper addrepo -f obs://Cloud:OpenStack:Mitaka/SLE_12_SP1 Mitaka</pre></div><p>Then you can install the packages:</p><div class="verbatim-wrap"><pre class="screen"># zypper install python-PROJECTclient</pre></div></li></ul></div></div></div><div class="sect2 " id="id-1.4.16.4.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upgrade or remove clients</span> <a title="Permalink" class="permalink" href="#id-1.4.16.4.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To upgrade a client, add the <code class="literal">--upgrade</code> option to the
<code class="command">pip install</code> command:</p><div class="verbatim-wrap"><pre class="screen"># pip install --upgrade python-PROJECTclient</pre></div><p>To remove the client, run the <code class="command">pip uninstall</code> command:</p><div class="verbatim-wrap"><pre class="screen"># pip uninstall python-PROJECTclient</pre></div></div><div class="sect2 " id="id-1.4.16.4.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">What's next</span> <a title="Permalink" class="permalink" href="#id-1.4.16.4.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Before you can run client commands, you must create and source the
<code class="literal">PROJECT-openrc.sh</code> file to set environment variables. See
 <a class="xref" href="#sec-rcfile" title="14.4. Set environment variables using the OpenStack RC file">Section 14.4, “Set environment variables using the OpenStack RC file”</a>.</p></div></div><div class="sect1 " id="id-1.4.16.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Discover the version number for a client</span> <a title="Permalink" class="permalink" href="#id-1.4.16.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Run the following command to discover the version number for a client:</p><div class="verbatim-wrap"><pre class="screen">$ PROJECT --version</pre></div><p>For example, to see the version number for the <code class="literal">openstack</code> client,
run the following command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --version
openstack 3.2.0</pre></div></div><div class="sect1 " id="sec-rcfile"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Set environment variables using the OpenStack RC file</span> <a title="Permalink" class="permalink" href="#sec-rcfile">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>sec-rcfile</li></ul></div></div></div></div><p>To set the required environment variables for the OpenStack command-line
clients, you must create an environment file called an OpenStack rc
file, or <code class="literal">openrc.sh</code> file. If your OpenStack installation provides
it, you can download the file from the OpenStack Dashboard as an
administrative user or any other user. This project-specific environment
file contains the credentials that all OpenStack services use.</p><p>When you source the file, environment variables are set for your current
shell. The variables enable the OpenStack client commands to communicate
with the OpenStack services that run in the cloud.</p><div id="id-1.4.16.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Defining environment variables using an environment file is not a
common practice on Microsoft Windows. Environment variables are
usually defined in the <span class="guimenu ">Advanced</span> › <span class="guimenu ">System Properties</span>
dialog box. One method for using these scripts as-is on Windows is
to install <a class="link" href="https://git-for-windows.github.io/" target="_blank">Git for Windows</a> and using Git Bash to source the environment
variables and to run all CLI commands.</p></div><div class="sect2 " id="id-1.4.16.6.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Download and source the OpenStack RC file</span> <a title="Permalink" class="permalink" href="#id-1.4.16.6.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard and from the drop-down list select the project
for which you want to download the OpenStack RC file.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
click <span class="guimenu ">Access &amp; Security</span>.</p></li><li class="step "><p>On the <span class="guimenu ">API Access</span> tab, click <span class="guimenu ">Download OpenStack
RC File</span> and save the file. The filename will be of the form
<code class="literal">PROJECT-openrc.sh</code> where <code class="literal">PROJECT</code> is the name of the project for
which you downloaded the file.</p></li><li class="step "><p>Copy the <code class="literal">PROJECT-openrc.sh</code> file to the computer from which you
want to run OpenStack commands.</p><p>For example, copy the file to the computer from which you want to upload
an image with a <code class="literal">glance</code> client command.</p></li><li class="step "><p>On any shell from which you want to run OpenStack commands, source the
<code class="literal">PROJECT-openrc.sh</code> file for the respective project.</p><p>In the following example, the <code class="literal">demo-openrc.sh</code> file is sourced for
the demo project:</p><div class="verbatim-wrap"><pre class="screen">$ . demo-openrc.sh</pre></div></li><li class="step "><p>When you are prompted for an OpenStack password, enter the password for
the user who downloaded the <code class="literal">PROJECT-openrc.sh</code> file.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.6.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and source the OpenStack RC file</span> <a title="Permalink" class="permalink" href="#id-1.4.16.6.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Alternatively, you can create the <code class="literal">PROJECT-openrc.sh</code> file from
scratch, if you cannot download the file from the dashboard.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>In a text editor, create a file named <code class="literal">PROJECT-openrc.sh</code> and add
the following authentication information:</p><div class="verbatim-wrap highlight bash"><pre class="screen">export OS_USERNAME=username
export OS_PASSWORD=password
export OS_TENANT_NAME=projectName
export OS_AUTH_URL=https://identityHost:portNumber/v2.0
# The following lines can be omitted
export OS_TENANT_ID=tenantIDString
export OS_REGION_NAME=regionName
export OS_CACERT=/path/to/cacertFile</pre></div><div id="id-1.4.16.6.6.3.1.3" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Saving <code class="literal">OS_PASSWORD</code> in plain text may bring a security risk.
You should protect the file or not save <code class="literal">OS_PASSWORD</code> into
the file in the production environment.</p></div></li><li class="step "><p>On any shell from which you want to run OpenStack commands, source the
<code class="literal">PROJECT-openrc.sh</code> file for the respective project. In this
example, you source the <code class="literal">admin-openrc.sh</code> file for the admin
project:</p><div class="verbatim-wrap"><pre class="screen">$ . admin-openrc.sh</pre></div></li></ol></div></div><div id="id-1.4.16.6.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You are not prompted for the password with this method. The password
lives in clear text format in the <code class="literal">PROJECT-openrc.sh</code> file.
Restrict the permissions on this file to avoid security problems.
You can also remove the <code class="literal">OS_PASSWORD</code> variable from the file, and
use the <code class="literal">--password</code> parameter with OpenStack client commands
instead.</p></div><div id="id-1.4.16.6.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You must set the <code class="literal">OS_CACERT</code> environment variable when using the
https protocol in the <code class="literal">OS_AUTH_URL</code> environment setting because
the verification process for the TLS (HTTPS) server certificate uses
the one indicated in the environment. This certificate will be used
when verifying the TLS (HTTPS) server certificate.</p></div></div><div class="sect2 " id="id-1.4.16.6.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Override environment variable values</span> <a title="Permalink" class="permalink" href="#id-1.4.16.6.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you run OpenStack client commands, you can override some
environment variable settings by using the options that are listed at
the end of the <code class="literal">help</code> output of the various client commands. For
example, you can override the <code class="literal">OS_PASSWORD</code> setting in the
<code class="literal">PROJECT-openrc.sh</code> file by specifying a password on a
<code class="command">openstack</code> command, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-password PASSWORD server list</pre></div><p>Where <code class="literal">PASSWORD</code> is your password.</p><p>A user specifies their username and password credentials to interact
with OpenStack, using any client command. These credentials can be
specified using various mechanisms, namely, the environment variable
or command-line argument. It is not safe to specify the password using
either of these methods.</p><p>For example, when you specify your password using the command-line
client with the <code class="literal">--os-password</code> argument, anyone with access to your
computer can view it in plain text with the <code class="literal">ps</code> field.</p><p>To avoid storing the password in plain text, you can prompt for the
OpenStack password interactively.</p></div></div><div class="sect1 " id="id-1.4.16.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage projects, users, and roles</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrator, you manage projects, users, and
roles. Projects are organizational units in the cloud to which
you can assign users. Projects are also known as <span class="emphasis"><em>projects</em></span> or
<span class="emphasis"><em>accounts</em></span>. Users can be members of one or more projects. Roles
define which actions users can perform. You assign roles to
user-project pairs.</p><p>You can define actions for OpenStack service roles in the
<code class="literal">/etc/PROJECT/policy.json</code> files. For example, define actions for
Compute service roles in the <code class="literal">/etc/nova/policy.json</code> file.</p><p>You can manage projects, users, and roles independently from each other.</p><p>During cloud set up, the operator defines at least one project, user,
and role.</p><p>You can add, update, and delete projects and users, assign users to
one or more projects, and change or remove the assignment. To enable or
temporarily disable a project or user, update that project or user.
You can also change quotas at the project level.</p><p>Before you can delete a user account, you must remove the user account
from its primary project.</p><p>Before you can run client commands, you must download and
source an OpenStack RC file. See <a class="link" href="http://docs.openstack.org/user-guide/common/cli-set-environment-variables-using-openstack-rc.html#download-and-source-the-openstack-rc-file" target="_blank">Download and source the OpenStack RC file</a>.</p><div class="sect2 " id="id-1.4.16.7.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Projects</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A project is a group of zero or more users. In Compute, a project owns
virtual machines. In Object Storage, a project owns containers. Users
can be associated with more than one project. Each project and user
pairing can have a role associated with it.</p><div class="sect3 " id="id-1.4.16.7.9.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List projects</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.9.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>List all projects with their ID, name, and whether they are
enabled or disabled:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| f7ac731cc11f40efbc03a9f9e1d1d21f | admin              |
| c150ab41f0d9443f8874e32e725a4cc8 | alt_demo           |
| a9debfe41a6d4d09a677da737b907d5e | demo               |
| 9208739195a34c628c58c95d157917d7 | invisible_to_admin |
| 3943a53dc92a49b2827fae94363851e1 | service            |
| 80cab5e1f02045abad92a2864cfd76cb | test_project       |
+----------------------------------+--------------------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.9.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a project</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.9.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Create a project named <code class="literal">new-project</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project create --description 'my new project' new-project \
  --domain default
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | my new project                   |
| domain_id   | e601210181f54843b51b3edff41d4980 |
| enabled     | True                             |
| id          | 1a4a0618b306462c9830f876b0bd6af2 |
| is_domain   | False                            |
| name        | new-project                      |
| parent_id   | e601210181f54843b51b3edff41d4980 |
+-------------+----------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.9.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update a project</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.9.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Specify the project ID to update a project. You can update the name,
description, and enabled status of a project.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To temporarily disable a project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project set PROJECT_ID --disable</pre></div></li><li class="listitem "><p>To enable a disabled project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project set PROJECT_ID --enable</pre></div></li><li class="listitem "><p>To update the name of a project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project set PROJECT_ID --name project-new</pre></div></li><li class="listitem "><p>To verify your changes, show information for the updated project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project show PROJECT_ID
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | my new project                   |
| enabled     | True                             |
| id          | 0b0b995694234521bf93c792ed44247f |
| name        | new-project                      |
| properties  |                                  |
+-------------+----------------------------------+</pre></div></li></ul></div></div><div class="sect3 " id="id-1.4.16.7.9.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a project</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.9.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Specify the project ID to delete a project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project delete PROJECT_ID</pre></div></div></div><div class="sect2 " id="id-1.4.16.7.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Users</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.16.7.10.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List users</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.10.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>List all users:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user list
+----------------------------------+----------+
| ID                               | Name     |
+----------------------------------+----------+
| 352b37f5c89144d4ad0534139266d51f | admin    |
| 86c0de739bcb4802b8dc786921355813 | demo     |
| 32ec34aae8ea432e8af560a1cec0e881 | glance   |
| 7047fcb7908e420cb36e13bbd72c972c | nova     |
+----------------------------------+----------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.10.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.10.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create a user, you must specify a name. Optionally, you can
specify a project ID, password, and email address. It is recommended
that you include the project ID and password because the user cannot
log in to the dashboard without this information.</p><p>Create the <code class="literal">new-user</code> user:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user create --project new-project --password PASSWORD new-user
+------------+----------------------------------+
| Field      | Value                            |
+------------+----------------------------------+
| email      | None                             |
| enabled    | True                             |
| id         | 6322872d9c7e445dbbb49c1f9ca28adc |
| name       | new-user                         |
| project_id | 0b0b995694234521bf93c792ed44247f |
| username   | new-user                         |
+------------+----------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.10.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update a user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.10.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can update the name, email address, and enabled status for a user.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To temporarily disable a user account:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user set USER_NAME --disable</pre></div><p>If you disable a user account, the user cannot log in to the
dashboard. However, data for the user account is maintained, so you
can enable the user at any time.</p></li><li class="listitem "><p>To enable a disabled user account:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user set USER_NAME --enable</pre></div></li><li class="listitem "><p>To change the name and description for a user account:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user set USER_NAME --name user-new --email new-user@example.com
User has been updated.</pre></div></li></ul></div></div><div class="sect3 " id="id-1.4.16.7.10.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.10.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Delete a specified user account:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user delete USER_NAME</pre></div></div></div><div class="sect2 " id="id-1.4.16.7.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Roles and role assignments</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect3 " id="id-1.4.16.7.11.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List available roles</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.11.2">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>List the available roles:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role list
+----------------------------------+---------------+
| ID                               | Name          |
+----------------------------------+---------------+
| 71ccc37d41c8491c975ae72676db687f | Member        |
| 149f50a1fe684bfa88dae76a48d26ef7 | ResellerAdmin |
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_      |
| 6ecf391421604da985db2f141e46a7c8 | admin         |
| deb4fffd123c4d02a907c2c74559dccf | anotherrole   |
+----------------------------------+---------------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.11.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a role</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.11.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Users can be members of multiple projects. To assign users to multiple
projects, define a role and assign that role to a user-project pair.</p><p>Create the <code class="literal">new-role</code> role:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role create new-role
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | a34425c884c74c8881496dc2c2e84ffc |
| name      | new-role                         |
+-----------+----------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.11.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Assign a role</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.11.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To assign a user to a project, you must assign the role to a
user-project pair. To do this, you need the user, role, and project
IDs.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List users and note the user ID you want to assign to the role:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user list
+----------------------------------+----------+
| ID                               | Name     |
+----------------------------------+----------+
| 6ab5800949644c3e8fb86aaeab8275c8 | admin    |
| dfc484b9094f4390b9c51aba49a6df34 | demo     |
| 55389ff02f5e40cf85a053cc1cacb20c | alt_demo |
| bc52bcfd882f4d388485451c4a29f8e0 | nova     |
| 255388ffa6e54ec991f584cb03085e77 | glance   |
| 48b6e6dec364428da89ba67b654fac03 | cinder   |
| c094dd5a8e1d4010832c249d39541316 | neutron  |
| 6322872d9c7e445dbbb49c1f9ca28adc | new-user |
+----------------------------------+----------+</pre></div></li><li class="step "><p>List role IDs and note the role ID you want to assign:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role list
+----------------------------------+---------------+
| ID                               | Name          |
+----------------------------------+---------------+
| 71ccc37d41c8491c975ae72676db687f | Member        |
| 149f50a1fe684bfa88dae76a48d26ef7 | ResellerAdmin |
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_      |
| 6ecf391421604da985db2f141e46a7c8 | admin         |
| deb4fffd123c4d02a907c2c74559dccf | anotherrole   |
| bef1f95537914b1295da6aa038ef4de6 | new-role      |
+----------------------------------+---------------+</pre></div></li><li class="step "><p>List projects and note the project ID you want to assign to the role:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project list
+----------------------------------+--------------------+
| ID                               | Name               |
+----------------------------------+--------------------+
| 0b0b995694234521bf93c792ed44247f | new-project        |
| 29c09e68e6f741afa952a837e29c700b | admin              |
| 3a7ab11d3be74d3c9df3ede538840966 | invisible_to_admin |
| 71a2c23bab884c609774c2db6fcee3d0 | service            |
| 87e48a8394e34d13afc2646bc85a0d8c | alt_demo           |
| fef7ae86615f4bf5a37c1196d09bcb95 | demo               |
+----------------------------------+--------------------+</pre></div></li><li class="step "><p>Assign a role to a user-project pair:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role add --user USER_NAME --project TENANT_ID ROLE_NAME</pre></div><p>For example, assign the <code class="literal">new-role</code> role to the <code class="literal">demo</code> and
<code class="literal">test-project</code> pair:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role add --user demo --project test-project new-role</pre></div></li><li class="step "><p>Verify the role assignment:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role list --user USER_NAME --project TENANT_ID
Listing assignments using role list is deprecated as of the Newton release. Use role assignment list --user &lt;user-name&gt; --project &lt;project-name&gt; --names instead.
+----------------------------------+-------------+---------+------+
| ID                               | Name        | Project | User |
+----------------------------------+-------------+---------+------+
| a34425c884c74c8881496dc2c2e84ffc | new-role    | demo    | demo |
| 04a7e3192c0745a2b1e3d2baf5a3ee0f | Member      | demo    | demo |
| 62bcf3e27eef4f648eb72d1f9920f6e5 | anotherrole | demo    | demo |
+----------------------------------+-------------+---------+------+</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.16.7.11.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View role details</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.11.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>View details for a specified role:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role show ROLE_NAME
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| domain_id | None                             |
| id        | a34425c884c74c8881496dc2c2e84ffc |
| name      | new-role                         |
+-----------+----------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.16.7.11.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.5.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Remove a role</span> <a title="Permalink" class="permalink" href="#id-1.4.16.7.11.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Remove a role from a user-project pair:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Run the <code class="command">openstack role remove</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role remove --user USER_NAME --project TENANT_ID ROLE_NAME</pre></div></li><li class="step "><p>Verify the role removal:</p><div class="verbatim-wrap"><pre class="screen">$ openstack role list --user USER_NAME --project TENANT_ID</pre></div><p>If the role was removed, the command output omits the removed role.</p></li></ol></div></div></div></div></div><div class="sect1 " id="osadm-security-group"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage project security</span> <a title="Permalink" class="permalink" href="#osadm-security-group">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>osadm-security-group</li></ul></div></div></div></div><p>Security groups are sets of IP filter rules that are applied to all
project instances, which define networking access to the instance. Group
rules are project specific; project members can edit the default rules
for their group and add new rule sets.</p><p>All projects have a <code class="literal">default</code> security group which is applied to any
instance that has no other defined security group. Unless you change the
default, this security group denies all incoming traffic and allows only
outgoing traffic to your instance.</p><p>You can use the <code class="literal">allow_same_net_traffic</code> option in the
<code class="literal">/etc/nova/nova.conf</code> file to globally control whether the rules apply
to hosts which share a network.</p><p>If set to:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">True</code> (default), hosts on the same subnet are not filtered and are
allowed to pass all types of traffic between them. On a flat network,
this allows all instances from all projects unfiltered communication.
With VLAN networking, this allows access between instances within the
same project. You can also simulate this setting by configuring the
default security group to allow all traffic from the subnet.</p></li><li class="listitem "><p><code class="literal">False</code>, security groups are enforced for all connections.</p></li></ul></div><p>Additionally, the number of maximum rules per security group is
controlled by the <code class="literal">security_group_rules</code> and the number of allowed
security groups per project is controlled by the <code class="literal">security_groups</code>
quota (see <a class="xref" href="#manage-quotas" title="14.13. Manage quotas">Section 14.13, “Manage quotas”</a>).</p><div class="sect2 " id="id-1.4.16.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List and view current security groups</span> <a title="Permalink" class="permalink" href="#id-1.4.16.8.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>From the command-line you can get a list of security groups for the
project, using the <code class="command">openstack</code> and <code class="command">nova</code> commands:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Ensure your system variables are set for the user and project for
which you are checking security group rules. For example:</p><div class="verbatim-wrap"><pre class="screen">export OS_USERNAME=demo00
export OS_TENANT_NAME=tenant01</pre></div></li><li class="step "><p>Output security groups, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group list
+--------------------------------------+---------+-------------+
| Id                                   | Name    | Description |
+--------------------------------------+---------+-------------+
| 73580272-d8fa-4927-bd55-c85e43bc4877 | default | default     |
| 6777138a-deb7-4f10-8236-6400e7aff5b0 | open    | all ports   |
+--------------------------------------+---------+-------------+</pre></div></li><li class="step "><p>View the details of a group, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule list GROUPNAME</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule list open
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| ID                                   | IP Protocol | IP Range  | Port Range      | Remote Security Group |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| 353d0611-3f67-4848-8222-a92adbdb5d3a | udp         | 0.0.0.0/0 | 1:65535         | None                  |
| 63536865-e5b6-4df1-bac5-ca6d97d8f54d | tcp         | 0.0.0.0/0 | 1:65535         | None                  |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+</pre></div><p>These rules are allow type rules as the default is deny. The first
column is the IP protocol (one of icmp, tcp, or udp). The second and
third columns specify the affected port range. The third column
specifies the IP range in CIDR format. This example shows the full
port range for all protocols allowed from all IPs.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.8.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a security group</span> <a title="Permalink" class="permalink" href="#id-1.4.16.8.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When adding a new security group, you should pick a descriptive but
brief name. This name shows up in brief descriptions of the instances
that use it where the longer description field often does not. For
example, seeing that an instance is using security group "http" is much
easier to understand than "bobs_group" or "secgrp1".</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Ensure your system variables are set for the user and project for
which you are creating security group rules.</p></li><li class="step "><p>Add the new security group, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group create GroupName --description Description</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group create global_http --description "Allows Web traffic anywhere on the Internet."
+-----------------+--------------------------------------------------------------------------------------------------------------------------+
| Field           | Value                                                                                                                    |
+-----------------+--------------------------------------------------------------------------------------------------------------------------+
| created_at      | 2016-11-03T13:50:53Z                                                                                                     |
| description     | Allows Web traffic anywhere on the Internet.                                                                             |
| headers         |                                                                                                                          |
| id              | c0b92b20-4575-432a-b4a9-eaf2ad53f696                                                                                     |
| name            | global_http                                                                                                              |
| project_id      | 5669caad86a04256994cdf755df4d3c1                                                                                         |
| project_id      | 5669caad86a04256994cdf755df4d3c1                                                                                         |
| revision_number | 1                                                                                                                        |
| rules           | created_at='2016-11-03T13:50:53Z', direction='egress', ethertype='IPv4', id="4d8cec94-e0ee-4c20-9f56-8fb67c21e4df",      |
|                 | project_id='5669caad86a04256994cdf755df4d3c1', revision_number='1', updated_at='2016-11-03T13:50:53Z'                    |
|                 | created_at='2016-11-03T13:50:53Z', direction='egress', ethertype='IPv6', id="31be2ad1-be14-4aef-9492-ecebede2cf12",      |
|                 | project_id='5669caad86a04256994cdf755df4d3c1', revision_number='1', updated_at='2016-11-03T13:50:53Z'                    |
| updated_at      | 2016-11-03T13:50:53Z                                                                                                     |
+-----------------+--------------------------------------------------------------------------------------------------------------------------+</pre></div></li><li class="step "><p>Add a new group rule, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create SEC_GROUP_NAME --protocol PROTOCOL --dst-port FROM_PORT:TO_PORT --remote-ip CIDR</pre></div><p>The arguments are positional, and the <code class="literal">from-port</code> and <code class="literal">to-port</code>
arguments specify the local port range connections are allowed to
access, not the source and destination ports of the connection. For
example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create global_http --protocol tcp --dst-port 80:80 --remote-ip 0.0.0.0/0
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| created_at        | 2016-11-06T14:02:00Z                 |
| description       |                                      |
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| headers           |                                      |
| id                | 2ba06233-d5c8-43eb-93a9-8eaa94bc9eb5 |
| port_range_max    | 80                                   |
| port_range_min    | 80                                   |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| protocol          | tcp                                  |
| remote_group_id   | None                                 |
| remote_ip_prefix  | 0.0.0.0/0                            |
| revision_number   | 1                                    |
| security_group_id | c0b92b20-4575-432a-b4a9-eaf2ad53f696 |
| updated_at        | 2016-11-06T14:02:00Z                 |
+-------------------+--------------------------------------+</pre></div><p>You can create complex rule sets by creating additional rules. For
example, if you want to pass both HTTP and HTTPS traffic, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create global_http --protocol tcp --dst-port 443:443 --remote-ip 0.0.0.0/0
+-------------------+--------------------------------------+
| Field             | Value                                |
+-------------------+--------------------------------------+
| created_at        | 2016-11-06T14:09:20Z                 |
| description       |                                      |
| direction         | ingress                              |
| ethertype         | IPv4                                 |
| headers           |                                      |
| id                | 821c3ef6-9b21-426b-be5b-c8a94c2a839c |
| port_range_max    | 443                                  |
| port_range_min    | 443                                  |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| project_id        | 5669caad86a04256994cdf755df4d3c1     |
| protocol          | tcp                                  |
| remote_group_id   | None                                 |
| remote_ip_prefix  | 0.0.0.0/0                            |
| revision_number   | 1                                    |
| security_group_id | c0b92b20-4575-432a-b4a9-eaf2ad53f696 |
| updated_at        | 2016-11-06T14:09:20Z                 |
+-------------------+--------------------------------------+</pre></div><p>Despite only outputting the newly added rule, this operation is
additive (both rules are created and enforced).</p></li><li class="step "><p>View all rules for the new security group, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule list global_http
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| ID                                   | IP Protocol | IP Range  | Port Range      | Remote Security Group |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+
| 353d0611-3f67-4848-8222-a92adbdb5d3a | tcp         | 0.0.0.0/0 | 80:80           | None                  |
| 63536865-e5b6-4df1-bac5-ca6d97d8f54d | tcp         | 0.0.0.0/0 | 443:443         | None                  |
+--------------------------------------+-------------+-----------+-----------------+-----------------------+</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.8.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a security group</span> <a title="Permalink" class="permalink" href="#id-1.4.16.8.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Ensure your system variables are set for the user and project for
which you are deleting a security group.</p></li><li class="step "><p>Delete the new security group, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group delete GROUPNAME</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group delete global_http</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.8.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create security group rules for a cluster of instances</span> <a title="Permalink" class="permalink" href="#id-1.4.16.8.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Source Groups are a special, dynamic way of defining the CIDR of allowed
sources. The user specifies a Source Group (Security Group name), and
all the user's other Instances using the specified Source Group are
selected dynamically. This alleviates the need for individual rules to
allow each new member of the cluster.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Make sure to set the system variables for the user and project for
which you are creating a security group rule.</p></li><li class="step "><p>Add a source group, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create secGroupName --remote-group source-group \
    --protocol ip-protocol --dst-port from-port:to-port</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack security group rule create cluster --remote-group global_http \
    --protocol tcp --dst-port 22:22</pre></div><p>The <code class="literal">cluster</code> rule allows SSH access from any other instance that
uses the <code class="literal">global_http</code> group.</p></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.16.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage services</span> <a title="Permalink" class="permalink" href="#id-1.4.16.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2 " id="id-1.4.16.9.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage services and service users</span> <a title="Permalink" class="permalink" href="#id-1.4.16.9.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Identity service enables you to define services, as
follows:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Service catalog template. The Identity service acts
as a service catalog of endpoints for other OpenStack
services. The <code class="literal">/etc/keystone/default_catalog.templates</code>
template file defines the endpoints for services. When
the Identity service uses a template file back end,
any changes that are made to the endpoints are cached.
These changes do not persist when you restart the
service or reboot the machine.</p></li><li class="listitem "><p>An SQL back end for the catalog service. When the
Identity service is online, you must add the services
to the catalog. When you deploy a system for
production, use the SQL back end.</p></li></ul></div><p>The <code class="literal">auth_token</code> middleware supports the
use of either a shared secret or users for each
service.</p><p>To authenticate users against the Identity service, you must
create a service user for each OpenStack service. For example,
create a service user for the Compute, Block Storage, and
Networking services.</p><p>To configure the OpenStack services with service users,
create a project for all services and create users for each
service. Assign the admin role to each service user and
project pair. This role enables users to validate tokens and
authenticate and authorize other user requests.</p><div class="sect3 " id="id-1.4.16.9.2.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.7.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a service</span> <a title="Permalink" class="permalink" href="#id-1.4.16.9.2.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List the available services:</p><div class="verbatim-wrap"><pre class="screen">$ openstack service list
+----------------------------------+----------+------------+
| ID                               | Name     | Type       |
+----------------------------------+----------+------------+
| 9816f1faaa7c4842b90fb4821cd09223 | cinder   | volume     |
| 1250f64f31e34dcd9a93d35a075ddbe1 | cinderv2 | volumev2   |
| da8cf9f8546b4a428c43d5e032fe4afc | ec2      | ec2        |
| 5f105eeb55924b7290c8675ad7e294ae | glance   | image      |
| dcaa566e912e4c0e900dc86804e3dde0 | keystone | identity   |
| 4a715cfbc3664e9ebf388534ff2be76a | nova     | compute    |
| 1aed4a6cf7274297ba4026cf5d5e96c5 | novav21  | computev21 |
| bed063c790634c979778551f66c8ede9 | neutron  | network    |
| 6feb2e0b98874d88bee221974770e372 |    s3    |    s3      |
+----------------------------------+----------+------------+</pre></div></li><li class="step "><p>To create a service, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack service create --name SERVICE_NAME --description SERVICE_DESCRIPTION SERVICE_TYPE</pre></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.16.9.2.7.2.2.3.1"><span class="term ">The arguments are:</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">service_name</code>: the unique name of the new service.</p></li><li class="listitem "><p><code class="literal">service_type</code>: the service type, such as <code class="literal">identity</code>,
<code class="literal">compute</code>, <code class="literal">network</code>, <code class="literal">image</code>, <code class="literal">object-store</code>
or any other service identifier string.</p></li><li class="listitem "><p><code class="literal">service_description</code>: the description of the service.</p></li></ul></div></dd></dl></div><p>For example, to create a <code class="literal">swift</code> service of type
<code class="literal">object-store</code>, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack service create --name swift --description "object store service" object-store
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | object store service             |
| enabled     | True                             |
| id          | 84c23f4b942c44c38b9c42c5e517cd9a |
| name        | swift                            |
| type        | object-store                     |
+-------------+----------------------------------+</pre></div></li><li class="step "><p>To get details for a service, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack service show SERVICE_TYPE|SERVICE_NAME|SERVICE_ID</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack service show object-store
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | object store service             |
| enabled     | True                             |
| id          | 84c23f4b942c44c38b9c42c5e517cd9a |
| name        | swift                            |
| type        | object-store                     |
+-------------+----------------------------------+</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.16.9.2.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.7.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create service users</span> <a title="Permalink" class="permalink" href="#id-1.4.16.9.2.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create a project for the service users.
Typically, this project is named <code class="literal">service</code>,
but choose any name you like:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project create service --domain default
+-------------+----------------------------------+
| Field       | Value                            |
+-------------+----------------------------------+
| description | None                             |
| domain_id   | e601210181f54843b51b3edff41d4980 |
| enabled     | True                             |
| id          | 3e9f3f5399624b2db548d7f871bd5322 |
| is_domain   | False                            |
| name        | service                          |
| parent_id   | e601210181f54843b51b3edff41d4980 |
+-------------+----------------------------------+</pre></div></li><li class="step "><p>Create service users for the relevant services for your
deployment.</p></li><li class="step "><p>Assign the admin role to the user-project pair.</p><div class="verbatim-wrap"><pre class="screen">$ openstack role add --project service --user SERVICE_USER_NAME admin
+-------+----------------------------------+
| Field | Value                            |
+-------+----------------------------------+
| id    | 233109e756c1465292f31e7662b429b1 |
| name  | admin                            |
+-------+----------------------------------+</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.16.9.2.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.7.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a service</span> <a title="Permalink" class="permalink" href="#id-1.4.16.9.2.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To delete a specified service, specify its ID.</p><div class="verbatim-wrap"><pre class="screen">$ openstack service delete SERVICE_TYPE|SERVICE_NAME|SERVICE_ID</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack service delete object-store</pre></div></div></div><div class="sect2 " id="id-1.4.16.9.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage Compute services</span> <a title="Permalink" class="permalink" href="#id-1.4.16.9.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can enable and disable Compute services. The following
examples disable and enable the <code class="literal">nova-compute</code> service.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List the Compute services:</p><div class="verbatim-wrap"><pre class="screen">$ openstack compute service list
+----+--------------+------------+----------+---------+-------+--------------+
| ID | Binary       | Host       | Zone     | Status  | State | Updated At   |
+----+--------------+------------+----------+---------+-------+--------------+
|  4 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | consoleauth  |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  5 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | scheduler    |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  6 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | conductor    |            |          |         |       | 0:44:54.0000 |
|    |              |            |          |         |       | 00           |
|  9 | nova-compute | compute    | nova     | enabled | up    | 2016-10-21T0 |
|    |              |            |          |         |       | 2:35:03.0000 |
|    |              |            |          |         |       | 00           |
+----+--------------+------------+----------+---------+-------+--------------+</pre></div></li><li class="step "><p>Disable a nova service:</p><div class="verbatim-wrap"><pre class="screen">$ openstack compute service set --disable --disable-reason trial log nova nova-compute
+----------+--------------+----------+-------------------+
| Host     | Binary       | Status   | Disabled Reason   |
+----------+--------------+----------+-------------------+
| compute  | nova-compute | disabled | trial log         |
+----------+--------------+----------+-------------------+</pre></div></li><li class="step "><p>Check the service list:</p><div class="verbatim-wrap"><pre class="screen">$ openstack compute service list
+----+--------------+------------+----------+---------+-------+--------------+
| ID | Binary       | Host       | Zone     | Status  | State | Updated At   |
+----+--------------+------------+----------+---------+-------+--------------+
|  4 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | consoleauth  |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  5 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | scheduler    |            |          |         |       | 0:44:48.0000 |
|    |              |            |          |         |       | 00           |
|  6 | nova-        | controller | internal | enabled | up    | 2016-12-20T0 |
|    | conductor    |            |          |         |       | 0:44:54.0000 |
|    |              |            |          |         |       | 00           |
|  9 | nova-compute | compute    | nova     | disabled| up    | 2016-10-21T0 |
|    |              |            |          |         |       | 2:35:03.0000 |
|    |              |            |          |         |       | 00           |
+----+--------------+------------+----------+---------+-------+--------------+</pre></div></li><li class="step "><p>Enable the service:</p><div class="verbatim-wrap"><pre class="screen">$ openstack compute service set --enable nova nova-compute
+----------+--------------+---------+
| Host     | Binary       | Status  |
+----------+--------------+---------+
| compute  | nova-compute | enabled |
+----------+--------------+---------+</pre></div></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.16.10"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage images</span> <a title="Permalink" class="permalink" href="#id-1.4.16.10">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The cloud operator assigns roles to users. Roles determine who can
upload and manage images. The operator might restrict image upload and
management to only cloud administrators or operators.</p><p>You can upload images through the <code class="literal">glance</code> client or the Image service
API. You can use the <code class="literal">nova</code> client for the image management.
The latter provides mechanisms to list and delete images, set and delete
image metadata, and create images of a running instance or snapshot and
backup types.</p><p>After you upload an image, you cannot change it.</p><p>For details about image creation, see the <a class="link" href="http://docs.openstack.org/image-guide/" target="_blank">Virtual Machine Image
Guide</a>.</p><div class="sect2 " id="id-1.4.16.10.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List or get details for images (glance)</span> <a title="Permalink" class="permalink" href="#id-1.4.16.10.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To get a list of images and to get further details about a single
image, use <code class="command">openstack image list</code> and <code class="command">openstack image show</code>
commands.</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list
+--------------------------------------+---------------------------------+--------+
| ID                                   | Name                            | Status |
+--------------------------------------+---------------------------------+--------+
| dfc1dfb0-d7bf-4fff-8994-319dd6f703d7 | cirros-0.3.2-x86_64-uec         | active |
| a3867e29-c7a1-44b0-9e7f-10db587cad20 | cirros-0.3.2-x86_64-uec-kernel  | active |
| 4b916fba-6775-4092-92df-f41df7246a6b | cirros-0.3.2-x86_64-uec-ramdisk | active |
| d07831df-edc3-4817-9881-89141f9134c3 | myCirrosImage                   | active |
+--------------------------------------+---------------------------------+--------+</pre></div><div class="verbatim-wrap"><pre class="screen">$ openstack image show myCirrosImage
+------------------+------------------------------------------------------+
| Field            | Value                                                |
+------------------+------------------------------------------------------+
| checksum         | ee1eca47dc88f4879d8a229cc70a07c6                     |
| container_format | ami                                                  |
| created_at       | 2016-08-11T15:07:26Z                                 |
| disk_format      | ami                                                  |
| file             | /v2/images/d07831df-edc3-4817-9881-89141f9134c3/file |
| id               | d07831df-edc3-4817-9881-89141f9134c3                 |
| min_disk         | 0                                                    |
| min_ram          | 0                                                    |
| name             | myCirrosImage                                        |
| owner            | d88310717a8e4ebcae84ed075f82c51e                     |
| protected        | False                                                |
| schema           | /v2/schemas/image                                    |
| size             | 13287936                                             |
| status           | active                                               |
| tags             |                                                      |
| updated_at       | 2016-08-11T15:20:02Z                                 |
| virtual_size     | None                                                 |
| visibility       | private                                              |
+------------------+------------------------------------------------------+</pre></div><p>When viewing a list of images, you can also use <code class="literal">grep</code> to filter the
list, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list | grep 'cirros'
| dfc1dfb0-d7bf-4fff-8994-319dd6f703d7 | cirros-0.3.2-x86_64-uec         | active |
| a3867e29-c7a1-44b0-9e7f-10db587cad20 | cirros-0.3.2-x86_64-uec-kernel  | active |
| 4b916fba-6775-4092-92df-f41df7246a6b | cirros-0.3.2-x86_64-uec-ramdisk | active |</pre></div><div id="id-1.4.16.10.6.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To store location metadata for images, which enables direct file access for a client,
update the <code class="literal">/etc/glance/glance-api.conf</code> file with the following statements:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">show_multiple_locations = True</code>
              </p></li><li class="listitem "><p>
                <code class="literal">filesystem_store_metadata_file = filePath</code>
              </p><p>where filePath points to a JSON file that defines the mount point for OpenStack
images on your system and a unique ID. For example:</p></li></ul></div><div class="verbatim-wrap highlight json"><pre class="screen">[{
    "id": "2d9bb53f-70ea-4066-a68b-67960eaae673",
    "mountpoint": "/var/lib/glance/images/"
}]</pre></div><p>After you restart the Image service, you can use the following syntax to view
the image's location information:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-image-api-version 2 image show imageID</pre></div><p>For example, using the image ID shown above, you would issue the command as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack --os-image-api-version 2 image show 2d9bb53f-70ea-4066-a68b-67960eaae673</pre></div></div></div><div class="sect2 " id="id-1.4.16.10.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create or update an image (glance)</span> <a title="Permalink" class="permalink" href="#id-1.4.16.10.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create an image, use <code class="command">openstack image create</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create imageName</pre></div><p>To update an image by name or ID, use <code class="command">openstack image set</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set imageName</pre></div><p>The following list explains the optional arguments that you can use with
the <code class="literal">create</code> and <code class="literal">set</code> commands to modify image properties. For
more information, refer to the <a class="link" href="http://docs.openstack.org/developer/python-openstackclient/command-objects/image.html" target="_blank">OpenStack Image command reference</a>.</p><p>The following example shows the command that you would use to upload a
CentOS 6.3 image in qcow2 format and configure it for public access:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create --disk-format qcow2 --container-format bare \
  --public --file ./centos63.qcow2 centos63-image</pre></div><p>The following example shows how to update an existing image with a
properties that describe the disk bus, the CD-ROM bus, and the VIF
model:</p><div id="id-1.4.16.10.7.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When you use OpenStack with VMware vCenter Server, you need to specify
the <code class="literal">vmware_disktype</code> and <code class="literal">vmware_adaptertype</code> properties with
<code class="command">openstack image create</code>.
Also, we recommend that you set the <code class="literal">hypervisor_type="vmware"</code> property.
For more information, see <a class="link" href="http://docs.openstack.org/newton/config-reference/compute/hypervisor-vmware.html#images-with-vmware-vsphere" target="_blank">Images with VMware vSphere</a>
in the OpenStack Configuration Reference.</p></div><div class="verbatim-wrap"><pre class="screen">$ openstack image set \
    --property hw_disk_bus=scsi \
    --property hw_cdrom_bus=ide \
    --property hw_vif_model=e1000 \
    f16-x86_64-openstack-sda</pre></div><p>Currently the libvirt virtualization tool determines the disk, CD-ROM,
and VIF device models based on the configured hypervisor type
(<code class="literal">libvirt_type</code> in <code class="literal">/etc/nova/nova.conf</code> file). For the sake of optimal
performance, libvirt defaults to using virtio for both disk and VIF
(NIC) models. The disadvantage of this approach is that it is not
possible to run operating systems that lack virtio drivers, for example,
BSD, Solaris, and older versions of Linux and Windows.</p><p>The valid model values depend on the <code class="literal">libvirt_type</code> setting, as shown
in the following tables.</p><div class="table" id="disk-and-cd-rom-bus-model-values-table"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 14.3: </span><span class="name">Disk and CD-ROM bus model values </span><a title="Permalink" class="permalink" href="#disk-and-cd-rom-bus-model-values-table">#</a></h6></div><div class="table-contents"><table class="table" summary="Disk and CD-ROM bus model values" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>libvirt_type setting</p>
                </th><th>
                  <p>Supported model values</p>
                </th></tr></thead><tbody><tr><td>
                  <p>qemu or kvm</p>
                </td><td>
                  <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>ide</p></li><li class="listitem "><p>scsi</p></li><li class="listitem "><p>virtio</p></li></ul></div>
                </td></tr><tr><td>
                  <p>xen</p>
                </td><td>
                  <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>ide</p></li><li class="listitem "><p>xen</p></li></ul></div>
                </td></tr></tbody></table></div></div><div class="table" id="vif-model-values-table"><div class="table-title-wrap"><h6 class="table-title"><span class="number">Table 14.4: </span><span class="name">VIF model values </span><a title="Permalink" class="permalink" href="#vif-model-values-table">#</a></h6></div><div class="table-contents"><table class="table" summary="VIF model values" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>libvirt_type setting</p>
                </th><th>
                  <p>Supported model values</p>
                </th></tr></thead><tbody><tr><td>
                  <p>qemu or kvm</p>
                </td><td>
                  <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>e1000</p></li><li class="listitem "><p>ne2k_pci</p></li><li class="listitem "><p>pcnet</p></li><li class="listitem "><p>rtl8139</p></li><li class="listitem "><p>virtio</p></li></ul></div>
                </td></tr><tr><td>
                  <p>xen</p>
                </td><td>
                  <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>e1000</p></li><li class="listitem "><p>netfront</p></li><li class="listitem "><p>ne2k_pci</p></li><li class="listitem "><p>pcnet</p></li><li class="listitem "><p>rtl8139</p></li></ul></div>
                </td></tr><tr><td>
                  <p>vmware</p>
                </td><td>
                  <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>VirtualE1000</p></li><li class="listitem "><p>VirtualPCNet32</p></li><li class="listitem "><p>VirtualVmxnet</p></li></ul></div>
                </td></tr></tbody></table></div></div><div id="id-1.4.16.10.7.16" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>By default, hardware properties are retrieved from the image
properties. However, if this information is not available, the
<code class="literal">libosinfo</code> database provides an alternative source for these
values.</p><p>If the guest operating system is not in the database, or if the use
of <code class="literal">libosinfo</code> is disabled, the default system values are used.</p><p>Users can set the operating system ID or a <code class="literal">short-id</code> in image
properties. For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set --property short-id=fedora23 \
  name-of-my-fedora-image</pre></div><p>Alternatively, users can set <code class="literal">id</code> to a URL:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image set \
  --property id=http://fedoraproject.org/fedora/23 \
  ID-of-my-fedora-image</pre></div></div><div class="sect3 " id="id-1.4.16.10.7.17"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.8.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create an image from ISO image</span> <a title="Permalink" class="permalink" href="#id-1.4.16.10.7.17">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can upload ISO images to the Image service (glance).
You can subsequently boot an ISO image using Compute.</p><p>In the Image service, run the following command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image create ISO_IMAGE --file IMAGE.iso \
  --disk-format iso --container-format bare</pre></div><p>Optionally, to confirm the upload in Image service, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list</pre></div></div></div><div class="sect2 " id="id-1.4.16.10.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshoot image creation</span> <a title="Permalink" class="permalink" href="#id-1.4.16.10.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If you encounter problems in creating an image in the Image service or
Compute, the following information may help you troubleshoot the
creation process.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Ensure that the version of qemu you are using is version 0.14 or
later. Earlier versions of qemu result in an <code class="literal">unknown option -s</code>
error message in the <code class="literal">/var/log/nova/nova-compute.log</code> file.</p></li><li class="listitem "><p>Examine the <code class="literal">/var/log/nova/nova-api.log</code> and
<code class="literal">/var/log/nova/nova-compute.log</code> log files for error messages.</p></li></ul></div></div></div><div class="sect1 " id="id-1.4.16.11"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage volumes</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A volume is a detachable block storage device, similar to a USB hard
drive. You can attach a volume to only one instance. Use  the <code class="literal">openstack</code>
client commands to create and manage volumes.</p><div class="sect2 " id="id-1.4.16.11.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate a volume</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrator, you can migrate a volume with its data from one
location to another in a manner that is transparent to users and
workloads. You can migrate only detached volumes with no snapshots.</p><p>Possible use cases for data migration include:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Bring down a physical storage device for maintenance without
disrupting workloads.</p></li><li class="listitem "><p>Modify the properties of a volume.</p></li><li class="listitem "><p>Free up space in a thinly-provisioned back end.</p></li></ul></div><p>Migrate a volume with the <code class="command">cinder migrate</code> command, as shown in the
following example:</p><div class="verbatim-wrap"><pre class="screen">$ cinder migrate --force-host-copy &lt;True|False&gt;
                 --lock-volume &lt;True|False&gt;
                 &lt;volume&gt; &lt;host&gt;</pre></div><p>In this example, <code class="literal">--force-host-copy True</code> forces the generic
host-based migration mechanism and bypasses any driver optimizations.
<code class="literal">--lock-volume</code> applies to the available volume.
To determine whether the termination of volume migration caused by other
commands. <code class="literal">True</code>  locks the volume state and does not allow the
migration to be aborted.</p><div id="id-1.4.16.11.3.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If the volume has snapshots, the specified host destination cannot accept
the volume. If the user is not an administrator, the migration fails.</p></div></div><div class="sect2 " id="id-1.4.16.11.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a volume</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This example creates a <code class="literal">my-new-volume</code> volume based on an image.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List images, and note the ID of the image that you want to use for your
volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list
+--------------------------------------+---------------------------------+
| ID                                   | Name                            |
+--------------------------------------+---------------------------------+
| 8bf4dc2a-bf78-4dd1-aefa-f3347cf638c8 | cirros-0.3.4-x86_64-uec         |
| 9ff9bb2e-3a1d-4d98-acb5-b1d3225aca6c | cirros-0.3.4-x86_64-uec-kernel  |
| 4b227119-68a1-4b28-8505-f94c6ea4c6dc | cirros-0.3.4-x86_64-uec-ramdisk |
+--------------------------------------+---------------------------------+</pre></div></li><li class="step "><p>List the availability zones, and note the ID of the availability zone in
which you want to create your volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack availability zone list
+------+-----------+
| Name |   Status  |
+------+-----------+
| nova | available |
+------+-----------+</pre></div></li><li class="step "><p>Create a volume with 8 gibibytes (GiB) of space, and specify the
availability zone and image:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --image 8bf4dc2a-bf78-4dd1-aefa-f3347cf638c8 \
  --size 8 --availability-zone nova my-new-volume

+------------------------------+--------------------------------------+
| Property                     | Value                                |
+------------------------------+--------------------------------------+
| attachments                  | []                                   |
| availability_zone            | nova                                 |
| bootable                     | false                                |
| consistencygroup_id          | None                                 |
| created_at                   | 2016-09-23T07:52:42.000000           |
| description                  | None                                 |
| encrypted                    | False                                |
| id                           | bab4b0e0-ce3d-4d57-bf57-3c51319f5202 |
| metadata                     | {}                                   |
| multiattach                  | False                                |
| name                         | my-new-volume                        |
| os-vol-tenant-attr:tenant_id | 3f670abbe9b34ca5b81db6e7b540b8d8     |
| replication_status           | disabled                             |
| size                         | 8                                    |
| snapshot_id                  | None                                 |
| source_volid                 | None                                 |
| status                       | creating                             |
| updated_at                   | None                                 |
| user_id                      | fe19e3a9f63f4a14bd4697789247bbc5     |
| volume_type                  | lvmdriver-1                          |
+------------------------------+--------------------------------------+</pre></div></li><li class="step "><p>To verify that your volume was created successfully, list the available
volumes:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+--------------------------------------+---------------+-----------+------+-------------+
| ID                                   | DisplayName   |  Status   | Size | Attached to |
+--------------------------------------+---------------+-----------+------+-------------+
| bab4b0e0-ce3d-4d57-bf57-3c51319f5202 | my-new-volume | available | 8    |             |
+--------------------------------------+---------------+-----------+------+-------------+</pre></div><p>If your volume was created successfully, its status is <code class="literal">available</code>. If
its status is <code class="literal">error</code>, you might have exceeded your quota.</p></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.11.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a volume from specified volume type</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Cinder supports these three ways to specify <code class="literal">volume type</code> during
volume creation.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>volume_type</p></li><li class="step "><p>cinder_img_volume_type (via glance image metadata)</p></li><li class="step "><p>default_volume_type (via cinder.conf)</p></li></ol></div></div><div class="sect3 " id="id-1.4.16.11.5.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">volume_type</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.5.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>User can specify <code class="literal">volume type</code> when creating a volume.</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create -h -f {json,shell,table,value,yaml}
                         -c COLUMN --max-width &lt;integer&gt;
                         --noindent --prefix PREFIX --size &lt;size&gt;
                         --type &lt;volume-type&gt; --image &lt;image&gt;
                         --snapshot &lt;snapshot&gt; --source &lt;volume&gt;
                         --description &lt;description&gt; --user &lt;user&gt;
                         --project &lt;project&gt;
                         --availability-zone &lt;availability-zone&gt;
                         --property &lt;key=value&gt;
                         &lt;name&gt;</pre></div></div><div class="sect3 " id="id-1.4.16.11.5.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">cinder_img_volume_type</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.5.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If glance image has <code class="literal">cinder_img_volume_type</code> property, Cinder uses this
parameter to specify <code class="literal">volume type</code> when creating a volume.</p><p>Choose glance image which has <code class="literal">cinder_img_volume_type</code> property and create
a volume from the image.</p><div class="verbatim-wrap"><pre class="screen">$ openstack image list
+----------------------------------+---------------------------------+--------+
| ID                               | Name                            | Status |
+----------------------------------+---------------------------------+--------+
| 376bd633-c9c9-4c5d-a588-342f4f66 | cirros-0.3.4-x86_64-uec         | active |
| d086                             |                                 |        |
| 2c20fce7-2e68-45ee-ba8d-         | cirros-0.3.4-x86_64-uec-ramdisk | active |
| beba27a91ab5                     |                                 |        |
| a5752de4-9faf-4c47-acbc-         | cirros-0.3.4-x86_64-uec-kernel  | active |
| 78a5efa7cc6e                     |                                 |        |
+----------------------------------+---------------------------------+--------+


$ openstack image show 376bd633-c9c9-4c5d-a588-342f4f66d086
+------------------+-----------------------------------------------------------+
| Field            | Value                                                     |
+------------------+-----------------------------------------------------------+
| checksum         | eb9139e4942121f22bbc2afc0400b2a4                          |
| container_format | ami                                                       |
| created_at       | 2016-10-13T03:28:55Z                                      |
| disk_format      | ami                                                       |
| file             | /v2/images/376bd633-c9c9-4c5d-a588-342f4f66d086/file      |
| id               | 376bd633-c9c9-4c5d-a588-342f4f66d086                      |
| min_disk         | 0                                                         |
| min_ram          | 0                                                         |
| name             | cirros-0.3.4-x86_64-uec                                   |
| owner            | 88ba456e3a884c318394737765e0ef4d                          |
| properties       | kernel_id='a5752de4-9faf-4c47-acbc-78a5efa7cc6e',         |
|                  | ramdisk_id='2c20fce7-2e68-45ee-ba8d-beba27a91ab5'         |
| protected        | False                                                     |
| schema           | /v2/schemas/image                                         |
| size             | 25165824                                                  |
| status           | active                                                    |
| tags             |                                                           |
| updated_at       | 2016-10-13T03:28:55Z                                      |
| virtual_size     | None                                                      |
| visibility       | public                                                    |
+------------------+-----------------------------------------------------------+

$ openstack volume create --image 376bd633-c9c9-4c5d-a588-342f4f66d086 \
  --size 1 --availability-zone nova test
+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| attachments         | []                                   |
| availability_zone   | nova                                 |
| bootable            | false                                |
| consistencygroup_id | None                                 |
| created_at          | 2016-10-13T06:29:53.688599           |
| description         | None                                 |
| encrypted           | False                                |
| id                  | e6e6a72d-cda7-442c-830f-f306ea6a03d5 |
| multiattach         | False                                |
| name                | test                                 |
| properties          |                                      |
| replication_status  | disabled                             |
| size                | 1                                    |
| snapshot_id         | None                                 |
| source_volid        | None                                 |
| status              | creating                             |
| type                | lvmdriver-1                          |
| updated_at          | None                                 |
| user_id             | 33fdc37314914796883706b33e587d51     |
+---------------------+--------------------------------------+</pre></div></div><div class="sect3 " id="id-1.4.16.11.5.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">default_volume_type</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.5.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If above parameters are not set, Cinder uses default_volume_type which is
defined in cinder.conf during volume creation.</p><p>Example cinder.conf file configuration.</p><div class="verbatim-wrap"><pre class="screen">[default]
default_volume_type = lvmdriver-1</pre></div></div></div><div class="sect2 " id="id-1.4.16.11.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Attach a volume to an instance</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Attach your volume to a server, specifying the server ID and the volume
ID:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server add volume 84c6e57d-a6b1-44b6-81eb-fcb36afd31b5 \
  573e024d-5235-49ce-8332-be1576d323f8 --device /dev/vdb</pre></div></li><li class="step "><p>Show information for your volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume show 573e024d-5235-49ce-8332-be1576d323f8</pre></div><p>The output shows that the volume is attached to the server with ID
<code class="literal">84c6e57d-a6b1-44b6-81eb-fcb36afd31b5</code>, is in the nova availability
zone, and is bootable.</p><div class="verbatim-wrap"><pre class="screen">+------------------------------+-----------------------------------------------+
| Field                        | Value                                         |
+------------------------------+-----------------------------------------------+
| attachments                  | [{u'device': u'/dev/vdb',                     |
|                              |        u'server_id': u'84c6e57d-a             |
|                              |           u'id': u'573e024d-...               |
|                              |        u'volume_id': u'573e024d...            |
| availability_zone            | nova                                          |
| bootable                     | true                                          |
| consistencygroup_id          | None                                          |
| created_at                   | 2016-10-13T06:08:07.000000                    |
| description                  | None                                          |
| encrypted                    | False                                         |
| id                           | 573e024d-5235-49ce-8332-be1576d323f8          |
| multiattach                  | False                                         |
| name                         | my-new-volume                                 |
| os-vol-tenant-attr:tenant_id | 7ef070d3fee24bdfae054c17ad742e28              |
| properties                   |                                               |
| replication_status           | disabled                                      |
| size                         | 8                                             |
| snapshot_id                  | None                                          |
| source_volid                 | None                                          |
| status                       | in-use                                        |
| type                         | lvmdriver-1                                   |
| updated_at                   | 2016-10-13T06:08:11.000000                    |
| user_id                      | 33fdc37314914796883706b33e587d51              |
| volume_image_metadata        |{u'kernel_id': u'df430cc2...,                  |
|                              |        u'image_id': u'397e713c...,            |
|                              |        u'ramdisk_id': u'3cf852bd...,          |
|                              |u'image_name': u'cirros-0.3.2-x86_64-uec'}     |
+------------------------------+-----------------------------------------------+</pre></div></li></ol></div></div></div><div class="sect2 " id="resize-a-volume"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Resize a volume</span> <a title="Permalink" class="permalink" href="#resize-a-volume">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>resize-a-volume</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To resize your volume, you must first detach it from the server.
To detach the volume from your server, pass the server ID and volume ID
to the following command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server remove volume 84c6e57d-a6b1-44b6-81eb-fcb36afd31b5 573e024d-5235-49ce-8332-be1576d323f8</pre></div><p>This command does not provide any output.</p></li><li class="step "><p>List volumes:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+----------------+-----------------+-----------+------+-------------+
|       ID       |   Display Name  |  Status   | Size | Attached to |
+----------------+-----------------+-----------+------+-------------+
| 573e024d-52... |  my-new-volume  | available |  8   |             |
| bd7cf584-45... | my-bootable-vol | available |  8   |             |
+----------------+-----------------+-----------+------+-------------+</pre></div><p>Note that the volume is now available.</p></li><li class="step "><p>Resize the volume by passing the volume ID and the new size (a value
greater than the old one) as parameters:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume set 573e024d-5235-49ce-8332-be1576d323f8 --size 10</pre></div><p>This command does not provide any output.</p><div id="id-1.4.16.11.7.2.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>When extending an LVM volume with a snapshot, the volume will be
deactivated. The reactivation is automatic unless
<code class="literal">auto_activation_volume_list</code> is defined in <code class="literal">lvm.conf</code>. See
<code class="literal">lvm.conf</code> for more information.</p></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.11.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a volume</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To delete your volume, you must first detach it from the server.
To detach the volume from your server and check for the list of existing
volumes, see steps 1 and 2 in <a class="xref" href="#resize-a-volume" title="14.9.5. Resize a volume">Section 14.9.5, “Resize a volume”</a>.</p><p>Delete the volume using either the volume name or ID:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume delete my-new-volume</pre></div><p>This command does not provide any output.</p></li><li class="step "><p>List the volumes again, and note that the status of your volume is
<code class="literal">deleting</code>:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+----------------+-----------------+-----------+------+-------------+
|       ID       |   Display Name  |  Status   | Size | Attached to |
+----------------+-----------------+-----------+------+-------------+
| 573e024d-52... |  my-new-volume  |  deleting |  8   |             |
| bd7cf584-45... | my-bootable-vol | available |  8   |             |
+----------------+-----------------+-----------+------+-------------+</pre></div><p>When the volume is fully deleted, it disappears from the list of
volumes:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+----------------+-----------------+-----------+------+-------------+
|       ID       |   Display Name  |  Status   | Size | Attached to |
+----------------+-----------------+-----------+------+-------------+
| bd7cf584-45... | my-bootable-vol | available |  8   |             |
+----------------+-----------------+-----------+------+-------------+</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.11.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Transfer a volume</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can transfer a volume from one owner to another by using the
<code class="command">openstack volume transfer request create</code> command. The volume
donor, or original owner, creates a transfer request and sends the created
transfer ID and authorization key to the volume recipient. The volume
recipient, or new owner, accepts the transfer by using the ID and key.</p><div id="id-1.4.16.11.9.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The procedure for volume transfer is intended for tenants (both the
volume donor and recipient) within the same cloud.</p></div><p>Use cases include:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Create a custom bootable volume or a volume with a large data set and
transfer it to a customer.</p></li><li class="listitem "><p>For bulk import of data to the cloud, the data ingress system creates
a new Block Storage volume, copies data from the physical device, and
transfers device ownership to the end user.</p></li></ul></div><div class="sect3 " id="id-1.4.16.11.9.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a volume transfer request</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.9.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>While logged in as the volume donor, list the available volumes:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+-----------------+-----------------+-----------+------+-------------+
|       ID        |   Display Name  |  Status   | Size | Attached to |
+-----------------+-----------------+-----------+------+-------------+
| 72bfce9f-cac... |       None      |   error   |  1   |             |
| a1cdace0-08e... |       None      | available |  1   |             |
+-----------------+-----------------+-----------+------+-------------+</pre></div></li><li class="step "><p>As the volume donor, request a volume transfer authorization code for a
specific volume:</p><div class="verbatim-wrap"><pre class="screen">  $ openstack volume transfer request create &lt;volume&gt;

&lt;volume&gt;
   Name or ID of volume to transfer.</pre></div><p>The volume must be in an <code class="literal">available</code> state or the request will be
denied. If the transfer request is valid in the database (that is, it
has not expired or been deleted), the volume is placed in an
<code class="literal">awaiting-transfer</code> state. For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request create a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f</pre></div><p>The output shows the volume transfer ID in the <code class="literal">id</code> row and the
authorization key.</p><div class="verbatim-wrap"><pre class="screen">+------------+--------------------------------------+
| Field      | Value                                |
+------------+--------------------------------------+
| auth_key   | 0a59e53630f051e2                     |
| created_at | 2016-11-03T11:49:40.346181           |
| id         | 34e29364-142b-4c7b-8d98-88f765bf176f |
| name       | None                                 |
| volume_id  | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f |
+------------+--------------------------------------+</pre></div><div id="id-1.4.16.11.9.6.2.2.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Optionally, you can specify a name for the transfer by using the
<code class="literal">--name transferName</code> parameter.</p></div><div id="id-1.4.16.11.9.6.2.2.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>While the <code class="literal">auth_key</code> property is visible in the output of
<code class="literal">openstack volume transfer request create VOLUME_ID</code>, it will not be
available in subsequent <code class="literal">openstack volume transfer request show TRANSFER_ID</code>
command.</p></div></li><li class="step "><p>Send the volume transfer ID and authorization key to the new owner (for
example, by email).</p></li><li class="step "><p>View pending transfers:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request list
+--------------------------------------+--------------------------------------+------+
|               ID                     |             Volume                   | Name |
+--------------------------------------+--------------------------------------+------+
| 6e4e9aa4-bed5-4f94-8f76-df43232f44dc | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f | None |
+--------------------------------------+--------------------------------------+------+</pre></div></li><li class="step "><p>After the volume recipient, or new owner, accepts the transfer, you can
see that the transfer is no longer available:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request list
+----+-----------+------+
| ID | Volume ID | Name |
+----+-----------+------+
+----+-----------+------+</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.16.11.9.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Accept a volume transfer request</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.9.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>As the volume recipient, you must first obtain the transfer ID and
authorization key from the original owner.</p></li><li class="step "><p>Accept the request:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request accept transferID authKey</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request accept 6e4e9aa4-bed5-4f94-8f76-df43232f44dc b2c8e585cbc68a80
+-----------+--------------------------------------+
|  Property |                Value                 |
+-----------+--------------------------------------+
|     id    | 6e4e9aa4-bed5-4f94-8f76-df43232f44dc |
|    name   |                 None                 |
| volume_id | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f |
+-----------+--------------------------------------+</pre></div><div id="id-1.4.16.11.9.7.2.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you do not have a sufficient quota for the transfer, the transfer
is refused.</p></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.16.11.9.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a volume transfer</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.9.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List available volumes and their statuses:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+-----------------+-----------------+-----------------+------+-------------+
|       ID        |   Display Name  |      Status     | Size | Attached to |
+-----------------+-----------------+-----------------+------+-------------+
| 72bfce9f-cac... |       None      |      error      |  1   |             |
| a1cdace0-08e... |       None      |awaiting-transfer|  1   |             |
+-----------------+-----------------+-----------------+------+-------------+</pre></div></li><li class="step "><p>Find the matching transfer ID:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request list
+--------------------------------------+--------------------------------------+------+
|               ID                     |             VolumeID                 | Name |
+--------------------------------------+--------------------------------------+------+
| a6da6888-7cdf-4291-9c08-8c1f22426b8a | a1cdace0-08e4-4dc7-b9dc-457e9bcfe25f | None |
+--------------------------------------+--------------------------------------+------+</pre></div></li><li class="step "><p>Delete the volume:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request delete &lt;transfer&gt;</pre></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.16.11.9.8.2.3.3.1"><span class="term ">&lt;transfer&gt;</span></dt><dd><p>Name or ID of transfer to delete.</p></dd></dl></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request delete a6da6888-7cdf-4291-9c08-8c1f22426b8a</pre></div></li><li class="step "><p>Verify that transfer list is now empty and that the volume is again
available for transfer:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume transfer request list
+----+-----------+------+
| ID | Volume ID | Name |
+----+-----------+------+
+----+-----------+------+</pre></div><div class="verbatim-wrap"><pre class="screen">$ openstack volume list
+-----------------+-----------+--------------+------+-------------+----------+-------------+
|       ID        |   Status  | Display Name | Size | Volume Type | Bootable | Attached to |
+-----------------+-----------+--------------+------+-------------+----------+-------------+
| 72bfce9f-ca...  |   error   |     None     |  1   |     None    |  false   |             |
| a1cdace0-08...  | available |     None     |  1   |     None    |  false   |             |
+-----------------+-----------+--------------+------+-------------+----------+-------------+</pre></div></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.16.11.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.9.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage and unmanage a snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A snapshot is a point in time version of a volume. As an administrator,
you can manage and unmanage snapshots.</p><div class="sect3 " id="id-1.4.16.11.10.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage a snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.10.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Manage a snapshot with the <code class="command">openstack snapshot set</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack snapshot set \
  [--name &lt;name&gt;] \
  [--description &lt;description&gt;] \
  [--property &lt;key=value&gt; [...] ] \
  [--state &lt;state&gt;] \
  &lt;snapshot&gt;</pre></div><p>The arguments to be passed are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.16.11.10.3.5.1"><span class="term ">
                <code class="literal">--name</code>
              </span></dt><dd><p>New snapshot name</p></dd><dt id="id-1.4.16.11.10.3.5.2"><span class="term ">
                <code class="literal">--description</code>
              </span></dt><dd><p>New snapshot description</p></dd><dt id="id-1.4.16.11.10.3.5.3"><span class="term ">
                <code class="literal">--property</code>
              </span></dt><dd><p>Property to add or modify for this snapshot (repeat option to set
multiple properties)</p></dd><dt id="id-1.4.16.11.10.3.5.4"><span class="term ">
                <code class="literal">--state</code>
              </span></dt><dd><p>New snapshot state. (“available”, “error”, “creating”, “deleting”,
or “error_deleting”)
(admin only) (This option simply changes the state of the snapshot in the
database with no regard to actual status, exercise caution when using)</p></dd><dt id="id-1.4.16.11.10.3.5.5"><span class="term ">
                <code class="literal">&lt;snapshot&gt;</code>
              </span></dt><dd><p>Snapshot to modify (name or ID)</p></dd></dl></div><div class="verbatim-wrap"><pre class="screen">$ openstack snapshot set my-snapshot-id</pre></div></div><div class="sect3 " id="id-1.4.16.11.10.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.9.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Unmanage a snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.16.11.10.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Unmanage a snapshot with the <code class="command">cinder snapshot-unmanage</code> command:</p><div class="verbatim-wrap"><pre class="screen">$ cinder snapshot-unmanage SNAPSHOT</pre></div><p>The arguments to be passed are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.16.11.10.4.5.1"><span class="term ">SNAPSHOT</span></dt><dd><p>Name or ID of the snapshot to unmanage.</p></dd></dl></div><p>The following example unmanages the <code class="literal">my-snapshot-id</code> image:</p><div class="verbatim-wrap"><pre class="screen">$ cinder snapshot-unmanage my-snapshot-id</pre></div></div></div></div><div class="sect1 " id="id-1.4.16.12"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage shares</span> <a title="Permalink" class="permalink" href="#id-1.4.16.12">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A share is provided by file storage. You can give access to a share to
instances. To create and manage shares, use <code class="literal">manila</code> client commands.</p><div class="sect2 " id="id-1.4.16.12.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate a share</span> <a title="Permalink" class="permalink" href="#id-1.4.16.12.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrator, you can migrate a share with its data from one
location to another in a manner that is transparent to users and
workloads.</p><p>Possible use cases for data migration include:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Bring down a physical storage device for maintenance without
disrupting workloads.</p></li><li class="listitem "><p>Modify the properties of a share.</p></li><li class="listitem "><p>Free up space in a thinly-provisioned back end.</p></li></ul></div><p>Migrate a share with the <code class="command">manila migrate</code> command, as shown in the
following example:</p><div class="verbatim-wrap"><pre class="screen">$ manila migrate shareID destinationHost --force-host-copy True|False</pre></div><p>In this example, <code class="literal">--force-host-copy True</code> forces the generic
host-based migration mechanism and bypasses any driver optimizations.
<code class="literal">destinationHost</code> is in this format <code class="literal">host#pool</code> which includes
destination host and pool.</p><div id="id-1.4.16.12.3.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If the user is not an administrator, the migration fails.</p></div></div></div><div class="sect1 " id="osadm-manage-flavors-cmd"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage flavors</span> <a title="Permalink" class="permalink" href="#osadm-manage-flavors-cmd">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>osadm-manage-flavors-cmd</li></ul></div></div></div></div><p>In OpenStack, flavors define the compute, memory, and
storage capacity of nova computing instances. To put it
simply, a flavor is an available hardware configuration for a
server. It defines the <code class="literal">size</code> of a virtual server
that can be launched.</p><div id="id-1.4.16.13.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Flavors can also determine on which compute host a flavor
can be used to launch an instance. For information
about customizing flavors, refer to <a class="xref" href="#compute-flavors" title="5.4.3. Flavors">Section 5.4.3, “Flavors”</a>.</p></div><p>A flavor consists of the following parameters:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.16.13.5.1"><span class="term ">Flavor ID</span></dt><dd><p>Unique ID (integer or UUID) for the new flavor. If
specifying 'auto', a UUID will be automatically generated.</p></dd><dt id="id-1.4.16.13.5.2"><span class="term ">Name</span></dt><dd><p>Name for the new flavor.</p></dd><dt id="id-1.4.16.13.5.3"><span class="term ">VCPUs</span></dt><dd><p>Number of virtual CPUs to use.</p></dd><dt id="id-1.4.16.13.5.4"><span class="term ">Memory MB</span></dt><dd><p>Amount of RAM to use (in megabytes).</p></dd><dt id="id-1.4.16.13.5.5"><span class="term ">Root Disk GB</span></dt><dd><p>Amount of disk space (in gigabytes) to use for
the root (/) partition.</p></dd><dt id="id-1.4.16.13.5.6"><span class="term ">Ephemeral Disk GB</span></dt><dd><p>Amount of disk space (in gigabytes) to use for
the ephemeral partition. If unspecified, the value
is <code class="literal">0</code> by default.
Ephemeral disks offer machine local disk storage
linked to the lifecycle of a VM instance. When a
VM is terminated, all data on the ephemeral disk
is lost. Ephemeral disks are not included in any
snapshots.</p></dd><dt id="id-1.4.16.13.5.7"><span class="term ">Swap</span></dt><dd><p>Amount of swap space (in megabytes) to use. If
unspecified, the value is <code class="literal">0</code> by default.</p></dd><dt id="id-1.4.16.13.5.8"><span class="term ">RXTX Factor</span></dt><dd><p>Optional property that allows servers with a different bandwidth be
created with the RXTX Factor. The default value is <code class="literal">1.0</code>. That is,
the new bandwidth is the same as that of the attached network. The
RXTX Factor is available only for Xen or NSX based systems.</p></dd><dt id="id-1.4.16.13.5.9"><span class="term ">Is Public</span></dt><dd><p>Boolean value defines whether the flavor is available to all users.
Defaults to <code class="literal">True</code>.</p></dd><dt id="id-1.4.16.13.5.10"><span class="term ">Extra Specs</span></dt><dd><p>Key and value pairs that define on which compute nodes a
flavor can run. These pairs must match corresponding pairs on
the compute nodes. It can be used to implement special resources, such
as flavors that run on only compute nodes with GPU hardware.</p></dd></dl></div><p>As of Newton, there are no default flavors.  The following table
lists the default flavors for Mitaka and earlier.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /><col class="c3" /><col class="c4" /></colgroup><thead><tr><th>
                <p>Flavor</p>
              </th><th>
                <p>VCPUs</p>
              </th><th>
                <p>Disk (in GB)</p>
              </th><th>
                <p>RAM (in MB)</p>
              </th></tr></thead><tbody><tr><td>
                <p>m1.tiny</p>
              </td><td>
                <p>1</p>
              </td><td>
                <p>1</p>
              </td><td>
                <p>512</p>
              </td></tr><tr><td>
                <p>m1.small</p>
              </td><td>
                <p>1</p>
              </td><td>
                <p>20</p>
              </td><td>
                <p>2048</p>
              </td></tr><tr><td>
                <p>m1.medium</p>
              </td><td>
                <p>2</p>
              </td><td>
                <p>40</p>
              </td><td>
                <p>4096</p>
              </td></tr><tr><td>
                <p>m1.large</p>
              </td><td>
                <p>4</p>
              </td><td>
                <p>80</p>
              </td><td>
                <p>8192</p>
              </td></tr><tr><td>
                <p>m1.xlarge</p>
              </td><td>
                <p>8</p>
              </td><td>
                <p>160</p>
              </td><td>
                <p>16384</p>
              </td></tr></tbody></table></div><p>You can create and manage flavors with the
<code class="command">openstack flavor</code> commands provided by the <code class="literal">python-openstackclient</code>
package.</p><div class="sect2 " id="id-1.4.16.13.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a flavor</span> <a title="Permalink" class="permalink" href="#id-1.4.16.13.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List flavors to show the ID and name, the amount
of memory, the amount of disk space for the root
partition and for the ephemeral partition, the
swap, and the number of virtual CPUs for each
flavor:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor list</pre></div></li><li class="step "><p>To create a flavor, specify a name, ID, RAM
size, disk size, and the number of VCPUs for the
flavor, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor create FLAVOR_NAME --id FLAVOR_ID --ram RAM_IN_MB --disk ROOT_DISK_IN_GB --vcpus NUMBER_OF_VCPUS</pre></div><div id="id-1.4.16.13.9.2.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Unique ID (integer or UUID) for the new flavor. If
specifying 'auto', a UUID will be automatically generated.</p></div><p>Here is an example with additional optional
parameters filled in that creates a public <code class="literal">extra
tiny</code> flavor that automatically gets an ID
assigned, with 256 MB memory, no disk space, and
one VCPU. The rxtx-factor indicates the slice of
bandwidth that the instances with this flavor can
use (through the Virtual Interface (vif) creation
in the hypervisor):</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor create --public m1.extra_tiny --id auto --ram 256 --disk 0 --vcpus 1 --rxtx-factor 1</pre></div></li><li class="step "><p>If an individual user or group of users needs a custom
flavor that you do not want other projects to have access to,
you can change the flavor's access to make it a private flavor.
See
<a class="link" href="http://docs.openstack.org/ops-guide/ops-user-facing-operations.html#private-flavors" target="_blank">Private Flavors in the OpenStack Operations Guide</a>.</p><p>For a list of optional parameters, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack help flavor create</pre></div></li><li class="step "><p>After you create a flavor, assign it to a
project by specifying the flavor name or ID and
the project ID:</p><div class="verbatim-wrap"><pre class="screen">$ nova flavor-access-add FLAVOR TENANT_ID</pre></div></li><li class="step "><p>In addition, you can set or unset <code class="literal">extra_spec</code> for the existing flavor.
The <code class="literal">extra_spec</code> metadata keys can influence the instance directly when
it is launched. If a flavor sets the
<code class="literal">extra_spec key/value quota:vif_outbound_peak=65536</code>, the instance's
outbound peak bandwidth I/O should be LTE 512 Mbps. There are several
aspects that can work for an instance including <code class="literal">CPU limits</code>,
<code class="literal">Disk tuning</code>, <code class="literal">Bandwidth I/O</code>, <code class="literal">Watchdog behavior</code>, and
<code class="literal">Random-number generator</code>.
For information about supporting metadata keys, see
<a class="xref" href="#compute-flavors" title="5.4.3. Flavors">Section 5.4.3, “Flavors”</a>.</p><p>For a list of optional parameters, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ nova help flavor-key</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.13.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a flavor</span> <a title="Permalink" class="permalink" href="#id-1.4.16.13.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Delete a specified flavor, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor delete FLAVOR_ID</pre></div></div></div><div class="sect1 " id="id-1.4.16.14"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage the OpenStack environment</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This section includes tasks specific to the OpenStack environment.</p><div class="sect2 " id="id-1.4.16.14.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Select hosts where instances are launched</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>With the appropriate permissions, you can select which
host instances are launched on and which roles can boot instances
on this host.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To select the host where instances are launched, use
the <code class="literal">--availability-zone ZONE:HOST:NODE</code> parameter on the
<code class="command">openstack server create</code> command.</p><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server create --image IMAGE --flavor m1.tiny \
  --key-name KEY --availability-zone ZONE:HOST:NODE \
  --nic net-id=UUID SERVER</pre></div><div id="id-1.4.16.14.3.3.1.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>HOST is an optional parameter. In such cases,
use the <code class="literal">--availability-zone ZONE::NODE</code>.</p></div></li><li class="step "><p>To specify which roles can launch an instance on a
specified host, enable the <code class="literal">create:forced_host</code> option in
the <code class="literal">policy.json</code> file. By default, this option is
enabled for only the admin role. If you see <code class="literal">Forbidden (HTTP 403)</code>
in return, then you are not using admin credentials.</p></li><li class="step "><p>To view the list of valid zones, use the
<code class="command">openstack availability zone list</code> command.</p><div class="verbatim-wrap"><pre class="screen">$ openstack availability zone list
+-----------+-------------+
| Zone Name | Zone Status |
+-----------+-------------+
| zone1     | available   |
| zone2     | available   |
+-----------+-------------+</pre></div></li><li class="step "><p>To view the list of valid compute hosts, use the
<code class="command">openstack host list</code> command.</p><div class="verbatim-wrap"><pre class="screen">$ openstack host list
+----------------+-------------+----------+
| Host Name      | Service     | Zone     |
+----------------+-------------+----------+
| compute01      | compute     | nova     |
| compute02      | compute     | nova     |
+----------------+-------------+----------+</pre></div></li><li class="step "><p>To view the list of valid compute nodes, use the
<code class="command">openstack hypervisor list</code> command.</p><div class="verbatim-wrap"><pre class="screen">$ openstack hypervisor list
+----+---------------------+
| ID | Hypervisor Hostname |
+----+---------------------+
|  1 | server2             |
|  2 | server3             |
|  3 | server4             |
+----+---------------------+</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.14.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Consider NUMA topology when booting instances</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>NUMA topology can exist on both the physical hardware of the host, and the
virtual hardware of the instance. OpenStack Compute uses libvirt to tune
instances to take advantage of NUMA topologies. The libvirt driver boot
process looks at the NUMA topology field of both the instance and the host it
is being booted on, and uses that information to generate an appropriate
configuration.</p><p>If the host is NUMA capable, but the instance has not requested a NUMA
topology, Compute attempts to pack the instance into a single cell.
If this fails, though, Compute will not continue to try.</p><p>If the host is NUMA capable, and the instance has requested a specific NUMA
topology, Compute will try to pin the vCPUs of different NUMA cells
on the instance to the corresponding NUMA cells on the host. It will also
expose the NUMA topology of the instance to the guest OS.</p><p>If you want Compute to pin a particular vCPU as part of this process,
set the <code class="literal">vcpu_pin_set</code> parameter in the <code class="literal">nova.conf</code> configuration
file. For more information about the <code class="literal">vcpu_pin_set</code> parameter, see the
Configuration Reference Guide.</p></div><div class="sect2 " id="id-1.4.16.14.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Evacuate instances</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>If a hardware malfunction or other error causes a cloud compute node to fail,
you can evacuate instances to make them available again. You can optionally
include the target host on the <code class="command">nova evacuate</code> command. If you omit
the host, the scheduler chooses the target host.</p><p>To preserve user data on the server disk, configure shared storage on the
target host. When you evacuate the instance, Compute detects whether shared
storage is available on the target host. Also, you must validate that the
current VM host is not operational. Otherwise, the evacuation fails.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To find a host for the evacuated instance, list all hosts:</p><div class="verbatim-wrap"><pre class="screen">$ openstack host list</pre></div></li><li class="step "><p>Evacuate the instance. You can use the <code class="literal">--password PWD</code> option
to pass the instance password to the command. If you do not specify a
password, the command generates and prints one after it finishes
successfully. The following command evacuates a server from a failed host
to HOST_B.</p><div class="verbatim-wrap"><pre class="screen">$ nova evacuate EVACUATED_SERVER_NAME HOST_B</pre></div><p>The command rebuilds the instance from the original image or volume and
returns a password. The command preserves the original configuration, which
includes the instance ID, name, uid, IP address, and so on.</p><div class="verbatim-wrap"><pre class="screen">+-----------+--------------+
| Property  |    Value     |
+-----------+--------------+
| adminPass | kRAJpErnT4xZ |
+-----------+--------------+</pre></div></li><li class="step "><p>To preserve the user disk data on the evacuated server, deploy Compute
with a shared file system. To configure your system, see
<a class="xref" href="#section-configuring-compute-migrations" title="5.4.9. Configure migrations">Section 5.4.9, “Configure migrations”</a>.
The following example does not change the password.</p><div class="verbatim-wrap"><pre class="screen">$ nova evacuate EVACUATED_SERVER_NAME HOST_B --on-shared-storage</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.14.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Migrate a single instance to another compute host</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When you want to move an instance from one compute host to another,
you can use the <code class="command">openstack server migrate</code> command. The scheduler
chooses the destination compute host based on its settings. This process does
not assume that the instance has shared storage available on the
target host. If you are using SSH tunneling, you must ensure that
each node is configured with SSH key authentication so that the
Compute service can use SSH to move disks to other nodes.
For more information, see <a class="xref" href="#clinovamigratecfgssh" title="14.12.5. Configure SSH between compute nodes">Section 14.12.5, “Configure SSH between compute nodes”</a>.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To list the VMs you want to migrate, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack server list</pre></div></li><li class="step "><p>Use the <code class="command">openstack server migrate</code> command.</p><div class="verbatim-wrap"><pre class="screen">$ openstack server migrate --live TARGET_HOST VM_INSTANCE</pre></div></li><li class="step "><p>To migrate an instance and watch the status, use this example script:</p><div class="verbatim-wrap highlight bash"><pre class="screen">#!/bin/bash

# Provide usage
usage() {
echo "Usage: $0 VM_ID"
exit 1
}

[[ $# -eq 0 ]] &amp;&amp; usage

# Migrate the VM to an alternate hypervisor
echo -n "Migrating instance to alternate host"
VM_ID=$1
nova migrate $VM_ID
VM_OUTPUT=`nova show $VM_ID`
VM_STATUS=`echo "$VM_OUTPUT" | grep status | awk '{print $4}'`
while [[ "$VM_STATUS" != "VERIFY_RESIZE" ]]; do
echo -n "."
sleep 2
VM_OUTPUT=`nova show $VM_ID`
VM_STATUS=`echo "$VM_OUTPUT" | grep status | awk '{print $4}'`
done
nova resize-confirm $VM_ID
echo " instance migrated and resized."
echo;

# Show the details for the VM
echo "Updated instance details:"
nova show $VM_ID

# Pause to allow users to examine VM details
read -p "Pausing, press &lt;enter&gt; to exit."</pre></div></li></ol></div></div><div id="id-1.4.16.14.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you see this error, it means you are either
trying the command with the wrong credentials,
such as a non-admin user, or the <code class="literal">policy.json</code>
file prevents migration for your user:</p><p>
            <code class="literal">ERROR (Forbidden): Policy doesn't allow compute_extension:admin_actions:migrate
to be performed. (HTTP 403)</code>
          </p></div><div id="id-1.4.16.14.6.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>If you see an error similar to this message, SSH tunneling
was not set up between the compute nodes:</p><p>
            <code class="literal">ProcessExecutionError: Unexpected error while running command.</code>
          </p><p>
            <code class="literal">Stderr: u Host key verification failed.\r\n</code>
          </p></div><p>The instance is booted from a new host, but preserves its configuration
including its ID, name, any metadata, IP address, and other properties.</p></div><div class="sect2 " id="clinovamigratecfgssh"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure SSH between compute nodes</span> <a title="Permalink" class="permalink" href="#clinovamigratecfgssh">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>clinovamigratecfgssh</li></ul></div></div></div></div><p>If you are resizing or migrating an instance
between hypervisors, you might encounter an
SSH (Permission denied) error. Ensure that
each node is configured with SSH key authentication
so that the Compute service can use SSH
to move disks to other nodes.</p><p>To share a key pair between compute nodes,
complete the following steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>On the first node, obtain a key pair
(public key and private key). Use the root key
that is in the <code class="literal">/root/.ssh/id_rsa</code> and
<code class="literal">/root/.ssh/id_ras.pub</code> directories or
generate a new key pair.</p></li><li class="step "><p>Run <code class="command">setenforce 0</code> to put SELinux into
permissive mode.</p></li><li class="step "><p>Enable login abilities for the nova user:</p><div class="verbatim-wrap"><pre class="screen"># usermod -s /bin/bash nova</pre></div><p>Switch to the nova account.</p><div class="verbatim-wrap"><pre class="screen"># su nova</pre></div></li><li class="step "><p>As root, create the folder that is needed by SSH and place
the private key that you obtained in step 1 into this
folder:</p><div class="verbatim-wrap"><pre class="screen">mkdir -p /var/lib/nova/.ssh
cp &lt;private key&gt;  /var/lib/nova/.ssh/id_rsa
echo 'StrictHostKeyChecking no' &gt;&gt; /var/lib/nova/.ssh/config
chmod 600 /var/lib/nova/.ssh/id_rsa /var/lib/nova/.ssh/authorized_keys</pre></div></li><li class="step "><p>Repeat steps 2-4 on each node.</p><div id="id-1.4.16.14.7.4.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The nodes must share the same key pair, so do not generate
a new key pair for any subsequent nodes.</p></div></li><li class="step "><p>From the first node, where you created the SSH key, run:</p><div class="verbatim-wrap"><pre class="screen">ssh-copy-id -i &lt;pub key&gt; nova@remote-host</pre></div><p>This command installs your public key in a remote machine's <code class="literal">authorized_keys</code> folder.</p></li><li class="step "><p>Ensure that the nova user can now log in to each node without
using a password:</p><div class="verbatim-wrap"><pre class="screen"># su nova
$ ssh *computeNodeAddress*
$ exit</pre></div></li><li class="step "><p>As root on each node, restart both libvirt and the Compute services:</p><div class="verbatim-wrap"><pre class="screen"># systemctl restart libvirtd.service
# systemctl restart openstack-nova-compute.service</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.14.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage IP addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Each instance has a private, fixed IP address that is assigned when
the instance is launched. In addition, an instance can have a public
or floating IP address. Private IP addresses are used for
communication between instances, and public IP addresses are used
for communication with networks outside the cloud, including the
Internet.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>By default, both administrative and end users can associate floating IP
addresses with projects and instances. You can change user permissions for
managing IP addresses by updating the <code class="literal">/etc/nova/policy.json</code>
file. For basic floating-IP procedures, refer to the <a class="link" href="http://docs.openstack.org/user-guide/configure-access-and-security-for-instances.html#allocate-a-floating-ip-address-to-an-instance" target="_blank">Allocate a
floating address to an instance</a>
section in the OpenStack End User Guide.</p></li><li class="listitem "><p>For details on creating public networks using OpenStack Networking
(<code class="literal">neutron</code>), refer to <a class="xref" href="#networking-adv-features" title="9.9. Advanced features through API extensions">Section 9.9, “Advanced features through API extensions”</a>.
No floating IP addresses are created by default in OpenStack Networking.</p></li></ul></div><p>As an administrator using legacy networking (<code class="literal">nova-network</code>), you
can use the following bulk commands to list, create, and delete ranges
of floating IP addresses. These addresses can then be associated with
instances by end users.</p><div class="sect3 " id="id-1.4.16.14.8.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.12.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List addresses for all projects</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.8.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To list all floating IP addresses for all projects, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack floating ip list
+------------+---------------+---------------+--------+-----------+
| project_id | address       | instance_uuid | pool   | interface |
+------------+---------------+---------------+--------+-----------+
| None       | 172.24.4.225  | None          | public | eth0      |
| None       | 172.24.4.226  | None          | public | eth0      |
| None       | 172.24.4.227  | None          | public | eth0      |
| None       | 172.24.4.228  | None          | public | eth0      |
| None       | 172.24.4.229  | None          | public | eth0      |
| None       | 172.24.4.230  | None          | public | eth0      |
| None       | 172.24.4.231  | None          | public | eth0      |
| None       | 172.24.4.232  | None          | public | eth0      |
| None       | 172.24.4.233  | None          | public | eth0      |
| None       | 172.24.4.234  | None          | public | eth0      |
| None       | 172.24.4.235  | None          | public | eth0      |
| None       | 172.24.4.236  | None          | public | eth0      |
| None       | 172.24.4.237  | None          | public | eth0      |
| None       | 172.24.4.238  | None          | public | eth0      |
| None       | 192.168.253.1 | None          | test   | eth0      |
| None       | 192.168.253.2 | None          | test   | eth0      |
| None       | 192.168.253.3 | None          | test   | eth0      |
| None       | 192.168.253.4 | None          | test   | eth0      |
| None       | 192.168.253.5 | None          | test   | eth0      |
| None       | 192.168.253.6 | None          | test   | eth0      |
+------------+---------------+---------------+--------+-----------+</pre></div></div><div class="sect3 " id="id-1.4.16.14.8.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.12.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Bulk create floating IP addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.8.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To create a range of floating IP addresses, run:</p><div class="verbatim-wrap"><pre class="screen">$ nova floating-ip-bulk-create [--pool POOL_NAME] [--interface INTERFACE] RANGE_TO_CREATE</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova floating-ip-bulk-create --pool test 192.168.1.56/29</pre></div><p>By default, <code class="literal">floating-ip-bulk-create</code> uses the
<code class="literal">public</code> pool and <code class="literal">eth0</code> interface values.</p><div id="id-1.4.16.14.8.6.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>You should use a range of free IP addresses that is valid for your
network. If you are not sure, at least try to avoid the DHCP address
range:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Pick a small range (/29 gives an 8 address range, 6 of
which will be usable).</p></li><li class="listitem "><p>Use <code class="command">nmap</code> to check a range's availability. For example,
192.168.1.56/29 represents a small range of addresses
(192.168.1.56-63, with 57-62 usable), and you could run the
command <code class="command">nmap -sn 192.168.1.56/29</code> to check whether the entire
range is currently unused.</p></li></ul></div></div></div><div class="sect3 " id="id-1.4.16.14.8.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.12.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Bulk delete floating IP addresses</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.8.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To delete a range of floating IP addresses, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack floating ip delete RANGE_TO_DELETE</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ openstack floating ip delete 192.168.1.56/29</pre></div></div></div><div class="sect2 " id="id-1.4.16.14.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.12.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch and manage stacks using the CLI</span> <a title="Permalink" class="permalink" href="#id-1.4.16.14.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Orchestration service provides a template-based
orchestration engine. Administrators can use the orchestration engine
to create and manage OpenStack cloud infrastructure resources. For
example, an administrator can define storage, networking, instances,
and applications to use as a repeatable running environment.</p><p>Templates are used to create stacks, which are collections
of resources. For example, a stack might include instances,
floating IPs, volumes, security groups, or users.
The Orchestration service offers access to all OpenStack
core services through a single modular template, with additional
orchestration capabilities such as auto-scaling and basic
high availability.</p><p>For information about:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>basic creation and deletion of Orchestration stacks, refer
to the <a class="link" href="http://docs.openstack.org/user-guide/dashboard-stacks.html" target="_blank">OpenStack End User Guide</a></p></li><li class="listitem "><p><span class="bold"><strong>openstack</strong></span> CLI, see the <a class="link" href="http://docs.openstack.org/cli-reference/openstack.html" target="_blank">OpenStack Command-Line Interface
Reference</a></p></li></ul></div><div id="id-1.4.16.14.9.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <code class="literal">heat</code> CLI is deprecated in favor of <code class="literal">python-openstackclient</code>.
For a Python library, continue using <code class="literal">python-heatclient</code>.</p></div><p>As an administrator, you can also carry out stack functions
on behalf of your users. For example, to resume, suspend,
or delete a stack, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack stack resume STACK
$ openstack stack suspend STACK
$ openstack stack delete STACK</pre></div></div></div><div class="sect1 " id="manage-quotas"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage quotas</span> <a title="Permalink" class="permalink" href="#manage-quotas">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>manage-quotas</li></ul></div></div></div></div><p>To prevent system capacities from being exhausted without
notification, you can set up quotas. Quotas are operational
limits. For example, the number of gigabytes allowed for each
project can be controlled so that cloud resources are optimized.
Quotas can be enforced at both the project
and the project-user level.</p><p>Using the command-line interface, you can manage quotas for
the OpenStack Compute service, the OpenStack Block Storage service,
and the OpenStack Networking service.</p><p>The cloud operator typically changes default values because a
project requires more than ten volumes or 1 TB on a compute
node.</p><div id="id-1.4.16.15.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To view all projects, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack project list
+----------------------------------+----------+
| ID                               | Name     |
+----------------------------------+----------+
| e66d97ac1b704897853412fc8450f7b9 | admin    |
| bf4a37b885fe46bd86e999e50adad1d3 | services |
| 21bd1c7c95234fd28f589b60903606fa | tenant01 |
| f599c5cd1cba4125ae3d7caed08e288c | tenant02 |
+----------------------------------+----------+</pre></div><p>To display all current users for a project, run:</p><div class="verbatim-wrap"><pre class="screen">$ openstack user list --project PROJECT_NAME
+----------------------------------+--------+
| ID                               | Name   |
+----------------------------------+--------+
| ea30aa434ab24a139b0e85125ec8a217 | demo00 |
| 4f8113c1d838467cad0c2f337b3dfded | demo01 |
+----------------------------------+--------+</pre></div></div><p>Use <code class="literal">openstack quota show <em class="replaceable ">PROJECT_NAME</em></code> to list all quotas for a
project.</p><p>Use <code class="literal">openstack quota set <em class="replaceable ">PROJECT_NAME</em><em class="replaceable ">--parameters</em></code> to set quota
values.</p><div class="sect2 " id="id-1.4.16.15.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage Compute service quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrative user, you can use the <code class="command">nova quota-*</code>
commands, which are provided by the <code class="literal">python-novaclient</code>
package, to update the Compute service quotas for a specific project or
project user, as well as update the quota defaults for a new project.</p><p>
          <span class="bold"><strong>Compute quota descriptions</strong></span>
        </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Quota name</p>
                </th><th>
                  <p>Description</p>
                </th></tr></thead><tbody><tr><td>
                  <p>cores</p>
                </td><td>
                  <p>Number of instance cores (VCPUs) allowed per project.</p>
                </td></tr><tr><td>
                  <p>fixed-ips</p>
                </td><td>
                  <p>Number of fixed IP addresses allowed per project. This number
must be equal to or greater than the number of allowed
instances.</p>
                </td></tr><tr><td>
                  <p>floating-ips</p>
                </td><td>
                  <p>Number of floating IP addresses allowed per project.</p>
                </td></tr><tr><td>
                  <p>injected-file-content-bytes</p>
                </td><td>
                  <p>Number of content bytes allowed per injected file.</p>
                </td></tr><tr><td>
                  <p>injected-file-path-bytes</p>
                </td><td>
                  <p>Length of injected file path.</p>
                </td></tr><tr><td>
                  <p>injected-files</p>
                </td><td>
                  <p>Number of injected files allowed per project.</p>
                </td></tr><tr><td>
                  <p>instances</p>
                </td><td>
                  <p>Number of instances allowed per project.</p>
                </td></tr><tr><td>
                  <p>key-pairs</p>
                </td><td>
                  <p>Number of key pairs allowed per user.</p>
                </td></tr><tr><td>
                  <p>metadata-items</p>
                </td><td>
                  <p>Number of metadata items allowed per instance.</p>
                </td></tr><tr><td>
                  <p>ram</p>
                </td><td>
                  <p>Megabytes of instance ram allowed per project.</p>
                </td></tr><tr><td>
                  <p>security-groups</p>
                </td><td>
                  <p>Number of security groups per project.</p>
                </td></tr><tr><td>
                  <p>security-group-rules</p>
                </td><td>
                  <p>Number of rules per security group.</p>
                </td></tr><tr><td>
                  <p>server-groups</p>
                </td><td>
                  <p>Number of server groups per project.</p>
                </td></tr><tr><td>
                  <p>server-group-members</p>
                </td><td>
                  <p>Number of servers per server group.</p>
                </td></tr></tbody></table></div><div class="sect3 " id="id-1.4.16.15.8.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.13.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View and update Compute quotas for a project</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.16.15.8.5.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">14.13.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To view and update default quota values</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.5.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>List all default quotas for all projects:</p><div class="verbatim-wrap"><pre class="screen">$ openstack quota show --default

+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 10    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</pre></div></li><li class="step "><p>Update a default value for a new project, for example:</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-class-update --instances 15 default</pre></div></li></ol></div></div></div><div class="sect4 " id="id-1.4.16.15.8.5.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">14.13.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To view quota values for an existing project</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.5.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>List the currently set quota values for a project:</p><div class="verbatim-wrap"><pre class="screen">$ openstack quota show TENANT_NAME

+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 10    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</pre></div></li></ul></div></div></div><div class="sect4 " id="id-1.4.16.15.8.5.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">14.13.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To update quota values for an existing project</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.5.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Obtain the project ID.</p><div class="verbatim-wrap"><pre class="screen">$ tenant=$(openstack project show -f value -c id TENANT_NAME)</pre></div></li><li class="step "><p>Update a particular quota value.</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-update --QUOTA_NAME QUOTA_VALUE TENANT_ID</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-update --floating-ips 20 TENANT_NAME
$ openstack quota show TENANT_NAME
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 20    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</pre></div><div id="id-1.4.16.15.8.5.4.2.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To view a list of options for the <code class="command">nova quota-update</code> command,
run:</p><div class="verbatim-wrap"><pre class="screen">$ nova help quota-update</pre></div></div></li></ol></div></div></div></div><div class="sect3 " id="id-1.4.16.15.8.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.13.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View and update Compute quotas for a project user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect4 " id="id-1.4.16.15.8.6.2"><div class="titlepage"><div><div><h5 class="title"><span class="number">14.13.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To view quota values for a project user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.6.2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Place the user ID in a usable variable.</p><div class="verbatim-wrap"><pre class="screen">$ tenantUser=$(openstack user show -f value -c id USER_NAME)</pre></div></li><li class="step "><p>Place the user's project ID in a usable variable, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ tenant=$(openstack project show -f value -c id TENANT_NAME)</pre></div></li><li class="step "><p>List the currently set quota values for a project user.</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-show --user $tenantUser --tenant $tenant</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-show --user $tenantUser --tenant $tenant
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 20    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</pre></div></li></ol></div></div></div><div class="sect4 " id="id-1.4.16.15.8.6.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">14.13.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To update quota values for a project user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.6.3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Place the user ID in a usable variable.</p><div class="verbatim-wrap"><pre class="screen">$ tenantUser=$(openstack user show -f value -c id USER_NAME)</pre></div></li><li class="step "><p>Place the user's project ID in a usable variable, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ tenant=$(openstack project show -f value -c id TENANT_NAME)</pre></div></li><li class="step "><p>Update a particular quota value, as follows:</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-update  --user $tenantUser --QUOTA_NAME QUOTA_VALUE $tenant</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ nova quota-update --user $tenantUser --floating-ips 12 $tenant
$ nova quota-show --user $tenantUser --tenant $tenant
+-----------------------------+-------+
| Quota                       | Limit |
+-----------------------------+-------+
| instances                   | 10    |
| cores                       | 20    |
| ram                         | 51200 |
| floating_ips                | 12    |
| fixed_ips                   | -1    |
| metadata_items              | 128   |
| injected_files              | 5     |
| injected_file_content_bytes | 10240 |
| injected_file_path_bytes    | 255   |
| key_pairs                   | 100   |
| security_groups             | 10    |
| security_group_rules        | 20    |
| server_groups               | 10    |
| server_group_members        | 10    |
+-----------------------------+-------+</pre></div><div id="id-1.4.16.15.8.6.3.2.3.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To view a list of options for the <code class="command">nova quota-update</code> command,
run:</p><div class="verbatim-wrap"><pre class="screen">$ nova help quota-update</pre></div></div></li></ol></div></div></div><div class="sect4 " id="id-1.4.16.15.8.6.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">14.13.1.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To display the current quota usage for a project user</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.8.6.4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use <code class="command">nova absolute-limits</code> to get a list of the
current quota values and the current quota usage:</p><div class="verbatim-wrap"><pre class="screen">$ nova absolute-limits --tenant TENANT_NAME
+--------------------+------+-------+
| Name               | Used | Max   |
+--------------------+------+-------+
| Cores              | 0    | 20    |
| FloatingIps        | 0    | 10    |
| ImageMeta          | -    | 128   |
| Instances          | 0    | 10    |
| Keypairs           | -    | 100   |
| Personality        | -    | 5     |
| Personality Size   | -    | 10240 |
| RAM                | 0    | 51200 |
| SecurityGroupRules | -    | 20    |
| SecurityGroups     | 0    | 10    |
| Server Meta        | -    | 128   |
| ServerGroupMembers | -    | 10    |
| ServerGroups       | 0    | 10    |
+--------------------+------+-------+</pre></div></div></div></div><div class="sect2 " id="id-1.4.16.15.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.13.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage Block Storage service quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrative user, you can update the OpenStack Block
Storage service quotas for a project. You can also update the quota
defaults for a new project.</p><p>
          <span class="bold"><strong>Block Storage quotas</strong></span>
        </p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col class="c1" /><col class="c2" /></colgroup><thead><tr><th>
                  <p>Property name</p>
                </th><th>
                  <p>Defines the number of</p>
                </th></tr></thead><tbody><tr><td>
                  <p>gigabytes</p>
                </td><td>
                  <p>Volume gigabytes allowed for each project.</p>
                </td></tr><tr><td>
                  <p>snapshots</p>
                </td><td>
                  <p>Volume snapshots allowed for each project.</p>
                </td></tr><tr><td>
                  <p>volumes</p>
                </td><td>
                  <p>Volumes allowed for each project.</p>
                </td></tr></tbody></table></div><div class="sect3 " id="id-1.4.16.15.9.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.13.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View Block Storage quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.9.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Administrative users can view Block Storage service quotas.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Obtain the project ID.</p><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ project_id=$(openstack project show -f value -c id PROJECT_NAME)</pre></div></li><li class="step "><p>List the default quotas for a project:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-defaults PROJECT_ID</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-defaults $project_id
+-----------+-------+
|  Property | Value |
+-----------+-------+
| gigabytes |  1000 |
| snapshots |   10  |
|  volumes  |   10  |
+-----------+-------+</pre></div></li><li class="step "><p>View Block Storage service quotas for a project:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-show PROJECT_ID</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-show $project_id
+-----------+-------+
|  Property | Value |
+-----------+-------+
| gigabytes |  1000 |
| snapshots |   10  |
|  volumes  |   10  |
+-----------+-------+</pre></div></li><li class="step "><p>Show the current usage of a per-project quota:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-usage PROJECT_ID</pre></div><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-usage $project_id
+-----------+--------+----------+-------+
|    Type   | In_use | Reserved | Limit |
+-----------+--------+----------+-------+
| gigabytes |   0    |    0     |  1000 |
| snapshots |   0    |    0     |   10  |
|  volumes  |   0    |    0     |   15  |
+-----------+--------+----------+-------+</pre></div></li></ol></div></div></div><div class="sect3 " id="id-1.4.16.15.9.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.13.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit and update Block Storage service quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.9.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Administrative users can edit and update Block Storage
service quotas.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>To update a default value for a new project,
update the property in the <span class="guimenu ">cinder.quota</span>
section of the <code class="literal">/etc/cinder/cinder.conf</code> file.
For more information, see the <a class="link" href="http://docs.openstack.org/newton/config-reference/block-storage.html" target="_blank">Block Storage service</a>
in OpenStack Configuration Reference.</p></li><li class="step "><p>To update Block Storage service quotas for an existing project</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-update --QUOTA_NAME QUOTA_VALUE PROJECT_ID</pre></div><p>Replace <code class="literal">QUOTA_NAME</code> with the quota that is to be updated,
<code class="literal">QUOTA_VALUE</code> with the required new value, and <code class="literal">PROJECT_ID</code>
with the required project ID.</p><p>For example:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-update --volumes 15 $project_id
$ cinder quota-show $project_id
+-----------+-------+
|  Property | Value |
+-----------+-------+
| gigabytes |  1000 |
| snapshots |   10  |
|  volumes  |   15  |
+-----------+-------+</pre></div></li><li class="step "><p>To clear per-project quota limits:</p><div class="verbatim-wrap"><pre class="screen">$ cinder quota-delete PROJECT_ID</pre></div></li></ol></div></div></div></div><div class="sect2 " id="id-1.4.16.15.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.13.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage Networking service quotas</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A quota limits the number of available resources. A default
quota might be enforced for all projects. When you try to create
more resources than the quota allows, an error occurs:</p><div class="verbatim-wrap highlight ini"><pre class="screen">$ openstack network create test_net
 Quota exceeded for resources: ['network']</pre></div><p>Per-project quota configuration is also supported by the quota
extension API. See <a class="xref" href="#cfg-quotas-per-tenant" title="14.13.3.2. Configure per-project quotas">Section 14.13.3.2, “Configure per-project quotas”</a> for details.</p><div class="sect3 " id="id-1.4.16.15.10.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.13.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Basic quota configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.16.15.10.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In the Networking default quota mechanism, all projects have
the same quota values, such as the number of resources that a
project can create.</p><p>The quota value is defined in the OpenStack Networking
<code class="literal">/etc/neutron/neutron.conf</code> configuration file. This example shows the
default quota values:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[quotas]
# number of networks allowed per tenant, and minus means unlimited
quota_network = 10

# number of subnets allowed per tenant, and minus means unlimited
quota_subnet = 10

# number of ports allowed per tenant, and minus means unlimited
quota_port = 50

# default driver to use for quota checks
quota_driver = neutron.quota.ConfDriver</pre></div><p>OpenStack Networking also supports quotas for L3 resources:
router and floating IP. Add these lines to the
<code class="literal">quotas</code> section in the <code class="literal">/etc/neutron/neutron.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[quotas]
# number of routers allowed per tenant, and minus means unlimited
quota_router = 10

# number of floating IPs allowed per tenant, and minus means unlimited
quota_floatingip = 50</pre></div><p>OpenStack Networking also supports quotas for security group
resources: number of security groups and the number of rules for
each security group. Add these lines to the
<code class="literal">quotas</code> section in the <code class="literal">/etc/neutron/neutron.conf</code> file:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[quotas]
# number of security groups per tenant, and minus means unlimited
quota_security_group = 10

# number of security rules allowed per tenant, and minus means unlimited
quota_security_group_rule = 100</pre></div></div><div class="sect3 " id="cfg-quotas-per-tenant"><div class="titlepage"><div><div><h4 class="title"><span class="number">14.13.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure per-project quotas</span> <a title="Permalink" class="permalink" href="#cfg-quotas-per-tenant">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>cfg-quotas-per-tenant</li></ul></div></div></div></div><p>OpenStack Networking also supports per-project quota limit by
quota extension API.</p><p>Use these commands to manage per-project quotas:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.4.16.15.10.6.4.1"><span class="term ">neutron quota-delete</span></dt><dd><p>Delete defined quotas for a specified project</p></dd><dt id="id-1.4.16.15.10.6.4.2"><span class="term ">neutron quota-list</span></dt><dd><p>Lists defined quotas for all projects</p></dd><dt id="id-1.4.16.15.10.6.4.3"><span class="term ">neutron quota-show</span></dt><dd><p>Shows quotas for a specified project</p></dd><dt id="id-1.4.16.15.10.6.4.4"><span class="term ">neutron quota-default-show</span></dt><dd><p>Show default quotas for a specified tenant</p></dd><dt id="id-1.4.16.15.10.6.4.5"><span class="term ">neutron quota-update</span></dt><dd><p>Updates quotas for a specified project</p></dd></dl></div><p>Only users with the <code class="literal">admin</code> role can change a quota value. By default,
the default set of quotas are enforced for all projects, so no
<code class="command">quota-create</code> command exists.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Configure Networking to show per-project quotas</p><p>Set the <code class="literal">quota_driver</code> option in the <code class="literal">/etc/neutron/neutron.conf</code> file.</p><div class="verbatim-wrap highlight ini"><pre class="screen">quota_driver = neutron.db.quota_db.DbQuotaDriver</pre></div><p>When you set this option, the output for Networking commands shows <code class="literal">quotas</code>.</p></li><li class="step "><p>List Networking extensions.</p><p>To list the Networking extensions, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ openstack extension list --network</pre></div><p>The command shows the <code class="literal">quotas</code> extension, which provides
per-project quota management support.</p><div id="id-1.4.16.15.10.6.6.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Many of the extensions shown below are supported in the Mitaka release and later.</p></div><div class="verbatim-wrap"><pre class="screen">+------------------------+------------------------+--------------------------+
| Name                   | Alias                  | Description              |
+------------------------+------------------------+--------------------------+
| ...                    | ...                    | ...                      |
| Quota management       | quotas                 | Expose functions for     |
| support                |                        | quotas management per    |
|                        |                        | tenant                   |
| ...                    | ...                    | ...                      |
+------------------------+------------------------+--------------------------+</pre></div></li><li class="step "><p>Show information for the quotas extension.</p><p>To show information for the <code class="literal">quotas</code> extension, run this command:</p><div class="verbatim-wrap"><pre class="screen">$ neutron ext-show quotas
+-------------+------------------------------------------------------------+
| Field       | Value                                                      |
+-------------+------------------------------------------------------------+
| alias       | quotas                                                     |
| description | Expose functions for quotas management per tenant          |
| links       |                                                            |
| name        | Quota management support                                   |
| namespace   | http://docs.openstack.org/network/ext/quotas-sets/api/v2.0 |
| updated     | 2012-07-29T10:00:00-00:00                                  |
+-------------+------------------------------------------------------------+</pre></div><div id="id-1.4.16.15.10.6.6.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Only some plug-ins support per-project quotas.
Specifically, Open vSwitch, Linux Bridge, and VMware NSX
support them, but new versions of other plug-ins might
bring additional functionality. See the documentation for
each plug-in.</p></div></li><li class="step "><p>List projects who have per-project quota support.</p><p>The <code class="command">neutron quota-list</code> command lists projects for which the
per-project quota is enabled. The command does not list projects with
default quota support. You must be an administrative user to run this
command:</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-list
+------------+---------+------+--------+--------+----------------------------------+
| floatingip | network | port | router | subnet | tenant_id                        |
+------------+---------+------+--------+--------+----------------------------------+
|         20 |       5 |   20 |     10 |      5 | 6f88036c45344d9999a1f971e4882723 |
|         25 |      10 |   30 |     10 |     10 | bff5c9455ee24231b5bc713c1b96d422 |
+------------+---------+------+--------+--------+----------------------------------+</pre></div></li><li class="step "><p>Show per-project quota values.</p><p>The <code class="command">neutron quota-show</code> command reports the current
set of quota limits for the specified project.
Non-administrative users can run this command without the
<code class="literal">--tenant_id</code> parameter. If per-project quota limits are
not enabled for the project, the command shows the default
set of quotas.</p><div id="id-1.4.16.15.10.6.6.5.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Additional quotas added in the Mitaka release include <code class="literal">security_group</code>,
<code class="literal">security_group_rule</code>, <code class="literal">subnet</code>, and <code class="literal">subnetpool</code>.</p></div><div class="verbatim-wrap"><pre class="screen">$ neutron quota-show --tenant_id 6f88036c45344d9999a1f971e4882723
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 10    |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10    |
| subnetpool          | -1    |
+---------------------+-------+</pre></div><p>The following command shows the command output for a
non-administrative user.</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-show
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 10    |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10    |
| subnetpool          | -1    |
+---------------------+-------+</pre></div></li><li class="step "><p>Update quota values for a specified project.</p><p>Use the <code class="command">neutron quota-update</code> command to
update a quota for a specified project.</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 --network 5
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 5     |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10    |
| subnetpool          | -1    |
+---------------------+-------+</pre></div><p>You can update quotas for multiple resources through one
command.</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 --subnet 5 --port 20
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 5     |
| port                | 20    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 5     |
| subnetpool          | -1    |
+---------------------+-------+</pre></div><p>To update the limits for an L3 resource such as, router
or floating IP, you must define new values for the quotas
after the <code class="literal">--</code> directive.</p><p>This example updates the limit of the number of floating
IPs for the specified project.</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 --floatingip 20
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 20    |
| network             | 5     |
| port                | 20    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 5     |
| subnetpool          | -1    |
+---------------------+-------+</pre></div><p>You can update the limits of multiple resources by
including L2 resources and L3 resource through one
command:</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-update --tenant_id 6f88036c45344d9999a1f971e4882723 \
  --network 3 --subnet 3 --port 3 --floatingip 3 --router 3
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 3     |
| network             | 3     |
| port                | 3     |
| rbac_policy         | 10    |
| router              | 3     |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 3     |
| subnetpool          | -1    |
+---------------------+-------+</pre></div></li><li class="step "><p>Delete per-project quota values.</p><p>To clear per-project quota limits, use the
<code class="command">neutron quota-delete</code> command.</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-delete --tenant_id 6f88036c45344d9999a1f971e4882723
 Deleted quota: 6f88036c45344d9999a1f971e4882723</pre></div><p>After you run this command, you can see that quota
values for the project are reset to the default values.</p><div class="verbatim-wrap"><pre class="screen">$ neutron quota-show --tenant_id 6f88036c45344d9999a1f971e4882723
+---------------------+-------+
| Field               | Value |
+---------------------+-------+
| floatingip          | 50    |
| network             | 10    |
| port                | 50    |
| rbac_policy         | 10    |
| router              | 10    |
| security_group      | 10    |
| security_group_rule | 100   |
| subnet              | 10     |
| subnetpool          | -1    |
+---------------------+-------+</pre></div></li></ol></div></div></div></div></div><div class="sect1 " id="id-1.4.16.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Analyze log files</span> <a title="Permalink" class="permalink" href="#id-1.4.16.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Use the swift command-line client for Object Storage to analyze log files.</p><p>The swift client is simple to use, scalable, and flexible.</p><p>Use the swift client <code class="literal">-o</code> or <code class="literal">-output</code> option to get
short answers to questions about logs.</p><p>You can use the <code class="literal">-o</code> or <code class="literal">--output</code> option with a single object
download to redirect the command output to a specific file or to STDOUT
(<code class="literal">-</code>). The ability to redirect the output to STDOUT enables you to
pipe (<code class="literal">|</code>) data without saving it to disk first.</p><div class="sect2 " id="id-1.4.16.16.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.14.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upload and analyze log files</span> <a title="Permalink" class="permalink" href="#id-1.4.16.16.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>This example assumes that <code class="literal">logtest</code> directory contains the
following log files.</p><div class="verbatim-wrap"><pre class="screen">2010-11-16-21_access.log
2010-11-16-22_access.log
2010-11-15-21_access.log
2010-11-15-22_access.log</pre></div><p>Each file uses the following line format.</p><div class="verbatim-wrap"><pre class="screen">Nov 15 21:53:52 lucid64 proxy-server - 127.0.0.1 15/Nov/2010/22/53/52 DELETE /v1/AUTH_cd4f57824deb4248a533f2c28bf156d3/2eefc05599d44df38a7f18b0b42ffedd HTTP/1.0 204 - \
 - test%3Atester%2CAUTH_tkcdab3c6296e249d7b7e2454ee57266ff - - - txaba5984c-aac7-460e-b04b-afc43f0c6571 - 0.0432</pre></div></li><li class="step "><p>Change into the <code class="literal">logtest</code> directory:</p><div class="verbatim-wrap"><pre class="screen">$ cd logtest</pre></div></li><li class="step "><p>Upload the log files into the <code class="literal">logtest</code> container:</p><div class="verbatim-wrap"><pre class="screen">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing upload logtest *.log</pre></div><div class="verbatim-wrap"><pre class="screen">2010-11-16-21_access.log
2010-11-16-22_access.log
2010-11-15-21_access.log
2010-11-15-22_access.log</pre></div></li><li class="step "><p>Get statistics for the account:</p><div class="verbatim-wrap"><pre class="screen">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing \
-q stat</pre></div><div class="verbatim-wrap"><pre class="screen">Account: AUTH_cd4f57824deb4248a533f2c28bf156d3
Containers: 1
Objects: 4
Bytes: 5888268</pre></div></li><li class="step "><p>Get statistics for the <code class="literal">logtest</code> container:</p><div class="verbatim-wrap"><pre class="screen">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing \
stat logtest</pre></div><div class="verbatim-wrap"><pre class="screen">Account: AUTH_cd4f57824deb4248a533f2c28bf156d3
Container: logtest
Objects: 4
Bytes: 5864468
Read ACL:
Write ACL:</pre></div></li><li class="step "><p>List all objects in the logtest container:</p><div class="verbatim-wrap"><pre class="screen">$ swift -A http:///swift-auth.com:11000/v1.0 -U test:tester -K testing \
list logtest</pre></div><div class="verbatim-wrap"><pre class="screen">2010-11-15-21_access.log
2010-11-15-22_access.log
2010-11-16-21_access.log
2010-11-16-22_access.log</pre></div></li></ol></div></div></div><div class="sect2 " id="id-1.4.16.16.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.14.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Download and analyze an object</span> <a title="Permalink" class="permalink" href="#id-1.4.16.16.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This example uses the <code class="literal">-o</code> option and a hyphen (<code class="literal">-</code>) to get
information about an object.</p><p>Use the <code class="command">swift download</code> command to download the object. On this
command, stream the output to <code class="literal">awk</code> to break down requests by return
code and the date <code class="literal">2200 on November 16th, 2010</code>.</p><p>Using the log line format, find the request type in column 9 and the
return code in column 12.</p><p>After <code class="literal">awk</code> processes the output, it pipes it to <code class="literal">sort</code> and <code class="literal">uniq
-c</code> to sum up the number of occurrences for each request type and
return code combination.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Download an object:</p><div class="verbatim-wrap"><pre class="screen">$ swift -A http://swift-auth.com:11000/v1.0 -U test:tester -K testing \
     download -o - logtest 2010-11-16-22_access.log | awk '{ print \
     $9""$12}' | sort | uniq -c</pre></div><div class="verbatim-wrap"><pre class="screen">805 DELETE-204
12 DELETE-404
2 DELETE-409
723 GET-200
142 GET-204
74 GET-206
80 GET-304
34 GET-401
5 GET-403
18 GET-404
166 GET-412
2 GET-416
50 HEAD-200
17 HEAD-204
20 HEAD-401
8 HEAD-404
30 POST-202
25 POST-204
22 POST-400
6 POST-404
842 PUT-201
2 PUT-202
32 PUT-400
4 PUT-403
4 PUT-404
2 PUT-411
6 PUT-412
6 PUT-413
2 PUT-422
8 PUT-499</pre></div></li><li class="step "><p>Discover how many PUT requests are in each log file.</p><p>Use a bash for loop with awk and swift with the <code class="literal">-o</code> or
<code class="literal">--output</code> option and a hyphen (<code class="literal">-</code>) to discover how many
PUT requests are in each log file.</p><p>Run the <code class="command">swift list</code> command to list objects in the logtest
container. Then, for each item in the list, run the
<code class="command">swift download -o -</code> command. Pipe the output into grep to
filter the PUT requests. Finally, pipe into <code class="literal">wc -l</code> to count the lines.</p><div class="verbatim-wrap"><pre class="screen">$ for f in `swift -A http://swift-auth.com:11000/v1.0 -U test:tester \
 -K testing list logtest` ; \
        do  echo -ne "PUTS - " ; swift -A \
        http://swift-auth.com:11000/v1.0 -U test:tester \
        -K testing download -o -  logtest $f | grep PUT | wc -l ; \
    done</pre></div><div class="verbatim-wrap"><pre class="screen">2010-11-15-21_access.log - PUTS - 402
2010-11-15-22_access.log - PUTS - 1091
2010-11-16-21_access.log - PUTS - 892
2010-11-16-22_access.log - PUTS - 910</pre></div></li><li class="step "><p>List the object names that begin with a specified string.</p></li><li class="step "><p>Run the <code class="command">swift list -p 2010-11-15</code> command to list objects
in the logtest container that begin with the <code class="literal">2010-11-15</code> string.</p></li><li class="step "><p>For each item in the list, run the <code class="command">swift download -o -</code> command.</p></li><li class="step "><p>Pipe the output to <code class="command">grep</code> and <code class="command">wc</code>.
Use the <code class="command">echo</code> command to display the object name.</p><div class="verbatim-wrap"><pre class="screen">$ for f in `swift -A http://swift-auth.com:11000/v1.0 -U test:tester \
 -K testing list -p 2010-11-15 logtest` ; \
        do  echo -ne "$f - PUTS - " ; swift -A \
        http://127.0.0.1:11000/v1.0 -U test:tester \
        -K testing download -o - logtest $f | grep PUT | wc -l ; \
      done</pre></div><div class="verbatim-wrap"><pre class="screen">2010-11-15-21_access.log - PUTS - 402
2010-11-15-22_access.log - PUTS - 910</pre></div></li></ol></div></div></div></div><div class="sect1 " id="id-1.4.16.17"><div class="titlepage"><div><div><h2 class="title"><span class="number">14.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage Block Storage scheduling</span> <a title="Permalink" class="permalink" href="#id-1.4.16.17">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>As an administrative user, you have some control over which volume
back end your volumes reside on. You can specify affinity or
anti-affinity between two volumes. Affinity between volumes means
that they are stored on the same back end, whereas anti-affinity
means that they are stored on different back ends.</p><p>For information on how to set up multiple back ends for Cinder,
refer to <a class="xref" href="#multi-backend" title="7.2.4. Configure multiple-storage back ends">Section 7.2.4, “Configure multiple-storage back ends”</a>.</p><div class="sect2 " id="id-1.4.16.17.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">14.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example Usages</span> <a title="Permalink" class="permalink" href="#id-1.4.16.17.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create a new volume on the same back end as Volume_A:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --hint same_host=Volume_A-UUID \
  --size SIZE VOLUME_NAME</pre></div></li><li class="step "><p>Create a new volume on a different back end than Volume_A:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --hint different_host=Volume_A-UUID \
  --size SIZE VOLUME_NAME</pre></div></li><li class="step "><p>Create a new volume on the same back end as Volume_A and Volume_B:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --hint same_host=Volume_A-UUID \
  --hint same_host=Volume_B-UUID --size SIZE VOLUME_NAME</pre></div><p>Or:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --hint same_host="[Volume_A-UUID, \
  Volume_B-UUID]" --size SIZE VOLUME_NAME</pre></div></li><li class="step "><p>Create a new volume on a different back end than both Volume_A and
Volume_B:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --hint different_host=Volume_A-UUID \
  --hint different_host=Volume_B-UUID --size SIZE VOLUME_NAME</pre></div><p>Or:</p><div class="verbatim-wrap"><pre class="screen">$ openstack volume create --hint different_host="[Volume_A-UUID, \
  Volume_B-UUID]" --size SIZE VOLUME_NAME</pre></div></li></ol></div></div></div></div></div><div class="chapter " id="id-1.4.17"><div class="titlepage"><div><div><h1 class="title"><span class="number">15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cross-project features</span> <a title="Permalink" class="permalink" href="#id-1.4.17">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.17.4"><span class="number">15.1 </span><span class="name">Cross-origin resource sharing</span></a></span></dt></dl></div></div><p>Many features are common to all the OpenStack services and are consistent in
their configuration and deployment patterns. Unless explicitly noted, you can
safely assume that the features in this chapter are supported and configured
in a consistent manner.</p><div class="sect1 " id="id-1.4.17.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cross-origin resource sharing</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.4.17.4.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>This is a new feature in OpenStack Liberty.</p></div><p>OpenStack supports <a class="xref" href="#term-cross-origin-resource-sharing-cors" title="Cross-Origin Resource Sharing (CORS)">Cross-Origin Resource Sharing (CORS)</a>, a W3C
specification defining a contract by which the single-origin policy of a user
agent (usually a browser) may be relaxed. It permits the javascript engine
to access an API that does not reside on the same domain, protocol, or port.</p><p>This feature is most useful to organizations which maintain one or more
custom user interfaces for OpenStack, as it permits those interfaces to access
the services directly, rather than requiring an intermediate proxy server. It
can, however, also be misused by malicious actors; please review the
security advisory below for more information.</p><div class="sect2 " id="id-1.4.17.4.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">15.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling CORS with configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In most cases, CORS support is built directly into the service itself. To
enable it, simply follow the configuration options exposed in the default
configuration file, or add it yourself according to the pattern below.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[cors]
allowed_origin = https://first_ui.example.com
max_age = 3600
allow_methods = GET,POST,PUT,DELETE
allow_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header
expose_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header</pre></div><p>Additional origins can be explicitly added. To express this in
your configuration file, first begin with a <code class="literal">[cors]</code> group as above,
into which you place your default configuration values. Then, add as many
additional configuration groups as necessary, naming them
<code class="literal">[cors.{something}]</code> (each name must be unique). The purpose of the
suffix to <code class="literal">cors.</code> is legibility, we recommend using a reasonable
human-readable string:</p><div class="verbatim-wrap highlight ini"><pre class="screen">[cors.ironic_webclient]
# CORS Configuration for a hypothetical ironic webclient, which overrides
# authentication
allowed_origin = https://ironic.example.com:443
allow_credentials = True

[cors.horizon]
# CORS Configuration for horizon, which uses global options.
allowed_origin = https://horizon.example.com:443

[cors.wildcard]
# CORS Configuration for the CORS specified domain wildcard, which only
# permits HTTP GET requests.
allowed_origin = *
allow_methods = GET</pre></div><p>For more information about CORS configuration,
see <a class="link" href="http://docs.openstack.org/newton/config-reference/common-configurations/cors.html" target="_blank">cross-origin resource sharing</a>
in OpenStack Configuration Reference.</p></div><div class="sect2 " id="id-1.4.17.4.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">15.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling CORS with PasteDeploy</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>CORS can also be configured using PasteDeploy. First of all, ensure that
OpenStack's <code class="literal">oslo_middleware</code> package (version 2.4.0 or later) is
available in the Python environment that is running the service. Then,
add the following configuration block to your <code class="literal">paste.ini</code> file.</p><div class="verbatim-wrap highlight ini"><pre class="screen">[filter:cors]
paste.filter_factory = oslo_middleware.cors:filter_factory
allowed_origin = https://website.example.com:443
max_age = 3600
allow_methods = GET,POST,PUT,DELETE
allow_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header
expose_headers = Content-Type,Cache-Control,Content-Language,Expires,Last-Modified,Pragma,X-Custom-Header</pre></div><div id="id-1.4.17.4.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>To add an additional domain in oslo_middleware v2.4.0, add
another filter. In v3.0.0 and after, you may add multiple domains
in the above <code class="literal">allowed_origin</code> field, separated by commas.</p></div></div><div class="sect2 " id="id-1.4.17.4.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">15.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Security concerns</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>CORS specifies a wildcard character <code class="literal">*</code>, which permits access to all user
agents, regardless of domain, protocol, or host. While there are valid use
cases for this approach, it also permits a malicious actor to create a
convincing facsimile of a user interface, and trick users into revealing
authentication credentials. Please carefully evaluate your use case and the
relevant documentation for any risk to your organization.</p><div id="id-1.4.17.4.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The CORS specification does not support using this wildcard as
a part of a URI. Setting <code class="literal">allowed_origin</code> to <code class="literal">*</code> would work, while
<code class="literal">*.openstack.org</code> would not.</p></div></div><div class="sect2 " id="id-1.4.17.4.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">15.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>CORS is very easy to get wrong, as even one incorrect property will violate
the prescribed contract. Here are some steps you can take to troubleshoot
your configuration.</p><div class="sect3 " id="id-1.4.17.4.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Check the service log</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The CORS middleware used by OpenStack provides verbose debug logging that
should reveal most configuration problems. Here are some example log
messages, and how to resolve them.</p></div><div class="sect3 " id="id-1.4.17.4.8.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.4">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
            <code class="literal">CORS request from origin 'http://example.com' not permitted.</code>
          </p></div><div class="sect3 " id="id-1.4.17.4.8.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A request was received from the origin <code class="literal">http://example.com</code>, however this
origin was not found in the permitted list. The cause may be a superfluous
port notation (ports 80 and 443 do not need to be specified). To correct,
ensure that the configuration property for this host is identical to the
host indicated in the log message.</p></div><div class="sect3 " id="id-1.4.17.4.8.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
            <code class="literal">Request method 'DELETE' not in permitted list: GET,PUT,POST</code>
          </p></div><div class="sect3 " id="id-1.4.17.4.8.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A user agent has requested permission to perform a DELETE request, however
the CORS configuration for the domain does not permit this. To correct, add
this method to the <code class="literal">allow_methods</code> configuration property.</p></div><div class="sect3 " id="id-1.4.17.4.8.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Problem</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
            <code class="literal">Request header 'X-Custom-Header' not in permitted list: X-Other-Header</code>
          </p></div><div class="sect3 " id="id-1.4.17.4.8.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Solution</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A request was received with the header <code class="literal">X-Custom-Header</code>, which is not
permitted. Add this header to the <code class="literal">allow_headers</code> configuration
property.</p></div><div class="sect3 " id="id-1.4.17.4.8.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Open your browser's console log</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Most browsers provide helpful debug output when a CORS request is rejected.
Usually this happens when a request was successful, but the return headers on
the response do not permit access to a property which the browser is trying
to access.</p></div><div class="sect3 " id="id-1.4.17.4.8.11"><div class="titlepage"><div><div><h4 class="title"><span class="number">15.1.4.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manually construct a CORS request</span> <a title="Permalink" class="permalink" href="#id-1.4.17.4.8.11">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By using <code class="literal">curl</code> or a similar tool, you can trigger a CORS response with a
properly constructed HTTP request. An example request and response might look
like this.</p><p>Request example:</p><div class="verbatim-wrap"><pre class="screen">$ curl -I -X OPTIONS https://api.example.com/api -H "Origin: https://ui.example.com"</pre></div><p>Response example:</p><div class="verbatim-wrap"><pre class="screen">HTTP/1.1 204 No Content
Content-Length: 0
Access-Control-Allow-Origin: https://ui.example.com
Access-Control-Allow-Methods: GET,POST,PUT,DELETE
Access-Control-Expose-Headers: origin,authorization,accept,x-total,x-limit,x-marker,x-client,content-type
Access-Control-Allow-Headers: origin,authorization,accept,x-total,x-limit,x-marker,x-client,content-type
Access-Control-Max-Age: 3600</pre></div><p>If the service does not return any access control headers, check the service
log, such as <code class="literal">/var/log/upstart/ironic-api.log</code> for an indication on what
went wrong.</p></div></div></div></div><div class="chapter " id="id-1.4.18"><div class="titlepage"><div><div><h1 class="title"><span class="number">16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Appendix</span> <a title="Permalink" class="permalink" href="#id-1.4.18">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="sect1"><a href="#id-1.4.18.3"><span class="number">16.1 </span><span class="name">Community support</span></a></span></dt></dl></div></div><div class="sect1 " id="id-1.4.18.3"><div class="titlepage"><div><div><h2 class="title"><span class="number">16.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Community support</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following resources are available to help you run and use OpenStack.
The OpenStack community constantly improves and adds to the main
features of OpenStack, but if you have any questions, do not hesitate to
ask. Use the following resources to get OpenStack support and
troubleshoot your installations.</p><div class="sect2 " id="id-1.4.18.3.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Documentation</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>For the available OpenStack documentation, see
<a class="link" href="http://docs.openstack.org" target="_blank">docs.openstack.org</a>.</p><p>To provide feedback on documentation, join and use the
<a class="link" href="mailto:openstack-docs@lists.openstack.org" target="_blank">openstack-docs@lists.openstack.org</a> mailing list at <a class="link" href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs" target="_blank">OpenStack
Documentation Mailing
List</a>,
join our IRC channel <code class="literal">#openstack-doc</code> on the freenode IRC network,
or <a class="link" href="https://bugs.launchpad.net/openstack-manuals/+filebug" target="_blank">report a
bug</a>.</p><p>The following books explain how to install an OpenStack cloud and its
associated components:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/install-guide-obs/" target="_blank">Installation Tutorial for openSUSE and SUSE Linux Enterprise</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/install-guide-rdo/" target="_blank">Installation Tutorial for Red Hat Enterprise Linux 7 and CentOS 7</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/install-guide-ubuntu/" target="_blank">Installation Tutorial for Ubuntu 16.04 (LTS)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/install-guide-debconf/" target="_blank">Installation Tutorial for Debian with Debconf</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/install-guide-debian/" target="_blank">Installation Tutorial for Debian</a>
            </p></li></ul></div><p>The following books explain how to configure and run an OpenStack cloud:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/arch-design/" target="_blank">Architecture Design Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/admin-guide/" target="_blank">Administrator Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/config-reference/" target="_blank">Configuration Reference</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/ops/" target="_blank">Operations Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/newton/networking-guide" target="_blank">Networking Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/ha-guide/" target="_blank">High Availability Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/sec/" target="_blank">Security Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/image-guide/" target="_blank">Virtual Machine Image Guide</a>
            </p></li></ul></div><p>The following books explain how to use the OpenStack Dashboard and
command-line clients:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/user-guide/" target="_blank">End User Guide</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/cli-reference/" target="_blank">Command-Line Interface Reference</a>
            </p></li></ul></div><p>The following documentation provides reference and guidance information
for the OpenStack APIs:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://developer.openstack.org/api-guide/quick-start/" target="_blank">API Guide</a>
            </p></li></ul></div><p>The following guide provides how to contribute to OpenStack documentation:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/contributor-guide/" target="_blank">Documentation Contributor Guide</a>
            </p></li></ul></div></div><div class="sect2 " id="id-1.4.18.3.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">ask.openstack.org</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>During the set up or testing of OpenStack, you might have questions
about how a specific task is completed or be in a situation where a
feature does not work correctly. Use the
<a class="link" href="https://ask.openstack.org" target="_blank">ask.openstack.org</a> site to ask questions
and get answers. When you visit the <a class="link" href="https://ask.openstack.org" target="_blank">https://ask.openstack.org</a> site, scan
the recently asked questions to see whether your question has already
been answered. If not, ask a new question. Be sure to give a clear,
concise summary in the title and provide as much detail as possible in
the description. Paste in your command output or stack traces, links to
screen shots, and any other information which might be useful.</p></div><div class="sect2 " id="id-1.4.18.3.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack mailing lists</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A great way to get answers and insights is to post your question or
problematic scenario to the OpenStack mailing list. You can learn from
and help others who might have similar issues. To subscribe or view the
archives, go to
<a class="link" href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack" target="_blank">http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack</a>. If you are
interested in the other mailing lists for specific projects or development,
refer to <a class="link" href="https://wiki.openstack.org/wiki/Mailing_Lists" target="_blank">Mailing Lists</a>.</p></div><div class="sect2 " id="id-1.4.18.3.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The OpenStack wiki</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <a class="link" href="https://wiki.openstack.org/" target="_blank">OpenStack wiki</a> contains a broad
range of topics but some of the information can be difficult to find or
is a few pages deep. Fortunately, the wiki search feature enables you to
search by title or content. If you search for specific information, such
as about networking or OpenStack Compute, you can find a large amount
of relevant material. More is being added all the time, so be sure to
check back often. You can find the search box in the upper-right corner
of any OpenStack wiki page.</p></div><div class="sect2 " id="id-1.4.18.3.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Launchpad Bugs area</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack community values your set up and testing efforts and wants
your feedback. To log a bug, you must sign up for a Launchpad account at
<a class="link" href="https://launchpad.net/+login" target="_blank">https://launchpad.net/+login</a>. You can view existing bugs and report bugs
in the Launchpad Bugs area. Use the search feature to determine whether
the bug has already been reported or already been fixed. If it still
seems like your bug is unreported, fill out a bug report.</p><p>Some tips:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Give a clear, concise summary.</p></li><li class="listitem "><p>Provide as much detail as possible in the description. Paste in your
command output or stack traces, links to screen shots, and any other
information which might be useful.</p></li><li class="listitem "><p>Be sure to include the software and package versions that you are
using, especially if you are using a development branch, such as,
<code class="literal">"Kilo release" vs git commit bc79c3ecc55929bac585d04a03475b72e06a3208</code>.</p></li><li class="listitem "><p>Any deployment-specific information is helpful, such as whether you
are using Ubuntu 14.04 or are performing a multi-node installation.</p></li></ul></div><p>The following Launchpad Bugs areas are available:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/cinder" target="_blank">Bugs: OpenStack Block Storage
(cinder)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/nova" target="_blank">Bugs: OpenStack Compute (nova)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/horizon" target="_blank">Bugs: OpenStack Dashboard
(horizon)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/keystone" target="_blank">Bugs: OpenStack Identity
(keystone)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/glance" target="_blank">Bugs: OpenStack Image service
(glance)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/neutron" target="_blank">Bugs: OpenStack Networking
(neutron)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/swift" target="_blank">Bugs: OpenStack Object Storage
(swift)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/murano" target="_blank">Bugs: Application catalog (murano)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/ironic" target="_blank">Bugs: Bare metal service (ironic)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/senlin" target="_blank">Bugs: Clustering service (senlin)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/magnum" target="_blank">Bugs: Container Infrastructure Management service (magnum)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/sahara" target="_blank">Bugs: Data processing service
(sahara)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/trove" target="_blank">Bugs: Database service (trove)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/fuel" target="_blank">Bugs: Deployment service (fuel)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/designate" target="_blank">Bugs: DNS service (designate)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/barbican" target="_blank">Bugs: Key Manager Service (barbican)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/monasca" target="_blank">Bugs: Monitoring (monasca)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/heat" target="_blank">Bugs: Orchestration (heat)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/cloudkitty" target="_blank">Bugs: Rating (cloudkitty)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/manila" target="_blank">Bugs: Shared file systems (manila)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/ceilometer" target="_blank">Bugs: Telemetry
(ceilometer)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/gnocchi" target="_blank">Bugs: Telemetry v3
(gnocchi)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/mistral" target="_blank">Bugs: Workflow service
(mistral)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/zaqar" target="_blank">Bugs: Messaging service
(zaqar)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/openstack-api-site" target="_blank">Bugs: OpenStack API Documentation
(developer.openstack.org)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://bugs.launchpad.net/openstack-manuals" target="_blank">Bugs: OpenStack Documentation
(docs.openstack.org)</a>
            </p></li></ul></div></div><div class="sect2 " id="id-1.4.18.3.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The OpenStack IRC channel</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The OpenStack community lives in the #openstack IRC channel on the
Freenode network. You can hang out, ask questions, or get immediate
feedback for urgent and pressing issues. To install an IRC client or use
a browser-based client, go to
<a class="link" href="https://webchat.freenode.net" target="_blank">https://webchat.freenode.net/</a>. You can
also use Colloquy (Mac OS X, <a class="link" href="http://colloquy.info/" target="_blank">http://colloquy.info/</a>), mIRC (Windows,
<a class="link" href="http://www.mirc.com/" target="_blank">http://www.mirc.com/</a>), or XChat (Linux). When you are in the IRC channel
and want to share code or command output, the generally accepted method
is to use a Paste Bin. The OpenStack project has one at
<a class="link" href="http://paste.openstack.org" target="_blank">http://paste.openstack.org</a>. Just paste your longer amounts of text or
logs in the web form and you get a URL that you can paste into the
channel. The OpenStack IRC channel is <code class="literal">#openstack</code> on
<code class="literal">irc.freenode.net</code>. You can find a list of all OpenStack IRC channels
at <a class="link" href="https://wiki.openstack.org/wiki/IRC" target="_blank">https://wiki.openstack.org/wiki/IRC</a>.</p></div><div class="sect2 " id="id-1.4.18.3.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Documentation feedback</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To provide feedback on documentation, join and use the
<a class="link" href="mailto:openstack-docs@lists.openstack.org" target="_blank">openstack-docs@lists.openstack.org</a> mailing list at <a class="link" href="http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs" target="_blank">OpenStack
Documentation Mailing
List</a>,
or <a class="link" href="https://bugs.launchpad.net/openstack-manuals/+filebug" target="_blank">report a
bug</a>.</p></div><div class="sect2 " id="id-1.4.18.3.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">16.1.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack distribution packages</span> <a title="Permalink" class="permalink" href="#id-1.4.18.3.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following Linux distributions provide community-supported packages
for OpenStack:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <span class="bold"><strong>Debian:</strong></span>
              <a class="link" href="https://wiki.debian.org/OpenStack" target="_blank">https://wiki.debian.org/OpenStack</a>
            </p></li><li class="listitem "><p>
              <span class="bold"><strong>CentOS, Fedora, and Red Hat Enterprise Linux:</strong></span>
              <a class="link" href="https://www.rdoproject.org/" target="_blank">https://www.rdoproject.org/</a>
            </p></li><li class="listitem "><p>
              <span class="bold"><strong>openSUSE and SUSE Linux Enterprise Server:</strong></span>
              <a class="link" href="https://en.opensuse.org/Portal:OpenStack" target="_blank">https://en.opensuse.org/Portal:OpenStack</a>
            </p></li><li class="listitem "><p>
              <span class="bold"><strong>Ubuntu:</strong></span>
              <a class="link" href="https://wiki.ubuntu.com/ServerTeam/CloudArchive" target="_blank">https://wiki.ubuntu.com/ServerTeam/CloudArchive</a>
            </p></li></ul></div></div></div></div><div class="glossary"><div class="titlepage"><div><div><h1 class="title"><span class="number"> </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Glossary</span> <a title="Permalink" class="permalink" href="#id-1.4.19">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>bk_openstack_admin.xml</li><li><span class="ds-label">ID: </span>book-upstream-admin</li></ul></div></div></div></div><div class="line"></div><p>This glossary offers a list of terms and definitions to define a
vocabulary for OpenStack-related concepts.</p><p>To add to OpenStack glossary, clone the <a class="link" href="https://git.openstack.org/cgit/openstack/openstack-manuals" target="_blank">openstack/openstack-manuals
repository</a> and
update the source file <code class="literal">doc/common/glossary.rst</code> through the
OpenStack contribution process.</p><div class="glossdiv" id="id-1.4.19.5"><h3 class="title">0-9</h3><dl><dt id="id-1.4.19.5.3"><span><span class="glossterm">6to4</span> <a title="Permalink" class="permalink" href="#id-1.4.19.5.3">#</a></span></dt><dd class="glossdef"><p>A mechanism that allows IPv6 packets to be transmitted
over an IPv4 network, providing a strategy for migrating to
IPv6.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.6"><h3 class="title">A</h3><dl><dt id="id-1.4.19.6.3"><span><span class="glossterm">absolute limit</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.3">#</a></span></dt><dd class="glossdef"><p>Impassable limits for guest VMs. Settings include total RAM
size, maximum number of vCPUs, and maximum disk size.</p></dd><dt id="id-1.4.19.6.4"><span><span class="glossterm">access control list (ACL)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.4">#</a></span></dt><dd class="glossdef"><p>A list of permissions attached to an object. An ACL specifies
which users or system processes have access to objects. It also
defines which operations can be performed on specified objects. Each
entry in a typical ACL specifies a subject and an operation. For
instance, the ACL entry <code class="literal">(Alice, delete)</code> for a file gives
Alice permission to delete the file.</p></dd><dt id="id-1.4.19.6.5"><span><span class="glossterm">access key</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.5">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Amazon EC2 access key. See EC2 access
key.</p></dd><dt id="id-1.4.19.6.6"><span><span class="glossterm">account</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.6">#</a></span></dt><dd class="glossdef"><p>The Object Storage context of an account. Do not confuse with a
user account from an authentication service, such as Active Directory,
/etc/passwd, OpenLDAP, OpenStack Identity, and so on.</p></dd><dt id="id-1.4.19.6.7"><span><span class="glossterm">account auditor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.7">#</a></span></dt><dd class="glossdef"><p>Checks for missing replicas and incorrect or corrupted objects
in a specified Object Storage account by running queries against the
back-end SQLite database.</p></dd><dt id="id-1.4.19.6.8"><span><span class="glossterm">account database</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.8">#</a></span></dt><dd class="glossdef"><p>A SQLite database that contains Object Storage accounts and
related metadata and that the accounts server accesses.</p></dd><dt id="id-1.4.19.6.9"><span><span class="glossterm">account reaper</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.9">#</a></span></dt><dd class="glossdef"><p>An Object Storage worker that scans for and deletes account
databases and that the account server has marked for deletion.</p></dd><dt id="id-1.4.19.6.10"><span><span class="glossterm">account server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.10">#</a></span></dt><dd class="glossdef"><p>Lists containers in Object Storage and stores container
information in the account database.</p></dd><dt id="id-1.4.19.6.11"><span><span class="glossterm">account service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.11">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that provides account services such
as list, create, modify, and audit. Do not confuse with OpenStack
Identity service, OpenLDAP, or similar user-account services.</p></dd><dt id="id-1.4.19.6.12"><span><span class="glossterm">accounting</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.12">#</a></span></dt><dd class="glossdef"><p>The Compute service provides accounting information through the
event notification and system usage data facilities.</p></dd><dt id="id-1.4.19.6.13"><span><span class="glossterm">Active Directory</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.13">#</a></span></dt><dd class="glossdef"><p>Authentication and identity service by Microsoft, based on LDAP.
Supported in OpenStack.</p></dd><dt id="id-1.4.19.6.14"><span><span class="glossterm">active/active configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.14">#</a></span></dt><dd class="glossdef"><p>In a high-availability setup with an active/active
configuration, several systems share the load together and if one
fails, the load is distributed to the remaining systems.</p></dd><dt id="id-1.4.19.6.15"><span><span class="glossterm">active/passive configuration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.15">#</a></span></dt><dd class="glossdef"><p>In a high-availability setup with an active/passive
configuration, systems are set up to bring additional resources online
to replace those that have failed.</p></dd><dt id="id-1.4.19.6.16"><span><span class="glossterm">address pool</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.16">#</a></span></dt><dd class="glossdef"><p>A group of fixed and/or floating IP addresses that are assigned
to a project and can be used by or assigned to the VM instances in a
project.</p></dd><dt id="id-1.4.19.6.17"><span><span class="glossterm">Address Resolution Protocol (ARP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.17">#</a></span></dt><dd class="glossdef"><p>The protocol by which layer-3 IP addresses are resolved into
layer-2 link local addresses.</p></dd><dt id="id-1.4.19.6.18"><span><span class="glossterm">admin API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.18">#</a></span></dt><dd class="glossdef"><p>A subset of API calls that are accessible to authorized
administrators and are generally not accessible to end users or the
public Internet. They can exist as a separate service (keystone) or
can be a subset of another API (nova).</p></dd><dt id="id-1.4.19.6.19"><span><span class="glossterm">admin server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.19">#</a></span></dt><dd class="glossdef"><p>In the context of the Identity service, the worker process that
provides access to the admin API.</p></dd><dt id="id-1.4.19.6.20"><span><span class="glossterm">administrator</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.20">#</a></span></dt><dd class="glossdef"><p>The person responsible for installing, configuring,
and managing an OpenStack cloud.</p></dd><dt id="id-1.4.19.6.21"><span><span class="glossterm">Advanced Message Queuing Protocol (AMQP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.21">#</a></span></dt><dd class="glossdef"><p>The open standard messaging protocol used by OpenStack
components for intra-service communications, provided by RabbitMQ,
Qpid, or ZeroMQ.</p></dd><dt id="id-1.4.19.6.22"><span><span class="glossterm">Advanced RISC Machine (ARM)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.22">#</a></span></dt><dd class="glossdef"><p>Lower power consumption CPU often found in mobile and embedded
devices. Supported by OpenStack.</p></dd><dt id="id-1.4.19.6.23"><span><span class="glossterm">alert</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.23">#</a></span></dt><dd class="glossdef"><p>The Compute service can send alerts through its notification
system, which includes a facility to create custom notification
drivers. Alerts can be sent to and displayed on the dashboard.</p></dd><dt id="id-1.4.19.6.24"><span><span class="glossterm">allocate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.24">#</a></span></dt><dd class="glossdef"><p>The process of taking a floating IP address from the address
pool so it can be associated with a fixed IP on a guest VM
instance.</p></dd><dt id="id-1.4.19.6.25"><span><span class="glossterm">Amazon Kernel Image (AKI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.25">#</a></span></dt><dd class="glossdef"><p>Both a VM container format and disk format. Supported by Image
service.</p></dd><dt id="id-1.4.19.6.26"><span><span class="glossterm">Amazon Machine Image (AMI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.26">#</a></span></dt><dd class="glossdef"><p>Both a VM container format and disk format. Supported by Image
service.</p></dd><dt id="id-1.4.19.6.27"><span><span class="glossterm">Amazon Ramdisk Image (ARI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.27">#</a></span></dt><dd class="glossdef"><p>Both a VM container format and disk format. Supported by Image
service.</p></dd><dt id="id-1.4.19.6.28"><span><span class="glossterm">Anvil</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.28">#</a></span></dt><dd class="glossdef"><p>A project that ports the shell script-based project named
DevStack to Python.</p></dd><dt id="id-1.4.19.6.29"><span><span class="glossterm">aodh</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.29">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; provides alarming functionality.</p></dd><dt id="id-1.4.19.6.30"><span><span class="glossterm">Apache</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.30">#</a></span></dt><dd class="glossdef"><p>The Apache Software Foundation supports the Apache community of
open-source software projects. These projects provide software
products for the public good.</p></dd><dt id="id-1.4.19.6.31"><span><span class="glossterm">Apache License 2.0</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.31">#</a></span></dt><dd class="glossdef"><p>All OpenStack core projects are provided under the terms of the
Apache License 2.0 license.</p></dd><dt id="id-1.4.19.6.32"><span><span class="glossterm">Apache Web Server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.32">#</a></span></dt><dd class="glossdef"><p>The most common web server software currently used on the
Internet.</p></dd><dt id="id-1.4.19.6.33"><span><span class="glossterm">API endpoint</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.33">#</a></span></dt><dd class="glossdef"><p>The daemon, worker, or service that a client communicates with
to access an API. API endpoints can provide any number of services,
such as authentication, sales data, performance meters, Compute VM
commands, census data, and so on.</p></dd><dt id="id-1.4.19.6.34"><span><span class="glossterm">API extension</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.34">#</a></span></dt><dd class="glossdef"><p>Custom modules that extend some OpenStack core APIs.</p></dd><dt id="id-1.4.19.6.35"><span><span class="glossterm">API extension plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.35">#</a></span></dt><dd class="glossdef"><p>Alternative term for a Networking plug-in or Networking API
extension.</p></dd><dt id="id-1.4.19.6.36"><span><span class="glossterm">API key</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.36">#</a></span></dt><dd class="glossdef"><p>Alternative term for an API token.</p></dd><dt id="id-1.4.19.6.37"><span><span class="glossterm">API server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.37">#</a></span></dt><dd class="glossdef"><p>Any node running a daemon or worker that provides an API
endpoint.</p></dd><dt id="id-1.4.19.6.38"><span><span class="glossterm">API token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.38">#</a></span></dt><dd class="glossdef"><p>Passed to API requests and used by OpenStack to verify that the
client is authorized to run the requested operation.</p></dd><dt id="id-1.4.19.6.39"><span><span class="glossterm">API version</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.39">#</a></span></dt><dd class="glossdef"><p>In OpenStack, the API version for a project is part of the URL.
For example, <code class="literal">example.com/nova/v1/foobar</code>.</p></dd><dt id="id-1.4.19.6.40"><span><span class="glossterm">applet</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.40">#</a></span></dt><dd class="glossdef"><p>A Java program that can be embedded into a web page.</p></dd><dt id="term-application-catalog-service-murano"><span><span class="glossterm">Application Catalog service (murano)</span> <a title="Permalink" class="permalink" href="#term-application-catalog-service-murano">#</a></span></dt><dd class="glossdef"><p>The project that provides an application catalog service so that users
can compose and deploy composite environments on an application
abstraction level while managing the application lifecycle.</p></dd><dt id="term-application-programming-interface-api"><span><span class="glossterm">Application Programming Interface (API)</span> <a title="Permalink" class="permalink" href="#term-application-programming-interface-api">#</a></span></dt><dd class="glossdef"><p>A collection of specifications used to access a service,
application, or program. Includes service calls, required parameters
for each call, and the expected return values.</p></dd><dt id="id-1.4.19.6.43"><span><span class="glossterm">application server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.43">#</a></span></dt><dd class="glossdef"><p>A piece of software that makes available another piece of
software over a network.</p></dd><dt id="id-1.4.19.6.44"><span><span class="glossterm">Application Service Provider (ASP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.44">#</a></span></dt><dd class="glossdef"><p>Companies that rent specialized applications that help
businesses and organizations provide additional services
with lower cost.</p></dd><dt id="id-1.4.19.6.45"><span><span class="glossterm">arptables</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.45">#</a></span></dt><dd class="glossdef"><p>Tool used for maintaining Address Resolution Protocol packet
filter rules in the Linux kernel firewall modules. Used along with
iptables, ebtables, and ip6tables in Compute to provide firewall
services for VMs.</p></dd><dt id="id-1.4.19.6.46"><span><span class="glossterm">associate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.46">#</a></span></dt><dd class="glossdef"><p>The process associating a Compute floating IP address with a
fixed IP address.</p></dd><dt id="id-1.4.19.6.47"><span><span class="glossterm">Asynchronous JavaScript and XML (AJAX)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.47">#</a></span></dt><dd class="glossdef"><p>A group of interrelated web development techniques used on the
client-side to create asynchronous web applications. Used extensively
in horizon.</p></dd><dt id="id-1.4.19.6.48"><span><span class="glossterm">ATA over Ethernet (AoE)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.48">#</a></span></dt><dd class="glossdef"><p>A disk storage protocol tunneled within Ethernet.</p></dd><dt id="id-1.4.19.6.49"><span><span class="glossterm">attach</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.49">#</a></span></dt><dd class="glossdef"><p>The process of connecting a VIF or vNIC to a L2 network in
Networking. In the context of Compute, this process connects a storage
volume to an instance.</p></dd><dt id="id-1.4.19.6.50"><span><span class="glossterm">attachment (network)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.50">#</a></span></dt><dd class="glossdef"><p>Association of an interface ID to a logical port. Plugs an
interface into a port.</p></dd><dt id="id-1.4.19.6.51"><span><span class="glossterm">auditing</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.51">#</a></span></dt><dd class="glossdef"><p>Provided in Compute through the system usage data
facility.</p></dd><dt id="id-1.4.19.6.52"><span><span class="glossterm">auditor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.52">#</a></span></dt><dd class="glossdef"><p>A worker process that verifies the integrity of Object Storage
objects, containers, and accounts. Auditors is the collective term for
the Object Storage account auditor, container auditor, and object
auditor.</p></dd><dt id="id-1.4.19.6.53"><span><span class="glossterm">Austin</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.53">#</a></span></dt><dd class="glossdef"><p>The code name for the initial release of
OpenStack. The first design summit took place in
Austin, Texas, US.</p></dd><dt id="id-1.4.19.6.54"><span><span class="glossterm">auth node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.54">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Object Storage authorization
node.</p></dd><dt id="id-1.4.19.6.55"><span><span class="glossterm">authentication</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.55">#</a></span></dt><dd class="glossdef"><p>The process that confirms that the user, process, or client is
really who they say they are through private key, secret token,
password, fingerprint, or similar method.</p></dd><dt id="id-1.4.19.6.56"><span><span class="glossterm">authentication token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.56">#</a></span></dt><dd class="glossdef"><p>A string of text provided to the client after authentication.
Must be provided by the user or process in subsequent requests to the
API endpoint.</p></dd><dt id="id-1.4.19.6.57"><span><span class="glossterm">AuthN</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.57">#</a></span></dt><dd class="glossdef"><p>The Identity service component that provides authentication
services.</p></dd><dt id="id-1.4.19.6.58"><span><span class="glossterm">authorization</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.58">#</a></span></dt><dd class="glossdef"><p>The act of verifying that a user, process, or client is
authorized to perform an action.</p></dd><dt id="id-1.4.19.6.59"><span><span class="glossterm">authorization node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.59">#</a></span></dt><dd class="glossdef"><p>An Object Storage node that provides authorization
services.</p></dd><dt id="id-1.4.19.6.60"><span><span class="glossterm">AuthZ</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.60">#</a></span></dt><dd class="glossdef"><p>The Identity component that provides high-level
authorization services.</p></dd><dt id="id-1.4.19.6.61"><span><span class="glossterm">Auto ACK</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.61">#</a></span></dt><dd class="glossdef"><p>Configuration setting within RabbitMQ that enables or disables
message acknowledgment. Enabled by default.</p></dd><dt id="id-1.4.19.6.62"><span><span class="glossterm">auto declare</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.62">#</a></span></dt><dd class="glossdef"><p>A Compute RabbitMQ setting that determines whether a message
exchange is automatically created when the program starts.</p></dd><dt id="id-1.4.19.6.63"><span><span class="glossterm">availability zone</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.63">#</a></span></dt><dd class="glossdef"><p>An Amazon EC2 concept of an isolated area that is used for fault
tolerance. Do not confuse with an OpenStack Compute zone or
cell.</p></dd><dt id="id-1.4.19.6.64"><span><span class="glossterm">AWS CloudFormation template</span> <a title="Permalink" class="permalink" href="#id-1.4.19.6.64">#</a></span></dt><dd class="glossdef"><p>AWS CloudFormation allows Amazon Web Services (AWS) users to create and manage a
collection of related resources. The Orchestration service
supports a CloudFormation-compatible format (CFN).</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.7"><h3 class="title">B</h3><dl><dt id="id-1.4.19.7.3"><span><span class="glossterm">back end</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.3">#</a></span></dt><dd class="glossdef"><p>Interactions and processes that are obfuscated from the user,
such as Compute volume mount, data transmission to an iSCSI target by
a daemon, or Object Storage object integrity checks.</p></dd><dt id="id-1.4.19.7.4"><span><span class="glossterm">back-end catalog</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.4">#</a></span></dt><dd class="glossdef"><p>The storage method used by the Identity service catalog service
to store and retrieve information about API endpoints that are
available to the client. Examples include an SQL database, LDAP
database, or KVS back end.</p></dd><dt id="id-1.4.19.7.5"><span><span class="glossterm">back-end store</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.5">#</a></span></dt><dd class="glossdef"><p>The persistent data store used to save and retrieve information
for a service, such as lists of Object Storage objects, current state
of guest VMs, lists of user names, and so on. Also, the method that the
Image service uses to get and store VM images. Options include Object
Storage, locally mounted file system, RADOS block devices, VMware
datastore, and HTTP.</p></dd><dt id="term-backup-restore-and-disaster-recovery-service-freezer"><span><span class="glossterm">Backup, Restore, and Disaster Recovery service (freezer)</span> <a title="Permalink" class="permalink" href="#term-backup-restore-and-disaster-recovery-service-freezer">#</a></span></dt><dd class="glossdef"><p>The project that provides integrated tooling for backing up, restoring,
and recovering file systems, instances, or database backups.</p></dd><dt id="id-1.4.19.7.7"><span><span class="glossterm">bandwidth</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.7">#</a></span></dt><dd class="glossdef"><p>The amount of available data used by communication resources,
such as the Internet. Represents the amount of data that is used to
download things or the amount of data available to download.</p></dd><dt id="id-1.4.19.7.8"><span><span class="glossterm">barbican</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.8">#</a></span></dt><dd class="glossdef"><p>Code name of the <a class="xref" href="#term-key-manager-service-barbican" title="Key Manager service (barbican)">Key Manager service (barbican)</a>.</p></dd><dt id="id-1.4.19.7.9"><span><span class="glossterm">bare</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.9">#</a></span></dt><dd class="glossdef"><p>An Image service container format that indicates that no
container exists for the VM image.</p></dd><dt id="term-bare-metal-service-ironic"><span><span class="glossterm">Bare Metal service (ironic)</span> <a title="Permalink" class="permalink" href="#term-bare-metal-service-ironic">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provides a service and associated libraries
capable of managing and provisioning physical machines in a
security-aware and fault-tolerant manner.</p></dd><dt id="id-1.4.19.7.11"><span><span class="glossterm">base image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.11">#</a></span></dt><dd class="glossdef"><p>An OpenStack-provided image.</p></dd><dt id="id-1.4.19.7.12"><span><span class="glossterm">Bell-LaPadula model</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.12">#</a></span></dt><dd class="glossdef"><p>A security model that focuses on data confidentiality
and controlled access to classified information.
This model divides the entities into subjects and objects.
The clearance of a subject is compared to the classification of the
object to determine if the subject is authorized for the specific access mode.
The clearance or classification scheme is expressed in terms of a lattice.</p></dd><dt id="term-benchmark-service-rally"><span><span class="glossterm">Benchmark service (rally)</span> <a title="Permalink" class="permalink" href="#term-benchmark-service-rally">#</a></span></dt><dd class="glossdef"><p>OpenStack project that provides a framework for
performance analysis and benchmarking of individual
OpenStack components as well as full production OpenStack
cloud deployments.</p></dd><dt id="id-1.4.19.7.14"><span><span class="glossterm">Bexar</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.14">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to
OpenStack that came out in February of 2011. It
included only Compute (nova) and Object Storage (swift).
Bexar is the code name for the second release of
OpenStack. The design summit took place in
San Antonio, Texas, US, which is the county seat for Bexar county.</p></dd><dt id="id-1.4.19.7.15"><span><span class="glossterm">binary</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.15">#</a></span></dt><dd class="glossdef"><p>Information that consists solely of ones and zeroes, which is
the language of computers.</p></dd><dt id="id-1.4.19.7.16"><span><span class="glossterm">bit</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.16">#</a></span></dt><dd class="glossdef"><p>A bit is a single digit number that is in base of 2 (either a
zero or one). Bandwidth usage is measured in bits per second.</p></dd><dt id="id-1.4.19.7.17"><span><span class="glossterm">bits per second (BPS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.17">#</a></span></dt><dd class="glossdef"><p>The universal measurement of how quickly data is transferred
from place to place.</p></dd><dt id="id-1.4.19.7.18"><span><span class="glossterm">block device</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.18">#</a></span></dt><dd class="glossdef"><p>A device that moves data in the form of blocks. These device
nodes interface the devices, such as hard disks, CD-ROM drives, flash
drives, and other addressable regions of memory.</p></dd><dt id="id-1.4.19.7.19"><span><span class="glossterm">block migration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.19">#</a></span></dt><dd class="glossdef"><p>A method of VM live migration used by KVM to evacuate instances
from one host to another with very little downtime during a
user-initiated switchover. Does not require shared storage. Supported
by Compute.</p></dd><dt id="id-1.4.19.7.20"><span><span class="glossterm">Block Storage API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.20">#</a></span></dt><dd class="glossdef"><p>An API on a separate endpoint for attaching,
detaching, and creating block storage for compute
VMs.</p></dd><dt id="term-block-storage-service-cinder"><span><span class="glossterm">Block Storage service (cinder)</span> <a title="Permalink" class="permalink" href="#term-block-storage-service-cinder">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that implement services and libraries to provide
on-demand, self-service access to Block Storage resources via abstraction
and automation on top of other block storage devices.</p></dd><dt id="id-1.4.19.7.22"><span><span class="glossterm">BMC (Baseboard Management Controller)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.22">#</a></span></dt><dd class="glossdef"><p>The intelligence in the IPMI architecture, which is a specialized
micro-controller that is embedded on the motherboard of a computer
and acts as a server. Manages the interface between system management
software and platform hardware.</p></dd><dt id="id-1.4.19.7.23"><span><span class="glossterm">bootable disk image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.23">#</a></span></dt><dd class="glossdef"><p>A type of VM image that exists as a single, bootable
file.</p></dd><dt id="id-1.4.19.7.24"><span><span class="glossterm">Bootstrap Protocol (BOOTP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.24">#</a></span></dt><dd class="glossdef"><p>A network protocol used by a network client to obtain an IP
address from a configuration server. Provided in Compute through the
dnsmasq daemon when using either the FlatDHCP manager or VLAN manager
network manager.</p></dd><dt id="id-1.4.19.7.25"><span><span class="glossterm">Border Gateway Protocol (BGP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.25">#</a></span></dt><dd class="glossdef"><p>The Border Gateway Protocol is a dynamic routing protocol
that connects autonomous systems.  Considered the
backbone of the Internet, this protocol connects disparate
networks to form a larger network.</p></dd><dt id="id-1.4.19.7.26"><span><span class="glossterm">browser</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.26">#</a></span></dt><dd class="glossdef"><p>Any client software that enables a computer or device to access
the Internet.</p></dd><dt id="id-1.4.19.7.27"><span><span class="glossterm">builder file</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.27">#</a></span></dt><dd class="glossdef"><p>Contains configuration information that Object Storage uses to
reconfigure a ring or to re-create it from scratch after a serious
failure.</p></dd><dt id="id-1.4.19.7.28"><span><span class="glossterm">bursting</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.28">#</a></span></dt><dd class="glossdef"><p>The practice of utilizing a secondary environment to
elastically build instances on-demand when the primary
environment is resource constrained.</p></dd><dt id="id-1.4.19.7.29"><span><span class="glossterm">button class</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.29">#</a></span></dt><dd class="glossdef"><p>A group of related button types within horizon. Buttons to
start, stop, and suspend VMs are in one class. Buttons to associate
and disassociate floating IP addresses are in another class, and so
on.</p></dd><dt id="id-1.4.19.7.30"><span><span class="glossterm">byte</span> <a title="Permalink" class="permalink" href="#id-1.4.19.7.30">#</a></span></dt><dd class="glossdef"><p>Set of bits that make up a single character; there are usually 8
bits to a byte.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.8"><h3 class="title">C</h3><dl><dt id="id-1.4.19.8.3"><span><span class="glossterm">cache pruner</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.3">#</a></span></dt><dd class="glossdef"><p>A program that keeps the Image service VM image cache at or
below its configured maximum size.</p></dd><dt id="id-1.4.19.8.4"><span><span class="glossterm">Cactus</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.4">#</a></span></dt><dd class="glossdef"><p>An OpenStack grouped release of projects that came out in the
spring of 2011. It included Compute (nova), Object Storage (swift),
and the Image service (glance).
Cactus is a city in Texas, US and is the code name for
the third release of OpenStack. When OpenStack releases went
from three to six months long, the code name of the release
changed to match a geography nearest the previous
summit.</p></dd><dt id="id-1.4.19.8.5"><span><span class="glossterm">CALL</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.5">#</a></span></dt><dd class="glossdef"><p>One of the RPC primitives used by the OpenStack message queue
software. Sends a message and waits for a response.</p></dd><dt id="id-1.4.19.8.6"><span><span class="glossterm">capability</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.6">#</a></span></dt><dd class="glossdef"><p>Defines resources for a cell, including CPU, storage, and
networking. Can apply to the specific services within a cell or a
whole cell.</p></dd><dt id="id-1.4.19.8.7"><span><span class="glossterm">capacity cache</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.7">#</a></span></dt><dd class="glossdef"><p>A Compute back-end database table that contains the current
workload, amount of free RAM, and number of VMs running on each host.
Used to determine on which host a VM starts.</p></dd><dt id="id-1.4.19.8.8"><span><span class="glossterm">capacity updater</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.8">#</a></span></dt><dd class="glossdef"><p>A notification driver that monitors VM instances and updates the
capacity cache as needed.</p></dd><dt id="id-1.4.19.8.9"><span><span class="glossterm">CAST</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.9">#</a></span></dt><dd class="glossdef"><p>One of the RPC primitives used by the OpenStack message queue
software. Sends a message and does not wait for a response.</p></dd><dt id="id-1.4.19.8.10"><span><span class="glossterm">catalog</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.10">#</a></span></dt><dd class="glossdef"><p>A list of API endpoints that are available to a user after
authentication with the Identity service.</p></dd><dt id="id-1.4.19.8.11"><span><span class="glossterm">catalog service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.11">#</a></span></dt><dd class="glossdef"><p>An Identity service that lists API endpoints that are available
to a user after authentication with the Identity service.</p></dd><dt id="id-1.4.19.8.12"><span><span class="glossterm">ceilometer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.12">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; gathers and stores metrics from other
OpenStack services.</p></dd><dt id="id-1.4.19.8.13"><span><span class="glossterm">cell</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.13">#</a></span></dt><dd class="glossdef"><p>Provides logical partitioning of Compute resources in a child
and parent relationship. Requests are passed from parent cells to
child cells if the parent cannot provide the requested
resource.</p></dd><dt id="id-1.4.19.8.14"><span><span class="glossterm">cell forwarding</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.14">#</a></span></dt><dd class="glossdef"><p>A Compute option that enables parent cells to pass resource
requests to child cells if the parent cannot provide the requested
resource.</p></dd><dt id="id-1.4.19.8.15"><span><span class="glossterm">cell manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.15">#</a></span></dt><dd class="glossdef"><p>The Compute component that contains a list of the current
capabilities of each host within the cell and routes requests as
appropriate.</p></dd><dt id="id-1.4.19.8.16"><span><span class="glossterm">CentOS</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.16">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.4.19.8.17"><span><span class="glossterm">Ceph</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.17">#</a></span></dt><dd class="glossdef"><p>Massively scalable distributed storage system that consists of
an object store, block store, and POSIX-compatible distributed file
system. Compatible with OpenStack.</p></dd><dt id="id-1.4.19.8.18"><span><span class="glossterm">CephFS</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.18">#</a></span></dt><dd class="glossdef"><p>The POSIX-compliant file system provided by Ceph.</p></dd><dt id="term-certificate-authority-ca"><span><span class="glossterm">certificate authority (CA)</span> <a title="Permalink" class="permalink" href="#term-certificate-authority-ca">#</a></span></dt><dd class="glossdef"><p>In cryptography, an entity that issues digital certificates. The digital
certificate certifies the ownership of a public key by the named
subject of the certificate. This enables others (relying parties) to
rely upon signatures or assertions made by the private key that
corresponds to the certified public key. In this model of trust
relationships, a CA is a trusted third party for both the subject
(owner) of the certificate and the party relying upon the certificate.
CAs are characteristic of many public key infrastructure (PKI)
schemes.
In OpenStack, a simple certificate authority is provided by Compute for
cloudpipe VPNs and VM image decryption.</p></dd><dt id="id-1.4.19.8.20"><span><span class="glossterm">Challenge-Handshake Authentication Protocol (CHAP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.20">#</a></span></dt><dd class="glossdef"><p>An iSCSI authentication method supported by Compute.</p></dd><dt id="id-1.4.19.8.21"><span><span class="glossterm">chance scheduler</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.21">#</a></span></dt><dd class="glossdef"><p>A scheduling method used by Compute that randomly chooses an
available host from the pool.</p></dd><dt id="id-1.4.19.8.22"><span><span class="glossterm">changes since</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.22">#</a></span></dt><dd class="glossdef"><p>A Compute API parameter that downloads changes to the requested
item since your last request, instead of downloading a new, fresh set
of data and comparing it against the old data.</p></dd><dt id="id-1.4.19.8.23"><span><span class="glossterm">Chef</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.23">#</a></span></dt><dd class="glossdef"><p>An operating system configuration management tool supporting
OpenStack deployments.</p></dd><dt id="id-1.4.19.8.24"><span><span class="glossterm">child cell</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.24">#</a></span></dt><dd class="glossdef"><p>If a requested resource such as CPU time, disk storage, or
memory is not available in the parent cell, the request is forwarded
to its associated child cells. If the child cell can fulfill the
request, it does. Otherwise, it attempts to pass the request to any of
its children.</p></dd><dt id="id-1.4.19.8.25"><span><span class="glossterm">cinder</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.25">#</a></span></dt><dd class="glossdef"><p>Codename for <a class="xref" href="#term-block-storage-service-cinder" title="Block Storage service (cinder)">Block Storage service (cinder)</a>.</p></dd><dt id="id-1.4.19.8.26"><span><span class="glossterm">CirrOS</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.26">#</a></span></dt><dd class="glossdef"><p>A minimal Linux distribution designed for use as a test
image on clouds such as OpenStack.</p></dd><dt id="id-1.4.19.8.27"><span><span class="glossterm">Cisco neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.27">#</a></span></dt><dd class="glossdef"><p>A Networking plug-in for Cisco devices and technologies,
including UCS and Nexus.</p></dd><dt id="id-1.4.19.8.28"><span><span class="glossterm">cloud architect</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.28">#</a></span></dt><dd class="glossdef"><p>A person who plans, designs, and oversees the creation of
clouds.</p></dd><dt id="id-1.4.19.8.29"><span><span class="glossterm">Cloud Auditing Data Federation (CADF)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.29">#</a></span></dt><dd class="glossdef"><p>Cloud Auditing Data Federation (CADF) is a
specification for audit event data. CADF is
supported by OpenStack Identity.</p></dd><dt id="id-1.4.19.8.30"><span><span class="glossterm">cloud computing</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.30">#</a></span></dt><dd class="glossdef"><p>A model that enables access to a shared pool of configurable
computing resources, such as networks, servers, storage, applications,
and services, that can be rapidly provisioned and released with
minimal management effort or service provider interaction.</p></dd><dt id="term-cloud-controller"><span><span class="glossterm">cloud controller</span> <a title="Permalink" class="permalink" href="#term-cloud-controller">#</a></span></dt><dd class="glossdef"><p>Collection of Compute components that represent the global state
of the cloud; talks to services, such as Identity authentication,
Object Storage, and node/storage workers through a
queue.</p></dd><dt id="id-1.4.19.8.32"><span><span class="glossterm">cloud controller node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.32">#</a></span></dt><dd class="glossdef"><p>A node that runs network, volume, API, scheduler, and image
services. Each service may be broken out into separate nodes for
scalability or availability.</p></dd><dt id="id-1.4.19.8.33"><span><span class="glossterm">Cloud Data Management Interface (CDMI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.33">#</a></span></dt><dd class="glossdef"><p>SINA standard that defines a RESTful API for managing objects in
the cloud, currently unsupported in OpenStack.</p></dd><dt id="id-1.4.19.8.34"><span><span class="glossterm">Cloud Infrastructure Management Interface (CIMI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.34">#</a></span></dt><dd class="glossdef"><p>An in-progress specification for cloud management. Currently
unsupported in OpenStack.</p></dd><dt id="id-1.4.19.8.35"><span><span class="glossterm">cloud-init</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.35">#</a></span></dt><dd class="glossdef"><p>A package commonly installed in VM images that performs
initialization of an instance after boot using information that it
retrieves from the metadata service, such as the SSH public key and
user data.</p></dd><dt id="id-1.4.19.8.36"><span><span class="glossterm">cloudadmin</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.36">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system. Grants
complete system access.</p></dd><dt id="id-1.4.19.8.37"><span><span class="glossterm">Cloudbase-Init</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.37">#</a></span></dt><dd class="glossdef"><p>A Windows project providing guest initialization features,
similar to cloud-init.</p></dd><dt id="id-1.4.19.8.38"><span><span class="glossterm">cloudpipe</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.38">#</a></span></dt><dd class="glossdef"><p>A compute service that creates VPNs on a per-project
basis.</p></dd><dt id="id-1.4.19.8.39"><span><span class="glossterm">cloudpipe image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.39">#</a></span></dt><dd class="glossdef"><p>A pre-made VM image that serves as a cloudpipe server.
Essentially, OpenVPN running on Linux.</p></dd><dt id="term-clustering-service-senlin"><span><span class="glossterm">Clustering service (senlin)</span> <a title="Permalink" class="permalink" href="#term-clustering-service-senlin">#</a></span></dt><dd class="glossdef"><p>The project that implements clustering services and libraries
for the management of groups of homogeneous objects exposed
by other OpenStack services.</p></dd><dt id="id-1.4.19.8.41"><span><span class="glossterm">command filter</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.41">#</a></span></dt><dd class="glossdef"><p>Lists allowed commands within the Compute rootwrap
facility.</p></dd><dt id="id-1.4.19.8.42"><span><span class="glossterm">Common Internet File System (CIFS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.42">#</a></span></dt><dd class="glossdef"><p>A file sharing protocol. It is a public or open variation of the
original Server Message Block (SMB) protocol developed and used by
Microsoft. Like the SMB protocol, CIFS runs at a higher level and uses
the TCP/IP protocol.</p></dd><dt id="term-common-libraries-oslo"><span><span class="glossterm">Common Libraries (oslo)</span> <a title="Permalink" class="permalink" href="#term-common-libraries-oslo">#</a></span></dt><dd class="glossdef"><p>The project that produces a set of python libraries containing code
shared by OpenStack projects. The APIs provided by these libraries
should be high quality, stable, consistent, documented and generally
applicable.</p></dd><dt id="id-1.4.19.8.44"><span><span class="glossterm">community project</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.44">#</a></span></dt><dd class="glossdef"><p>A project that is not officially endorsed by the OpenStack
Foundation. If the project is successful enough, it might be elevated
to an incubated project and then to a core project, or it might be
merged with the main code trunk.</p></dd><dt id="id-1.4.19.8.45"><span><span class="glossterm">compression</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.45">#</a></span></dt><dd class="glossdef"><p>Reducing the size of files by special encoding, the file can be
decompressed again to its original content. OpenStack supports
compression at the Linux file system level but does not support
compression for things such as Object Storage objects or Image service
VM images.</p></dd><dt id="term-compute-api-nova-api"><span><span class="glossterm">Compute API (Nova API)</span> <a title="Permalink" class="permalink" href="#term-compute-api-nova-api">#</a></span></dt><dd class="glossdef"><p>The nova-api daemon provides access to nova services. Can communicate with
other APIs, such as the Amazon EC2 API.</p></dd><dt id="id-1.4.19.8.47"><span><span class="glossterm">compute controller</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.47">#</a></span></dt><dd class="glossdef"><p>The Compute component that chooses suitable hosts on which to
start VM instances.</p></dd><dt id="id-1.4.19.8.48"><span><span class="glossterm">compute host</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.48">#</a></span></dt><dd class="glossdef"><p>Physical host dedicated to running compute nodes.</p></dd><dt id="id-1.4.19.8.49"><span><span class="glossterm">compute node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.49">#</a></span></dt><dd class="glossdef"><p>A node that runs the nova-compute daemon that manages VM
instances that provide a wide
range of services, such as web applications and analytics.</p></dd><dt id="term-compute-service-nova"><span><span class="glossterm">Compute service (nova)</span> <a title="Permalink" class="permalink" href="#term-compute-service-nova">#</a></span></dt><dd class="glossdef"><p>The OpenStack core project that implements services and associated
libraries to provide massively-scalable, on-demand, self-service
access to compute resources, including bare metal, virtual machines,
and containers.</p></dd><dt id="id-1.4.19.8.51"><span><span class="glossterm">compute worker</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.51">#</a></span></dt><dd class="glossdef"><p>The Compute component that runs on each compute node and manages
the VM instance lifecycle, including run, reboot, terminate,
attach/detach volumes, and so on. Provided by the nova-compute daemon.</p></dd><dt id="id-1.4.19.8.52"><span><span class="glossterm">concatenated object</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.52">#</a></span></dt><dd class="glossdef"><p>A set of segment objects that Object Storage combines and sends
to the client.</p></dd><dt id="id-1.4.19.8.53"><span><span class="glossterm">conductor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.53">#</a></span></dt><dd class="glossdef"><p>In Compute, conductor is the process that proxies database
requests from the compute process. Using conductor improves security
because compute nodes do not need direct access to the
database.</p></dd><dt id="id-1.4.19.8.54"><span><span class="glossterm">congress</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.54">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-governance-service-congress" title="Governance service (congress)">Governance service (congress)</a>.</p></dd><dt id="id-1.4.19.8.55"><span><span class="glossterm">consistency window</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.55">#</a></span></dt><dd class="glossdef"><p>The amount of time it takes for a new Object Storage object to
become accessible to all clients.</p></dd><dt id="id-1.4.19.8.56"><span><span class="glossterm">console log</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.56">#</a></span></dt><dd class="glossdef"><p>Contains the output from a Linux VM console in Compute.</p></dd><dt id="id-1.4.19.8.57"><span><span class="glossterm">container</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.57">#</a></span></dt><dd class="glossdef"><p>Organizes and stores objects in Object Storage. Similar to the
concept of a Linux directory but cannot be nested. Alternative term
for an Image service container format.</p></dd><dt id="id-1.4.19.8.58"><span><span class="glossterm">container auditor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.58">#</a></span></dt><dd class="glossdef"><p>Checks for missing replicas or incorrect objects in specified
Object Storage containers through queries to the SQLite back-end
database.</p></dd><dt id="id-1.4.19.8.59"><span><span class="glossterm">container database</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.59">#</a></span></dt><dd class="glossdef"><p>A SQLite database that stores Object Storage containers and
container metadata. The container server accesses this
database.</p></dd><dt id="id-1.4.19.8.60"><span><span class="glossterm">container format</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.60">#</a></span></dt><dd class="glossdef"><p>A wrapper used by the Image service that contains a VM image and
its associated metadata, such as machine state, OS disk size, and so
on.</p></dd><dt id="term-container-infrastructure-management-service-magnum"><span><span class="glossterm">Container Infrastructure Management service (magnum)</span> <a title="Permalink" class="permalink" href="#term-container-infrastructure-management-service-magnum">#</a></span></dt><dd class="glossdef"><p>The project which provides a set of services for provisioning, scaling,
and managing container orchestration engines.</p></dd><dt id="id-1.4.19.8.62"><span><span class="glossterm">container server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.62">#</a></span></dt><dd class="glossdef"><p>An Object Storage server that manages containers.</p></dd><dt id="id-1.4.19.8.63"><span><span class="glossterm">container service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.63">#</a></span></dt><dd class="glossdef"><p>The Object Storage component that provides container services,
such as create, delete, list, and so on.</p></dd><dt id="id-1.4.19.8.64"><span><span class="glossterm">content delivery network (CDN)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.64">#</a></span></dt><dd class="glossdef"><p>A content delivery network is a specialized network that is
used to distribute content to clients, typically located
close to the client for increased performance.</p></dd><dt id="id-1.4.19.8.65"><span><span class="glossterm">controller node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.65">#</a></span></dt><dd class="glossdef"><p>Alternative term for a cloud controller node.</p></dd><dt id="id-1.4.19.8.66"><span><span class="glossterm">core API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.66">#</a></span></dt><dd class="glossdef"><p>Depending on context, the core API is either the OpenStack API
or the main API of a specific core project, such as Compute,
Networking, Image service, and so on.</p></dd><dt id="id-1.4.19.8.67"><span><span class="glossterm">core service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.67">#</a></span></dt><dd class="glossdef"><p>An official OpenStack service defined as core by
DefCore Committee. Currently, consists of
Block Storage service (cinder), Compute service (nova),
Identity service (keystone), Image service (glance),
Networking service (neutron), and Object Storage service (swift).</p></dd><dt id="id-1.4.19.8.68"><span><span class="glossterm">cost</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.68">#</a></span></dt><dd class="glossdef"><p>Under the Compute distributed scheduler, this is calculated by
looking at the capabilities of each host relative to the flavor of the
VM instance being requested.</p></dd><dt id="id-1.4.19.8.69"><span><span class="glossterm">credentials</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.69">#</a></span></dt><dd class="glossdef"><p>Data that is only known to or accessible by a user and
used to verify that the user is who he says he is.
Credentials are presented to the server during
authentication. Examples include a password, secret key,
digital certificate, and fingerprint.</p></dd><dt id="term-cross-origin-resource-sharing-cors"><span><span class="glossterm">Cross-Origin Resource Sharing (CORS)</span> <a title="Permalink" class="permalink" href="#term-cross-origin-resource-sharing-cors">#</a></span></dt><dd class="glossdef"><p>A mechanism that allows many resources (for example,
fonts, JavaScript) on a web page to be requested from
another domain outside the domain from which the resource
originated. In particular, JavaScript's AJAX calls can use
the XMLHttpRequest mechanism.</p></dd><dt id="id-1.4.19.8.71"><span><span class="glossterm">Crowbar</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.71">#</a></span></dt><dd class="glossdef"><p>An open source community project by Dell that aims to provide
all necessary services to quickly deploy clouds.</p></dd><dt id="id-1.4.19.8.72"><span><span class="glossterm">current workload</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.72">#</a></span></dt><dd class="glossdef"><p>An element of the Compute capacity cache that is calculated
based on the number of build, snapshot, migrate, and resize operations
currently in progress on a given host.</p></dd><dt id="id-1.4.19.8.73"><span><span class="glossterm">customer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.73">#</a></span></dt><dd class="glossdef"><p>Alternative term for project.</p></dd><dt id="id-1.4.19.8.74"><span><span class="glossterm">customization module</span> <a title="Permalink" class="permalink" href="#id-1.4.19.8.74">#</a></span></dt><dd class="glossdef"><p>A user-created Python module that is loaded by horizon to change
the look and feel of the dashboard.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.9"><h3 class="title">D</h3><dl><dt id="id-1.4.19.9.3"><span><span class="glossterm">daemon</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.3">#</a></span></dt><dd class="glossdef"><p>A process that runs in the background and waits for requests.
May or may not listen on a TCP or UDP port. Do not confuse with a
worker.</p></dd><dt id="term-dashboard-horizon"><span><span class="glossterm">Dashboard (horizon)</span> <a title="Permalink" class="permalink" href="#term-dashboard-horizon">#</a></span></dt><dd class="glossdef"><p>OpenStack project which provides an extensible, unified, web-based
user interface for all OpenStack services.</p></dd><dt id="id-1.4.19.9.5"><span><span class="glossterm">data encryption</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.5">#</a></span></dt><dd class="glossdef"><p>Both Image service and Compute support encrypted virtual machine
(VM) images (but not instances). In-transit data encryption is
supported in OpenStack using technologies such as HTTPS, SSL, TLS, and
SSH. Object Storage does not support object encryption at the
application level but may support storage that uses disk encryption.</p></dd><dt id="id-1.4.19.9.6"><span><span class="glossterm">Data loss prevention (DLP) software</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.6">#</a></span></dt><dd class="glossdef"><p>Software programs used to protect sensitive information
and prevent it from leaking outside a network boundary
through the detection and denying of the data transportation.</p></dd><dt id="term-data-processing-service-sahara"><span><span class="glossterm">Data Processing service (sahara)</span> <a title="Permalink" class="permalink" href="#term-data-processing-service-sahara">#</a></span></dt><dd class="glossdef"><p>OpenStack project that provides a scalable
data-processing stack and associated management
interfaces.</p></dd><dt id="term-data-store"><span><span class="glossterm">data store</span> <a title="Permalink" class="permalink" href="#term-data-store">#</a></span></dt><dd class="glossdef"><p>A database engine supported by the Database service.</p></dd><dt id="id-1.4.19.9.9"><span><span class="glossterm">database ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.9">#</a></span></dt><dd class="glossdef"><p>A unique ID given to each replica of an Object Storage
database.</p></dd><dt id="id-1.4.19.9.10"><span><span class="glossterm">database replicator</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.10">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that copies changes in the account,
container, and object databases to other nodes.</p></dd><dt id="term-database-service-trove"><span><span class="glossterm">Database service (trove)</span> <a title="Permalink" class="permalink" href="#term-database-service-trove">#</a></span></dt><dd class="glossdef"><p>An integrated project that provides scalable and reliable
Cloud Database-as-a-Service functionality for both
relational and non-relational database engines.</p></dd><dt id="id-1.4.19.9.12"><span><span class="glossterm">deallocate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.12">#</a></span></dt><dd class="glossdef"><p>The process of removing the association between a floating IP
address and a fixed IP address. Once this association is removed, the
floating IP returns to the address pool.</p></dd><dt id="id-1.4.19.9.13"><span><span class="glossterm">Debian</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.13">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.4.19.9.14"><span><span class="glossterm">deduplication</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.14">#</a></span></dt><dd class="glossdef"><p>The process of finding duplicate data at the disk block, file,
and/or object level to minimize storage use—currently unsupported
within OpenStack.</p></dd><dt id="id-1.4.19.9.15"><span><span class="glossterm">default panel</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.15">#</a></span></dt><dd class="glossdef"><p>The default panel that is displayed when a user accesses the
dashboard.</p></dd><dt id="id-1.4.19.9.16"><span><span class="glossterm">default project</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.16">#</a></span></dt><dd class="glossdef"><p>New users are assigned to this project if no project is specified
when a user is created.</p></dd><dt id="id-1.4.19.9.17"><span><span class="glossterm">default token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.17">#</a></span></dt><dd class="glossdef"><p>An Identity service token that is not associated with a specific
project and is exchanged for a scoped token.</p></dd><dt id="id-1.4.19.9.18"><span><span class="glossterm">delayed delete</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.18">#</a></span></dt><dd class="glossdef"><p>An option within Image service so that an image is deleted after
a predefined number of seconds instead of immediately.</p></dd><dt id="id-1.4.19.9.19"><span><span class="glossterm">delivery mode</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.19">#</a></span></dt><dd class="glossdef"><p>Setting for the Compute RabbitMQ message delivery mode; can be
set to either transient or persistent.</p></dd><dt id="id-1.4.19.9.20"><span><span class="glossterm">denial of service (DoS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.20">#</a></span></dt><dd class="glossdef"><p>Denial of service (DoS) is a short form for
denial-of-service attack. This is a malicious attempt to
prevent legitimate users from using a service.</p></dd><dt id="id-1.4.19.9.21"><span><span class="glossterm">deprecated auth</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.21">#</a></span></dt><dd class="glossdef"><p>An option within Compute that enables administrators to create
and manage users through the <code class="literal">nova-manage</code> command as
opposed to using the Identity service.</p></dd><dt id="id-1.4.19.9.22"><span><span class="glossterm">designate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.22">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-dns-service-designate" title="DNS service (designate)">DNS service (designate)</a>.</p></dd><dt id="id-1.4.19.9.23"><span><span class="glossterm">Desktop-as-a-Service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.23">#</a></span></dt><dd class="glossdef"><p>A platform that provides a suite of desktop environments
that users access to receive a desktop experience from
any location. This may provide general use, development, or
even homogeneous testing environments.</p></dd><dt id="id-1.4.19.9.24"><span><span class="glossterm">developer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.24">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system and the
default role assigned to a new user.</p></dd><dt id="id-1.4.19.9.25"><span><span class="glossterm">device ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.25">#</a></span></dt><dd class="glossdef"><p>Maps Object Storage partitions to physical storage
devices.</p></dd><dt id="id-1.4.19.9.26"><span><span class="glossterm">device weight</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.26">#</a></span></dt><dd class="glossdef"><p>Distributes partitions proportionately across Object Storage
devices based on the storage capacity of each device.</p></dd><dt id="id-1.4.19.9.27"><span><span class="glossterm">DevStack</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.27">#</a></span></dt><dd class="glossdef"><p>Community project that uses shell scripts to quickly build
complete OpenStack development environments.</p></dd><dt id="id-1.4.19.9.28"><span><span class="glossterm">DHCP agent</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.28">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides DHCP services
for virtual networks.</p></dd><dt id="id-1.4.19.9.29"><span><span class="glossterm">Diablo</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.29">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to OpenStack that came out
in the fall of 2011, the fourth release of OpenStack. It included
Compute (nova 2011.3), Object Storage (swift 1.4.3), and the Image
service (glance).
Diablo is the code name for the fourth release of
OpenStack. The design summit took place in
the Bay Area near Santa Clara,
California, US and Diablo is a nearby city.</p></dd><dt id="id-1.4.19.9.30"><span><span class="glossterm">direct consumer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.30">#</a></span></dt><dd class="glossdef"><p>An element of the Compute RabbitMQ that comes to life when a RPC
call is executed. It connects to a direct exchange through a unique
exclusive queue, sends the message, and terminates.</p></dd><dt id="id-1.4.19.9.31"><span><span class="glossterm">direct exchange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.31">#</a></span></dt><dd class="glossdef"><p>A routing table that is created within the Compute RabbitMQ
during RPC calls; one is created for each RPC call that is
invoked.</p></dd><dt id="id-1.4.19.9.32"><span><span class="glossterm">direct publisher</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.32">#</a></span></dt><dd class="glossdef"><p>Element of RabbitMQ that provides a response to an incoming MQ
message.</p></dd><dt id="id-1.4.19.9.33"><span><span class="glossterm">disassociate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.33">#</a></span></dt><dd class="glossdef"><p>The process of removing the association between a floating IP
address and fixed IP and thus returning the floating IP address to the
address pool.</p></dd><dt id="id-1.4.19.9.34"><span><span class="glossterm">Discretionary Access Control (DAC)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.34">#</a></span></dt><dd class="glossdef"><p>Governs the ability of subjects to access objects, while enabling
users to make policy decisions and assign security attributes.
The traditional UNIX system of users, groups, and read-write-execute
permissions is an example of DAC.</p></dd><dt id="id-1.4.19.9.35"><span><span class="glossterm">disk encryption</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.35">#</a></span></dt><dd class="glossdef"><p>The ability to encrypt data at the file system, disk partition,
or whole-disk level. Supported within Compute VMs.</p></dd><dt id="id-1.4.19.9.36"><span><span class="glossterm">disk format</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.36">#</a></span></dt><dd class="glossdef"><p>The underlying format that a disk image for a VM is stored as
within the Image service back-end store. For example, AMI, ISO, QCOW2,
VMDK, and so on.</p></dd><dt id="id-1.4.19.9.37"><span><span class="glossterm">dispersion</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.37">#</a></span></dt><dd class="glossdef"><p>In Object Storage, tools to test and ensure dispersion of
objects and containers to ensure fault tolerance.</p></dd><dt id="id-1.4.19.9.38"><span><span class="glossterm">distributed virtual router (DVR)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.38">#</a></span></dt><dd class="glossdef"><p>Mechanism for highly available multi-host routing when using
OpenStack Networking (neutron).</p></dd><dt id="id-1.4.19.9.39"><span><span class="glossterm">Django</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.39">#</a></span></dt><dd class="glossdef"><p>A web framework used extensively in horizon.</p></dd><dt id="id-1.4.19.9.40"><span><span class="glossterm">DNS record</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.40">#</a></span></dt><dd class="glossdef"><p>A record that specifies information about a particular domain
and belongs to the domain.</p></dd><dt id="term-dns-service-designate"><span><span class="glossterm">DNS service (designate)</span> <a title="Permalink" class="permalink" href="#term-dns-service-designate">#</a></span></dt><dd class="glossdef"><p>OpenStack project that provides scalable, on demand, self
service access to authoritative DNS services, in a
technology-agnostic manner.</p></dd><dt id="id-1.4.19.9.42"><span><span class="glossterm">dnsmasq</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.42">#</a></span></dt><dd class="glossdef"><p>Daemon that provides DNS, DHCP, BOOTP, and TFTP services for
virtual networks.</p></dd><dt id="id-1.4.19.9.43"><span><span class="glossterm">domain</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.43">#</a></span></dt><dd class="glossdef"><p>An Identity API v3 entity. Represents a collection of
projects, groups and users that defines administrative boundaries for
managing OpenStack Identity entities.
On the Internet, separates a website from other sites. Often,
the domain name has two or more parts that are separated by dots.
For example, yahoo.com, usa.gov, harvard.edu, or
mail.yahoo.com.
Also, a domain is an entity or container of all DNS-related
information containing one or more records.</p></dd><dt id="id-1.4.19.9.44"><span><span class="glossterm">Domain Name System (DNS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.44">#</a></span></dt><dd class="glossdef"><p>A system by which Internet domain name-to-address and
address-to-name resolutions are determined.
DNS helps navigate the Internet by translating the IP address
into an address that is easier to remember. For example, translating
111.111.111.1 into www.yahoo.com.
All domains and their components, such as mail servers, utilize
DNS to resolve to the appropriate locations. DNS servers are usually
set up in a master-slave relationship such that failure of the master
invokes the slave. DNS servers might also be clustered or replicated
such that changes made to one DNS server are automatically propagated
to other active servers.
In Compute, the support that enables associating DNS entries
with floating IP addresses, nodes, or cells so that hostnames are
consistent across reboots.</p></dd><dt id="id-1.4.19.9.45"><span><span class="glossterm">download</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.45">#</a></span></dt><dd class="glossdef"><p>The transfer of data, usually in the form of files, from one
computer to another.</p></dd><dt id="id-1.4.19.9.46"><span><span class="glossterm">durable exchange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.46">#</a></span></dt><dd class="glossdef"><p>The Compute RabbitMQ message exchange that remains active when
the server restarts.</p></dd><dt id="id-1.4.19.9.47"><span><span class="glossterm">durable queue</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.47">#</a></span></dt><dd class="glossdef"><p>A Compute RabbitMQ message queue that remains active when the
server restarts.</p></dd><dt id="id-1.4.19.9.48"><span><span class="glossterm">Dynamic Host Configuration Protocol (DHCP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.48">#</a></span></dt><dd class="glossdef"><p>A network protocol that configures devices that are connected to a
network so that they can communicate on that network by using the
Internet Protocol (IP). The protocol is implemented in a client-server
model where DHCP clients request configuration data, such as an IP
address, a default route, and one or more DNS server addresses from a
DHCP server.
A method to automatically configure networking for a host at
boot time. Provided by both Networking and Compute.</p></dd><dt id="id-1.4.19.9.49"><span><span class="glossterm">Dynamic HyperText Markup Language (DHTML)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.9.49">#</a></span></dt><dd class="glossdef"><p>Pages that use HTML, JavaScript, and Cascading Style Sheets to
enable users to interact with a web page or show simple
animation.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.10"><h3 class="title">E</h3><dl><dt id="id-1.4.19.10.3"><span><span class="glossterm">east-west traffic</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.3">#</a></span></dt><dd class="glossdef"><p>Network traffic between servers in the same cloud or data center.
See also north-south traffic.</p></dd><dt id="id-1.4.19.10.4"><span><span class="glossterm">EBS boot volume</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.4">#</a></span></dt><dd class="glossdef"><p>An Amazon EBS storage volume that contains a bootable VM image,
currently unsupported in OpenStack.</p></dd><dt id="id-1.4.19.10.5"><span><span class="glossterm">ebtables</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.5">#</a></span></dt><dd class="glossdef"><p>Filtering tool for a Linux bridging firewall, enabling
filtering of network traffic passing through a Linux bridge.
Used in Compute along with arptables, iptables, and ip6tables
to ensure isolation of network communications.</p></dd><dt id="id-1.4.19.10.6"><span><span class="glossterm">EC2</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.6">#</a></span></dt><dd class="glossdef"><p>The Amazon commercial compute product, similar to
Compute.</p></dd><dt id="id-1.4.19.10.7"><span><span class="glossterm">EC2 access key</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.7">#</a></span></dt><dd class="glossdef"><p>Used along with an EC2 secret key to access the Compute EC2
API.</p></dd><dt id="id-1.4.19.10.8"><span><span class="glossterm">EC2 API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.8">#</a></span></dt><dd class="glossdef"><p>OpenStack supports accessing the Amazon EC2 API through
Compute.</p></dd><dt id="id-1.4.19.10.9"><span><span class="glossterm">EC2 Compatibility API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.9">#</a></span></dt><dd class="glossdef"><p>A Compute component that enables OpenStack to communicate with
Amazon EC2.</p></dd><dt id="id-1.4.19.10.10"><span><span class="glossterm">EC2 secret key</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.10">#</a></span></dt><dd class="glossdef"><p>Used along with an EC2 access key when communicating with the
Compute EC2 API; used to digitally sign each request.</p></dd><dt id="id-1.4.19.10.11"><span><span class="glossterm">Elastic Block Storage (EBS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.11">#</a></span></dt><dd class="glossdef"><p>The Amazon commercial block storage product.</p></dd><dt id="id-1.4.19.10.12"><span><span class="glossterm">encapsulation</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.12">#</a></span></dt><dd class="glossdef"><p>The practice of placing one packet type within another for
the purposes of abstracting or securing data. Examples
include GRE, MPLS, or IPsec.</p></dd><dt id="id-1.4.19.10.13"><span><span class="glossterm">encryption</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.13">#</a></span></dt><dd class="glossdef"><p>OpenStack supports encryption technologies such as HTTPS, SSH,
SSL, TLS, digital certificates, and data encryption.</p></dd><dt id="id-1.4.19.10.14"><span><span class="glossterm">endpoint</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.14">#</a></span></dt><dd class="glossdef"><p>See API endpoint.</p></dd><dt id="id-1.4.19.10.15"><span><span class="glossterm">endpoint registry</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.15">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Identity service catalog.</p></dd><dt id="id-1.4.19.10.16"><span><span class="glossterm">endpoint template</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.16">#</a></span></dt><dd class="glossdef"><p>A list of URL and port number endpoints that indicate where a
service, such as Object Storage, Compute, Identity, and so on, can be
accessed.</p></dd><dt id="id-1.4.19.10.17"><span><span class="glossterm">entity</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.17">#</a></span></dt><dd class="glossdef"><p>Any piece of hardware or software that wants to connect to the
network services provided by Networking, the network connectivity
service. An entity can make use of Networking by implementing a
VIF.</p></dd><dt id="id-1.4.19.10.18"><span><span class="glossterm">ephemeral image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.18">#</a></span></dt><dd class="glossdef"><p>A VM image that does not save changes made to its volumes and
reverts them to their original state after the instance is
terminated.</p></dd><dt id="id-1.4.19.10.19"><span><span class="glossterm">ephemeral volume</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.19">#</a></span></dt><dd class="glossdef"><p>Volume that does not save the changes made to it and reverts to
its original state when the current user relinquishes control.</p></dd><dt id="id-1.4.19.10.20"><span><span class="glossterm">Essex</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.20">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to OpenStack that came out
in April 2012, the fifth release of OpenStack. It included Compute
(nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity
(keystone), and Dashboard (horizon).
Essex is the code name for the fifth release of
OpenStack. The design summit took place in
Boston, Massachusetts, US and Essex is a nearby city.</p></dd><dt id="id-1.4.19.10.21"><span><span class="glossterm">ESXi</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.21">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.4.19.10.22"><span><span class="glossterm">ETag</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.22">#</a></span></dt><dd class="glossdef"><p>MD5 hash of an object within Object Storage, used to ensure data
integrity.</p></dd><dt id="id-1.4.19.10.23"><span><span class="glossterm">euca2ools</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.23">#</a></span></dt><dd class="glossdef"><p>A collection of command-line tools for administering VMs; most
are compatible with OpenStack.</p></dd><dt id="id-1.4.19.10.24"><span><span class="glossterm">Eucalyptus Kernel Image (EKI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.24">#</a></span></dt><dd class="glossdef"><p>Used along with an ERI to create an EMI.</p></dd><dt id="id-1.4.19.10.25"><span><span class="glossterm">Eucalyptus Machine Image (EMI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.25">#</a></span></dt><dd class="glossdef"><p>VM image container format supported by Image service.</p></dd><dt id="id-1.4.19.10.26"><span><span class="glossterm">Eucalyptus Ramdisk Image (ERI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.26">#</a></span></dt><dd class="glossdef"><p>Used along with an EKI to create an EMI.</p></dd><dt id="id-1.4.19.10.27"><span><span class="glossterm">evacuate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.27">#</a></span></dt><dd class="glossdef"><p>The process of migrating one or all virtual machine (VM)
instances from one host to another, compatible with both shared
storage live migration and block migration.</p></dd><dt id="id-1.4.19.10.28"><span><span class="glossterm">exchange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.28">#</a></span></dt><dd class="glossdef"><p>Alternative term for a RabbitMQ message exchange.</p></dd><dt id="id-1.4.19.10.29"><span><span class="glossterm">exchange type</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.29">#</a></span></dt><dd class="glossdef"><p>A routing algorithm in the Compute RabbitMQ.</p></dd><dt id="id-1.4.19.10.30"><span><span class="glossterm">exclusive queue</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.30">#</a></span></dt><dd class="glossdef"><p>Connected to by a direct consumer in RabbitMQ—Compute, the
message can be consumed only by the current connection.</p></dd><dt id="id-1.4.19.10.31"><span><span class="glossterm">extended attributes (xattr)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.31">#</a></span></dt><dd class="glossdef"><p>File system option that enables storage of additional
information beyond owner, group, permissions, modification time, and
so on. The underlying Object Storage file system must support extended
attributes.</p></dd><dt id="id-1.4.19.10.32"><span><span class="glossterm">extension</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.32">#</a></span></dt><dd class="glossdef"><p>Alternative term for an API extension or plug-in. In the context
of Identity service, this is a call that is specific to the
implementation, such as adding support for OpenID.</p></dd><dt id="id-1.4.19.10.33"><span><span class="glossterm">external network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.33">#</a></span></dt><dd class="glossdef"><p>A network segment typically used for instance Internet
access.</p></dd><dt id="id-1.4.19.10.34"><span><span class="glossterm">extra specs</span> <a title="Permalink" class="permalink" href="#id-1.4.19.10.34">#</a></span></dt><dd class="glossdef"><p>Specifies additional requirements when Compute determines where
to start a new instance. Examples include a minimum amount of network
bandwidth or a GPU.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.11"><h3 class="title">F</h3><dl><dt id="id-1.4.19.11.3"><span><span class="glossterm">FakeLDAP</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.3">#</a></span></dt><dd class="glossdef"><p>An easy method to create a local LDAP directory for testing
Identity and Compute. Requires Redis.</p></dd><dt id="id-1.4.19.11.4"><span><span class="glossterm">fan-out exchange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.4">#</a></span></dt><dd class="glossdef"><p>Within RabbitMQ and Compute, it is the messaging interface that
is used by the scheduler service to receive capability messages from
the compute, volume, and network nodes.</p></dd><dt id="id-1.4.19.11.5"><span><span class="glossterm">federated identity</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.5">#</a></span></dt><dd class="glossdef"><p>A method to establish trusts between identity providers and the
OpenStack cloud.</p></dd><dt id="id-1.4.19.11.6"><span><span class="glossterm">Fedora</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.6">#</a></span></dt><dd class="glossdef"><p>A Linux distribution compatible with OpenStack.</p></dd><dt id="id-1.4.19.11.7"><span><span class="glossterm">Fibre Channel</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.7">#</a></span></dt><dd class="glossdef"><p>Storage protocol similar in concept to TCP/IP; encapsulates SCSI
commands and data.</p></dd><dt id="id-1.4.19.11.8"><span><span class="glossterm">Fibre Channel over Ethernet (FCoE)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.8">#</a></span></dt><dd class="glossdef"><p>The fibre channel protocol tunneled within Ethernet.</p></dd><dt id="id-1.4.19.11.9"><span><span class="glossterm">fill-first scheduler</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.9">#</a></span></dt><dd class="glossdef"><p>The Compute scheduling method that attempts to fill a host with
VMs rather than starting new VMs on a variety of hosts.</p></dd><dt id="id-1.4.19.11.10"><span><span class="glossterm">filter</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.10">#</a></span></dt><dd class="glossdef"><p>The step in the Compute scheduling process when hosts that
cannot run VMs are eliminated and not chosen.</p></dd><dt id="id-1.4.19.11.11"><span><span class="glossterm">firewall</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.11">#</a></span></dt><dd class="glossdef"><p>Used to restrict communications between hosts and/or nodes,
implemented in Compute using iptables, arptables, ip6tables, and
ebtables.</p></dd><dt id="id-1.4.19.11.12"><span><span class="glossterm">FireWall-as-a-Service (FWaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.12">#</a></span></dt><dd class="glossdef"><p>A Networking extension that provides perimeter firewall
functionality.</p></dd><dt id="id-1.4.19.11.13"><span><span class="glossterm">fixed IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.13">#</a></span></dt><dd class="glossdef"><p>An IP address that is associated with the same instance each
time that instance boots, is generally not accessible to end users or
the public Internet, and is used for management of the
instance.</p></dd><dt id="id-1.4.19.11.14"><span><span class="glossterm">Flat Manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.14">#</a></span></dt><dd class="glossdef"><p>The Compute component that gives IP addresses to authorized
nodes and assumes DHCP, DNS, and routing configuration and services
are provided by something else.</p></dd><dt id="id-1.4.19.11.15"><span><span class="glossterm">flat mode injection</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.15">#</a></span></dt><dd class="glossdef"><p>A Compute networking method where the OS network configuration
information is injected into the VM image before the instance
starts.</p></dd><dt id="id-1.4.19.11.16"><span><span class="glossterm">flat network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.16">#</a></span></dt><dd class="glossdef"><p>Virtual network type that uses neither VLANs nor tunnels to
segregate project traffic. Each flat network typically requires
a separate underlying physical interface defined by bridge
mappings. However, a flat network can contain multiple
subnets.</p></dd><dt id="id-1.4.19.11.17"><span><span class="glossterm">FlatDHCP Manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.17">#</a></span></dt><dd class="glossdef"><p>The Compute component that provides dnsmasq (DHCP, DNS, BOOTP,
TFTP) and radvd (routing) services.</p></dd><dt id="id-1.4.19.11.18"><span><span class="glossterm">flavor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.18">#</a></span></dt><dd class="glossdef"><p>Alternative term for a VM instance type.</p></dd><dt id="id-1.4.19.11.19"><span><span class="glossterm">flavor ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.19">#</a></span></dt><dd class="glossdef"><p>UUID for each Compute or Image service VM flavor or instance
type.</p></dd><dt id="id-1.4.19.11.20"><span><span class="glossterm">floating IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.20">#</a></span></dt><dd class="glossdef"><p>An IP address that a project can associate with a VM so that the
instance has the same public IP address each time that it boots. You
create a pool of floating IP addresses and assign them to instances as
they are launched to maintain a consistent IP address for maintaining
DNS assignment.</p></dd><dt id="id-1.4.19.11.21"><span><span class="glossterm">Folsom</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.21">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to OpenStack that came out
in the fall of 2012, the sixth release of OpenStack. It includes
Compute (nova), Object Storage (swift), Identity (keystone),
Networking (neutron), Image service (glance), and Volumes or Block
Storage (cinder).
Folsom is the code name for the sixth release of
OpenStack. The design summit took place in
San Francisco, California, US and Folsom is a nearby city.</p></dd><dt id="id-1.4.19.11.22"><span><span class="glossterm">FormPost</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.22">#</a></span></dt><dd class="glossdef"><p>Object Storage middleware that uploads (posts) an image through
a form on a web page.</p></dd><dt id="id-1.4.19.11.23"><span><span class="glossterm">freezer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.23">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-backup-restore-and-disaster-recovery-service-freezer" title="Backup, Restore, and Disaster Recovery service (freezer)">Backup, Restore, and Disaster Recovery service (freezer)</a>.</p></dd><dt id="id-1.4.19.11.24"><span><span class="glossterm">front end</span> <a title="Permalink" class="permalink" href="#id-1.4.19.11.24">#</a></span></dt><dd class="glossdef"><p>The point where a user interacts with a service; can be an API
endpoint, the dashboard, or a command-line tool.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.12"><h3 class="title">G</h3><dl><dt id="id-1.4.19.12.3"><span><span class="glossterm">gateway</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.3">#</a></span></dt><dd class="glossdef"><p>An IP address, typically assigned to a router, that
passes network traffic between different networks.</p></dd><dt id="id-1.4.19.12.4"><span><span class="glossterm">generic receive offload (GRO)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.4">#</a></span></dt><dd class="glossdef"><p>Feature of certain network interface drivers that
combines many smaller received packets into a large packet
before delivery to the kernel IP stack.</p></dd><dt id="id-1.4.19.12.5"><span><span class="glossterm">generic routing encapsulation (GRE)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.5">#</a></span></dt><dd class="glossdef"><p>Protocol that encapsulates a wide variety of network
layer protocols inside virtual point-to-point links.</p></dd><dt id="id-1.4.19.12.6"><span><span class="glossterm">glance</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.6">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-image-service-glance" title="Image service (glance)">Image service (glance)</a>.</p></dd><dt id="id-1.4.19.12.7"><span><span class="glossterm">glance API server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.7">#</a></span></dt><dd class="glossdef"><p>Alternative name for the <a class="xref" href="#term-image-api" title="Image API">Image API</a>.</p></dd><dt id="id-1.4.19.12.8"><span><span class="glossterm">glance registry</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.8">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Image service <a class="xref" href="#term-image-registry" title="image registry">image registry</a>.</p></dd><dt id="id-1.4.19.12.9"><span><span class="glossterm">global endpoint template</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.9">#</a></span></dt><dd class="glossdef"><p>The Identity service endpoint template that contains services
available to all projects.</p></dd><dt id="id-1.4.19.12.10"><span><span class="glossterm">GlusterFS</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.10">#</a></span></dt><dd class="glossdef"><p>A file system designed to aggregate NAS hosts, compatible with
OpenStack.</p></dd><dt id="id-1.4.19.12.11"><span><span class="glossterm">gnocchi</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.11">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; provides an indexer and time-series
database.</p></dd><dt id="id-1.4.19.12.12"><span><span class="glossterm">golden image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.12">#</a></span></dt><dd class="glossdef"><p>A method of operating system installation where a finalized disk
image is created and then used by all nodes without
modification.</p></dd><dt id="term-governance-service-congress"><span><span class="glossterm">Governance service (congress)</span> <a title="Permalink" class="permalink" href="#term-governance-service-congress">#</a></span></dt><dd class="glossdef"><p>The project that provides Governance-as-a-Service across
any collection of cloud services in order to monitor,
enforce, and audit policy over dynamic infrastructure.</p></dd><dt id="id-1.4.19.12.14"><span><span class="glossterm">Graphic Interchange Format (GIF)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.14">#</a></span></dt><dd class="glossdef"><p>A type of image file that is commonly used for animated images
on web pages.</p></dd><dt id="id-1.4.19.12.15"><span><span class="glossterm">Graphics Processing Unit (GPU)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.15">#</a></span></dt><dd class="glossdef"><p>Choosing a host based on the existence of a GPU is currently
unsupported in OpenStack.</p></dd><dt id="id-1.4.19.12.16"><span><span class="glossterm">Green Threads</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.16">#</a></span></dt><dd class="glossdef"><p>The cooperative threading model used by Python; reduces race
conditions and only context switches when specific library calls are
made. Each OpenStack service is its own thread.</p></dd><dt id="id-1.4.19.12.17"><span><span class="glossterm">Grizzly</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.17">#</a></span></dt><dd class="glossdef"><p>The code name for the seventh release of
OpenStack. The design summit took place in
San Diego, California, US and Grizzly is an element of the state flag of
California.</p></dd><dt id="id-1.4.19.12.18"><span><span class="glossterm">Group</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.18">#</a></span></dt><dd class="glossdef"><p>An Identity v3 API entity. Represents a collection of users that is
owned by a specific domain.</p></dd><dt id="id-1.4.19.12.19"><span><span class="glossterm">guest OS</span> <a title="Permalink" class="permalink" href="#id-1.4.19.12.19">#</a></span></dt><dd class="glossdef"><p>An operating system instance running under the control of a
hypervisor.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.13"><h3 class="title">H</h3><dl><dt id="id-1.4.19.13.3"><span><span class="glossterm">Hadoop</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.3">#</a></span></dt><dd class="glossdef"><p>Apache Hadoop is an open source software framework that supports
data-intensive distributed applications.</p></dd><dt id="id-1.4.19.13.4"><span><span class="glossterm">Hadoop Distributed File System (HDFS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.4">#</a></span></dt><dd class="glossdef"><p>A distributed, highly fault-tolerant file system designed to run
on low-cost commodity hardware.</p></dd><dt id="id-1.4.19.13.5"><span><span class="glossterm">handover</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.5">#</a></span></dt><dd class="glossdef"><p>An object state in Object Storage where a new replica of the
object is automatically created due to a drive failure.</p></dd><dt id="term-haproxy"><span><span class="glossterm">HAProxy</span> <a title="Permalink" class="permalink" href="#term-haproxy">#</a></span></dt><dd class="glossdef"><p>Provides a high availability load balancer and proxy server for
TCP and HTTP-based applications that spreads requests across
multiple servers.</p></dd><dt id="id-1.4.19.13.7"><span><span class="glossterm">hard reboot</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.7">#</a></span></dt><dd class="glossdef"><p>A type of reboot where a physical or virtual power button is
pressed as opposed to a graceful, proper shutdown of the operating
system.</p></dd><dt id="id-1.4.19.13.8"><span><span class="glossterm">Havana</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.8">#</a></span></dt><dd class="glossdef"><p>The code name for the eighth release of OpenStack. The
design summit took place in Portland, Oregon, US and Havana is
an unincorporated community in Oregon.</p></dd><dt id="id-1.4.19.13.9"><span><span class="glossterm">health monitor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.9">#</a></span></dt><dd class="glossdef"><p>Determines whether back-end members of a VIP pool can
process a request. A pool can have several health monitors
associated with it. When a pool has several monitors
associated with it, all monitors check each member of the
pool. All monitors must declare a member to be healthy for
it to stay active.</p></dd><dt id="id-1.4.19.13.10"><span><span class="glossterm">heat</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.10">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-orchestration-service-heat" title="Orchestration service (heat)">Orchestration service (heat)</a>.</p></dd><dt id="id-1.4.19.13.11"><span><span class="glossterm">Heat Orchestration Template (HOT)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.11">#</a></span></dt><dd class="glossdef"><p>Heat input in the format native to OpenStack.</p></dd><dt id="id-1.4.19.13.12"><span><span class="glossterm">high availability (HA)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.12">#</a></span></dt><dd class="glossdef"><p>A high availability system design approach and associated
service implementation ensures that a prearranged level of
operational performance will be met during a contractual
measurement period. High availability systems seek to
minimize system downtime and data loss.</p></dd><dt id="id-1.4.19.13.13"><span><span class="glossterm">horizon</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.13">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-dashboard-horizon" title="Dashboard (horizon)">Dashboard (horizon)</a>.</p></dd><dt id="id-1.4.19.13.14"><span><span class="glossterm">horizon plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.14">#</a></span></dt><dd class="glossdef"><p>A plug-in for the OpenStack Dashboard (horizon).</p></dd><dt id="id-1.4.19.13.15"><span><span class="glossterm">host</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.15">#</a></span></dt><dd class="glossdef"><p>A physical computer, not a VM instance (node).</p></dd><dt id="id-1.4.19.13.16"><span><span class="glossterm">host aggregate</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.16">#</a></span></dt><dd class="glossdef"><p>A method to further subdivide availability zones into hypervisor
pools, a collection of common hosts.</p></dd><dt id="id-1.4.19.13.17"><span><span class="glossterm">Host Bus Adapter (HBA)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.17">#</a></span></dt><dd class="glossdef"><p>Device plugged into a PCI slot, such as a fibre channel or
network card.</p></dd><dt id="id-1.4.19.13.18"><span><span class="glossterm">hybrid cloud</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.18">#</a></span></dt><dd class="glossdef"><p>A hybrid cloud is a composition of two or more clouds
(private, community or public) that remain distinct entities
but are bound together, offering the benefits of multiple
deployment models.  Hybrid cloud can also mean the ability
to connect colocation, managed and/or dedicated services
with cloud resources.</p></dd><dt id="id-1.4.19.13.19"><span><span class="glossterm">hyperlink</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.19">#</a></span></dt><dd class="glossdef"><p>Any kind of text that contains a link to some other site,
commonly found in documents where clicking on a word or words opens up
a different website.</p></dd><dt id="id-1.4.19.13.20"><span><span class="glossterm">Hypertext Transfer Protocol (HTTP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.20">#</a></span></dt><dd class="glossdef"><p>An application protocol for distributed, collaborative,
hypermedia information systems. It is the foundation of data
communication for the World Wide Web. Hypertext is structured
text that uses logical links (hyperlinks) between nodes containing
text. HTTP is the protocol to exchange or transfer hypertext.</p></dd><dt id="id-1.4.19.13.21"><span><span class="glossterm">Hypertext Transfer Protocol Secure (HTTPS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.21">#</a></span></dt><dd class="glossdef"><p>An encrypted communications protocol for secure communication
over a computer network, with especially wide deployment on the
Internet. Technically, it is not a protocol in and of itself;
rather, it is the result of simply layering the Hypertext Transfer
Protocol (HTTP) on top of the TLS or SSL protocol, thus adding the
security capabilities of TLS or SSL to standard HTTP communications.
Most OpenStack API endpoints and many inter-component communications
support HTTPS communication.</p></dd><dt id="id-1.4.19.13.22"><span><span class="glossterm">hypervisor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.22">#</a></span></dt><dd class="glossdef"><p>Software that arbitrates and controls VM access to the actual
underlying hardware.</p></dd><dt id="id-1.4.19.13.23"><span><span class="glossterm">hypervisor pool</span> <a title="Permalink" class="permalink" href="#id-1.4.19.13.23">#</a></span></dt><dd class="glossdef"><p>A collection of hypervisors grouped together through host
aggregates.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.14"><h3 class="title">I</h3><dl><dt id="id-1.4.19.14.3"><span><span class="glossterm">Icehouse</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.3">#</a></span></dt><dd class="glossdef"><p>The code name for the ninth release of OpenStack. The
design summit took place in Hong Kong and Ice House is a
street in that city.</p></dd><dt id="id-1.4.19.14.4"><span><span class="glossterm">ID number</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.4">#</a></span></dt><dd class="glossdef"><p>Unique numeric ID associated with each user in Identity,
conceptually similar to a Linux or LDAP UID.</p></dd><dt id="id-1.4.19.14.5"><span><span class="glossterm">Identity API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.5">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Identity service API.</p></dd><dt id="id-1.4.19.14.6"><span><span class="glossterm">Identity back end</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.6">#</a></span></dt><dd class="glossdef"><p>The source used by Identity service to retrieve user
information; an OpenLDAP server, for example.</p></dd><dt id="id-1.4.19.14.7"><span><span class="glossterm">identity provider</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.7">#</a></span></dt><dd class="glossdef"><p>A directory service, which allows users to login with a user
name and password. It is a typical source of authentication
tokens.</p></dd><dt id="term-identity-service-keystone"><span><span class="glossterm">Identity service (keystone)</span> <a title="Permalink" class="permalink" href="#term-identity-service-keystone">#</a></span></dt><dd class="glossdef"><p>The project that facilitates API client authentication, service
discovery, distributed multi-tenant authorization, and auditing.
It provides a central directory of users mapped to the OpenStack
services they can access. It also registers endpoints for OpenStack
services and acts as a common authentication system.</p></dd><dt id="id-1.4.19.14.9"><span><span class="glossterm">Identity service API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.9">#</a></span></dt><dd class="glossdef"><p>The API used to access the OpenStack Identity service provided
through keystone.</p></dd><dt id="id-1.4.19.14.10"><span><span class="glossterm">image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.10">#</a></span></dt><dd class="glossdef"><p>A collection of files for a specific operating system (OS) that
you use to create or rebuild a server. OpenStack provides pre-built
images. You can also create custom images, or snapshots, from servers
that you have launched. Custom images can be used for data backups or
as "gold" images for additional servers.</p></dd><dt id="term-image-api"><span><span class="glossterm">Image API</span> <a title="Permalink" class="permalink" href="#term-image-api">#</a></span></dt><dd class="glossdef"><p>The Image service API endpoint for management of VM
images.
Processes client requests for VMs, updates Image service
metadata on the registry server, and communicates with the store
adapter to upload VM images from the back-end store.</p></dd><dt id="id-1.4.19.14.12"><span><span class="glossterm">image cache</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.12">#</a></span></dt><dd class="glossdef"><p>Used by Image service to obtain images on the local host rather
than re-downloading them from the image server each time one is
requested.</p></dd><dt id="id-1.4.19.14.13"><span><span class="glossterm">image ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.13">#</a></span></dt><dd class="glossdef"><p>Combination of a URI and UUID used to access Image service VM
images through the image API.</p></dd><dt id="id-1.4.19.14.14"><span><span class="glossterm">image membership</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.14">#</a></span></dt><dd class="glossdef"><p>A list of projects that can access a given VM image within Image
service.</p></dd><dt id="id-1.4.19.14.15"><span><span class="glossterm">image owner</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.15">#</a></span></dt><dd class="glossdef"><p>The project who owns an Image service virtual machine
image.</p></dd><dt id="term-image-registry"><span><span class="glossterm">image registry</span> <a title="Permalink" class="permalink" href="#term-image-registry">#</a></span></dt><dd class="glossdef"><p>A list of VM images that are available through Image
service.</p></dd><dt id="term-image-service-glance"><span><span class="glossterm">Image service (glance)</span> <a title="Permalink" class="permalink" href="#term-image-service-glance">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provide services and associated libraries
to store, browse, share, distribute and manage bootable disk images,
other data closely associated with initializing compute resources,
and metadata definitions.</p></dd><dt id="id-1.4.19.14.18"><span><span class="glossterm">image status</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.18">#</a></span></dt><dd class="glossdef"><p>The current status of a VM image in Image service, not to be
confused with the status of a running instance.</p></dd><dt id="id-1.4.19.14.19"><span><span class="glossterm">image store</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.19">#</a></span></dt><dd class="glossdef"><p>The back-end store used by Image service to store VM images,
options include Object Storage, locally mounted file system,
RADOS block devices, VMware datastore, or HTTP.</p></dd><dt id="id-1.4.19.14.20"><span><span class="glossterm">image UUID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.20">#</a></span></dt><dd class="glossdef"><p>UUID used by Image service to uniquely identify each VM
image.</p></dd><dt id="id-1.4.19.14.21"><span><span class="glossterm">incubated project</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.21">#</a></span></dt><dd class="glossdef"><p>A community project may be elevated to this status and is then
promoted to a core project.</p></dd><dt id="term-infrastructure-optimization-service-watcher"><span><span class="glossterm">Infrastructure Optimization service (watcher)</span> <a title="Permalink" class="permalink" href="#term-infrastructure-optimization-service-watcher">#</a></span></dt><dd class="glossdef"><p>OpenStack project that aims to provide a flexible and scalable resource
optimization service for multi-tenant OpenStack-based clouds.</p></dd><dt id="term-infrastructure-as-a-service-iaas"><span><span class="glossterm">Infrastructure-as-a-Service (IaaS)</span> <a title="Permalink" class="permalink" href="#term-infrastructure-as-a-service-iaas">#</a></span></dt><dd class="glossdef"><p>IaaS is a provisioning model in which an organization outsources
physical components of a data center, such as storage, hardware,
servers, and networking components. A service provider owns the
equipment and is responsible for housing, operating and maintaining
it. The client typically pays on a per-use basis.
IaaS is a model for providing cloud services.</p></dd><dt id="id-1.4.19.14.24"><span><span class="glossterm">ingress filtering</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.24">#</a></span></dt><dd class="glossdef"><p>The process of filtering incoming network traffic. Supported by
Compute.</p></dd><dt id="id-1.4.19.14.25"><span><span class="glossterm">INI format</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.25">#</a></span></dt><dd class="glossdef"><p>The OpenStack configuration files use an INI format to
describe options and their values. It consists of sections
and key value pairs.</p></dd><dt id="id-1.4.19.14.26"><span><span class="glossterm">injection</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.26">#</a></span></dt><dd class="glossdef"><p>The process of putting a file into a virtual machine image
before the instance is started.</p></dd><dt id="term-input-output-operations-per-second-iops"><span><span class="glossterm">Input/Output Operations Per Second (IOPS)</span> <a title="Permalink" class="permalink" href="#term-input-output-operations-per-second-iops">#</a></span></dt><dd class="glossdef"><p>IOPS are a common performance measurement used to benchmark computer
storage devices like hard disk drives, solid state drives, and
storage area networks.</p></dd><dt id="id-1.4.19.14.28"><span><span class="glossterm">instance</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.28">#</a></span></dt><dd class="glossdef"><p>A running VM, or a VM in a known state such as suspended, that
can be used like a hardware server.</p></dd><dt id="id-1.4.19.14.29"><span><span class="glossterm">instance ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.29">#</a></span></dt><dd class="glossdef"><p>Alternative term for instance UUID.</p></dd><dt id="id-1.4.19.14.30"><span><span class="glossterm">instance state</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.30">#</a></span></dt><dd class="glossdef"><p>The current state of a guest VM image.</p></dd><dt id="id-1.4.19.14.31"><span><span class="glossterm">instance tunnels network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.31">#</a></span></dt><dd class="glossdef"><p>A network segment used for instance traffic tunnels
between compute nodes and the network node.</p></dd><dt id="id-1.4.19.14.32"><span><span class="glossterm">instance type</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.32">#</a></span></dt><dd class="glossdef"><p>Describes the parameters of the various virtual machine images
that are available to users; includes parameters such as CPU, storage,
and memory. Alternative term for flavor.</p></dd><dt id="id-1.4.19.14.33"><span><span class="glossterm">instance type ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.33">#</a></span></dt><dd class="glossdef"><p>Alternative term for a flavor ID.</p></dd><dt id="id-1.4.19.14.34"><span><span class="glossterm">instance UUID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.34">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each guest VM instance.</p></dd><dt id="id-1.4.19.14.35"><span><span class="glossterm">Intelligent Platform Management Interface (IPMI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.35">#</a></span></dt><dd class="glossdef"><p>IPMI is a standardized computer system interface used by system
administrators for out-of-band management of computer systems and
monitoring of their operation. In layman's terms, it is a way to
manage a computer using a direct network connection, whether it is
turned on or not; connecting to the hardware rather than an operating
system or login shell.</p></dd><dt id="id-1.4.19.14.36"><span><span class="glossterm">interface</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.36">#</a></span></dt><dd class="glossdef"><p>A physical or virtual device that provides connectivity
to another device or medium.</p></dd><dt id="id-1.4.19.14.37"><span><span class="glossterm">interface ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.37">#</a></span></dt><dd class="glossdef"><p>Unique ID for a Networking VIF or vNIC in the form of a
UUID.</p></dd><dt id="id-1.4.19.14.38"><span><span class="glossterm">Internet Control Message Protocol (ICMP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.38">#</a></span></dt><dd class="glossdef"><p>A network protocol used by network devices for control messages.
For example, <code class="command">ping</code> uses ICMP to test
connectivity.</p></dd><dt id="id-1.4.19.14.39"><span><span class="glossterm">Internet protocol (IP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.39">#</a></span></dt><dd class="glossdef"><p>Principal communications protocol in the internet protocol
suite for relaying datagrams across network boundaries.</p></dd><dt id="id-1.4.19.14.40"><span><span class="glossterm">Internet Service Provider (ISP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.40">#</a></span></dt><dd class="glossdef"><p>Any business that provides Internet access to individuals or
businesses.</p></dd><dt id="id-1.4.19.14.41"><span><span class="glossterm">Internet Small Computer System Interface (iSCSI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.41">#</a></span></dt><dd class="glossdef"><p>Storage protocol that encapsulates SCSI frames for transport
over IP networks.
Supported by Compute, Object Storage, and Image service.</p></dd><dt id="id-1.4.19.14.42"><span><span class="glossterm">IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.42">#</a></span></dt><dd class="glossdef"><p>Number that is unique to every computer system on the Internet.
Two versions of the Internet Protocol (IP) are in use for addresses:
IPv4 and IPv6.</p></dd><dt id="id-1.4.19.14.43"><span><span class="glossterm">IP Address Management (IPAM)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.43">#</a></span></dt><dd class="glossdef"><p>The process of automating IP address allocation, deallocation,
and management. Currently provided by Compute, melange, and
Networking.</p></dd><dt id="id-1.4.19.14.44"><span><span class="glossterm">ip6tables</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.44">#</a></span></dt><dd class="glossdef"><p>Tool used to set up, maintain, and inspect the tables of IPv6
packet filter rules in the Linux kernel. In OpenStack Compute,
ip6tables is used along with arptables, ebtables, and iptables to
create firewalls for both nodes and VMs.</p></dd><dt id="id-1.4.19.14.45"><span><span class="glossterm">ipset</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.45">#</a></span></dt><dd class="glossdef"><p>Extension to iptables that allows creation of firewall rules
that match entire "sets" of IP addresses simultaneously. These
sets reside in indexed data structures to increase efficiency,
particularly on systems with a large quantity of rules.</p></dd><dt id="id-1.4.19.14.46"><span><span class="glossterm">iptables</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.46">#</a></span></dt><dd class="glossdef"><p>Used along with arptables and ebtables, iptables create
firewalls in Compute. iptables are the tables provided by the Linux
kernel firewall (implemented as different Netfilter modules) and the
chains and rules it stores. Different kernel modules and programs are
currently used for different protocols: iptables applies to IPv4,
ip6tables to IPv6, arptables to ARP, and ebtables to Ethernet frames.
Requires root privilege to manipulate.</p></dd><dt id="id-1.4.19.14.47"><span><span class="glossterm">ironic</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.47">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-bare-metal-service-ironic" title="Bare Metal service (ironic)">Bare Metal service (ironic)</a>.</p></dd><dt id="term-iscsi-qualified-name-iqn"><span><span class="glossterm">iSCSI Qualified Name (IQN)</span> <a title="Permalink" class="permalink" href="#term-iscsi-qualified-name-iqn">#</a></span></dt><dd class="glossdef"><p>IQN is the format most commonly used for iSCSI names, which uniquely
identify nodes in an iSCSI network.
All IQNs follow the pattern iqn.yyyy-mm.domain:identifier, where
'yyyy-mm' is the year and month in which the domain was registered,
'domain' is the reversed domain name of the issuing organization, and
'identifier' is an optional string which makes each IQN under the same
domain unique. For example, 'iqn.2015-10.org.openstack.408ae959bce1'.</p></dd><dt id="id-1.4.19.14.49"><span><span class="glossterm">ISO9660</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.49">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.4.19.14.50"><span><span class="glossterm">itsec</span> <a title="Permalink" class="permalink" href="#id-1.4.19.14.50">#</a></span></dt><dd class="glossdef"><p>A default role in the Compute RBAC system that can quarantine an
instance in any project.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.15"><h3 class="title">J</h3><dl><dt id="id-1.4.19.15.3"><span><span class="glossterm">Java</span> <a title="Permalink" class="permalink" href="#id-1.4.19.15.3">#</a></span></dt><dd class="glossdef"><p>A programming language that is used to create systems that
involve more than one computer by way of a network.</p></dd><dt id="id-1.4.19.15.4"><span><span class="glossterm">JavaScript</span> <a title="Permalink" class="permalink" href="#id-1.4.19.15.4">#</a></span></dt><dd class="glossdef"><p>A scripting language that is used to build web pages.</p></dd><dt id="id-1.4.19.15.5"><span><span class="glossterm">JavaScript Object Notation (JSON)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.15.5">#</a></span></dt><dd class="glossdef"><p>One of the supported response formats in OpenStack.</p></dd><dt id="id-1.4.19.15.6"><span><span class="glossterm">Jenkins</span> <a title="Permalink" class="permalink" href="#id-1.4.19.15.6">#</a></span></dt><dd class="glossdef"><p>Tool used to run jobs automatically for OpenStack
development.</p></dd><dt id="id-1.4.19.15.7"><span><span class="glossterm">jumbo frame</span> <a title="Permalink" class="permalink" href="#id-1.4.19.15.7">#</a></span></dt><dd class="glossdef"><p>Feature in modern Ethernet networks that supports frames up to
approximately 9000 bytes.</p></dd><dt id="id-1.4.19.15.8"><span><span class="glossterm">Juno</span> <a title="Permalink" class="permalink" href="#id-1.4.19.15.8">#</a></span></dt><dd class="glossdef"><p>The code name for the tenth release of OpenStack. The
design summit took place in Atlanta, Georgia, US and Juno is
an unincorporated community in Georgia.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.16"><h3 class="title">K</h3><dl><dt id="id-1.4.19.16.3"><span><span class="glossterm">Kerberos</span> <a title="Permalink" class="permalink" href="#id-1.4.19.16.3">#</a></span></dt><dd class="glossdef"><p>A network authentication protocol which works on the basis of
tickets. Kerberos allows nodes communication over a non-secure
network, and allows nodes to prove their identity to one another in a
secure manner.</p></dd><dt id="id-1.4.19.16.4"><span><span class="glossterm">kernel-based VM (KVM)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.16.4">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor. KVM is a full
virtualization solution for Linux on x86 hardware containing
virtualization extensions (Intel VT or AMD-V), ARM, IBM
Power, and IBM zSeries. It consists of a loadable kernel
module, that provides the core virtualization infrastructure
and a processor specific module.</p></dd><dt id="term-key-manager-service-barbican"><span><span class="glossterm">Key Manager service (barbican)</span> <a title="Permalink" class="permalink" href="#term-key-manager-service-barbican">#</a></span></dt><dd class="glossdef"><p>The project that produces a secret storage and
generation system capable of providing key management for
services wishing to enable encryption features.</p></dd><dt id="id-1.4.19.16.6"><span><span class="glossterm">keystone</span> <a title="Permalink" class="permalink" href="#id-1.4.19.16.6">#</a></span></dt><dd class="glossdef"><p>Codename of the <a class="xref" href="#term-identity-service-keystone" title="Identity service (keystone)">Identity service (keystone)</a>.</p></dd><dt id="id-1.4.19.16.7"><span><span class="glossterm">Kickstart</span> <a title="Permalink" class="permalink" href="#id-1.4.19.16.7">#</a></span></dt><dd class="glossdef"><p>A tool to automate system configuration and installation on Red
Hat, Fedora, and CentOS-based Linux distributions.</p></dd><dt id="id-1.4.19.16.8"><span><span class="glossterm">Kilo</span> <a title="Permalink" class="permalink" href="#id-1.4.19.16.8">#</a></span></dt><dd class="glossdef"><p>The code name for the eleventh release of OpenStack. The
design summit took place in Paris, France. Due to delays in the name
selection, the release was known only as K. Because <code class="literal">k</code> is the
unit symbol for kilo and the reference artifact is stored near Paris
in the Pavillon de Breteuil in Sèvres, the community chose Kilo as
the release name.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.17"><h3 class="title">L</h3><dl><dt id="id-1.4.19.17.3"><span><span class="glossterm">large object</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.3">#</a></span></dt><dd class="glossdef"><p>An object within Object Storage that is larger than 5 GB.</p></dd><dt id="id-1.4.19.17.4"><span><span class="glossterm">Launchpad</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.4">#</a></span></dt><dd class="glossdef"><p>The collaboration site for OpenStack.</p></dd><dt id="id-1.4.19.17.5"><span><span class="glossterm">Layer-2 (L2) agent</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.5">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides layer-2
connectivity for virtual networks.</p></dd><dt id="id-1.4.19.17.6"><span><span class="glossterm">Layer-2 network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.6">#</a></span></dt><dd class="glossdef"><p>Term used in the OSI network architecture for the data link
layer. The data link layer is responsible for media access
control, flow control and detecting and possibly correcting
errors that may occur in the physical layer.</p></dd><dt id="id-1.4.19.17.7"><span><span class="glossterm">Layer-3 (L3) agent</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.7">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides layer-3
(routing) services for virtual networks.</p></dd><dt id="id-1.4.19.17.8"><span><span class="glossterm">Layer-3 network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.8">#</a></span></dt><dd class="glossdef"><p>Term used in the OSI network architecture for the network
layer. The network layer is responsible for packet
forwarding including routing from one node to another.</p></dd><dt id="id-1.4.19.17.9"><span><span class="glossterm">Liberty</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.9">#</a></span></dt><dd class="glossdef"><p>The code name for the twelfth release of OpenStack. The
design summit took place in Vancouver, Canada and Liberty is
the name of a village in the Canadian province of
Saskatchewan.</p></dd><dt id="id-1.4.19.17.10"><span><span class="glossterm">libvirt</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.10">#</a></span></dt><dd class="glossdef"><p>Virtualization API library used by OpenStack to interact with
many of its supported hypervisors.</p></dd><dt id="id-1.4.19.17.11"><span><span class="glossterm">Lightweight Directory Access Protocol (LDAP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.11">#</a></span></dt><dd class="glossdef"><p>An application protocol for accessing and maintaining distributed
directory information services over an IP network.</p></dd><dt id="id-1.4.19.17.12"><span><span class="glossterm">Linux bridge</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.12">#</a></span></dt><dd class="glossdef"><p>Software that enables multiple VMs to share a single physical
NIC within Compute.</p></dd><dt id="id-1.4.19.17.13"><span><span class="glossterm">Linux Bridge neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.13">#</a></span></dt><dd class="glossdef"><p>Enables a Linux bridge to understand a Networking port,
interface attachment, and other abstractions.</p></dd><dt id="id-1.4.19.17.14"><span><span class="glossterm">Linux containers (LXC)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.14">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.4.19.17.15"><span><span class="glossterm">live migration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.15">#</a></span></dt><dd class="glossdef"><p>The ability within Compute to move running virtual machine
instances from one host to another with only a small service
interruption during switchover.</p></dd><dt id="id-1.4.19.17.16"><span><span class="glossterm">load balancer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.16">#</a></span></dt><dd class="glossdef"><p>A load balancer is a logical device that belongs to a cloud
account. It is used to distribute workloads between multiple back-end
systems or services, based on the criteria defined as part of its
configuration.</p></dd><dt id="id-1.4.19.17.17"><span><span class="glossterm">load balancing</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.17">#</a></span></dt><dd class="glossdef"><p>The process of spreading client requests between two or more
nodes to improve performance and availability.</p></dd><dt id="id-1.4.19.17.18"><span><span class="glossterm">Load-Balancer-as-a-Service (LBaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.17.18">#</a></span></dt><dd class="glossdef"><p>Enables Networking to distribute incoming requests evenly
between designated instances.</p></dd><dt id="term-load-balancing-service-octavia"><span><span class="glossterm">Load-balancing service (octavia)</span> <a title="Permalink" class="permalink" href="#term-load-balancing-service-octavia">#</a></span></dt><dd class="glossdef"><p>The project that aims to rovide scalable, on demand, self service
access to load-balancer services, in technology-agnostic manner.</p></dd><dt id="term-logical-volume-manager-lvm"><span><span class="glossterm">Logical Volume Manager (LVM)</span> <a title="Permalink" class="permalink" href="#term-logical-volume-manager-lvm">#</a></span></dt><dd class="glossdef"><p>Provides a method of allocating space on mass-storage
devices that is more flexible than conventional partitioning
schemes.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.18"><h3 class="title">M</h3><dl><dt id="id-1.4.19.18.3"><span><span class="glossterm">magnum</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.3">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-container-infrastructure-management-service-magnum" title="Container Infrastructure Management service (magnum)">Container Infrastructure Management service (magnum)</a>.</p></dd><dt id="id-1.4.19.18.4"><span><span class="glossterm">management API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.4">#</a></span></dt><dd class="glossdef"><p>Alternative term for an admin API.</p></dd><dt id="id-1.4.19.18.5"><span><span class="glossterm">management network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.5">#</a></span></dt><dd class="glossdef"><p>A network segment used for administration, not accessible to the
public Internet.</p></dd><dt id="id-1.4.19.18.6"><span><span class="glossterm">manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.6">#</a></span></dt><dd class="glossdef"><p>Logical groupings of related code, such as the Block Storage
volume manager or network manager.</p></dd><dt id="id-1.4.19.18.7"><span><span class="glossterm">manifest</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.7">#</a></span></dt><dd class="glossdef"><p>Used to track segments of a large object within Object
Storage.</p></dd><dt id="id-1.4.19.18.8"><span><span class="glossterm">manifest object</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.8">#</a></span></dt><dd class="glossdef"><p>A special Object Storage object that contains the manifest for a
large object.</p></dd><dt id="id-1.4.19.18.9"><span><span class="glossterm">manila</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.9">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-shared-file-systems-service-manila" title="Shared File Systems service (manila)">Shared File Systems service (manila)</a>.</p></dd><dt id="id-1.4.19.18.10"><span><span class="glossterm">manila-share</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.10">#</a></span></dt><dd class="glossdef"><p>Responsible for managing Shared File System Service devices, specifically
the back-end devices.</p></dd><dt id="id-1.4.19.18.11"><span><span class="glossterm">maximum transmission unit (MTU)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.11">#</a></span></dt><dd class="glossdef"><p>Maximum frame or packet size for a particular network
medium. Typically 1500 bytes for Ethernet networks.</p></dd><dt id="id-1.4.19.18.12"><span><span class="glossterm">mechanism driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.12">#</a></span></dt><dd class="glossdef"><p>A driver for the Modular Layer 2 (ML2) neutron plug-in that
provides layer-2 connectivity for virtual instances. A
single OpenStack installation can use multiple mechanism
drivers.</p></dd><dt id="id-1.4.19.18.13"><span><span class="glossterm">melange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.13">#</a></span></dt><dd class="glossdef"><p>Project name for OpenStack Network Information Service. To be
merged with Networking.</p></dd><dt id="id-1.4.19.18.14"><span><span class="glossterm">membership</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.14">#</a></span></dt><dd class="glossdef"><p>The association between an Image service VM image and a project.
Enables images to be shared with specified projects.</p></dd><dt id="id-1.4.19.18.15"><span><span class="glossterm">membership list</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.15">#</a></span></dt><dd class="glossdef"><p>A list of projects that can access a given VM image within Image
service.</p></dd><dt id="id-1.4.19.18.16"><span><span class="glossterm">memcached</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.16">#</a></span></dt><dd class="glossdef"><p>A distributed memory object caching system that is used by
Object Storage for caching.</p></dd><dt id="id-1.4.19.18.17"><span><span class="glossterm">memory overcommit</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.17">#</a></span></dt><dd class="glossdef"><p>The ability to start new VM instances based on the actual memory
usage of a host, as opposed to basing the decision on the amount of
RAM each running instance thinks it has available. Also known as RAM
overcommit.</p></dd><dt id="id-1.4.19.18.18"><span><span class="glossterm">message broker</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.18">#</a></span></dt><dd class="glossdef"><p>The software package used to provide AMQP messaging capabilities
within Compute. Default package is RabbitMQ.</p></dd><dt id="id-1.4.19.18.19"><span><span class="glossterm">message bus</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.19">#</a></span></dt><dd class="glossdef"><p>The main virtual communication line used by all AMQP messages
for inter-cloud communications within Compute.</p></dd><dt id="id-1.4.19.18.20"><span><span class="glossterm">message queue</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.20">#</a></span></dt><dd class="glossdef"><p>Passes requests from clients to the appropriate workers and
returns the output to the client after the job completes.</p></dd><dt id="term-message-service-zaqar"><span><span class="glossterm">Message service (zaqar)</span> <a title="Permalink" class="permalink" href="#term-message-service-zaqar">#</a></span></dt><dd class="glossdef"><p>The project that provides a messaging service that affords a
variety of distributed application patterns in an efficient,
scalable and highly available manner, and to create and maintain
associated Python libraries and documentation.</p></dd><dt id="id-1.4.19.18.22"><span><span class="glossterm">Meta-Data Server (MDS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.22">#</a></span></dt><dd class="glossdef"><p>Stores CephFS metadata.</p></dd><dt id="id-1.4.19.18.23"><span><span class="glossterm">Metadata agent</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.23">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides metadata
services for instances.</p></dd><dt id="id-1.4.19.18.24"><span><span class="glossterm">migration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.24">#</a></span></dt><dd class="glossdef"><p>The process of moving a VM instance from one host to
another.</p></dd><dt id="id-1.4.19.18.25"><span><span class="glossterm">mistral</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.25">#</a></span></dt><dd class="glossdef"><p>Code name for <a class="xref" href="#term-workflow-service-mistral" title="Workflow service (mistral)">Workflow service (mistral)</a>.</p></dd><dt id="id-1.4.19.18.26"><span><span class="glossterm">Mitaka</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.26">#</a></span></dt><dd class="glossdef"><p>The code name for the thirteenth release of OpenStack.
The design summit took place in Tokyo, Japan. Mitaka
is a city in Tokyo.</p></dd><dt id="id-1.4.19.18.27"><span><span class="glossterm">Modular Layer 2 (ML2) neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.27">#</a></span></dt><dd class="glossdef"><p>Can concurrently use multiple layer-2 networking technologies,
such as 802.1Q and VXLAN, in Networking.</p></dd><dt id="id-1.4.19.18.28"><span><span class="glossterm">monasca</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.28">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-monitoring-monasca" title="Monitoring (monasca)">Monitoring (monasca)</a>.</p></dd><dt id="id-1.4.19.18.29"><span><span class="glossterm">Monitor (LBaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.29">#</a></span></dt><dd class="glossdef"><p>LBaaS feature that provides availability monitoring using the
<code class="literal">ping</code> command, TCP, and HTTP/HTTPS GET.</p></dd><dt id="id-1.4.19.18.30"><span><span class="glossterm">Monitor (Mon)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.30">#</a></span></dt><dd class="glossdef"><p>A Ceph component that communicates with external clients, checks
data state and consistency, and performs quorum functions.</p></dd><dt id="term-monitoring-monasca"><span><span class="glossterm">Monitoring (monasca)</span> <a title="Permalink" class="permalink" href="#term-monitoring-monasca">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provides a multi-tenant, highly scalable,
performant, fault-tolerant monitoring-as-a-service solution for metrics,
complex event processing and logging. To build an extensible platform for
advanced monitoring services that can be used by both operators and
tenants to gain operational insight and visibility, ensuring availability
and stability.</p></dd><dt id="id-1.4.19.18.32"><span><span class="glossterm">multi-factor authentication</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.32">#</a></span></dt><dd class="glossdef"><p>Authentication method that uses two or more credentials, such as
a password and a private key. Currently not supported in
Identity.</p></dd><dt id="id-1.4.19.18.33"><span><span class="glossterm">multi-host</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.33">#</a></span></dt><dd class="glossdef"><p>High-availability mode for legacy (nova) networking.
Each compute node handles NAT and DHCP and acts as a gateway
for all of the VMs on it. A networking failure on one compute
node doesn't affect VMs on other compute nodes.</p></dd><dt id="id-1.4.19.18.34"><span><span class="glossterm">multinic</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.34">#</a></span></dt><dd class="glossdef"><p>Facility in Compute that allows each virtual machine instance to
have more than one VIF connected to it.</p></dd><dt id="id-1.4.19.18.35"><span><span class="glossterm">murano</span> <a title="Permalink" class="permalink" href="#id-1.4.19.18.35">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-application-catalog-service-murano" title="Application Catalog service (murano)">Application Catalog service (murano)</a>.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.19"><h3 class="title">N</h3><dl><dt id="id-1.4.19.19.3"><span><span class="glossterm">Nebula</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.3">#</a></span></dt><dd class="glossdef"><p>Released as open source by NASA in 2010 and is the basis for
Compute.</p></dd><dt id="id-1.4.19.19.4"><span><span class="glossterm">netadmin</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.4">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system. Enables the
user to allocate publicly accessible IP addresses to instances and
change firewall rules.</p></dd><dt id="id-1.4.19.19.5"><span><span class="glossterm">NetApp volume driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.5">#</a></span></dt><dd class="glossdef"><p>Enables Compute to communicate with NetApp storage devices
through the NetApp OnCommand
Provisioning Manager.</p></dd><dt id="id-1.4.19.19.6"><span><span class="glossterm">network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.6">#</a></span></dt><dd class="glossdef"><p>A virtual network that provides connectivity between entities.
For example, a collection of virtual ports that share network
connectivity. In Networking terminology, a network is always a layer-2
network.</p></dd><dt id="id-1.4.19.19.7"><span><span class="glossterm">Network Address Translation (NAT)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.7">#</a></span></dt><dd class="glossdef"><p>Process of modifying IP address information while in transit.
Supported by Compute and Networking.</p></dd><dt id="id-1.4.19.19.8"><span><span class="glossterm">network controller</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.8">#</a></span></dt><dd class="glossdef"><p>A Compute daemon that orchestrates the network configuration of
nodes, including IP addresses, VLANs, and bridging. Also manages
routing for both public and private networks.</p></dd><dt id="id-1.4.19.19.9"><span><span class="glossterm">Network File System (NFS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.9">#</a></span></dt><dd class="glossdef"><p>A method for making file systems available over the network.
Supported by OpenStack.</p></dd><dt id="id-1.4.19.19.10"><span><span class="glossterm">network ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.10">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each network segment within Networking.
Same as network UUID.</p></dd><dt id="id-1.4.19.19.11"><span><span class="glossterm">network manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.11">#</a></span></dt><dd class="glossdef"><p>The Compute component that manages various network components,
such as firewall rules, IP address allocation, and so on.</p></dd><dt id="id-1.4.19.19.12"><span><span class="glossterm">network namespace</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.12">#</a></span></dt><dd class="glossdef"><p>Linux kernel feature that provides independent virtual
networking instances on a single host with separate routing
tables and interfaces. Similar to virtual routing and forwarding
(VRF) services on physical network equipment.</p></dd><dt id="id-1.4.19.19.13"><span><span class="glossterm">network node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.13">#</a></span></dt><dd class="glossdef"><p>Any compute node that runs the network worker daemon.</p></dd><dt id="id-1.4.19.19.14"><span><span class="glossterm">network segment</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.14">#</a></span></dt><dd class="glossdef"><p>Represents a virtual, isolated OSI layer-2 subnet in
Networking.</p></dd><dt id="id-1.4.19.19.15"><span><span class="glossterm">Network Service Header (NSH)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.15">#</a></span></dt><dd class="glossdef"><p>Provides a mechanism for metadata exchange along the
instantiated service path.</p></dd><dt id="id-1.4.19.19.16"><span><span class="glossterm">Network Time Protocol (NTP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.16">#</a></span></dt><dd class="glossdef"><p>Method of keeping a clock for a host or node correct via
communication with a trusted, accurate time source.</p></dd><dt id="id-1.4.19.19.17"><span><span class="glossterm">network UUID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.17">#</a></span></dt><dd class="glossdef"><p>Unique ID for a Networking network segment.</p></dd><dt id="id-1.4.19.19.18"><span><span class="glossterm">network worker</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.18">#</a></span></dt><dd class="glossdef"><p>The <code class="literal">nova-network</code> worker daemon; provides
services such as giving an IP address to a booting nova
instance.</p></dd><dt id="term-networking-api-neutron-api"><span><span class="glossterm">Networking API (Neutron API)</span> <a title="Permalink" class="permalink" href="#term-networking-api-neutron-api">#</a></span></dt><dd class="glossdef"><p>API used to access OpenStack Networking. Provides an extensible
architecture to enable custom plug-in creation.</p></dd><dt id="term-networking-service-neutron"><span><span class="glossterm">Networking service (neutron)</span> <a title="Permalink" class="permalink" href="#term-networking-service-neutron">#</a></span></dt><dd class="glossdef"><p>The OpenStack project which implements services and associated
libraries to provide on-demand, scalable, and technology-agnostic
network abstraction.</p></dd><dt id="id-1.4.19.19.21"><span><span class="glossterm">neutron</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.21">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-networking-service-neutron" title="Networking service (neutron)">Networking service (neutron)</a>.</p></dd><dt id="id-1.4.19.19.22"><span><span class="glossterm">neutron API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.22">#</a></span></dt><dd class="glossdef"><p>An alternative name for <a class="xref" href="#term-networking-api-neutron-api" title="Networking API (Neutron API)">Networking API (Neutron API)</a>.</p></dd><dt id="id-1.4.19.19.23"><span><span class="glossterm">neutron manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.23">#</a></span></dt><dd class="glossdef"><p>Enables Compute and Networking integration, which enables
Networking to perform network management for guest VMs.</p></dd><dt id="id-1.4.19.19.24"><span><span class="glossterm">neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.24">#</a></span></dt><dd class="glossdef"><p>Interface within Networking that enables organizations to create
custom plug-ins for advanced features, such as QoS, ACLs, or
IDS.</p></dd><dt id="id-1.4.19.19.25"><span><span class="glossterm">Newton</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.25">#</a></span></dt><dd class="glossdef"><p>The code name for the fourteenth release of OpenStack. The
design summit took place in Austin, Texas, US. The
release is named after "Newton House" which is located at
1013 E. Ninth St., Austin, TX. which is listed on the
National Register of Historic Places.</p></dd><dt id="id-1.4.19.19.26"><span><span class="glossterm">Nexenta volume driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.26">#</a></span></dt><dd class="glossdef"><p>Provides support for NexentaStor devices in Compute.</p></dd><dt id="term-nfv-orchestration-service-tacker"><span><span class="glossterm">NFV Orchestration Service (tacker)</span> <a title="Permalink" class="permalink" href="#term-nfv-orchestration-service-tacker">#</a></span></dt><dd class="glossdef"><p>OpenStack service that aims to implement Network Function Virtualization
(NFV) Orchestration services and libraries for end-to-end life-cycle
management of Network Services and Virtual Network Functions (VNFs).</p></dd><dt id="id-1.4.19.19.28"><span><span class="glossterm">Nginx</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.28">#</a></span></dt><dd class="glossdef"><p>An HTTP and reverse proxy server, a mail proxy server, and a generic
TCP/UDP proxy server.</p></dd><dt id="id-1.4.19.19.29"><span><span class="glossterm">No ACK</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.29">#</a></span></dt><dd class="glossdef"><p>Disables server-side message acknowledgment in the Compute
RabbitMQ. Increases performance but decreases reliability.</p></dd><dt id="id-1.4.19.19.30"><span><span class="glossterm">node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.30">#</a></span></dt><dd class="glossdef"><p>A VM instance that runs on a host.</p></dd><dt id="id-1.4.19.19.31"><span><span class="glossterm">non-durable exchange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.31">#</a></span></dt><dd class="glossdef"><p>Message exchange that is cleared when the service restarts. Its
data is not written to persistent storage.</p></dd><dt id="id-1.4.19.19.32"><span><span class="glossterm">non-durable queue</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.32">#</a></span></dt><dd class="glossdef"><p>Message queue that is cleared when the service restarts. Its
data is not written to persistent storage.</p></dd><dt id="id-1.4.19.19.33"><span><span class="glossterm">non-persistent volume</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.33">#</a></span></dt><dd class="glossdef"><p>Alternative term for an ephemeral volume.</p></dd><dt id="id-1.4.19.19.34"><span><span class="glossterm">north-south traffic</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.34">#</a></span></dt><dd class="glossdef"><p>Network traffic between a user or client (north) and a
server (south), or traffic into the cloud (south) and
out of the cloud (north). See also east-west traffic.</p></dd><dt id="id-1.4.19.19.35"><span><span class="glossterm">nova</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.35">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-compute-service-nova" title="Compute service (nova)">Compute service (nova)</a>.</p></dd><dt id="id-1.4.19.19.36"><span><span class="glossterm">Nova API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.36">#</a></span></dt><dd class="glossdef"><p>Alternative term for the <a class="xref" href="#term-compute-api-nova-api" title="Compute API (Nova API)">Compute API (Nova API)</a>.</p></dd><dt id="id-1.4.19.19.37"><span><span class="glossterm">nova-network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.19.37">#</a></span></dt><dd class="glossdef"><p>A Compute component that manages IP address allocation,
firewalls, and other network-related tasks. This is the legacy
networking option and an alternative to Networking.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.20"><h3 class="title">O</h3><dl><dt id="id-1.4.19.20.3"><span><span class="glossterm">object</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.3">#</a></span></dt><dd class="glossdef"><p>A BLOB of data held by Object Storage; can be in any
format.</p></dd><dt id="id-1.4.19.20.4"><span><span class="glossterm">object auditor</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.4">#</a></span></dt><dd class="glossdef"><p>Opens all objects for an object server and verifies the MD5
hash, size, and metadata for each object.</p></dd><dt id="id-1.4.19.20.5"><span><span class="glossterm">object expiration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.5">#</a></span></dt><dd class="glossdef"><p>A configurable option within Object Storage to automatically
delete objects after a specified amount of time has passed or a
certain date is reached.</p></dd><dt id="id-1.4.19.20.6"><span><span class="glossterm">object hash</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.6">#</a></span></dt><dd class="glossdef"><p>Unique ID for an Object Storage object.</p></dd><dt id="id-1.4.19.20.7"><span><span class="glossterm">object path hash</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.7">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage to determine the location of an object in
the ring. Maps objects to partitions.</p></dd><dt id="id-1.4.19.20.8"><span><span class="glossterm">object replicator</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.8">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that copies an object to remote
partitions for fault tolerance.</p></dd><dt id="id-1.4.19.20.9"><span><span class="glossterm">object server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.9">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that is responsible for managing
objects.</p></dd><dt id="id-1.4.19.20.10"><span><span class="glossterm">Object Storage API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.10">#</a></span></dt><dd class="glossdef"><p>API used to access OpenStack <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a>.</p></dd><dt id="id-1.4.19.20.11"><span><span class="glossterm">Object Storage Device (OSD)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.11">#</a></span></dt><dd class="glossdef"><p>The Ceph storage daemon.</p></dd><dt id="term-object-storage-service-swift"><span><span class="glossterm">Object Storage service (swift)</span> <a title="Permalink" class="permalink" href="#term-object-storage-service-swift">#</a></span></dt><dd class="glossdef"><p>The OpenStack core project that provides eventually consistent
and redundant storage and retrieval of fixed digital content.</p></dd><dt id="id-1.4.19.20.13"><span><span class="glossterm">object versioning</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.13">#</a></span></dt><dd class="glossdef"><p>Allows a user to set a flag on an <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a> container so that all objects within the container are
versioned.</p></dd><dt id="id-1.4.19.20.14"><span><span class="glossterm">Ocata</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.14">#</a></span></dt><dd class="glossdef"><p>The code name for the fifteenth release of OpenStack. The
design summit will take place in Barcelona, Spain. Ocata is
a beach north of Barcelona.</p></dd><dt id="term-octavia"><span><span class="glossterm">Octavia</span> <a title="Permalink" class="permalink" href="#term-octavia">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-load-balancing-service-octavia" title="Load-balancing service (octavia)">Load-balancing service (octavia)</a>.</p></dd><dt id="id-1.4.19.20.16"><span><span class="glossterm">Oldie</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.16">#</a></span></dt><dd class="glossdef"><p>Term for an <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a>
process that runs for a long time.  Can indicate a hung process.</p></dd><dt id="id-1.4.19.20.17"><span><span class="glossterm">Open Cloud Computing Interface (OCCI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.17">#</a></span></dt><dd class="glossdef"><p>A standardized interface for managing compute, data, and network
resources, currently unsupported in OpenStack.</p></dd><dt id="id-1.4.19.20.18"><span><span class="glossterm">Open Virtualization Format (OVF)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.18">#</a></span></dt><dd class="glossdef"><p>Standard for packaging VM images. Supported in OpenStack.</p></dd><dt id="id-1.4.19.20.19"><span><span class="glossterm">Open vSwitch</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.19">#</a></span></dt><dd class="glossdef"><p>Open vSwitch is a production quality, multilayer virtual
switch licensed under the open source Apache 2.0 license. It
is designed to enable massive network automation through
programmatic extension, while still supporting standard
management interfaces and protocols (for example NetFlow,
sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag).</p></dd><dt id="id-1.4.19.20.20"><span><span class="glossterm">Open vSwitch (OVS) agent</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.20">#</a></span></dt><dd class="glossdef"><p>Provides an interface to the underlying Open vSwitch service for
the Networking plug-in.</p></dd><dt id="id-1.4.19.20.21"><span><span class="glossterm">Open vSwitch neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.21">#</a></span></dt><dd class="glossdef"><p>Provides support for Open vSwitch in Networking.</p></dd><dt id="id-1.4.19.20.22"><span><span class="glossterm">OpenLDAP</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.22">#</a></span></dt><dd class="glossdef"><p>An open source LDAP server. Supported by both Compute and
Identity.</p></dd><dt id="id-1.4.19.20.23"><span><span class="glossterm">OpenStack</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.23">#</a></span></dt><dd class="glossdef"><p>OpenStack is a cloud operating system that controls large pools
of compute, storage, and networking resources throughout a data
center, all managed through a dashboard that gives administrators
control while empowering their users to provision resources through a
web interface. OpenStack is an open source project licensed under the
Apache License 2.0.</p></dd><dt id="id-1.4.19.20.24"><span><span class="glossterm">OpenStack code name</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.24">#</a></span></dt><dd class="glossdef"><p>Each OpenStack release has a code name. Code names ascend in
alphabetical order: Austin, Bexar, Cactus, Diablo, Essex,
Folsom, Grizzly, Havana, Icehouse, Juno, Kilo, Liberty,
Mitaka, Newton, Ocata, Pike, and Queens.
Code names are cities or counties near where the
corresponding OpenStack design summit took place. An
exception, called the Waldon exception, is granted to
elements of the state flag that sound especially cool. Code
names are chosen by popular vote.</p></dd><dt id="id-1.4.19.20.25"><span><span class="glossterm">openSUSE</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.25">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.4.19.20.26"><span><span class="glossterm">operator</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.26">#</a></span></dt><dd class="glossdef"><p>The person responsible for planning and maintaining an OpenStack
installation.</p></dd><dt id="id-1.4.19.20.27"><span><span class="glossterm">optional service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.27">#</a></span></dt><dd class="glossdef"><p>An official OpenStack service defined as optional by
DefCore Committee. Currently, consists of
Dashboard (horizon), Telemetry service (Telemetry),
Orchestration service (heat), Database service (trove),
Bare Metal service (ironic), and so on.</p></dd><dt id="term-orchestration-service-heat"><span><span class="glossterm">Orchestration service (heat)</span> <a title="Permalink" class="permalink" href="#term-orchestration-service-heat">#</a></span></dt><dd class="glossdef"><p>The OpenStack service which orchestrates composite cloud
applications using a declarative template format through
an OpenStack-native REST API.</p></dd><dt id="id-1.4.19.20.29"><span><span class="glossterm">orphan</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.29">#</a></span></dt><dd class="glossdef"><p>In the context of Object Storage, this is a process that is not
terminated after an upgrade, restart, or reload of the service.</p></dd><dt id="id-1.4.19.20.30"><span><span class="glossterm">Oslo</span> <a title="Permalink" class="permalink" href="#id-1.4.19.20.30">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-common-libraries-oslo" title="Common Libraries (oslo)">Common Libraries (oslo)</a>.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.21"><h3 class="title">P</h3><dl><dt id="id-1.4.19.21.3"><span><span class="glossterm">panko</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.3">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; provides event storage.</p></dd><dt id="id-1.4.19.21.4"><span><span class="glossterm">parent cell</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.4">#</a></span></dt><dd class="glossdef"><p>If a requested resource, such as CPU time, disk storage, or
memory, is not available in the parent cell, the request is forwarded
to associated child cells.</p></dd><dt id="id-1.4.19.21.5"><span><span class="glossterm">partition</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.5">#</a></span></dt><dd class="glossdef"><p>A unit of storage within Object Storage used to store objects.
It exists on top of devices and is replicated for fault
tolerance.</p></dd><dt id="id-1.4.19.21.6"><span><span class="glossterm">partition index</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.6">#</a></span></dt><dd class="glossdef"><p>Contains the locations of all Object Storage partitions within
the ring.</p></dd><dt id="id-1.4.19.21.7"><span><span class="glossterm">partition shift value</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.7">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage to determine which partition data should
reside on.</p></dd><dt id="id-1.4.19.21.8"><span><span class="glossterm">path MTU discovery (PMTUD)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.8">#</a></span></dt><dd class="glossdef"><p>Mechanism in IP networks to detect end-to-end MTU and adjust
packet size accordingly.</p></dd><dt id="id-1.4.19.21.9"><span><span class="glossterm">pause</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.9">#</a></span></dt><dd class="glossdef"><p>A VM state where no changes occur (no changes in memory, network
communications stop, etc); the VM is frozen but not shut down.</p></dd><dt id="id-1.4.19.21.10"><span><span class="glossterm">PCI passthrough</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.10">#</a></span></dt><dd class="glossdef"><p>Gives guest VMs exclusive access to a PCI device. Currently
supported in OpenStack Havana and later releases.</p></dd><dt id="id-1.4.19.21.11"><span><span class="glossterm">persistent message</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.11">#</a></span></dt><dd class="glossdef"><p>A message that is stored both in memory and on disk. The message
is not lost after a failure or restart.</p></dd><dt id="id-1.4.19.21.12"><span><span class="glossterm">persistent volume</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.12">#</a></span></dt><dd class="glossdef"><p>Changes to these types of disk volumes are saved.</p></dd><dt id="id-1.4.19.21.13"><span><span class="glossterm">personality file</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.13">#</a></span></dt><dd class="glossdef"><p>A file used to customize a Compute instance. It can be used to
inject SSH keys or a specific network configuration.</p></dd><dt id="id-1.4.19.21.14"><span><span class="glossterm">Pike</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.14">#</a></span></dt><dd class="glossdef"><p>The code name for the sixteenth release of OpenStack. The design
summit will take place in Boston, Massachusetts, US. The release
is named after the Massachusetts Turnpike, abbreviated commonly
as the Mass Pike, which is the eastermost stretch of
Interstate 90.</p></dd><dt id="id-1.4.19.21.15"><span><span class="glossterm">Platform-as-a-Service (PaaS)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.15">#</a></span></dt><dd class="glossdef"><p>Provides to the consumer the ability to deploy applications
through a programming language or tools supported by the cloud
platform provider. An example of Platform-as-a-Service is an
Eclipse/Java programming platform provided with no downloads
required.</p></dd><dt id="id-1.4.19.21.16"><span><span class="glossterm">plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.16">#</a></span></dt><dd class="glossdef"><p>Software component providing the actual implementation for
Networking APIs, or for Compute APIs, depending on the context.</p></dd><dt id="id-1.4.19.21.17"><span><span class="glossterm">policy service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.17">#</a></span></dt><dd class="glossdef"><p>Component of Identity that provides a rule-management
interface and a rule-based authorization engine.</p></dd><dt id="id-1.4.19.21.18"><span><span class="glossterm">policy-based routing (PBR)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.18">#</a></span></dt><dd class="glossdef"><p>Provides a mechanism to implement packet forwarding and routing
according to the policies defined by the network administrator.</p></dd><dt id="id-1.4.19.21.19"><span><span class="glossterm">pool</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.19">#</a></span></dt><dd class="glossdef"><p>A logical set of devices, such as web servers, that you
group together to receive and process traffic. The load
balancing function chooses which member of the pool handles
the new requests or connections received on the VIP
address. Each VIP has one pool.</p></dd><dt id="id-1.4.19.21.20"><span><span class="glossterm">pool member</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.20">#</a></span></dt><dd class="glossdef"><p>An application that runs on the back-end server in a
load-balancing system.</p></dd><dt id="id-1.4.19.21.21"><span><span class="glossterm">port</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.21">#</a></span></dt><dd class="glossdef"><p>A virtual network port within Networking; VIFs / vNICs are
connected to a port.</p></dd><dt id="id-1.4.19.21.22"><span><span class="glossterm">port UUID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.22">#</a></span></dt><dd class="glossdef"><p>Unique ID for a Networking port.</p></dd><dt id="id-1.4.19.21.23"><span><span class="glossterm">preseed</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.23">#</a></span></dt><dd class="glossdef"><p>A tool to automate system configuration and installation on
Debian-based Linux distributions.</p></dd><dt id="id-1.4.19.21.24"><span><span class="glossterm">private image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.24">#</a></span></dt><dd class="glossdef"><p>An Image service VM image that is only available to specified
projects.</p></dd><dt id="id-1.4.19.21.25"><span><span class="glossterm">private IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.25">#</a></span></dt><dd class="glossdef"><p>An IP address used for management and administration, not
available to the public Internet.</p></dd><dt id="id-1.4.19.21.26"><span><span class="glossterm">private network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.26">#</a></span></dt><dd class="glossdef"><p>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. A private network interface can be a flat or VLAN network
interface. A flat network interface is controlled by the
flat_interface with flat managers. A VLAN network interface is
controlled by the <code class="literal">vlan_interface</code> option with VLAN
managers.</p></dd><dt id="id-1.4.19.21.27"><span><span class="glossterm">project</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.27">#</a></span></dt><dd class="glossdef"><p>Projects represent the base unit of “ownership” in OpenStack,
in that all resources in OpenStack should be owned by a specific project.
In OpenStack Identity, a project must be owned by a specific domain.</p></dd><dt id="term-project-id"><span><span class="glossterm">project ID</span> <a title="Permalink" class="permalink" href="#term-project-id">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each project by the Identity service.</p></dd><dt id="id-1.4.19.21.29"><span><span class="glossterm">project VPN</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.29">#</a></span></dt><dd class="glossdef"><p>Alternative term for a cloudpipe.</p></dd><dt id="id-1.4.19.21.30"><span><span class="glossterm">promiscuous mode</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.30">#</a></span></dt><dd class="glossdef"><p>Causes the network interface to pass all traffic it
receives to the host rather than passing only the frames
addressed to it.</p></dd><dt id="id-1.4.19.21.31"><span><span class="glossterm">protected property</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.31">#</a></span></dt><dd class="glossdef"><p>Generally, extra properties on an Image service image to
which only cloud administrators have access. Limits which user
roles can perform CRUD operations on that property. The cloud
administrator can configure any image property as
protected.</p></dd><dt id="id-1.4.19.21.32"><span><span class="glossterm">provider</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.32">#</a></span></dt><dd class="glossdef"><p>An administrator who has access to all hosts and
instances.</p></dd><dt id="id-1.4.19.21.33"><span><span class="glossterm">proxy node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.33">#</a></span></dt><dd class="glossdef"><p>A node that provides the Object Storage proxy service.</p></dd><dt id="id-1.4.19.21.34"><span><span class="glossterm">proxy server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.34">#</a></span></dt><dd class="glossdef"><p>Users of Object Storage interact with the service through the
proxy server, which in turn looks up the location of the requested
data within the ring and returns the results to the user.</p></dd><dt id="id-1.4.19.21.35"><span><span class="glossterm">public API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.35">#</a></span></dt><dd class="glossdef"><p>An API endpoint used for both service-to-service communication
and end-user interactions.</p></dd><dt id="id-1.4.19.21.36"><span><span class="glossterm">public image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.36">#</a></span></dt><dd class="glossdef"><p>An Image service VM image that is available to all
projects.</p></dd><dt id="id-1.4.19.21.37"><span><span class="glossterm">public IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.37">#</a></span></dt><dd class="glossdef"><p>An IP address that is accessible to end-users.</p></dd><dt id="id-1.4.19.21.38"><span><span class="glossterm">public key authentication</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.38">#</a></span></dt><dd class="glossdef"><p>Authentication method that uses keys rather than
passwords.</p></dd><dt id="id-1.4.19.21.39"><span><span class="glossterm">public network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.39">#</a></span></dt><dd class="glossdef"><p>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. The public network interface is controlled by the
<code class="literal">public_interface</code> option.</p></dd><dt id="id-1.4.19.21.40"><span><span class="glossterm">Puppet</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.40">#</a></span></dt><dd class="glossdef"><p>An operating system configuration-management tool supported by
OpenStack.</p></dd><dt id="id-1.4.19.21.41"><span><span class="glossterm">Python</span> <a title="Permalink" class="permalink" href="#id-1.4.19.21.41">#</a></span></dt><dd class="glossdef"><p>Programming language used extensively in OpenStack.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.22"><h3 class="title">Q</h3><dl><dt id="id-1.4.19.22.3"><span><span class="glossterm">QEMU Copy On Write 2 (QCOW2)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.22.3">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.4.19.22.4"><span><span class="glossterm">Qpid</span> <a title="Permalink" class="permalink" href="#id-1.4.19.22.4">#</a></span></dt><dd class="glossdef"><p>Message queue software supported by OpenStack; an alternative to
RabbitMQ.</p></dd><dt id="term-quality-of-service-qos"><span><span class="glossterm">Quality of Service (QoS)</span> <a title="Permalink" class="permalink" href="#term-quality-of-service-qos">#</a></span></dt><dd class="glossdef"><p>The ability to guarantee certain network or storage requirements to
satisfy a Service Level Agreement (SLA) between an application provider
and end users.
Typically includes performance requirements like networking bandwidth,
latency, jitter correction, and reliability as well as storage
performance in Input/Output Operations Per Second (IOPS), throttling
agreements, and performance expectations at peak load.</p></dd><dt id="id-1.4.19.22.6"><span><span class="glossterm">quarantine</span> <a title="Permalink" class="permalink" href="#id-1.4.19.22.6">#</a></span></dt><dd class="glossdef"><p>If Object Storage finds objects, containers, or accounts that
are corrupt, they are placed in this state, are not replicated, cannot
be read by clients, and a correct copy is re-replicated.</p></dd><dt id="id-1.4.19.22.7"><span><span class="glossterm">Queens</span> <a title="Permalink" class="permalink" href="#id-1.4.19.22.7">#</a></span></dt><dd class="glossdef"><p>The code name for the seventeenth release of OpenStack. The
design summit will take place in Sydney, Australia. The release
is named after the Queens Pound river in the South Coast region
of New South Wales.</p></dd><dt id="id-1.4.19.22.8"><span><span class="glossterm">Quick EMUlator (QEMU)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.22.8">#</a></span></dt><dd class="glossdef"><p>QEMU is a generic and open source machine emulator and
virtualizer.
One of the hypervisors supported by OpenStack, generally used
for development purposes.</p></dd><dt id="id-1.4.19.22.9"><span><span class="glossterm">quota</span> <a title="Permalink" class="permalink" href="#id-1.4.19.22.9">#</a></span></dt><dd class="glossdef"><p>In Compute and Block Storage, the ability to set resource limits
on a per-project basis.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.23"><h3 class="title">R</h3><dl><dt id="id-1.4.19.23.3"><span><span class="glossterm">RabbitMQ</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.3">#</a></span></dt><dd class="glossdef"><p>The default message queue software used by OpenStack.</p></dd><dt id="id-1.4.19.23.4"><span><span class="glossterm">Rackspace Cloud Files</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.4">#</a></span></dt><dd class="glossdef"><p>Released as open source by Rackspace in 2010; the basis for
Object Storage.</p></dd><dt id="id-1.4.19.23.5"><span><span class="glossterm">RADOS Block Device (RBD)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.5">#</a></span></dt><dd class="glossdef"><p>Ceph component that enables a Linux block device to be striped
over multiple distributed data stores.</p></dd><dt id="id-1.4.19.23.6"><span><span class="glossterm">radvd</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.6">#</a></span></dt><dd class="glossdef"><p>The router advertisement daemon, used by the Compute VLAN
manager and FlatDHCP manager to provide routing services for VM
instances.</p></dd><dt id="id-1.4.19.23.7"><span><span class="glossterm">rally</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.7">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-benchmark-service-rally" title="Benchmark service (rally)">Benchmark service (rally)</a>.</p></dd><dt id="id-1.4.19.23.8"><span><span class="glossterm">RAM filter</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.8">#</a></span></dt><dd class="glossdef"><p>The Compute setting that enables or disables RAM
overcommitment.</p></dd><dt id="id-1.4.19.23.9"><span><span class="glossterm">RAM overcommit</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.9">#</a></span></dt><dd class="glossdef"><p>The ability to start new VM instances based on the actual memory
usage of a host, as opposed to basing the decision on the amount of
RAM each running instance thinks it has available. Also known as
memory overcommit.</p></dd><dt id="id-1.4.19.23.10"><span><span class="glossterm">rate limit</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.10">#</a></span></dt><dd class="glossdef"><p>Configurable option within Object Storage to limit database
writes on a per-account and/or per-container basis.</p></dd><dt id="id-1.4.19.23.11"><span><span class="glossterm">raw</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.11">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image service; an
unstructured disk image.</p></dd><dt id="id-1.4.19.23.12"><span><span class="glossterm">rebalance</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.12">#</a></span></dt><dd class="glossdef"><p>The process of distributing Object Storage partitions across all
drives in the ring; used during initial ring creation and after ring
reconfiguration.</p></dd><dt id="id-1.4.19.23.13"><span><span class="glossterm">reboot</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.13">#</a></span></dt><dd class="glossdef"><p>Either a soft or hard reboot of a server. With a soft reboot,
the operating system is signaled to restart, which enables a graceful
shutdown of all processes. A hard reboot is the equivalent of power
cycling the server. The virtualization platform should ensure that the
reboot action has completed successfully, even in cases in which the
underlying domain/VM is paused or halted/stopped.</p></dd><dt id="id-1.4.19.23.14"><span><span class="glossterm">rebuild</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.14">#</a></span></dt><dd class="glossdef"><p>Removes all data on the server and replaces it with the
specified image. Server ID and IP addresses remain the same.</p></dd><dt id="id-1.4.19.23.15"><span><span class="glossterm">Recon</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.15">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that collects meters.</p></dd><dt id="id-1.4.19.23.16"><span><span class="glossterm">record</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.16">#</a></span></dt><dd class="glossdef"><p>Belongs to a particular domain and is used to specify
information about the domain.
There are several types of DNS records. Each record type contains
particular information used to describe the purpose of that record.
Examples include mail exchange (MX) records, which specify the mail
server for a particular domain; and name server (NS) records, which
specify the authoritative name servers for a domain.</p></dd><dt id="id-1.4.19.23.17"><span><span class="glossterm">record ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.17">#</a></span></dt><dd class="glossdef"><p>A number within a database that is incremented each time a
change is made. Used by Object Storage when replicating.</p></dd><dt id="id-1.4.19.23.18"><span><span class="glossterm">Red Hat Enterprise Linux (RHEL)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.18">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.4.19.23.19"><span><span class="glossterm">reference architecture</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.19">#</a></span></dt><dd class="glossdef"><p>A recommended architecture for an OpenStack cloud.</p></dd><dt id="id-1.4.19.23.20"><span><span class="glossterm">region</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.20">#</a></span></dt><dd class="glossdef"><p>A discrete OpenStack environment with dedicated API endpoints
that typically shares only the Identity (keystone) with other
regions.</p></dd><dt id="id-1.4.19.23.21"><span><span class="glossterm">registry</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.21">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Image service registry.</p></dd><dt id="id-1.4.19.23.22"><span><span class="glossterm">registry server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.22">#</a></span></dt><dd class="glossdef"><p>An Image service that provides VM image metadata information to
clients.</p></dd><dt id="id-1.4.19.23.23"><span><span class="glossterm">Reliable, Autonomic Distributed Object Store</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.23">#</a></span></dt><dd class="glossdef"><p>(RADOS)</p><p>A collection of components that provides object storage within
Ceph. Similar to OpenStack Object Storage.</p></dd><dt id="term-remote-procedure-call-rpc"><span><span class="glossterm">Remote Procedure Call (RPC)</span> <a title="Permalink" class="permalink" href="#term-remote-procedure-call-rpc">#</a></span></dt><dd class="glossdef"><p>The method used by the Compute RabbitMQ for intra-service
communications.</p></dd><dt id="id-1.4.19.23.25"><span><span class="glossterm">replica</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.25">#</a></span></dt><dd class="glossdef"><p>Provides data redundancy and fault tolerance by creating copies
of Object Storage objects, accounts, and containers so that they are
not lost when the underlying storage fails.</p></dd><dt id="id-1.4.19.23.26"><span><span class="glossterm">replica count</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.26">#</a></span></dt><dd class="glossdef"><p>The number of replicas of the data in an Object Storage
ring.</p></dd><dt id="id-1.4.19.23.27"><span><span class="glossterm">replication</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.27">#</a></span></dt><dd class="glossdef"><p>The process of copying data to a separate physical device for
fault tolerance and performance.</p></dd><dt id="id-1.4.19.23.28"><span><span class="glossterm">replicator</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.28">#</a></span></dt><dd class="glossdef"><p>The Object Storage back-end process that creates and manages
object replicas.</p></dd><dt id="id-1.4.19.23.29"><span><span class="glossterm">request ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.29">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each request sent to Compute.</p></dd><dt id="id-1.4.19.23.30"><span><span class="glossterm">rescue image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.30">#</a></span></dt><dd class="glossdef"><p>A special type of VM image that is booted when an instance is
placed into rescue mode. Allows an administrator to mount the file
systems for an instance to correct the problem.</p></dd><dt id="id-1.4.19.23.31"><span><span class="glossterm">resize</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.31">#</a></span></dt><dd class="glossdef"><p>Converts an existing server to a different flavor, which scales
the server up or down. The original server is saved to enable rollback
if a problem occurs. All resizes must be tested and explicitly
confirmed, at which time the original server is removed.</p></dd><dt id="id-1.4.19.23.32"><span><span class="glossterm">RESTful</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.32">#</a></span></dt><dd class="glossdef"><p>A kind of web service API that uses REST, or Representational
State Transfer. REST is the style of architecture for hypermedia
systems that is used for the World Wide Web.</p></dd><dt id="id-1.4.19.23.33"><span><span class="glossterm">ring</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.33">#</a></span></dt><dd class="glossdef"><p>An entity that maps Object Storage data to partitions. A
separate ring exists for each service, such as account, object, and
container.</p></dd><dt id="id-1.4.19.23.34"><span><span class="glossterm">ring builder</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.34">#</a></span></dt><dd class="glossdef"><p>Builds and manages rings within Object Storage, assigns
partitions to devices, and pushes the configuration to other storage
nodes.</p></dd><dt id="id-1.4.19.23.35"><span><span class="glossterm">role</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.35">#</a></span></dt><dd class="glossdef"><p>A personality that a user assumes to perform a specific set of
operations. A role includes a set of rights and privileges. A user
assuming that role inherits those rights and privileges.</p></dd><dt id="id-1.4.19.23.36"><span><span class="glossterm">Role Based Access Control (RBAC)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.36">#</a></span></dt><dd class="glossdef"><p>Provides a predefined list of actions that the user can perform,
such as start or stop VMs, reset passwords, and so on. Supported in
both Identity and Compute and can be configured using the dashboard.</p></dd><dt id="id-1.4.19.23.37"><span><span class="glossterm">role ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.37">#</a></span></dt><dd class="glossdef"><p>Alphanumeric ID assigned to each Identity service role.</p></dd><dt id="term-root-cause-analysis-rca-service-vitrage"><span><span class="glossterm">Root Cause Analysis (RCA) service (Vitrage)</span> <a title="Permalink" class="permalink" href="#term-root-cause-analysis-rca-service-vitrage">#</a></span></dt><dd class="glossdef"><p>OpenStack project that aims to organize, analyze and visualize OpenStack
alarms and events, yield insights regarding the root cause of problems
and deduce their existence before they are directly detected.</p></dd><dt id="id-1.4.19.23.39"><span><span class="glossterm">rootwrap</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.39">#</a></span></dt><dd class="glossdef"><p>A feature of Compute that allows the unprivileged "nova" user to
run a specified list of commands as the Linux root user.</p></dd><dt id="id-1.4.19.23.40"><span><span class="glossterm">round-robin scheduler</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.40">#</a></span></dt><dd class="glossdef"><p>Type of Compute scheduler that evenly distributes instances
among available hosts.</p></dd><dt id="id-1.4.19.23.41"><span><span class="glossterm">router</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.41">#</a></span></dt><dd class="glossdef"><p>A physical or virtual network device that passes network
traffic between different networks.</p></dd><dt id="id-1.4.19.23.42"><span><span class="glossterm">routing key</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.42">#</a></span></dt><dd class="glossdef"><p>The Compute direct exchanges, fanout exchanges, and topic
exchanges use this key to determine how to process a message;
processing varies depending on exchange type.</p></dd><dt id="id-1.4.19.23.43"><span><span class="glossterm">RPC driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.43">#</a></span></dt><dd class="glossdef"><p>Modular system that allows the underlying message queue software
of Compute to be changed. For example, from RabbitMQ to ZeroMQ or
Qpid.</p></dd><dt id="id-1.4.19.23.44"><span><span class="glossterm">rsync</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.44">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage to push object replicas.</p></dd><dt id="id-1.4.19.23.45"><span><span class="glossterm">RXTX cap</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.45">#</a></span></dt><dd class="glossdef"><p>Absolute limit on the amount of network traffic a Compute VM
instance can send and receive.</p></dd><dt id="id-1.4.19.23.46"><span><span class="glossterm">RXTX quota</span> <a title="Permalink" class="permalink" href="#id-1.4.19.23.46">#</a></span></dt><dd class="glossdef"><p>Soft limit on the amount of network traffic a Compute VM
instance can send and receive.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.24"><h3 class="title">S</h3><dl><dt id="id-1.4.19.24.3"><span><span class="glossterm">sahara</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.3">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-data-processing-service-sahara" title="Data Processing service (sahara)">Data Processing service (sahara)</a>.</p></dd><dt id="id-1.4.19.24.4"><span><span class="glossterm">SAML assertion</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.4">#</a></span></dt><dd class="glossdef"><p>Contains information about a user as provided by the identity
provider. It is an indication that a user has been authenticated.</p></dd><dt id="id-1.4.19.24.5"><span><span class="glossterm">scheduler manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.5">#</a></span></dt><dd class="glossdef"><p>A Compute component that determines where VM instances should
start. Uses modular design to support a variety of scheduler
types.</p></dd><dt id="id-1.4.19.24.6"><span><span class="glossterm">scoped token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.6">#</a></span></dt><dd class="glossdef"><p>An Identity service API access token that is associated with a
specific project.</p></dd><dt id="id-1.4.19.24.7"><span><span class="glossterm">scrubber</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.7">#</a></span></dt><dd class="glossdef"><p>Checks for and deletes unused VMs; the component of Image
service that implements delayed delete.</p></dd><dt id="id-1.4.19.24.8"><span><span class="glossterm">secret key</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.8">#</a></span></dt><dd class="glossdef"><p>String of text known only by the user; used along with an access
key to make requests to the Compute API.</p></dd><dt id="id-1.4.19.24.9"><span><span class="glossterm">secure boot</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.9">#</a></span></dt><dd class="glossdef"><p>Process whereby the system firmware validates the authenticity of
the code involved in the boot process.</p></dd><dt id="id-1.4.19.24.10"><span><span class="glossterm">secure shell (SSH)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.10">#</a></span></dt><dd class="glossdef"><p>Open source tool used to access remote hosts through an
encrypted communications channel, SSH key injection is supported by
Compute.</p></dd><dt id="id-1.4.19.24.11"><span><span class="glossterm">security group</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.11">#</a></span></dt><dd class="glossdef"><p>A set of network traffic filtering rules that are applied to a
Compute instance.</p></dd><dt id="id-1.4.19.24.12"><span><span class="glossterm">segmented object</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.12">#</a></span></dt><dd class="glossdef"><p>An Object Storage large object that has been broken up into
pieces. The re-assembled object is called a concatenated
object.</p></dd><dt id="id-1.4.19.24.13"><span><span class="glossterm">self-service</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.13">#</a></span></dt><dd class="glossdef"><p>For IaaS, ability for a regular (non-privileged) account to
manage a virtual infrastructure component such as networks without
involving an administrator.</p></dd><dt id="id-1.4.19.24.14"><span><span class="glossterm">SELinux</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.14">#</a></span></dt><dd class="glossdef"><p>Linux kernel security module that provides the mechanism for
supporting access control policies.</p></dd><dt id="id-1.4.19.24.15"><span><span class="glossterm">senlin</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.15">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-clustering-service-senlin" title="Clustering service (senlin)">Clustering service (senlin)</a>.</p></dd><dt id="id-1.4.19.24.16"><span><span class="glossterm">server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.16">#</a></span></dt><dd class="glossdef"><p>Computer that provides explicit services to the client software
running on that system, often managing a variety of computer
operations.
A server is a VM instance in the Compute system. Flavor and
image are requisite elements when creating a server.</p></dd><dt id="id-1.4.19.24.17"><span><span class="glossterm">server image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.17">#</a></span></dt><dd class="glossdef"><p>Alternative term for a VM image.</p></dd><dt id="id-1.4.19.24.18"><span><span class="glossterm">server UUID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.18">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each guest VM instance.</p></dd><dt id="term-service"><span><span class="glossterm">service</span> <a title="Permalink" class="permalink" href="#term-service">#</a></span></dt><dd class="glossdef"><p>An OpenStack service, such as Compute, Object Storage, or Image
service. Provides one or more endpoints through which users can access
resources and perform operations.</p></dd><dt id="id-1.4.19.24.20"><span><span class="glossterm">service catalog</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.20">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Identity service catalog.</p></dd><dt id="id-1.4.19.24.21"><span><span class="glossterm">Service Function Chain (SFC)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.21">#</a></span></dt><dd class="glossdef"><p>For a given service, SFC is the abstracted view of the required
service functions and the order in which they are to be applied.</p></dd><dt id="id-1.4.19.24.22"><span><span class="glossterm">service ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.22">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each service that is available in the
Identity service catalog.</p></dd><dt id="id-1.4.19.24.23"><span><span class="glossterm">Service Level Agreement (SLA)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.23">#</a></span></dt><dd class="glossdef"><p>Contractual obligations that ensure the availability of a
service.</p></dd><dt id="id-1.4.19.24.24"><span><span class="glossterm">service project</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.24">#</a></span></dt><dd class="glossdef"><p>Special project that contains all services that are listed in the
catalog.</p></dd><dt id="id-1.4.19.24.25"><span><span class="glossterm">service provider</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.25">#</a></span></dt><dd class="glossdef"><p>A system that provides services to other system entities. In
case of federated identity, OpenStack Identity is the service
provider.</p></dd><dt id="id-1.4.19.24.26"><span><span class="glossterm">service registration</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.26">#</a></span></dt><dd class="glossdef"><p>An Identity service feature that enables services, such as
Compute, to automatically register with the catalog.</p></dd><dt id="id-1.4.19.24.27"><span><span class="glossterm">service token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.27">#</a></span></dt><dd class="glossdef"><p>An administrator-defined token used by Compute to communicate
securely with the Identity service.</p></dd><dt id="id-1.4.19.24.28"><span><span class="glossterm">session back end</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.28">#</a></span></dt><dd class="glossdef"><p>The method of storage used by horizon to track client sessions,
such as local memory, cookies, a database, or memcached.</p></dd><dt id="id-1.4.19.24.29"><span><span class="glossterm">session persistence</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.29">#</a></span></dt><dd class="glossdef"><p>A feature of the load-balancing service. It attempts to force
subsequent connections to a service to be redirected to the same node
as long as it is online.</p></dd><dt id="id-1.4.19.24.30"><span><span class="glossterm">session storage</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.30">#</a></span></dt><dd class="glossdef"><p>A horizon component that stores and tracks client session
information. Implemented through the Django sessions framework.</p></dd><dt id="id-1.4.19.24.31"><span><span class="glossterm">share</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.31">#</a></span></dt><dd class="glossdef"><p>A remote, mountable file system in the context of the <a class="xref" href="#term-shared-file-systems-service-manila" title="Shared File Systems service (manila)">Shared File Systems service (manila)</a>. You can
mount a share to, and access a share from, several hosts by several
users at a time.</p></dd><dt id="id-1.4.19.24.32"><span><span class="glossterm">share network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.32">#</a></span></dt><dd class="glossdef"><p>An entity in the context of the <a class="xref" href="#term-shared-file-systems-service-manila" title="Shared File Systems service (manila)">Shared File Systems service (manila)</a> that encapsulates
interaction with the Networking service. If the driver you selected
runs in the mode requiring such kind of interaction, you need to
specify the share network to create a share.</p></dd><dt id="id-1.4.19.24.33"><span><span class="glossterm">Shared File Systems API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.33">#</a></span></dt><dd class="glossdef"><p>A Shared File Systems service that provides a stable RESTful API.
The service authenticates and routes requests throughout the Shared
File Systems service. There is python-manilaclient to interact with
the API.</p></dd><dt id="term-shared-file-systems-service-manila"><span><span class="glossterm">Shared File Systems service (manila)</span> <a title="Permalink" class="permalink" href="#term-shared-file-systems-service-manila">#</a></span></dt><dd class="glossdef"><p>The service that provides a set of services for
management of shared file systems in a multi-tenant cloud
environment, similar to how OpenStack provides block-based storage
management through the OpenStack <a class="xref" href="#term-block-storage-service-cinder" title="Block Storage service (cinder)">Block Storage service (cinder)</a> project.
With the Shared File Systems service, you can create a remote file
system and mount the file system on your instances. You can also
read and write data from your instances to and from your file system.</p></dd><dt id="id-1.4.19.24.35"><span><span class="glossterm">shared IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.35">#</a></span></dt><dd class="glossdef"><p>An IP address that can be assigned to a VM instance within the
shared IP group. Public IP addresses can be shared across multiple
servers for use in various high-availability scenarios. When an IP
address is shared to another server, the cloud network restrictions
are modified to enable each server to listen to and respond on that IP
address. You can optionally specify that the target server network
configuration be modified. Shared IP addresses can be used with many
standard heartbeat facilities, such as keepalive, that monitor for
failure and manage IP failover.</p></dd><dt id="id-1.4.19.24.36"><span><span class="glossterm">shared IP group</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.36">#</a></span></dt><dd class="glossdef"><p>A collection of servers that can share IPs with other members of
the group. Any server in a group can share one or more public IPs with
any other server in the group. With the exception of the first server
in a shared IP group, servers must be launched into shared IP groups.
A server may be a member of only one shared IP group.</p></dd><dt id="id-1.4.19.24.37"><span><span class="glossterm">shared storage</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.37">#</a></span></dt><dd class="glossdef"><p>Block storage that is simultaneously accessible by multiple
clients, for example, NFS.</p></dd><dt id="id-1.4.19.24.38"><span><span class="glossterm">Sheepdog</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.38">#</a></span></dt><dd class="glossdef"><p>Distributed block storage system for QEMU, supported by
OpenStack.</p></dd><dt id="id-1.4.19.24.39"><span><span class="glossterm">Simple Cloud Identity Management (SCIM)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.39">#</a></span></dt><dd class="glossdef"><p>Specification for managing identity in the cloud, currently
unsupported by OpenStack.</p></dd><dt id="id-1.4.19.24.40"><span><span class="glossterm">Simple Protocol for Independent Computing Environments (SPICE)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.40">#</a></span></dt><dd class="glossdef"><p>SPICE provides remote desktop access to guest virtual machines. It
is an alternative to VNC. SPICE is supported by OpenStack.</p></dd><dt id="id-1.4.19.24.41"><span><span class="glossterm">Single-root I/O Virtualization (SR-IOV)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.41">#</a></span></dt><dd class="glossdef"><p>A specification that, when implemented by a physical PCIe
device, enables it to appear as multiple separate PCIe devices. This
enables multiple virtualized guests to share direct access to the
physical device, offering improved performance over an equivalent
virtual device. Currently supported in OpenStack Havana and later
releases.</p></dd><dt id="id-1.4.19.24.42"><span><span class="glossterm">SmokeStack</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.42">#</a></span></dt><dd class="glossdef"><p>Runs automated tests against the core OpenStack API; written in
Rails.</p></dd><dt id="id-1.4.19.24.43"><span><span class="glossterm">snapshot</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.43">#</a></span></dt><dd class="glossdef"><p>A point-in-time copy of an OpenStack storage volume or image.
Use storage volume snapshots to back up volumes. Use image snapshots
to back up data, or as "gold" images for additional servers.</p></dd><dt id="id-1.4.19.24.44"><span><span class="glossterm">soft reboot</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.44">#</a></span></dt><dd class="glossdef"><p>A controlled reboot where a VM instance is properly restarted
through operating system commands.</p></dd><dt id="term-software-development-lifecycle-automation-service-solum"><span><span class="glossterm">Software Development Lifecycle Automation service (solum)</span> <a title="Permalink" class="permalink" href="#term-software-development-lifecycle-automation-service-solum">#</a></span></dt><dd class="glossdef"><p>OpenStack project that aims to make cloud services easier to
consume and integrate with application development process
by automating the source-to-image process, and simplifying
app-centric deployment.</p></dd><dt id="id-1.4.19.24.46"><span><span class="glossterm">Software-defined networking (SDN)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.46">#</a></span></dt><dd class="glossdef"><p>Provides an approach for network administrators to manage computer
network services through abstraction of lower-level functionality.</p></dd><dt id="id-1.4.19.24.47"><span><span class="glossterm">SolidFire Volume Driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.47">#</a></span></dt><dd class="glossdef"><p>The Block Storage driver for the SolidFire iSCSI storage
appliance.</p></dd><dt id="id-1.4.19.24.48"><span><span class="glossterm">solum</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.48">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-software-development-lifecycle-automation-service-solum" title="Software Development Lifecycle Automation service (solum)">Software Development Lifecycle Automation service (solum)</a>.</p></dd><dt id="id-1.4.19.24.49"><span><span class="glossterm">spread-first scheduler</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.49">#</a></span></dt><dd class="glossdef"><p>The Compute VM scheduling algorithm that attempts to start a new
VM on the host with the least amount of load.</p></dd><dt id="id-1.4.19.24.50"><span><span class="glossterm">SQLAlchemy</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.50">#</a></span></dt><dd class="glossdef"><p>An open source SQL toolkit for Python, used in OpenStack.</p></dd><dt id="id-1.4.19.24.51"><span><span class="glossterm">SQLite</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.51">#</a></span></dt><dd class="glossdef"><p>A lightweight SQL database, used as the default persistent
storage method in many OpenStack services.</p></dd><dt id="id-1.4.19.24.52"><span><span class="glossterm">stack</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.52">#</a></span></dt><dd class="glossdef"><p>A set of OpenStack resources created and managed by the
Orchestration service according to a given template (either an
AWS CloudFormation template or a Heat Orchestration
Template (HOT)).</p></dd><dt id="id-1.4.19.24.53"><span><span class="glossterm">StackTach</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.53">#</a></span></dt><dd class="glossdef"><p>Community project that captures Compute AMQP communications;
useful for debugging.</p></dd><dt id="id-1.4.19.24.54"><span><span class="glossterm">static IP address</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.54">#</a></span></dt><dd class="glossdef"><p>Alternative term for a fixed IP address.</p></dd><dt id="id-1.4.19.24.55"><span><span class="glossterm">StaticWeb</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.55">#</a></span></dt><dd class="glossdef"><p>WSGI middleware component of Object Storage that serves
container data as a static web page.</p></dd><dt id="id-1.4.19.24.56"><span><span class="glossterm">storage back end</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.56">#</a></span></dt><dd class="glossdef"><p>The method that a service uses for persistent storage, such as
iSCSI, NFS, or local disk.</p></dd><dt id="id-1.4.19.24.57"><span><span class="glossterm">storage manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.57">#</a></span></dt><dd class="glossdef"><p>A XenAPI component that provides a pluggable interface to
support a wide variety of persistent storage back ends.</p></dd><dt id="id-1.4.19.24.58"><span><span class="glossterm">storage manager back end</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.58">#</a></span></dt><dd class="glossdef"><p>A persistent storage method supported by XenAPI, such as iSCSI
or NFS.</p></dd><dt id="id-1.4.19.24.59"><span><span class="glossterm">storage node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.59">#</a></span></dt><dd class="glossdef"><p>An Object Storage node that provides container services, account
services, and object services; controls the account databases,
container databases, and object storage.</p></dd><dt id="id-1.4.19.24.60"><span><span class="glossterm">storage services</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.60">#</a></span></dt><dd class="glossdef"><p>Collective name for the Object Storage object services,
container services, and account services.</p></dd><dt id="term-strategy"><span><span class="glossterm">strategy</span> <a title="Permalink" class="permalink" href="#term-strategy">#</a></span></dt><dd class="glossdef"><p>Specifies the authentication source used by Image service or
Identity. In the Database service, it refers to the extensions
implemented for a data store.</p></dd><dt id="id-1.4.19.24.62"><span><span class="glossterm">subdomain</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.62">#</a></span></dt><dd class="glossdef"><p>A domain within a parent domain. Subdomains cannot be
registered. Subdomains enable you to delegate domains. Subdomains can
themselves have subdomains, so third-level, fourth-level, fifth-level,
and deeper levels of nesting are possible.</p></dd><dt id="id-1.4.19.24.63"><span><span class="glossterm">subnet</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.63">#</a></span></dt><dd class="glossdef"><p>Logical subdivision of an IP network.</p></dd><dt id="id-1.4.19.24.64"><span><span class="glossterm">SUSE Linux Enterprise Server (SLES)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.64">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.4.19.24.65"><span><span class="glossterm">suspend</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.65">#</a></span></dt><dd class="glossdef"><p>Alternative term for a paused VM instance.</p></dd><dt id="id-1.4.19.24.66"><span><span class="glossterm">swap</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.66">#</a></span></dt><dd class="glossdef"><p>Disk-based virtual memory used by operating systems to provide
more memory than is actually available on the system.</p></dd><dt id="id-1.4.19.24.67"><span><span class="glossterm">swauth</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.67">#</a></span></dt><dd class="glossdef"><p>An authentication and authorization service for Object Storage,
implemented through WSGI middleware; uses Object Storage itself as the
persistent backing store.</p></dd><dt id="id-1.4.19.24.68"><span><span class="glossterm">swift</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.68">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a>.</p></dd><dt id="id-1.4.19.24.69"><span><span class="glossterm">swift All in One (SAIO)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.69">#</a></span></dt><dd class="glossdef"><p>Creates a full Object Storage development environment within a
single VM.</p></dd><dt id="id-1.4.19.24.70"><span><span class="glossterm">swift middleware</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.70">#</a></span></dt><dd class="glossdef"><p>Collective term for Object Storage components that provide
additional functionality.</p></dd><dt id="id-1.4.19.24.71"><span><span class="glossterm">swift proxy server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.71">#</a></span></dt><dd class="glossdef"><p>Acts as the gatekeeper to Object Storage and is responsible for
authenticating the user.</p></dd><dt id="id-1.4.19.24.72"><span><span class="glossterm">swift storage node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.72">#</a></span></dt><dd class="glossdef"><p>A node that runs Object Storage account, container, and object
services.</p></dd><dt id="id-1.4.19.24.73"><span><span class="glossterm">sync point</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.73">#</a></span></dt><dd class="glossdef"><p>Point in time since the last container and accounts database
sync among nodes within Object Storage.</p></dd><dt id="id-1.4.19.24.74"><span><span class="glossterm">sysadmin</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.74">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system. Enables a
user to add other users to a project, interact with VM images that are
associated with the project, and start and stop VM instances.</p></dd><dt id="id-1.4.19.24.75"><span><span class="glossterm">system usage</span> <a title="Permalink" class="permalink" href="#id-1.4.19.24.75">#</a></span></dt><dd class="glossdef"><p>A Compute component that, along with the notification system,
collects meters and usage information. This information can be used
for billing.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.25"><h3 class="title">T</h3><dl><dt id="id-1.4.19.25.3"><span><span class="glossterm">tacker</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.3">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-nfv-orchestration-service-tacker" title="NFV Orchestration Service (tacker)">NFV Orchestration Service (tacker)</a></p></dd><dt id="term-telemetry-service-telemetry"><span><span class="glossterm">Telemetry service (telemetry)</span> <a title="Permalink" class="permalink" href="#term-telemetry-service-telemetry">#</a></span></dt><dd class="glossdef"><p>The OpenStack project which collects measurements of the utilization
of the physical and virtual resources comprising deployed clouds,
persists this data for subsequent retrieval and analysis, and triggers
actions when defined criteria are met.</p></dd><dt id="id-1.4.19.25.5"><span><span class="glossterm">TempAuth</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.5">#</a></span></dt><dd class="glossdef"><p>An authentication facility within Object Storage that enables
Object Storage itself to perform authentication and authorization.
Frequently used in testing and development.</p></dd><dt id="id-1.4.19.25.6"><span><span class="glossterm">Tempest</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.6">#</a></span></dt><dd class="glossdef"><p>Automated software test suite designed to run against the trunk
of the OpenStack core project.</p></dd><dt id="id-1.4.19.25.7"><span><span class="glossterm">TempURL</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.7">#</a></span></dt><dd class="glossdef"><p>An Object Storage middleware component that enables creation of
URLs for temporary object access.</p></dd><dt id="id-1.4.19.25.8"><span><span class="glossterm">tenant</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.8">#</a></span></dt><dd class="glossdef"><p>A group of users; used to isolate access to Compute resources.
An alternative term for a project.</p></dd><dt id="id-1.4.19.25.9"><span><span class="glossterm">Tenant API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.9">#</a></span></dt><dd class="glossdef"><p>An API that is accessible to projects.</p></dd><dt id="id-1.4.19.25.10"><span><span class="glossterm">tenant endpoint</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.10">#</a></span></dt><dd class="glossdef"><p>An Identity service API endpoint that is associated with one or
more projects.</p></dd><dt id="id-1.4.19.25.11"><span><span class="glossterm">tenant ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.11">#</a></span></dt><dd class="glossdef"><p>An alternative term for <a class="xref" href="#term-project-id" title="project ID">project ID</a>.</p></dd><dt id="id-1.4.19.25.12"><span><span class="glossterm">token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.12">#</a></span></dt><dd class="glossdef"><p>An alpha-numeric string of text used to access OpenStack APIs
and resources.</p></dd><dt id="id-1.4.19.25.13"><span><span class="glossterm">token services</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.13">#</a></span></dt><dd class="glossdef"><p>An Identity service component that manages and validates tokens
after a user or project has been authenticated.</p></dd><dt id="id-1.4.19.25.14"><span><span class="glossterm">tombstone</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.14">#</a></span></dt><dd class="glossdef"><p>Used to mark Object Storage objects that have been
deleted; ensures that the object is not updated on another node after
it has been deleted.</p></dd><dt id="id-1.4.19.25.15"><span><span class="glossterm">topic publisher</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.15">#</a></span></dt><dd class="glossdef"><p>A process that is created when a RPC call is executed; used to
push the message to the topic exchange.</p></dd><dt id="id-1.4.19.25.16"><span><span class="glossterm">Torpedo</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.16">#</a></span></dt><dd class="glossdef"><p>Community project used to run automated tests against the
OpenStack API.</p></dd><dt id="id-1.4.19.25.17"><span><span class="glossterm">transaction ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.17">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each Object Storage request; used for
debugging and tracing.</p></dd><dt id="id-1.4.19.25.18"><span><span class="glossterm">transient</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.18">#</a></span></dt><dd class="glossdef"><p>Alternative term for non-durable.</p></dd><dt id="id-1.4.19.25.19"><span><span class="glossterm">transient exchange</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.19">#</a></span></dt><dd class="glossdef"><p>Alternative term for a non-durable exchange.</p></dd><dt id="id-1.4.19.25.20"><span><span class="glossterm">transient message</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.20">#</a></span></dt><dd class="glossdef"><p>A message that is stored in memory and is lost after the server
is restarted.</p></dd><dt id="id-1.4.19.25.21"><span><span class="glossterm">transient queue</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.21">#</a></span></dt><dd class="glossdef"><p>Alternative term for a non-durable queue.</p></dd><dt id="id-1.4.19.25.22"><span><span class="glossterm">TripleO</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.22">#</a></span></dt><dd class="glossdef"><p>OpenStack-on-OpenStack program. The code name for the
OpenStack Deployment program.</p></dd><dt id="id-1.4.19.25.23"><span><span class="glossterm">trove</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.23">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-database-service-trove" title="Database service (trove)">Database service (trove)</a>.</p></dd><dt id="id-1.4.19.25.24"><span><span class="glossterm">trusted platform module (TPM)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.25.24">#</a></span></dt><dd class="glossdef"><p>Specialized microprocessor for incorporating cryptographic keys
into devices for authenticating and securing a hardware platform.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.26"><h3 class="title">U</h3><dl><dt id="id-1.4.19.26.3"><span><span class="glossterm">Ubuntu</span> <a title="Permalink" class="permalink" href="#id-1.4.19.26.3">#</a></span></dt><dd class="glossdef"><p>A Debian-based Linux distribution.</p></dd><dt id="id-1.4.19.26.4"><span><span class="glossterm">unscoped token</span> <a title="Permalink" class="permalink" href="#id-1.4.19.26.4">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Identity service default token.</p></dd><dt id="id-1.4.19.26.5"><span><span class="glossterm">updater</span> <a title="Permalink" class="permalink" href="#id-1.4.19.26.5">#</a></span></dt><dd class="glossdef"><p>Collective term for a group of Object Storage components that
processes queued and failed updates for containers and objects.</p></dd><dt id="id-1.4.19.26.6"><span><span class="glossterm">user</span> <a title="Permalink" class="permalink" href="#id-1.4.19.26.6">#</a></span></dt><dd class="glossdef"><p>In OpenStack Identity,  entities represent individual API
consumers and are owned by a specific domain. In OpenStack Compute,
a user can be associated with roles, projects, or both.</p></dd><dt id="id-1.4.19.26.7"><span><span class="glossterm">user data</span> <a title="Permalink" class="permalink" href="#id-1.4.19.26.7">#</a></span></dt><dd class="glossdef"><p>A blob of data that the user can specify when they launch
an instance. The instance can access this data through the
metadata service or config drive.
Commonly used to pass a shell script that the instance runs on boot.</p></dd><dt id="id-1.4.19.26.8"><span><span class="glossterm">User Mode Linux (UML)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.26.8">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.27"><h3 class="title">V</h3><dl><dt id="id-1.4.19.27.3"><span><span class="glossterm">VIF UUID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.3">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each Networking VIF.</p></dd><dt id="id-1.4.19.27.4"><span><span class="glossterm">Virtual Central Processing Unit (vCPU)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.4">#</a></span></dt><dd class="glossdef"><p>Subdivides physical CPUs. Instances can then use those
divisions.</p></dd><dt id="id-1.4.19.27.5"><span><span class="glossterm">Virtual Disk Image (VDI)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.5">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.4.19.27.6"><span><span class="glossterm">Virtual Extensible LAN (VXLAN)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.6">#</a></span></dt><dd class="glossdef"><p>A network virtualization technology that attempts to reduce the
scalability problems associated with large cloud computing
deployments. It uses a VLAN-like encapsulation technique to
encapsulate Ethernet frames within UDP packets.</p></dd><dt id="id-1.4.19.27.7"><span><span class="glossterm">Virtual Hard Disk (VHD)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.7">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.4.19.27.8"><span><span class="glossterm">virtual IP address (VIP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.8">#</a></span></dt><dd class="glossdef"><p>An Internet Protocol (IP) address configured on the load
balancer for use by clients connecting to a service that is load
balanced. Incoming connections are distributed to back-end nodes based
on the configuration of the load balancer.</p></dd><dt id="id-1.4.19.27.9"><span><span class="glossterm">virtual machine (VM)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.9">#</a></span></dt><dd class="glossdef"><p>An operating system instance that runs on top of a hypervisor.
Multiple VMs can run at the same time on the same physical
host.</p></dd><dt id="id-1.4.19.27.10"><span><span class="glossterm">virtual network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.10">#</a></span></dt><dd class="glossdef"><p>An L2 network segment within Networking.</p></dd><dt id="id-1.4.19.27.11"><span><span class="glossterm">Virtual Network Computing (VNC)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.11">#</a></span></dt><dd class="glossdef"><p>Open source GUI and CLI tools used for remote console access to
VMs. Supported by Compute.</p></dd><dt id="id-1.4.19.27.12"><span><span class="glossterm">Virtual Network InterFace (VIF)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.12">#</a></span></dt><dd class="glossdef"><p>An interface that is plugged into a port in a Networking
network. Typically a virtual network interface belonging to a
VM.</p></dd><dt id="id-1.4.19.27.13"><span><span class="glossterm">virtual networking</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.13">#</a></span></dt><dd class="glossdef"><p>A generic term for virtualization of network functions
such as switching, routing, load balancing, and security using
a combination of VMs and overlays on physical network
infrastructure.</p></dd><dt id="id-1.4.19.27.14"><span><span class="glossterm">virtual port</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.14">#</a></span></dt><dd class="glossdef"><p>Attachment point where a virtual interface connects to a virtual
network.</p></dd><dt id="id-1.4.19.27.15"><span><span class="glossterm">virtual private network (VPN)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.15">#</a></span></dt><dd class="glossdef"><p>Provided by Compute in the form of cloudpipes, specialized
instances that are used to create VPNs on a per-project basis.</p></dd><dt id="id-1.4.19.27.16"><span><span class="glossterm">virtual server</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.16">#</a></span></dt><dd class="glossdef"><p>Alternative term for a VM or guest.</p></dd><dt id="id-1.4.19.27.17"><span><span class="glossterm">virtual switch (vSwitch)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.17">#</a></span></dt><dd class="glossdef"><p>Software that runs on a host or node and provides the features
and functions of a hardware-based network switch.</p></dd><dt id="id-1.4.19.27.18"><span><span class="glossterm">virtual VLAN</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.18">#</a></span></dt><dd class="glossdef"><p>Alternative term for a virtual network.</p></dd><dt id="id-1.4.19.27.19"><span><span class="glossterm">VirtualBox</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.19">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.4.19.27.20"><span><span class="glossterm">Vitrage</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.20">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-root-cause-analysis-rca-service-vitrage" title="Root Cause Analysis (RCA) service (Vitrage)">Root Cause Analysis (RCA) service (Vitrage)</a>.</p></dd><dt id="id-1.4.19.27.21"><span><span class="glossterm">VLAN manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.21">#</a></span></dt><dd class="glossdef"><p>A Compute component that provides dnsmasq and radvd and sets up
forwarding to and from cloudpipe instances.</p></dd><dt id="id-1.4.19.27.22"><span><span class="glossterm">VLAN network</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.22">#</a></span></dt><dd class="glossdef"><p>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. A VLAN network is a private network interface, which is
controlled by the <code class="literal">vlan_interface</code> option with VLAN
managers.</p></dd><dt id="id-1.4.19.27.23"><span><span class="glossterm">VM disk (VMDK)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.23">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.4.19.27.24"><span><span class="glossterm">VM image</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.24">#</a></span></dt><dd class="glossdef"><p>Alternative term for an image.</p></dd><dt id="id-1.4.19.27.25"><span><span class="glossterm">VM Remote Control (VMRC)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.25">#</a></span></dt><dd class="glossdef"><p>Method to access VM instance consoles using a web browser.
Supported by Compute.</p></dd><dt id="id-1.4.19.27.26"><span><span class="glossterm">VMware API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.26">#</a></span></dt><dd class="glossdef"><p>Supports interaction with VMware products in Compute.</p></dd><dt id="id-1.4.19.27.27"><span><span class="glossterm">VMware NSX Neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.27">#</a></span></dt><dd class="glossdef"><p>Provides support for VMware NSX in Neutron.</p></dd><dt id="id-1.4.19.27.28"><span><span class="glossterm">VNC proxy</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.28">#</a></span></dt><dd class="glossdef"><p>A Compute component that provides users access to the consoles
of their VM instances through VNC or VMRC.</p></dd><dt id="id-1.4.19.27.29"><span><span class="glossterm">volume</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.29">#</a></span></dt><dd class="glossdef"><p>Disk-based data storage generally represented as an iSCSI target
with a file system that supports extended attributes; can be
persistent or ephemeral.</p></dd><dt id="id-1.4.19.27.30"><span><span class="glossterm">Volume API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.30">#</a></span></dt><dd class="glossdef"><p>Alternative name for the Block Storage API.</p></dd><dt id="id-1.4.19.27.31"><span><span class="glossterm">volume controller</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.31">#</a></span></dt><dd class="glossdef"><p>A Block Storage component that oversees and coordinates storage
volume actions.</p></dd><dt id="id-1.4.19.27.32"><span><span class="glossterm">volume driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.32">#</a></span></dt><dd class="glossdef"><p>Alternative term for a volume plug-in.</p></dd><dt id="id-1.4.19.27.33"><span><span class="glossterm">volume ID</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.33">#</a></span></dt><dd class="glossdef"><p>Unique ID applied to each storage volume under the Block Storage
control.</p></dd><dt id="id-1.4.19.27.34"><span><span class="glossterm">volume manager</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.34">#</a></span></dt><dd class="glossdef"><p>A Block Storage component that creates, attaches, and detaches
persistent storage volumes.</p></dd><dt id="id-1.4.19.27.35"><span><span class="glossterm">volume node</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.35">#</a></span></dt><dd class="glossdef"><p>A Block Storage node that runs the cinder-volume daemon.</p></dd><dt id="id-1.4.19.27.36"><span><span class="glossterm">volume plug-in</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.36">#</a></span></dt><dd class="glossdef"><p>Provides support for new and specialized types of back-end
storage for the Block Storage volume manager.</p></dd><dt id="id-1.4.19.27.37"><span><span class="glossterm">volume worker</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.37">#</a></span></dt><dd class="glossdef"><p>A cinder component that interacts with back-end storage to manage
the creation and deletion of volumes and the creation of compute
volumes, provided by the cinder-volume daemon.</p></dd><dt id="id-1.4.19.27.38"><span><span class="glossterm">vSphere</span> <a title="Permalink" class="permalink" href="#id-1.4.19.27.38">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.28"><h3 class="title">W</h3><dl><dt id="id-1.4.19.28.3"><span><span class="glossterm">Watcher</span> <a title="Permalink" class="permalink" href="#id-1.4.19.28.3">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-infrastructure-optimization-service-watcher" title="Infrastructure Optimization service (watcher)">Infrastructure Optimization service (watcher)</a>.</p></dd><dt id="id-1.4.19.28.4"><span><span class="glossterm">weight</span> <a title="Permalink" class="permalink" href="#id-1.4.19.28.4">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage devices to determine which storage
devices are suitable for the job. Devices are weighted by size.</p></dd><dt id="id-1.4.19.28.5"><span><span class="glossterm">weighted cost</span> <a title="Permalink" class="permalink" href="#id-1.4.19.28.5">#</a></span></dt><dd class="glossdef"><p>The sum of each cost used when deciding where to start a new VM
instance in Compute.</p></dd><dt id="id-1.4.19.28.6"><span><span class="glossterm">weighting</span> <a title="Permalink" class="permalink" href="#id-1.4.19.28.6">#</a></span></dt><dd class="glossdef"><p>A Compute process that determines the suitability of the VM
instances for a job for a particular host. For example, not enough RAM
on the host, too many CPUs on the host, and so on.</p></dd><dt id="id-1.4.19.28.7"><span><span class="glossterm">worker</span> <a title="Permalink" class="permalink" href="#id-1.4.19.28.7">#</a></span></dt><dd class="glossdef"><p>A daemon that listens to a queue and carries out tasks in
response to messages. For example, the cinder-volume worker manages volume
creation and deletion on storage arrays.</p></dd><dt id="term-workflow-service-mistral"><span><span class="glossterm">Workflow service (mistral)</span> <a title="Permalink" class="permalink" href="#term-workflow-service-mistral">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provides a simple YAML-based language to
write workflows (tasks and transition rules) and a service that
allows to upload them, modify, run them at scale and in a highly
available manner, manage and monitor workflow execution state and state
of individual tasks.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.29"><h3 class="title">X</h3><dl><dt id="id-1.4.19.29.3"><span><span class="glossterm">Xen</span> <a title="Permalink" class="permalink" href="#id-1.4.19.29.3">#</a></span></dt><dd class="glossdef"><p>Xen is a hypervisor using a microkernel design, providing
services that allow multiple computer operating systems to
execute on the same computer hardware concurrently.</p></dd><dt id="id-1.4.19.29.4"><span><span class="glossterm">Xen API</span> <a title="Permalink" class="permalink" href="#id-1.4.19.29.4">#</a></span></dt><dd class="glossdef"><p>The Xen administrative API, which is supported by
Compute.</p></dd><dt id="id-1.4.19.29.5"><span><span class="glossterm">Xen Cloud Platform (XCP)</span> <a title="Permalink" class="permalink" href="#id-1.4.19.29.5">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.4.19.29.6"><span><span class="glossterm">Xen Storage Manager Volume Driver</span> <a title="Permalink" class="permalink" href="#id-1.4.19.29.6">#</a></span></dt><dd class="glossdef"><p>A Block Storage volume plug-in that enables communication with
the Xen Storage Manager API.</p></dd><dt id="id-1.4.19.29.7"><span><span class="glossterm">XenServer</span> <a title="Permalink" class="permalink" href="#id-1.4.19.29.7">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.4.19.29.8"><span><span class="glossterm">XFS</span> <a title="Permalink" class="permalink" href="#id-1.4.19.29.8">#</a></span></dt><dd class="glossdef"><p>High-performance 64-bit file system created by Silicon
Graphics. Excels in parallel I/O operations and data
consistency.</p></dd></dl></div><div class="glossdiv" id="id-1.4.19.30"><h3 class="title">Z</h3><dl><dt id="id-1.4.19.30.3"><span><span class="glossterm">zaqar</span> <a title="Permalink" class="permalink" href="#id-1.4.19.30.3">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-message-service-zaqar" title="Message service (zaqar)">Message service (zaqar)</a>.</p></dd><dt id="id-1.4.19.30.4"><span><span class="glossterm">ZeroMQ</span> <a title="Permalink" class="permalink" href="#id-1.4.19.30.4">#</a></span></dt><dd class="glossdef"><p>Message queue software supported by OpenStack. An alternative to
RabbitMQ. Also spelled 0MQ.</p></dd><dt id="id-1.4.19.30.5"><span><span class="glossterm">Zuul</span> <a title="Permalink" class="permalink" href="#id-1.4.19.30.5">#</a></span></dt><dd class="glossdef"><p>Tool used in OpenStack development to ensure correctly ordered
testing of changes in parallel.</p></dd></dl></div></div></div></div><div class="page-bottom"><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2020 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>