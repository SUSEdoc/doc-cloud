<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>OpenStack User Guide | SUSE OpenStack Cloud Crowbar</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" />
<meta name="title" content="OpenStack User Guide | SUSE OpenStack Cloud Crowbar" />
<meta name="description" content="Ironic is an OpenStack project which provisions bare metal (as opposed to virtual) machines. It may be used independently or as part of an OpenStack Cloud, and…" />
<meta name="product-name" content="SUSE OpenStack Cloud Crowbar" />
<meta name="book-title" content="OpenStack User Guide" />
<meta property="og:title" content="OpenStack User Guide | SUSE OpenStack Cloud Crowbar" />
<meta property="og:description" content="Ironic is an OpenStack project which provisions bare metal (as opposed to virtual) machines. It may be used independently or as part of an OpenStack Cloud, and…" />
<meta property="og:type" content="article" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="OpenStack User Guide | SUSE OpenStack Cloud Crowbar" />
<meta name="twitter:description" content="Ironic is an OpenStack project which provisions bare metal (as opposed to virtual) machines. It may be used independently or as part of an OpenStack Cloud, and…" />

<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft single offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #E11;"><div id="_header"><div id="_logo"><img src="static/images/logo.svg" alt="Logo" /></div><div class="crumbs inactive"><a class="single-crumb" href="#book-upstream-user" accesskey="c"><span class="single-contents-icon"></span>OpenStack User Guide</a><div class="bubble-corner active-contents"></div></div><div class="clearme"></div></div></div><div id="_fixed-header-wrap" style="background-color: #E11;" class="inactive"><div id="_fixed-header"><div class="crumbs inactive"><a class="single-crumb" href="#book-upstream-user" accesskey="c"><span class="single-contents-icon"></span>Show Contents: OpenStack User Guide</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="clearme"></div></div><div class="clearme"></div></div><div class="active-contents bubble"><div class="bubble-container"><div id="_bubble-toc"><ol><li class="inactive"><a href="#glance-user-guide"><span class="number">1 </span><span class="name">Glance User Guide</span></a></li><li class="inactive"><a href="#ironic-user-guide"><span class="number">2 </span><span class="name">Ironic User Guide</span></a></li><li class="inactive"><a href="#horizon-user-guide"><span class="number">3 </span><span class="name">Horizon User Guide</span></a></li><li class="inactive"><a href="#keystone-user-guide"><span class="number">4 </span><span class="name">Keystone User Guide</span></a></li><li class="inactive"><a href="#magnum-user-guide"><span class="number">5 </span><span class="name">Magnum User Documentation</span></a></li><li class="inactive"><a href="#nova-user-guide"><span class="number">6 </span><span class="name">Nova User Guide</span></a></li><li class="inactive"><a href="#id-1.9"><span class="number"> </span><span class="name">Glossary</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_toc-bubble-wrap"></div><div id="_content" class="draft "><div class="documentation"><div xml:lang="en" class="book" id="book-upstream-user" lang="en"><div class="titlepage"><div><h6 class="version-info"><span class="productname "><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud Crowbar</span></span></span></h6><div><h1 class="title"><span class="productname">OpenStack</span> User Guide <a title="Permalink" class="permalink" href="#book-upstream-user">#</a></h1></div><div class="date"><span class="imprint-label">Publication Date: </span>04/04/2022</div></div></div><div class="toc"><dl><dt><span class="chapter"><a href="#glance-user-guide"><span class="number">1 </span><span class="name">Glance User Guide</span></a></span></dt><dd><dl><dt><span class="section"><a href="#image-identifiers"><span class="number">1.1 </span><span class="name">Image Identifiers</span></a></span></dt><dt><span class="section"><a href="#image-statuses"><span class="number">1.2 </span><span class="name">Image Statuses</span></a></span></dt><dt><span class="section"><a href="#task-statuses"><span class="number">1.3 </span><span class="name">Task Statuses</span></a></span></dt><dt><span class="section"><a href="#id-1.3.5"><span class="number">1.4 </span><span class="name">Image Statuses</span></a></span></dt><dt><span class="section"><a href="#id-1.3.6"><span class="number">1.5 </span><span class="name">Task Statuses</span></a></span></dt><dt><span class="section"><a href="#formats"><span class="number">1.6 </span><span class="name">Disk and Container Formats</span></a></span></dt><dt><span class="section"><a href="#common-image-properties"><span class="number">1.7 </span><span class="name">Common Image Properties</span></a></span></dt><dt><span class="section"><a href="#metadata-definition-concepts"><span class="number">1.8 </span><span class="name">Metadata Definition Concepts</span></a></span></dt><dt><span class="section"><a href="#using-glance-s-image-public-apis"><span class="number">1.9 </span><span class="name">Using Glance’s Image Public APIs</span></a></span></dt><dt><span class="section"><a href="#using-glance-s-client-tools"><span class="number">1.10 </span><span class="name">Using Glance’s Client Tools</span></a></span></dt><dt><span class="section"><a href="#using-glance-s-metadata-definitions-catalog-public-apis"><span class="number">1.11 </span><span class="name">Using Glance’s Metadata Definitions Catalog Public APIs</span></a></span></dt><dt><span class="section"><a href="#image-signature-verification"><span class="number">1.12 </span><span class="name">Image Signature Verification</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#ironic-user-guide"><span class="number">2 </span><span class="name">Ironic User Guide</span></a></span></dt><dd><dl><dt><span class="section"><a href="#why-provision-bare-metal"><span class="number">2.1 </span><span class="name">Why Provision Bare Metal</span></a></span></dt><dt><span class="section"><a href="#conceptual-architecture"><span class="number">2.2 </span><span class="name">Conceptual Architecture</span></a></span></dt><dt><span class="section"><a href="#logical-architecture"><span class="number">2.3 </span><span class="name">Logical Architecture</span></a></span></dt><dt><span class="section"><a href="#key-technologies-for-bare-metal-hosting"><span class="number">2.4 </span><span class="name">Key Technologies for Bare Metal Hosting</span></a></span></dt><dt><span class="section"><a href="#ironic-deployment-architecture"><span class="number">2.5 </span><span class="name">Ironic Deployment Architecture</span></a></span></dt><dt><span class="section"><a href="#understanding-bare-metal-deployment"><span class="number">2.6 </span><span class="name">Understanding Bare Metal Deployment</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#horizon-user-guide"><span class="number">3 </span><span class="name">Horizon User Guide</span></a></span></dt><dd><dl><dt><span class="section"><a href="#openstack-dashboard-user-documentation"><span class="number">3.1 </span><span class="name">OpenStack Dashboard User Documentation</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#keystone-user-guide"><span class="number">4 </span><span class="name">Keystone User Guide</span></a></span></dt><dd><dl><dt><span class="section"><a href="#user-documentation"><span class="number">4.1 </span><span class="name">User Documentation</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#magnum-user-guide"><span class="number">5 </span><span class="name">Magnum User Documentation</span></a></span></dt><dd><dl><dt><span class="section"><a href="#id-1.7.2"><span class="number">5.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="section"><a href="#id-1.7.3"><span class="number">5.2 </span><span class="name">Terminology</span></a></span></dt><dt><span class="section"><a href="#id-1.7.4"><span class="number">5.3 </span><span class="name">Overview</span></a></span></dt><dt><span class="section"><a href="#id-1.7.5"><span class="number">5.4 </span><span class="name">ClusterTemplate</span></a></span></dt><dt><span class="section"><a href="#id-1.7.6"><span class="number">5.5 </span><span class="name">Cluster</span></a></span></dt><dt><span class="section"><a href="#id-1.7.7"><span class="number">5.6 </span><span class="name">Python Client</span></a></span></dt><dt><span class="section"><a href="#id-1.7.8"><span class="number">5.7 </span><span class="name">Horizon Interface</span></a></span></dt><dt><span class="section"><a href="#id-1.7.9"><span class="number">5.8 </span><span class="name">Cluster Drivers</span></a></span></dt><dt><span class="section"><a href="#id-1.7.10"><span class="number">5.9 </span><span class="name">Cluster Type Definition</span></a></span></dt><dt><span class="section"><a href="#id-1.7.11"><span class="number">5.10 </span><span class="name">Heat Stack Templates</span></a></span></dt><dt><span class="section"><a href="#id-1.7.12"><span class="number">5.11 </span><span class="name">Choosing a COE</span></a></span></dt><dt><span class="section"><a href="#id-1.7.13"><span class="number">5.12 </span><span class="name">Native Clients</span></a></span></dt><dt><span class="section"><a href="#id-1.7.14"><span class="number">5.13 </span><span class="name">Kubernetes</span></a></span></dt><dt><span class="section"><a href="#id-1.7.15"><span class="number">5.14 </span><span class="name">Swarm</span></a></span></dt><dt><span class="section"><a href="#id-1.7.16"><span class="number">5.15 </span><span class="name">Mesos</span></a></span></dt><dt><span class="section"><a href="#id-1.7.17"><span class="number">5.16 </span><span class="name">Transport Layer Security</span></a></span></dt><dt><span class="section"><a href="#id-1.7.18"><span class="number">5.17 </span><span class="name">Networking</span></a></span></dt><dt><span class="section"><a href="#id-1.7.19"><span class="number">5.18 </span><span class="name">High Availability</span></a></span></dt><dt><span class="section"><a href="#id-1.7.20"><span class="number">5.19 </span><span class="name">Scaling</span></a></span></dt><dt><span class="section"><a href="#id-1.7.21"><span class="number">5.20 </span><span class="name">Storage</span></a></span></dt><dt><span class="section"><a href="#id-1.7.22"><span class="number">5.21 </span><span class="name">Image Management</span></a></span></dt><dt><span class="section"><a href="#id-1.7.23"><span class="number">5.22 </span><span class="name">Notification</span></a></span></dt><dt><span class="section"><a href="#id-1.7.24"><span class="number">5.23 </span><span class="name">Container Monitoring</span></a></span></dt><dt><span class="section"><a href="#id-1.7.25"><span class="number">5.24 </span><span class="name">Kubernetes External Load Balancer</span></a></span></dt><dt><span class="section"><a href="#id-1.7.26"><span class="number">5.25 </span><span class="name">Terminology</span></a></span></dt><dt><span class="section"><a href="#id-1.7.27"><span class="number">5.26 </span><span class="name">Overview</span></a></span></dt><dt><span class="section"><a href="#id-1.7.28"><span class="number">5.27 </span><span class="name">ClusterTemplate</span></a></span></dt><dt><span class="section"><a href="#id-1.7.29"><span class="number">5.28 </span><span class="name">Cluster</span></a></span></dt><dt><span class="section"><a href="#id-1.7.30"><span class="number">5.29 </span><span class="name">Python Client</span></a></span></dt><dt><span class="section"><a href="#id-1.7.31"><span class="number">5.30 </span><span class="name">Horizon Interface</span></a></span></dt><dt><span class="section"><a href="#id-1.7.32"><span class="number">5.31 </span><span class="name">Cluster Drivers</span></a></span></dt><dt><span class="section"><a href="#id-1.7.33"><span class="number">5.32 </span><span class="name">Cluster Type Definition</span></a></span></dt><dt><span class="section"><a href="#id-1.7.34"><span class="number">5.33 </span><span class="name">Heat Stack Templates</span></a></span></dt><dt><span class="section"><a href="#id-1.7.35"><span class="number">5.34 </span><span class="name">Choosing a COE</span></a></span></dt><dt><span class="section"><a href="#id-1.7.36"><span class="number">5.35 </span><span class="name">Native Clients</span></a></span></dt><dt><span class="section"><a href="#id-1.7.37"><span class="number">5.36 </span><span class="name">Kubernetes</span></a></span></dt><dt><span class="section"><a href="#id-1.7.38"><span class="number">5.37 </span><span class="name">Swarm</span></a></span></dt><dt><span class="section"><a href="#id-1.7.39"><span class="number">5.38 </span><span class="name">Mesos</span></a></span></dt><dt><span class="section"><a href="#id-1.7.40"><span class="number">5.39 </span><span class="name">Transport Layer Security</span></a></span></dt><dt><span class="section"><a href="#id-1.7.41"><span class="number">5.40 </span><span class="name">Networking</span></a></span></dt><dt><span class="section"><a href="#id-1.7.42"><span class="number">5.41 </span><span class="name">High Availability</span></a></span></dt><dt><span class="section"><a href="#id-1.7.43"><span class="number">5.42 </span><span class="name">Scaling</span></a></span></dt><dt><span class="section"><a href="#id-1.7.44"><span class="number">5.43 </span><span class="name">Storage</span></a></span></dt><dt><span class="section"><a href="#id-1.7.45"><span class="number">5.44 </span><span class="name">Image Management</span></a></span></dt><dt><span class="section"><a href="#id-1.7.46"><span class="number">5.45 </span><span class="name">Notification</span></a></span></dt><dt><span class="section"><a href="#id-1.7.47"><span class="number">5.46 </span><span class="name">Container Monitoring</span></a></span></dt><dt><span class="section"><a href="#id-1.7.48"><span class="number">5.47 </span><span class="name">Kubernetes External Load Balancer</span></a></span></dt></dl></dd><dt><span class="chapter"><a href="#nova-user-guide"><span class="number">6 </span><span class="name">Nova User Guide</span></a></span></dt><dd><dl><dt><span class="section"><a href="#tools-for-using-nova"><span class="number">6.1 </span><span class="name">Tools for using Nova</span></a></span></dt><dt><span class="section"><a href="#writing-to-the-api"><span class="number">6.2 </span><span class="name">Writing to the API</span></a></span></dt></dl></dd><dt><span class="glossary"><a href="#id-1.9"><span class="name">Glossary</span></a></span></dt></dl></div><div class="list-of-figures"><div class="toc-title">List of Figures</div><dl><dt><span class="figure"><a href="#id-1.3.3.4"><span class="number">1.1 </span><span class="name">This is a representation of how the image move from one status to the next.</span></a></span></dt><dt><span class="figure"><a href="#id-1.3.5.4"><span class="number">1.2 </span><span class="name">This is a representation of how the image move from one status to the next.</span></a></span></dt><dt><span class="figure"><a href="#id-1.5.3.3.5.4"><span class="number">3.1 </span><span class="name">Figure: Project tab</span></a></span></dt><dt><span class="figure"><a href="#id-1.5.3.3.6.3"><span class="number">3.2 </span><span class="name">Figure: Admin tab</span></a></span></dt><dt><span class="figure"><a href="#id-1.5.3.3.7.2"><span class="number">3.3 </span><span class="name">Figure:Identity tab</span></a></span></dt><dt><span class="figure"><a href="#id-1.5.3.3.8.2"><span class="number">3.4 </span><span class="name">Figure:Settings tab</span></a></span></dt><dt><span class="figure"><a href="#id-1.5.3.4.5.3.4.3"><span class="number">3.5 </span><span class="name">Dashboard — Create Image</span></a></span></dt></dl></div><div class="chapter " id="glance-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Glance User Guide</span> <a title="Permalink" class="permalink" href="#glance-user-guide">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>glance-user-guide</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#image-identifiers"><span class="number">1.1 </span><span class="name">Image Identifiers</span></a></span></dt><dt><span class="section"><a href="#image-statuses"><span class="number">1.2 </span><span class="name">Image Statuses</span></a></span></dt><dt><span class="section"><a href="#task-statuses"><span class="number">1.3 </span><span class="name">Task Statuses</span></a></span></dt><dt><span class="section"><a href="#id-1.3.5"><span class="number">1.4 </span><span class="name">Image Statuses</span></a></span></dt><dt><span class="section"><a href="#id-1.3.6"><span class="number">1.5 </span><span class="name">Task Statuses</span></a></span></dt><dt><span class="section"><a href="#formats"><span class="number">1.6 </span><span class="name">Disk and Container Formats</span></a></span></dt><dt><span class="section"><a href="#common-image-properties"><span class="number">1.7 </span><span class="name">Common Image Properties</span></a></span></dt><dt><span class="section"><a href="#metadata-definition-concepts"><span class="number">1.8 </span><span class="name">Metadata Definition Concepts</span></a></span></dt><dt><span class="section"><a href="#using-glance-s-image-public-apis"><span class="number">1.9 </span><span class="name">Using Glance’s Image Public APIs</span></a></span></dt><dt><span class="section"><a href="#using-glance-s-client-tools"><span class="number">1.10 </span><span class="name">Using Glance’s Client Tools</span></a></span></dt><dt><span class="section"><a href="#using-glance-s-metadata-definitions-catalog-public-apis"><span class="number">1.11 </span><span class="name">Using Glance’s Metadata Definitions Catalog Public APIs</span></a></span></dt><dt><span class="section"><a href="#image-signature-verification"><span class="number">1.12 </span><span class="name">Image Signature Verification</span></a></span></dt></dl></div></div><div class="sect1" id="image-identifiers"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Identifiers</span> <a title="Permalink" class="permalink" href="#image-identifiers">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>image-identifiers</li></ul></div></div></div></div><p>Images are uniquely identified by way of a URI that
            matches the following signature:</p><div class="verbatim-wrap"><pre class="screen">&lt;Glance Server Location&gt;/v1/images/&lt;ID&gt;</pre></div><p>where <code class="literal">&lt;Glance Server Location&gt;</code> is the resource location of the Glance service
            that knows about an image, and <code class="literal">&lt;ID&gt;</code> is the image’s identifier. Image
            identifiers in Glance are <span class="emphasis"><em>uuids</em></span>, making them <span class="emphasis"><em>globally unique</em></span>.</p></div><div class="sect1" id="image-statuses"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Statuses</span> <a title="Permalink" class="permalink" href="#image-statuses">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>image-statuses</li></ul></div></div></div></div><p>Images in Glance can be in one the following statuses:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <code class="literal">queued</code>
            </p><p>The image identifier has been reserved for an image in the Glance
                    registry. No image data has been uploaded to Glance and the image
                    size was not explicitly set to zero on creation.</p></li><li class="listitem "><p>
              <code class="literal">saving</code>
            </p><p>Denotes that an image’s raw data is currently being uploaded to Glance.
                    When an image is registered with a call to <code class="literal">POST /images</code> and there
                    is an <code class="literal">x-image-meta-location</code> header present, that image will never be in
                    the <code class="literal">saving</code> status (as the image data is already available in some other
                    location).</p></li><li class="listitem "><p>
              <code class="literal">active</code>
            </p><p>Denotes an image that is fully available in Glance. This occurs when
                    the image data is uploaded, or the image size is explicitly set to
                    zero on creation.</p></li><li class="listitem "><p>
              <code class="literal">deactivated</code>
            </p><p>Denotes that access to image data is not allowed to any non-admin user.
                    Prohibiting downloads of an image also prohibits operations like image
                    export and image cloning that may require image data.</p></li><li class="listitem "><p>
              <code class="literal">killed</code>
            </p><p>Denotes that an error occurred during the uploading of an image’s data,
                    and that the image is not readable.</p></li><li class="listitem "><p>
              <code class="literal">deleted</code>
            </p><p>Glance has retained the information about the image, but it is no longer
                    available to use. An image in this state will be removed automatically
                    at a later date.</p></li><li class="listitem "><p>
              <code class="literal">pending_delete</code>
            </p><p>This is similar to <code class="literal">deleted</code>, however, Glance has not yet removed the
                    image data. An image in this state is not recoverable.</p></li></ul></div><div class="figure" id="id-1.3.3.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/image_status_transition.png" target="_blank"><img src="images/image_status_transition.png" width="" alt="This is a representation of how the image move from one status to the next." /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.1: </span><span class="name">This is a representation of how the image move from one status to the next. </span><a title="Permalink" class="permalink" href="#id-1.3.3.4">#</a></h6></div></div></div><div class="sect1" id="task-statuses"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Task Statuses</span> <a title="Permalink" class="permalink" href="#task-statuses">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>task-statuses</li></ul></div></div></div></div><p>Tasks in Glance can be in one the following statuses:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <code class="literal">pending</code>
            </p><p>The task identifier has been reserved for a task in the Glance.
                    No processing has begun on it yet.</p></li><li class="listitem "><p>
              <code class="literal">processing</code>
            </p><p>The task has been picked up by the underlying executor and is being run
                    using the backend Glance execution logic for that task type.</p></li><li class="listitem "><p>
              <code class="literal">success</code>
            </p><p>Denotes that the task has had a successful run within Glance. The <code class="literal">result</code>
                    field of the task shows more details about the outcome.</p></li><li class="listitem "><p>
              <code class="literal">failure</code>
            </p><p>Denotes that an error occurred during the execution of the task and it
                    cannot continue processing. The <code class="literal">message</code> field of the task shows what the
                    error was.</p></li></ul></div></div><div class="sect1" id="id-1.3.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Statuses</span> <a title="Permalink" class="permalink" href="#id-1.3.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Images in Glance can be in one the following statuses:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <code class="literal">queued</code>
            </p><p>The image identifier has been reserved for an image in the Glance
                    registry. No image data has been uploaded to Glance and the image
                    size was not explicitly set to zero on creation.</p></li><li class="listitem "><p>
              <code class="literal">saving</code>
            </p><p>Denotes that an image’s raw data is currently being uploaded to Glance.
                    When an image is registered with a call to <code class="literal">POST /images</code> and there
                    is an <code class="literal">x-image-meta-location</code> header present, that image will never be in
                    the <code class="literal">saving</code> status (as the image data is already available in some other
                    location).</p></li><li class="listitem "><p>
              <code class="literal">active</code>
            </p><p>Denotes an image that is fully available in Glance. This occurs when
                    the image data is uploaded, or the image size is explicitly set to
                    zero on creation.</p></li><li class="listitem "><p>
              <code class="literal">deactivated</code>
            </p><p>Denotes that access to image data is not allowed to any non-admin user.
                    Prohibiting downloads of an image also prohibits operations like image
                    export and image cloning that may require image data.</p></li><li class="listitem "><p>
              <code class="literal">killed</code>
            </p><p>Denotes that an error occurred during the uploading of an image’s data,
                    and that the image is not readable.</p></li><li class="listitem "><p>
              <code class="literal">deleted</code>
            </p><p>Glance has retained the information about the image, but it is no longer
                    available to use. An image in this state will be removed automatically
                    at a later date.</p></li><li class="listitem "><p>
              <code class="literal">pending_delete</code>
            </p><p>This is similar to <code class="literal">deleted</code>, however, Glance has not yet removed the
                    image data. An image in this state is not recoverable.</p></li></ul></div><div class="figure" id="id-1.3.5.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/image_status_transition.png" target="_blank"><img src="images/image_status_transition.png" width="" alt="This is a representation of how the image move from one status to the next." /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 1.2: </span><span class="name">This is a representation of how the image move from one status to the next. </span><a title="Permalink" class="permalink" href="#id-1.3.5.4">#</a></h6></div></div></div><div class="sect1" id="id-1.3.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Task Statuses</span> <a title="Permalink" class="permalink" href="#id-1.3.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Tasks in Glance can be in one the following statuses:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <code class="literal">pending</code>
            </p><p>The task identifier has been reserved for a task in the Glance.
                    No processing has begun on it yet.</p></li><li class="listitem "><p>
              <code class="literal">processing</code>
            </p><p>The task has been picked up by the underlying executor and is being run
                    using the backend Glance execution logic for that task type.</p></li><li class="listitem "><p>
              <code class="literal">success</code>
            </p><p>Denotes that the task has had a successful run within Glance. The <code class="literal">result</code>
                    field of the task shows more details about the outcome.</p></li><li class="listitem "><p>
              <code class="literal">failure</code>
            </p><p>Denotes that an error occurred during the execution of the task and it
                    cannot continue processing. The <code class="literal">message</code> field of the task shows what the
                    error was.</p></li></ul></div></div><div class="sect1" id="formats"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disk and Container Formats</span> <a title="Permalink" class="permalink" href="#formats">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>formats</li></ul></div></div></div></div><p>When adding an image to Glance, you must specify what the virtual
            machine image’s <span class="emphasis"><em>disk format</em></span> and <span class="emphasis"><em>container format</em></span> are. Disk and container
            formats are configurable on a per-deployment basis. This document intends to
            establish a global convention for what specific values of <span class="emphasis"><em>disk_format</em></span> and
            <span class="emphasis"><em>container_format</em></span> mean.</p><div class="sect2" id="disk-format"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disk Format</span> <a title="Permalink" class="permalink" href="#disk-format">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>disk-format</li></ul></div></div></div></div><p>The disk format of a virtual machine image is the format of the underlying
                disk image. Virtual appliance vendors have different formats for laying out
                the information contained in a virtual machine disk image.</p><p>You can set your image’s disk format to one of the following:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <span class="bold"><strong>raw</strong></span>
              </p><p>This is an unstructured disk image format</p></li><li class="listitem "><p>
                <span class="bold"><strong>vhd</strong></span>
              </p><p>This is the VHD disk format, a common disk format used by virtual machine
                        monitors from VMware, Xen, Microsoft, VirtualBox, and others.</p></li><li class="listitem "><p>
                <span class="bold"><strong>vhdx</strong></span>
              </p><p>This is the VHDX disk format, an enhanced version of the VHD format which
                        supports larger disk sizes among other features.</p></li><li class="listitem "><p>
                <span class="bold"><strong>vmdk</strong></span>
              </p><p>Another common disk format supported by many common virtual machine monitors.</p></li><li class="listitem "><p>
                <span class="bold"><strong>vdi</strong></span>
              </p><p>A disk format supported by VirtualBox virtual machine monitor and the QEMU
                        emulator.</p></li><li class="listitem "><p>
                <span class="bold"><strong>iso</strong></span>
              </p><p>An archive format for the data contents of an optical disc (For example, CDROM).</p></li><li class="listitem "><p>
                <span class="bold"><strong>ploop</strong></span>
              </p><p>A disk format supported and used by Virtuozzo to run OS Containers.</p></li><li class="listitem "><p>
                <span class="bold"><strong>qcow2</strong></span>
              </p><p>A disk format supported by the QEMU emulator that can expand dynamically and
                        supports Copy on Write.</p></li><li class="listitem "><p>
                <span class="bold"><strong>aki</strong></span>
              </p><p>This indicates what is stored in Glance is an Amazon kernel image.</p></li><li class="listitem "><p>
                <span class="bold"><strong>ari</strong></span>
              </p><p>This indicates what is stored in Glance is an Amazon ramdisk image.</p></li><li class="listitem "><p>
                <span class="bold"><strong>ami</strong></span>
              </p><p>This indicates what is stored in Glance is an Amazon machine image.</p></li></ul></div></div><div class="sect2" id="container-format"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Container Format</span> <a title="Permalink" class="permalink" href="#container-format">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>container-format</li></ul></div></div></div></div><p>The container format refers to whether the virtual machine image is in a
                file format that also contains metadata about the actual virtual machine.</p><div id="id-1.3.7.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The container format string is not currently used by Glance or
                other OpenStack components, so it is safe to simply specify <span class="bold"><strong>bare</strong></span> as
                the container format if you are unsure.</p></div><p>You can set your image’s container format to one of the following:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <span class="bold"><strong>bare</strong></span>
              </p><p>This indicates there is no container or metadata envelope for the image.</p></li><li class="listitem "><p>
                <span class="bold"><strong>ovf</strong></span>
              </p><p>This is the OVF container format.</p></li><li class="listitem "><p>
                <span class="bold"><strong>aki</strong></span>
              </p><p>This indicates what is stored in Glance is an Amazon kernel image.</p></li><li class="listitem "><p>
                <span class="bold"><strong>ari</strong></span>
              </p><p>This indicates what is stored in Glance is an Amazon ramdisk image.</p></li><li class="listitem "><p>
                <span class="bold"><strong>ami</strong></span>
              </p><p>This indicates what is stored in Glance is an Amazon machine image</p></li><li class="listitem "><p>
                <span class="bold"><strong>ova</strong></span>
              </p><p>This indicates what is stored in Glance is an OVA tar archive file.</p></li><li class="listitem "><p>
                <span class="bold"><strong>docker</strong></span>
              </p><p>This indicates what is stored in Glance is a Docker tar archive of
                        the container filesystem.</p></li></ul></div></div></div><div class="sect1" id="common-image-properties"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Common Image Properties</span> <a title="Permalink" class="permalink" href="#common-image-properties">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>common-image-properties</li></ul></div></div></div></div><p>When adding an image to Glance, you may specify some common image properties
            that may prove useful to consumers of your image.</p><p>This document explains the names of these properties and the expected values.</p><p>The common image properties are also described in a JSON schema, found in
              <code class="literal">/etc/glance/schema-image.json</code> in the Glance source code.</p><div class="sect2" id="architecture"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
            <span class="bold"><strong>architecture</strong></span>
          </span> <a title="Permalink" class="permalink" href="#architecture">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>architecture</li></ul></div></div></div></div><p>Operating system architecture as specified in
                <a class="link" href="https://docs.openstack.org/python-glanceclient/latest/cli/property-keys.html" target="_blank">https://docs.openstack.org/python-glanceclient/latest/cli/property-keys.html</a>.</p></div><div class="sect2" id="instance-uuid"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
            <span class="bold"><strong>instance_uuid</strong></span>
          </span> <a title="Permalink" class="permalink" href="#instance-uuid">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>instance-uuid</li></ul></div></div></div></div><p>Metadata which can be used to record which instance this image is associated
                with. (Informational only, does not create an instance snapshot.)</p></div><div class="sect2" id="kernel-id"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
            <span class="bold"><strong>kernel_id</strong></span>
          </span> <a title="Permalink" class="permalink" href="#kernel-id">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>kernel-id</li></ul></div></div></div></div><p>The ID of image stored in Glance that should be used as the kernel when booting
                an AMI-style image.</p></div><div class="sect2" id="ramdisk-id"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
            <span class="bold"><strong>ramdisk_id</strong></span>
          </span> <a title="Permalink" class="permalink" href="#ramdisk-id">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>ramdisk-id</li></ul></div></div></div></div><p>The ID of image stored in Glance that should be used as the ramdisk when
                booting an AMI-style image.</p></div><div class="sect2" id="os-distro"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.7.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
            <span class="bold"><strong>os_distro</strong></span>
          </span> <a title="Permalink" class="permalink" href="#os-distro">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>os-distro</li></ul></div></div></div></div><p>The common name of the operating system distribution as specified in
                <a class="link" href="https://docs.openstack.org/python-glanceclient/latest/cli/property-keys.html" target="_blank">https://docs.openstack.org/python-glanceclient/latest/cli/property-keys.html</a>.</p></div><div class="sect2" id="os-version"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.7.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">
            <span class="bold"><strong>os_version</strong></span>
          </span> <a title="Permalink" class="permalink" href="#os-version">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>os-version</li></ul></div></div></div></div><p>The operating system version as specified by the distributor.</p></div></div><div class="sect1" id="metadata-definition-concepts"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Metadata Definition Concepts</span> <a title="Permalink" class="permalink" href="#metadata-definition-concepts">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>metadata-definition-concepts</li></ul></div></div></div></div><p>The metadata definition service was added to Glance in the Juno release of
            OpenStack.</p><p>It provides a common API for vendors, admins, services, and users to
            meaningfully <span class="bold"><strong>define</strong></span> available key and value pair metadata that
            can be used on different types of resources (images, artifacts, volumes,
            flavors, aggregates, and other resources). A definition includes a property’s
            key, its description, its constraints, and the resource types to which it
            can be associated.</p><p>This catalog does not store the values for specific instance properties.</p><p>For example, a definition of a virtual CPU topology property for the number of
            cores will include the base key to use (for example, <code class="literal">cpu_cores</code>), a description,
            and value constraints like requiring it to be an integer. So, a user,
            potentially through Horizon, would be able to search this catalog to list the
            available properties they can add to a flavor or image. They will see the
            virtual CPU topology property in the list and know that it must be an integer.</p><p>When the user adds the property its key and value will be stored in the
            service that owns that resource (for example, Nova for flavors and in Glance
            for images). The catalog also includes any additional prefix required when
            the property is applied to different types of resources, such as <code class="literal">hw_</code> for
            images and <code class="literal">hw:</code> for flavors. So, on an image, the user would know to set the
            property as <code class="literal">hw_cpu_cores=1</code>.</p><div class="sect2" id="terminology"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Terminology</span> <a title="Permalink" class="permalink" href="#terminology">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>terminology</li></ul></div></div></div></div><div class="sect3" id="background"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.8.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Background</span> <a title="Permalink" class="permalink" href="#background">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>background</li></ul></div></div></div></div><p>The term <span class="emphasis"><em>metadata</em></span> can become very overloaded and confusing. This
                    catalog is about the additional metadata that is passed as arbitrary
                    key and value pairs or tags across various artifacts and OpenStack services.</p><p>Below are a few examples of the various terms used for metadata across
                    OpenStack services today:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="25" class="c1" /><col width="27" class="c2" /><col width="22" class="c3" /></colgroup><thead><tr><th>
                      <p>Nova</p>
                    </th><th>
                      <p>Cinder</p>
                    </th><th>
                      <p>Glance</p>
                    </th></tr></thead><tbody><tr><td>
                      <div class="variablelist "><dl class="variablelist"><dt id="id-1.3.9.7.2.4.1.5.1.1.1.1"><span class="term ">Flavor</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                                  <span class="emphasis"><em>extra specs</em></span>
                                </p></li></ul></div></dd><dt id="id-1.3.9.7.2.4.1.5.1.1.1.2"><span class="term ">Host Aggregate</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                                  <span class="emphasis"><em>metadata</em></span>
                                </p></li></ul></div></dd><dt id="id-1.3.9.7.2.4.1.5.1.1.1.3"><span class="term ">Servers</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                                  <span class="emphasis"><em>metadata</em></span>
                                </p></li><li class="listitem "><p>
                                  <span class="emphasis"><em>scheduler_hints</em></span>
                                </p></li><li class="listitem "><p>
                                  <span class="emphasis"><em>tags</em></span>
                                </p></li></ul></div></dd></dl></div>
                    </td><td>
                      <div class="variablelist "><dl class="variablelist"><dt id="id-1.3.9.7.2.4.1.5.1.2.1.1"><span class="term ">Volume &amp; Snapshot</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                                  <span class="emphasis"><em>image metadata</em></span>
                                </p></li><li class="listitem "><p>
                                  <span class="emphasis"><em>metadata</em></span>
                                </p></li></ul></div></dd><dt id="id-1.3.9.7.2.4.1.5.1.2.1.2"><span class="term ">VolumeType</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                                  <span class="emphasis"><em>extra specs</em></span>
                                </p></li><li class="listitem "><p>
                                  <span class="emphasis"><em>qos specs</em></span>
                                </p></li></ul></div></dd></dl></div>
                    </td><td>
                      <div class="variablelist "><dl class="variablelist"><dt id="id-1.3.9.7.2.4.1.5.1.3.1.1"><span class="term ">Image &amp; Snapshot</span></dt><dd><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                                  <span class="emphasis"><em>properties</em></span>
                                </p></li><li class="listitem "><p>
                                  <span class="emphasis"><em>tags</em></span>
                                </p></li></ul></div></dd></dl></div>
                    </td></tr></tbody></table></div></div><div class="sect3" id="catalog-concepts"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.8.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Catalog Concepts</span> <a title="Permalink" class="permalink" href="#catalog-concepts">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>catalog-concepts</li></ul></div></div></div></div><p>The below figure illustrates the concept terminology used in the metadata
                    definitions catalog:</p><div class="verbatim-wrap"><pre class="screen">A namespace is associated with 0 to many resource types, making it visible to
the API and UI for applying to that type of resource. RBAC Permissions are
managed at a namespace level.

+----------------------------------------------+
|         Namespace                            |
|                                              |
| +-----------------------------------------+  |
| |        Object Definition                |  |
| |                                         |  |        +--------------------+
| | +-------------------------------------+ |  |  +--&gt;  | Resource Type:     |
| | | Property Definition A (key=integer) | |  |  |     | e.g. Nova Flavor   |
| | +-------------------------------------+ |  |  |     +--------------------+
| |                                         |  |  |
| | +-------------------------------------+ |  |  |
| | | Property Definition B (key=string)  | |  |  |     +--------------------+
| | +-------------------------------------+ |  +--+--&gt;  | Resource Type:     |
| |                                         |  |  |     | e.g. Glance Image  |
| +-----------------------------------------+  |  |     +--------------------+
|                                              |  |
|  +-------------------------------------+     |  |
|  | Property Definition C (key=boolean) |     |  |     +--------------------+
|  +-------------------------------------+     |  +--&gt;  | Resource Type:     |
|                                              |        | e.g. Cinder Volume |
+----------------------------------------------+        +--------------------+

 Properties may be defined standalone or within the context of an object.</pre></div></div><div class="sect3" id="catalog-terminology"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.8.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Catalog Terminology</span> <a title="Permalink" class="permalink" href="#catalog-terminology">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>catalog-terminology</li></ul></div></div></div></div><p>The following terminology is used within the metadata definition catalog.</p><p>
              <span class="bold"><strong>Namespaces</strong></span>
            </p><p>Metadata definitions are contained in namespaces.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Specify the access controls (CRUD) for everything defined in it. Allows for
                            admin only, different projects, or the entire cloud to define and use the
                            definitions in the namespace.</p></li><li class="listitem "><p>Associates the contained definitions to different types of resources.</p></li></ul></div><p>
              <span class="bold"><strong>Properties</strong></span>
            </p><p>A property describes a single property and its primitive constraints. Each
                    property can only be a primitive type:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>string, integer, number, boolean, array</p></li></ul></div><p>Each primitive type is described using simple JSON schema notation. This
                    means no nested objects and no definition referencing.</p><p>
              <span class="bold"><strong>Objects</strong></span>
            </p><p>An object describes a group of one to many properties and their primitive
                    constraints. Each property in the group can ONLY be a primitive type:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>string, integer, number, boolean, array</p></li></ul></div><p>Each primitive type is described using simple JSON schema notation. This
                    means no nested objects.</p><p>The object may optionally define required properties under the semantic
                    understanding that a user who uses the object should provide all required
                    properties.</p><p>
              <span class="bold"><strong>Resource Type Association</strong></span>
            </p><p>Resource type association specifies the relationship between resource
                    types and the namespaces that are applicable to them. This information can be
                    used to drive UI and CLI views. For example, the same namespace of
                    objects, properties, and tags may be used for images, snapshots, volumes, and
                    flavors. Or a namespace may only apply to images.</p><p>Resource types should be aligned with Heat resource types whenever possible.
                    <a class="link" href="http://docs.openstack.org/developer/heat/template_guide/openstack.html" target="_blank">http://docs.openstack.org/developer/heat/template_guide/openstack.html</a></p><p>It is important to note that the same base property key can require different
                    prefixes depending on the target resource type. The API provides a way to
                    retrieve the correct property based on the target resource type.</p><p>Below are a few examples:</p><p>The desired virtual CPU topology can be set on both images and flavors
                    via metadata. The keys have different prefixes on images than on flavors.
                    On flavors keys are prefixed with <code class="literal">hw:</code>, but on images the keys are prefixed
                    with <code class="literal">hw_</code>.</p><p>For more: <a class="link" href="https://github.com/openstack/nova-specs/blob/master/specs/juno/implemented/virt-driver-vcpu-topology.rst" target="_blank">https://github.com/openstack/nova-specs/blob/master/specs/juno/implemented/virt-driver-vcpu-topology.rst</a>.</p><p>Another example is the <code class="literal">AggregateInstanceExtraSpecsFilter</code> and scoped properties
                    (For example, properties with <code class="literal">something:something=value</code>). For scoped or namespaced
                    properties, the <code class="literal">AggregateInstanceExtraSpecsFilter</code> requires a prefix of
                    <code class="literal">aggregate_instance_extra_specs:</code> to be used on flavors but not on the
                    aggregate itself. Otherwise, the filter will not evaluate the property during
                    scheduling.</p><p>So, on a host aggregate, you may see:</p><p><code class="literal">companyx:fastio=true</code></p><p>But then when used on the flavor, the <code class="literal">AggregateInstanceExtraSpecsFilter</code> needs:</p><p><code class="literal">aggregate_instance_extra_specs:companyx:fastio=true</code></p><p>In some cases, there may be multiple different filters that may use
                    the same property with different prefixes. In this case, the correct prefix
                    needs to be set based on which filter is enabled.</p></div></div></div><div class="sect1" id="using-glance-s-image-public-apis"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Glance’s Image Public APIs</span> <a title="Permalink" class="permalink" href="#using-glance-s-image-public-apis">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>using-glance-s-image-public-apis</li></ul></div></div></div></div><p>Glance is the reference implementation of the OpenStack Images API. As such,
            Glance fully implements versions 1 and 2 of the Images API.</p><div id="id-1.3.10.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The Images API v1 has been DEPRECATED in the Newton release. The
                migration path is to use the <a class="link" href="http://developer.openstack.org/api-ref/image/v2/" target="_blank">Images API v2</a> instead of version 1
                of the API. The Images API v1 will ultimately be removed, following the
                <a class="link" href="https://governance.openstack.org/reference/tags/assert_follows-standard-deprecation.html" target="_blank">OpenStack standard deprecation policy</a>.</p></div><p>There used to be a sentence here saying, “The Images API specification is
            developed alongside Glance, but is not considered part of the Glance project.”
            That’s only partially true (or completely false, depending upon how strict you
            are about these things). Conceptually, the OpenStack Images API is an
            independent definition of a REST API. In practice, however, the only way
            to participate in the evolution of the Images API is to work with the Glance
            community to define the new functionality and provide its reference
            implementation. Further, Glance falls under the designated sections provision
            of the OpenStack DefCore Guidelines, which basically means that in order to
            qualify as OpenStack, a cloud exposing an OpenStack Images API must include
            the Glance Images API implementation code. Thus, although conceptually
            independent, the OpenStack Images APIs are intimately associated with Glance.</p><p>
          <span class="bold"><strong>References</strong></span>
        </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://git.openstack.org/cgit/openstack/defcore/tree/doc/source/process/Lexicon.rst#n54" target="_blank">Designated sections (definition)</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://governance.openstack.org/resolutions/20140402-defcore-designated-sections-guidelines.html" target="_blank">2014-04-02 DefCore Designated Sections Guidelines</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://github.com/openstack/defcore/blob/master/doc/source/process/CoreDefinition.rst" target="_blank">OpenStack Core Definition</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="https://github.com/openstack/defcore" target="_blank">DefCore Guidelines Repository</a>
            </p></li></ul></div><div class="sect2" id="glance-and-the-images-apis-past-present-and-future"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Glance and the Images APIs: Past, Present, and Future</span> <a title="Permalink" class="permalink" href="#glance-and-the-images-apis-past-present-and-future">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>glance-and-the-images-apis-past-present-and-future</li></ul></div></div></div></div><p>Here’s a quick summary of the Images APIs that have been implemented by Glance.
                If you’re interested in more details, you can consult the Release Notes for all
                the OpenStack releases (beginning with “Bexar”) to follow the evolution of
                features in Glance and the Images APIs.</p><div class="sect3" id="images-v1-api"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Images v1 API</span> <a title="Permalink" class="permalink" href="#images-v1-api">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>images-v1-api</li></ul></div></div></div></div><p>The v1 API was originally designed as a service API for use by Nova and other
                    OpenStack services. In the Kilo release, the v1.1 API was downgraded from
                    CURRENT to SUPPORTED. In the Newton release, the version 1 API is officially
                    declared DEPRECATED.</p><p>During the deprecation period, the Images v1 API is closed to further
                    development. The Glance code implementing the v1 API accepts only serious
                    bug fixes.</p><p>Since Folsom, it has been possible to deploy OpenStack without exposing the
                    Images v1 API to end users. The Compute v2 API contains image-related API
                    calls allowing users to list images, list images details, show image details
                    for a specific image, delete images, and manipulate image metadata. Nova acts
                    as a proxy to Glance for these image-related calls. It’s important to note
                    that the image-related calls in the Compute v2 API are a proper subset of the
                    calls available in the Images APIs.</p><p>In the Newton release, Nova (and other OpenStack services that consume images)
                    have been modified to use the Images v2 API by default.</p><p>
              <span class="bold"><strong>Reference</strong></span>
            </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <a class="link" href="https://governance.openstack.org/reference/tags/assert_follows-standard-deprecation.html#requirements" target="_blank">OpenStack Standard Deprecation Requirements</a>
                </p></li></ul></div></div><div class="sect3" id="images-v2-api"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Images v2 API</span> <a title="Permalink" class="permalink" href="#images-v2-api">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>images-v2-api</li></ul></div></div></div></div><p>The v2 API is the CURRENT OpenStack Images API. It provides a more friendly
                    interface to consumers than did the v1 API, as it was specifically designed to
                    expose images-related functionality as a public-facing endpoint. It’s the
                    version that’s currently open to development.</p><p>A common strategy is to deploy multiple Glance nodes: internal-facing nodes
                    providing the Images APIs for internal consumers like Nova, and external-facing
                    nodes providing the Images v2 API for public use.</p></div><div class="sect3" id="the-future"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Future</span> <a title="Permalink" class="permalink" href="#the-future">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>the-future</li></ul></div></div></div></div><p>During the long and tumultuous design phase of what has since become an
                    independent service named “Glare” (the Glance Artifacts Repository), the Glance
                    community loosely spoke about the Artifacts API being “Glance v3”. This,
                    however, was only a shorthand way of speaking of the Artifacts effort. The
                    Artifacts API can’t be the Images v3 API since Artifacts are not the same as
                    Images. Conceptually, a virtual machine image could be an Artifact, and the
                    Glare code has been designed to be compatible with the Images v2 API. But at
                    this time, there are no plans to implement an Images v3 API.</p><p>During the Newton development cycle, Glare became an independent OpenStack
                    project. While it’s evident that there’s a need for an Artifact Repository in
                    OpenStack, whether it will be as ubiquitous as the need for an Images
                    Repository isn’t clear. On the other hand, industry trends could go in the
                    opposite direction where everyone needs Artifacts and deployers view images as
                    simply another type of digital artifact.</p></div></div><div class="sect2" id="id-1.3.10.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Authentication</span> <a title="Permalink" class="permalink" href="#id-1.3.10.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Glance depends on Keystone and the OpenStack Identity API to handle
                authentication of clients. You must obtain an authentication token from
                Keystone using and send it along with all API requests to Glance through
                the <code class="literal">X-Auth-Token</code> header. Glance will communicate back to Keystone to
                verify the token validity and obtain your identity credentials.</p><p>See <a class="link" href="https://docs.openstack.org/glance/pike/admin/authentication.html#authentication" target="_blank">Authentication With Keystone</a>
                for more information on integrating with Keystone.</p></div><div class="sect2" id="using-v1-x"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using v1.X</span> <a title="Permalink" class="permalink" href="#using-v1-x">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>using-v1-x</li></ul></div></div></div></div><div id="id-1.3.10.9.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The Images API v1 has been DEPRECATED in the Newton release. The
                    migration path is to use the <a class="link" href="http://developer.openstack.org/api-ref/image/v2/" target="_blank">Images API v2</a>
                    instead of version 1 of the API. The Images API v1 will ultimately be removed, following the
                    <a class="link" href="https://governance.openstack.org/reference/tags/assert_follows-standard-deprecation.html" target="_blank">OpenStack standard deprecation policy</a>.</p></div><p>For the purpose of examples, assume there is a Glance API server running
                at the URL <code class="literal">http://glance.openstack.example.org</code> on the default port 80.</p><div class="sect3" id="list-available-images"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Available Images</span> <a title="Permalink" class="permalink" href="#list-available-images">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-available-images</li></ul></div></div></div></div><p>We want to see a list of available images that the authenticated user has
                    access to. This includes images owned by the user, images shared with the user
                    and public images.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v1/images</code> to
                    retrieve this list of available images. The data is returned as a JSON-encoded
                    mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{'images': [
  {'uri': 'http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9',
   'name': 'SLES 15',
   'disk_format': 'vhd',
   'container_format': 'ovf',
   'size': '5368709120'}
  ...]}</pre></div></div><div class="sect3" id="list-available-images-in-more-detail"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Available Images in More Detail</span> <a title="Permalink" class="permalink" href="#list-available-images-in-more-detail">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-available-images-in-more-detail</li></ul></div></div></div></div><p>We want to see a more detailed list of available images that the authenticated
                    user has access to. This includes images owned by the user, images shared with
                    the user and public images.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v1/images/detail</code> to
                    retrieve this list of available images. The data is returned as a
                    JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{'images': [
  {'uri': 'http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9',
   'name': 'SLES 15',
   'disk_format': 'vhd',
   'container_format': 'ovf',
   'size': '5368709120',
   'checksum': 'c2e5db72bd7fd153f53ede5da5a06de3',
   'created_at': '2010-02-03 09:34:01',
   'updated_at': '2010-02-03 09:34:01',
   'deleted_at': '',
   'status': 'active',
   'is_public': true,
   'min_ram': 256,
   'min_disk': 5,
   'owner': null,
   'properties': {'distro': 'SLES 15'}},
  ...]}</pre></div><div id="id-1.3.10.9.5.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>All timestamps returned are in UTC.</p><p>The <code class="literal">updated_at</code> timestamp is the timestamp when an image’s metadata
                        was last updated, not its image data, as all image data is immutable
                        once stored in Glance.</p><p>The <code class="literal">properties</code> field is a mapping of free-form key and value pairs that
                        have been saved with the image metadata.</p><p>The <code class="literal">checksum</code> field is an MD5 checksum of the image file data.</p><p>The <code class="literal">is_public</code> field is a boolean indicating whether the image is
                        publicly available.</p><p>The <code class="literal">min_ram</code> field is an integer specifying the minimum amount of
                        RAM needed to run this image on an instance in megabytes.</p><p>The <code class="literal">min_disk</code> field is an integer specifying the minimum amount of
                        disk space needed to run this image on an instance in gigabytes.</p><p>The <code class="literal">owner</code> field is a string which may either be null or which will
                        indicate the owner of the image.</p></div></div><div class="sect3" id="filtering-images-lists"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Filtering Images Lists</span> <a title="Permalink" class="permalink" href="#filtering-images-lists">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>filtering-images-lists</li></ul></div></div></div></div><p>Both the <code class="literal">GET /v1/images</code> and <code class="literal">GET /v1/images/detail</code> requests take query
                    parameters that serve to filter the returned list of images. The following
                    list details these query parameters.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">name=NAME</code>
                </p><p>Filters images having a <code class="literal">name</code> attribute matching <code class="literal">NAME</code>.</p></li><li class="listitem "><p>
                  <code class="literal">container_format=FORMAT</code>
                </p><p>Filters images having a <code class="literal">container_format</code> attribute matching <code class="literal">FORMAT</code>.</p><p>For more information, see <a class="xref" href="#formats" title="1.6. Disk and Container Formats">Section 1.6, “Disk and Container Formats”</a>.</p></li><li class="listitem "><p>
                  <code class="literal">disk_format=FORMAT</code>
                </p><p>Filters images having a <code class="literal">disk_format</code> attribute matching <code class="literal">FORMAT</code>.</p><p>For more information, see <a class="xref" href="#formats" title="1.6. Disk and Container Formats">Section 1.6, “Disk and Container Formats”</a>.</p></li><li class="listitem "><p>
                  <code class="literal">status=STATUS</code>
                </p><p>Filters images having a <code class="literal">status</code> attribute matching <code class="literal">STATUS</code>.</p><p>For more information, see <a class="xref" href="#image-statuses" title="1.2. Image Statuses">Section 1.2, “Image Statuses”</a>.</p></li><li class="listitem "><p>
                  <code class="literal">size_min=BYTES</code>
                </p><p>Filters images having a <code class="literal">size</code> attribute greater than or equal to <code class="literal">BYTES</code>.</p></li><li class="listitem "><p>
                  <code class="literal">size_max=BYTES</code>
                </p><p>Filters images having a <code class="literal">size</code> attribute less than or equal to <code class="literal">BYTES</code>.</p></li></ul></div><p>These two resources also accept additional query parameters:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">sort_key=KEY</code>
                </p><p>Results will be ordered by the specified image attribute <code class="literal">KEY</code>. Accepted
                            values include <code class="literal">id</code>, <code class="literal">name</code>, <code class="literal">status</code>, <code class="literal">disk_format</code>,
                            <code class="literal">container_format</code>, <code class="literal">size</code>, <code class="literal">created_at</code> (default) and <code class="literal">updated_at</code>.</p></li><li class="listitem "><p>
                  <code class="literal">sort_dir=DIR</code>
                </p><p>Results will be sorted in the direction <code class="literal">DIR</code>. Accepted values are <code class="literal">asc</code>
                            for ascending or <code class="literal">desc</code> (default) for descending.</p></li><li class="listitem "><p>
                  <code class="literal">marker=ID</code>
                </p><p>An image identifier marker may be specified. When present, only images which
                            occur after the identifier <code class="literal">ID</code> will be listed. (These are the images that
                            have a <code class="literal">sort_key</code> later than that of the marker <code class="literal">ID</code> in the <code class="literal">sort_dir</code>
                            direction.)</p></li><li class="listitem "><p>
                  <code class="literal">limit=LIMIT</code>
                </p><p>When present, the maximum number of results returned will not exceed <code class="literal">LIMIT</code>.</p></li></ul></div><div id="id-1.3.10.9.6.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If the specified <code class="literal">LIMIT</code> exceeds the operator defined limit (<code class="literal">api_limit_max</code>)
                        then the number of results returned may be less than <code class="literal">LIMIT</code>.</p></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">is_public=PUBLIC</code>
                </p><p>An admin user may use the <code class="literal">is_public</code> parameter to control which results are
                            returned.</p><p>When the <code class="literal">is_public</code> parameter is absent or set to <code class="literal">True</code> the following images
                            will be listed: Images whose <code class="literal">is_public</code> field is <code class="literal">True</code>, owned images and
                            shared images.</p><p>When the <code class="literal">is_public</code> parameter is set to <code class="literal">False</code> the following images will be
                            listed: Images (owned, shared, or non-owned) whose <code class="literal">is_public</code> field is <code class="literal">False</code>.</p><p>When the <code class="literal">is_public</code> parameter is set to <code class="literal">None</code> all images will be listed
                            irrespective of owner, shared status or the <code class="literal">is_public</code> field.</p></li></ul></div><div id="id-1.3.10.9.6.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Use of the <code class="literal">is_public</code> parameter is restricted to admin users. For all other
                        users it will be ignored.</p></div></div><div class="sect3" id="retrieve-image-metadata"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Retrieve Image Metadata</span> <a title="Permalink" class="permalink" href="#retrieve-image-metadata">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>retrieve-image-metadata</li></ul></div></div></div></div><p>We want to see detailed information for a specific virtual machine image
                    that the Glance server knows about.</p><p>We have queried the Glance server for a list of images and the
                    data returned includes the <code class="literal">uri</code> field for each available image. This
                    <code class="literal">uri</code> field value contains the exact location needed to get the metadata
                    for a specific image.</p><p>Continuing the example from above, in order to get metadata about the
                    first image returned, we can issue a <code class="literal">HEAD</code> request to the Glance
                    server for the image’s URI.</p><p>We issue a <code class="literal">HEAD</code> request to
                    <code class="literal">http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9</code> to
                    retrieve complete metadata for that image. The metadata is returned as a
                    set of HTTP headers that begin with the prefix <code class="literal">x-image-meta-</code>. The
                    following shows an example of the HTTP headers returned from the above
                    <code class="literal">HEAD</code> request:</p><div class="verbatim-wrap"><pre class="screen">x-image-meta-uri              http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9
x-image-meta-name             SLES 15
x-image-meta-disk_format      vhd
x-image-meta-container_format ovf
x-image-meta-size             5368709120
x-image-meta-checksum         c2e5db72bd7fd153f53ede5da5a06de3
x-image-meta-created_at       2010-02-03 09:34:01
x-image-meta-updated_at       2010-02-03 09:34:01
x-image-meta-deleted_at
x-image-meta-status           available
x-image-meta-is_public        true
x-image-meta-min_ram          256
x-image-meta-min_disk         0
x-image-meta-owner            null
x-image-meta-property-distro  SLES 15</pre></div><div id="id-1.3.10.9.7.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>All timestamps returned are in UTC.</p><p>The <code class="literal">x-image-meta-updated_at</code> timestamp is the timestamp when an
                        image’s metadata was last updated, not its image data, as all
                        image data is immutable once stored in Glance.</p><p>There may be multiple headers that begin with the prefix
                        <code class="literal">x-image-meta-property-</code>. These headers are free-form key and value pairs
                        that have been saved with the image metadata. The key is the string
                        after <code class="literal">x-image-meta-property-</code> and the value is the value of the header.</p><p>The response’s <code class="literal">ETag</code> header will always be equal to the
                        <code class="literal">x-image-meta-checksum</code> value.</p><p>The response’s <code class="literal">x-image-meta-is_public</code> value is a boolean indicating
                        whether the image is publicly available.</p><p>The response’s <code class="literal">x-image-meta-owner</code> value is a string which may either
                        be null or which will indicate the owner of the image.</p></div></div><div class="sect3" id="retrieve-raw-image-data"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Retrieve Raw Image Data</span> <a title="Permalink" class="permalink" href="#retrieve-raw-image-data">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>retrieve-raw-image-data</li></ul></div></div></div></div><p>We want to retrieve that actual raw data for a specific virtual machine image
                    that the Glance server knows about.</p><p>We have queried the Glance server for a list of images and the
                    data returned includes the <code class="literal">uri</code> field for each available image. This
                    <code class="literal">uri</code> field value contains the exact location needed to get the metadata
                    for a specific image.</p><p>Continuing the example from above, in order to get metadata about the
                    first image returned, we can issue a <code class="literal">HEAD</code> request to the Glance
                    server for the image’s URI.</p><p>We issue a <code class="literal">GET</code> request to
                    <code class="literal">http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9</code> to
                    retrieve metadata for that image as well as the image itself encoded
                    into the response body.</p><p>The metadata is returned as a set of HTTP headers that begin with the
                    prefix <code class="literal">x-image-meta-</code>. The following shows an example of the HTTP headers
                    returned from the above <code class="literal">GET</code> request:</p><div class="verbatim-wrap"><pre class="screen">x-image-meta-uri              http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9
x-image-meta-name             SLES 15
x-image-meta-disk_format      vhd
x-image-meta-container_format ovf
x-image-meta-size             5368709120
x-image-meta-checksum         c2e5db72bd7fd153f53ede5da5a06de3
x-image-meta-created_at       2010-02-03 09:34:01
x-image-meta-updated_at       2010-02-03 09:34:01
x-image-meta-deleted_at
x-image-meta-status           available
x-image-meta-is_public        true
x-image-meta-min_ram          256
x-image-meta-min_disk         5
x-image-meta-owner            null
x-image-meta-property-distro  SLES 15</pre></div><div id="id-1.3.10.9.8.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>All timestamps returned are in UTC.</p><p>The <code class="literal">x-image-meta-updated_at</code> timestamp is the timestamp when an
                        image’s metadata was last updated, not its image data, as all
                        image data is immutable once stored in Glance.</p><p>There may be multiple headers that begin with the prefix
                        <code class="literal">x-image-meta-property-</code>. These headers are free-form key and value pairs
                        that have been saved with the image metadata. The key is the string
                        after <code class="literal">x-image-meta-property-</code> and the value is the value of the header.</p><p>The response’s <code class="literal">Content-Length</code> header shall be equal to the value of
                        the <code class="literal">x-image-meta-size</code> header.</p><p>The response’s <code class="literal">ETag</code> header will always be equal to the
                        <code class="literal">x-image-meta-checksum</code> value.</p><p>The response’s <code class="literal">x-image-meta-is_public</code> value is a boolean indicating
                        whether the image is publicly available.</p><p>The response’s <code class="literal">x-image-meta-owner</code> value is a string which may either
                        be null or which will indicate the owner of the image.</p><p>The image data itself will be the body of the HTTP response returned
                        from the request, which will have content-type of
                        <code class="literal">application/octet-stream</code>.</p></div></div><div class="sect3" id="add-a-new-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add a New Image</span> <a title="Permalink" class="permalink" href="#add-a-new-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>add-a-new-image</li></ul></div></div></div></div><p>We have created a new virtual machine image in some way (created a
                    snapshot or backed up an existing image) and we
                    wish to do two things:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Store the disk image data in Glance.</p></li><li class="listitem "><p>Store metadata about this image in Glance.</p></li></ul></div><p>We can do the above two activities in a single call to the Glance API.
                    Assuming, like in the examples above, that a Glance API server is running
                    at <code class="literal">http://glance.openstack.example.org</code>, we issue a <code class="literal">POST</code> request to add an image to
                    Glance:</p><div class="verbatim-wrap"><pre class="screen">POST http://glance.openstack.example.org/v1/images</pre></div><p>The metadata about the image is sent to Glance in HTTP headers. The body
                    of the HTTP request to the Glance API will be the MIME-encoded disk
                    image data.</p></div><div class="sect3" id="reserve-a-new-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Reserve a New Image</span> <a title="Permalink" class="permalink" href="#reserve-a-new-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>reserve-a-new-image</li></ul></div></div></div></div><p>We can also perform the activities described in <a class="xref" href="#add-a-new-image" title="1.9.3.6. Add a New Image">Section 1.9.3.6, “Add a New Image”</a> using two
                    separate calls to the Image API; the first to register the image metadata, and
                    the second to add the image disk data. This is known as reserving an image.</p><p>The first call should be a <code class="literal">POST</code> to <code class="literal">http://glance.openstack.example.org/v1/images</code>,
                    which will result in a new image id being registered with a status of
                    <code class="literal">queued</code>:</p><div class="verbatim-wrap"><pre class="screen">{'image':
 {'status': 'queued',
  'id': '71c675ab-d94f-49cd-a114-e12490b328d9',
  ...}
 ...}</pre></div><p>The image data can then be added using a <code class="literal">PUT</code> to
                    <code class="literal">http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9</code>.
                    The image status will then be set to <code class="literal">active</code> by Glance.</p><p>
              <span class="bold"><strong>Image Metadata in HTTP Headers</strong></span>
            </p><p>Glance will view as image metadata any HTTP header that it receives in a
                    <code class="literal">POST</code> request where the header key is prefixed with the strings
                    <code class="literal">x-image-meta-</code> and <code class="literal">x-image-meta-property-</code>.</p><p>The list of metadata headers that Glance accepts are listed below.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">x-image-meta-name</code>
                </p><p>This header is required, unless reserving an image. Its value should be the
                            name of the image.</p><div id="id-1.3.10.9.10.9.1.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The name of an image <span class="emphasis"><em>is not unique to a Glance node</em></span>. It
                            would be an unrealistic expectation of users to know all the unique
                            names of all other user’s images.</p></div></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-id</code>
                </p><p>This header is optional.</p><p>When present, Glance will use the supplied identifier for the image.
                            If the identifier already exists in that Glance node, then a
                            <span class="bold"><strong>409 Conflict</strong></span> will be returned by Glance. The value of the header
                            must be a uuid in hexadecimal string notation
                            (that is 71c675ab-d94f-49cd-a114-e12490b328d9).</p><p>When this header is <span class="emphasis"><em>not</em></span> present, Glance will generate an identifier
                            for the image and return this identifier in the response (see below).</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-store</code>
                </p><p>This header is optional. Valid values are one of <code class="literal">file</code>, <code class="literal">rbd</code>,
                            <code class="literal">swift</code>, <code class="literal">cinder</code>, <code class="literal">sheepdog</code> or <code class="literal">vsphere</code>.</p><p>When present, Glance will attempt to store the disk image data in the
                            backing store indicated by the value of the header. If the Glance node
                            does not support the backing store, Glance will return a <span class="bold"><strong>400 Bad Request</strong></span>.</p><p>When not present, Glance will store the disk image data in the backing
                            store that is marked as default. See the configuration option <code class="literal">default_store</code>
                            for more information.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-disk_format</code>
                </p><p>This header is required, unless reserving an image. Valid values are one of
                            <code class="literal">aki</code>, <code class="literal">ari</code>, <code class="literal">ami</code>, <code class="literal">raw</code>, <code class="literal">iso</code>, <code class="literal">vhd</code>, <code class="literal">vhdx</code>, <code class="literal">vdi</code>,
                            <code class="literal">qcow2</code>, <code class="literal">vmdk</code> or <code class="literal">ploop</code>.</p><p>For more information, see <a class="xref" href="#formats" title="1.6. Disk and Container Formats">Section 1.6, “Disk and Container Formats”</a>.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-container_format</code>
                </p><p>This header is required, unless reserving an image. Valid values are one of
                            <code class="literal">aki</code>, <code class="literal">ari</code>, <code class="literal">ami</code>, <code class="literal">bare</code>, <code class="literal">ova</code>, <code class="literal">ovf</code>, or <code class="literal">docker</code>.</p><p>For more information, see <a class="xref" href="#formats" title="1.6. Disk and Container Formats">Section 1.6, “Disk and Container Formats”</a>.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-size</code>
                </p><p>This header is optional.</p><p>When present, Glance assumes that the expected size of the request body
                            will be the value of this header. If the length in bytes of the request
                            body <span class="emphasis"><em>does not match</em></span> the value of this header, Glance will return a
                            <span class="bold"><strong>400 Bad Request</strong></span>.</p><p>When not present, Glance will calculate the image’s size based on the size
                            of the request body.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-checksum</code>
                </p><p>This header is optional. When present, it specifies the <span class="bold"><strong>MD5</strong></span> checksum
                            of the image file data.</p><p>When present, Glance will verify the checksum generated from the back-end
                            store while storing your image against this value and return a
                            <span class="bold"><strong>400 Bad Request</strong></span> if the values do not match.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-is_public</code>
                </p><p>This header is optional.</p><p>When Glance finds the string <code class="literal">true</code> (case-insensitive), the image is marked as
                            a public one, meaning that any user may view its metadata and may read
                            the disk image from Glance.</p><p>When not present, the image is assumed to be <span class="emphasis"><em>not public</em></span> and owned by
                            a user.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-min_ram</code>
                </p><p>This header is optional. When present, it specifies the minimum amount of
                            RAM in megabytes required to run this image on a server.</p><p>When not present, the image is assumed to have a minimum RAM requirement of 0.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-min_disk</code>
                </p><p>This header is optional. When present, it specifies the expected minimum disk
                            space in gigabytes required to run this image on a server.</p><p>When not present, the image is assumed to have a minimum disk space
                            requirement of 0.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-owner</code>
                </p><p>This header is optional and only meaningful for admins.</p><p>Glance normally sets the owner of an image to be the tenant or user
                            (depending on the <code class="literal">owner_is_tenant</code> configuration option) of the
                            authenticated user issuing the request. However, if the authenticated user
                            has the Admin role, this default may be overridden by setting this header to
                            null or to a string identifying the owner of the image.</p></li><li class="listitem "><p>
                  <code class="literal">x-image-meta-property-*</code>
                </p><p>When Glance receives any HTTP header whose key begins with the string prefix
                            <code class="literal">x-image-meta-property-</code>, Glance adds the key and value to a set of custom,
                            free-form image properties stored with the image. The key is a
                            lower-cased string following the prefix <code class="literal">x-image-meta-property-</code> with dashes
                            and punctuation replaced with underscores.</p><p>There is no limit on the number of free-form key and value attributes that can
                            be attached to the image. However, keep in mind that the 8K limit on the
                            size of all the HTTP headers sent in a request will effectively limit the
                            number of image properties.</p></li></ul></div></div><div class="sect3" id="update-an-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update an Image</span> <a title="Permalink" class="permalink" href="#update-an-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>update-an-image</li></ul></div></div></div></div><p>Glance will consider any HTTP header that it receives in a <code class="literal">PUT</code> request
                    as an instance of image metadata. In this case, the header key should be
                    prefixed with the strings <code class="literal">x-image-meta-</code> and <code class="literal">x-image-meta-property-</code>.</p><p>If an image was previously reserved, and thus is in the <code class="literal">queued</code> state, then
                    image data can be added by including it as the request body. If the image
                    already has data associated with it (for example, it is not in the <code class="literal">queued</code>
                    state), then including a request body will result in a <span class="bold"><strong>409 Conflict</strong></span>
                    exception.</p><p>On success, the <code class="literal">PUT</code> request will return the image metadata encoded as HTTP
                    headers.</p><p>See more about image statuses here <a class="xref" href="#image-statuses" title="1.2. Image Statuses">Section 1.2, “Image Statuses”</a>.</p></div><div class="sect3" id="list-image-memberships"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Image Memberships</span> <a title="Permalink" class="permalink" href="#list-image-memberships">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-image-memberships</li></ul></div></div></div></div><p>We want to see a list of the other system tenants (or users, if
                    <code class="literal">owner_is_tenant</code> is <code class="literal">False</code>) that may access a given virtual machine image that
                    the Glance server knows about. We take the <code class="literal">uri</code> field of the image data,
                    append <code class="literal">/members</code> to it, and issue a <code class="literal">GET</code> request on the resulting URL.</p><p>Continuing from the example above, in order to get the memberships for the
                    first image returned, we can issue a <code class="literal">GET</code> request to the Glance
                    server for
                    <code class="literal">http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9/members</code>.
                    And we will get back JSON data such as the following:</p><div class="verbatim-wrap"><pre class="screen">{'members': [
 {'member_id': 'tenant1',
  'can_share': false}
 ...]}</pre></div><p>The <code class="literal">member_id</code> field identifies a tenant with which the image is shared. If
                    that tenant is authorized to further share the image, the <code class="literal">can_share</code> field is
                    <code class="literal">true</code>.</p></div><div class="sect3" id="list-shared-images"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Shared Images</span> <a title="Permalink" class="permalink" href="#list-shared-images">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-shared-images</li></ul></div></div></div></div><p>We want to see a list of images which are shared with a given tenant. We issue
                    a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v1/shared-images/tenant1</code>. We
                    will get back JSON data such as the following:</p><div class="verbatim-wrap"><pre class="screen">{'shared_images': [
 {'image_id': '71c675ab-d94f-49cd-a114-e12490b328d9',
  'can_share': false}
 ...]}</pre></div><p>The <code class="literal">image_id</code> field identifies an image shared with the tenant named by
                    <span class="emphasis"><em>member_id</em></span>. If the tenant is authorized to further share the image, the
                    <code class="literal">can_share</code> field is <code class="literal">true</code>.</p></div><div class="sect3" id="add-a-member-to-an-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add a Member to an Image</span> <a title="Permalink" class="permalink" href="#add-a-member-to-an-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>add-a-member-to-an-image</li></ul></div></div></div></div><p>We want to authorize a tenant to access a private image. We issue a <code class="literal">PUT</code>
                    request to
                    <code class="literal">http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9/members/tenant1</code>.
                    With no body, this will add the membership to the image, leaving existing
                    memberships unmodified and defaulting new memberships to have <code class="literal">can_share</code>
                    set to <code class="literal">false</code>. We may also optionally attach a body of the following form:</p><div class="verbatim-wrap"><pre class="screen">{'member':
 {'can_share': true}
}</pre></div><p>If such a body is provided, both existing and new memberships will have
                    <code class="literal">can_share</code> set to the provided value (either <code class="literal">true</code> or <code class="literal">false</code>). This query
                    will return a 204 (<code class="literal">No Content</code>) status code.</p></div><div class="sect3" id="remove-a-member-from-an-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Remove a Member from an Image</span> <a title="Permalink" class="permalink" href="#remove-a-member-from-an-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>remove-a-member-from-an-image</li></ul></div></div></div></div><p>We want to revoke a tenant’s right to access a private image. We issue a
                    <code class="literal">DELETE</code> request to <code class="literal">http://glance.openstack.example.org/v1/images/1/members/tenant1</code>.
                    This query will return a 204 (<code class="literal">No Content</code>) status code.</p></div><div class="sect3" id="replace-a-membership-list-for-an-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.3.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Replace a Membership List for an Image</span> <a title="Permalink" class="permalink" href="#replace-a-membership-list-for-an-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>replace-a-membership-list-for-an-image</li></ul></div></div></div></div><p>The full membership list for a given image may be replaced. We issue a <code class="literal">PUT</code>
                    request to
                    <code class="literal">http://glance.openstack.example.org/v1/images/71c675ab-d94f-49cd-a114-e12490b328d9/members</code>
                    with a body of the following form:</p><div class="verbatim-wrap"><pre class="screen">{'memberships': [
 {'member_id': 'tenant1',
  'can_share': false}
 ...]}</pre></div><p>All existing memberships which are not named in the replacement body are
                    removed, and those which are named have their <code class="literal">can_share</code> settings changed as
                    specified. (The <code class="literal">can_share</code> setting may be omitted, which will cause that
                    setting to remain unchanged in the existing memberships.) All new memberships
                    will be created, with <code class="literal">can_share</code> defaulting to <code class="literal">false</code> unless it is specified
                    otherwise.</p></div></div><div class="sect2" id="image-membership-changes-in-version-2-0"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Membership Changes in Version 2.0</span> <a title="Permalink" class="permalink" href="#image-membership-changes-in-version-2-0">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>image-membership-changes-in-version-2-0</li></ul></div></div></div></div><p>Version 2.0 of the Images API eliminates the <code class="literal">can_share</code> attribute of image
                membership. In the version 2.0 model, image sharing is not transitive.</p><p>In version 2.0, image members have a <code class="literal">status</code> attribute that reflects
                how the image should be treated with respect to that image member’s image-list.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <code class="literal">status</code> attribute may have one of three values: <code class="literal">pending</code>,
                        <code class="literal">accepted</code>, or <code class="literal">rejected</code>.</p></li><li class="listitem "><p>By default, only those shared images with status <code class="literal">accepted</code> are included in
                        an image member’s image-list.</p></li><li class="listitem "><p>Only an image member may change their membership status.</p></li><li class="listitem "><p>Only an image owner may create members on an image. The status of a newly
                        created image member is <code class="literal">pending</code>. The image owner cannot change the
                        status of a member.</p></li></ul></div><div class="sect3" id="distinctions-from-version-1-x-api-calls"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Distinctions from Version 1.x API Calls</span> <a title="Permalink" class="permalink" href="#distinctions-from-version-1-x-api-calls">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>distinctions-from-version-1-x-api-calls</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The response to a request to list the members of an image has changed.</p><p>call: <code class="literal">GET</code> on <code class="literal">/v2/images/{imageId}/members</code></p><p>response: see the JSON schema at <code class="literal">/v2/schemas/members</code></p></li><li class="listitem "><p>The request body in the call to create an image member has changed.</p><p>call: <code class="literal">POST</code> to <code class="literal">/v2/images/{imageId}/members</code></p><p>request body:</p><div class="verbatim-wrap"><pre class="screen">{ "member": "&lt;MEMBER_ID&gt;" }</pre></div><p>Where the <code class="literal">{memberId}</code> is the tenant ID of the image member.</p><p>The member status of a newly created image member is <code class="literal">pending</code>.</p></li></ul></div></div><div class="sect3" id="new-api-calls"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">New API Calls</span> <a title="Permalink" class="permalink" href="#new-api-calls">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>new-api-calls</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Change the status of an image member</p><p>call: <code class="literal">PUT</code> on <code class="literal">/v2/images/{imageId}/members/{memberId}</code>.</p><p>Request body:</p><div class="verbatim-wrap"><pre class="screen">{ "status": "&lt;STATUS_VALUE&gt;" }</pre></div><p>Where &lt;STATUS_VALUE&gt; is <code class="literal">pending</code>, <code class="literal">accepted</code>, or <code class="literal">rejected</code>.
                            The <code class="literal">{memberId}</code> is the tenant ID of the image member.</p></li></ul></div></div></div><div class="sect2" id="images-v2-tasks-api"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.9.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Images v2 Tasks API</span> <a title="Permalink" class="permalink" href="#images-v2-tasks-api">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>images-v2-tasks-api</li></ul></div></div></div></div><p>Version 2 of the OpenStack Images API introduces a Task resource that is used
                to create and monitor long-running asynchronous image-related processes. See
                the <a class="link" href="https://docs.openstack.org/glance/pike/admin/tasks.html#tasks" target="_blank">Tasks</a>
                section of the Glance documentation for more information.</p><p>The following Task calls are available:</p><div class="sect3" id="create-a-task"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a Task</span> <a title="Permalink" class="permalink" href="#create-a-task">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>create-a-task</li></ul></div></div></div></div><p>A user wants to initiate a Task. The user issues a <code class="literal">POST</code> request to
                    <code class="literal">/v2/tasks</code>. The request body is of Content-type <code class="literal">application/json</code> and
                    must contain the following fields:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">type</code>: A string specified by the enumeration defined in the Task schema.</p></li><li class="listitem "><p><code class="literal">input</code>: A JSON object. The content is defined by the cloud provider who
                            has exposed the endpoint being contacted.</p></li></ul></div><p>The response is a Task entity as defined by the Task schema. It includes an
                    <code class="literal">id</code> field that can be used in a subsequent call to poll the Task for status
                    changes.</p><p>A Task is created in <code class="literal">pending</code> status.</p></div><div class="sect3" id="show-a-task"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Show a Task</span> <a title="Permalink" class="permalink" href="#show-a-task">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>show-a-task</li></ul></div></div></div></div><p>A user wants to see detailed information about a Task the user owns. The user
                    issues a <code class="literal">GET</code> request to <code class="literal">/v2/tasks/{taskId}</code>.</p><p>The response is in <code class="literal">application/json</code> format. The exact structure is given
                    by the Task schema located at <code class="literal">/v2/schemas/task</code>.</p></div><div class="sect3" id="list-tasks"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Tasks</span> <a title="Permalink" class="permalink" href="#list-tasks">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-tasks</li></ul></div></div></div></div><p>A user wants to see what Tasks have been created in their project. The
                    user issues a <code class="literal">GET</code> request to <code class="literal">/v2/tasks</code>.</p><p>The response is in <code class="literal">application/json</code> format. The exact structure is given
                    by the task schema located at <code class="literal">/v2/schemas/tasks</code>.</p><div id="id-1.3.10.11.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>As indicated by the schema, the list of Tasks is provided in a
                    sparse format. To see more information about a particular Task in the list,
                    the user would use the show Task call described above.</p></div></div><div class="sect3" id="filtering-and-sorting-the-tasks-list"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Filtering and Sorting the Tasks List</span> <a title="Permalink" class="permalink" href="#filtering-and-sorting-the-tasks-list">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>filtering-and-sorting-the-tasks-list</li></ul></div></div></div></div><p>The <code class="literal">GET /v2/tasks</code> request takes query parameters that server to filter the
                    returned list of Tasks. The following list details these query parameters.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">status={status}</code>
                </p><p>Filters the list to display only those tasks in the specified status. See
                      the Task schema or the <a class="xref" href="#task-statuses" title="1.3. Task Statuses">Section 1.3, “Task Statuses”</a> section of this
                      documentation for the legal values to use for <code class="literal">{status}</code>.</p><p>For example, a request to <code class="literal">GET /v2/tasks?status=pending</code> would return only
                            those Tasks whose current status is <code class="literal">pending</code>.</p></li><li class="listitem "><p>
                  <code class="literal">type={type}</code>
                </p><p>Filters the list to display only those Tasks of the specified type. See the
                            enumeration defined in the Task schema for the legal values to use for
                            <code class="literal">{type}</code>.</p><p>For example, a request to <code class="literal">GET /v2/tasks?type=import</code> would return only
                            import Tasks.</p></li><li class="listitem "><p>
                  <code class="literal">sort_dir={direction}</code>
                </p><p>Sorts the list of tasks according to <code class="literal">updated_at</code> datetime. Legal values
                            are <code class="literal">asc</code> (ascending) and <code class="literal">desc</code> (descending). By default, the Task list
                            is sorted by <code class="literal">created_at</code> time in descending chronological order.</p></li></ul></div></div></div><div class="sect2" id="id-1.3.10.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.9.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">API Message Localization</span> <a title="Permalink" class="permalink" href="#id-1.3.10.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Glance supports HTTP message localization. For example, an HTTP client can
                receive API messages in Chinese even if the locale language of the server is
                English.</p><div class="sect3" id="id-1.3.10.12.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.9.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How to use it</span> <a title="Permalink" class="permalink" href="#id-1.3.10.12.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To receive localized API messages, the HTTP client needs to specify the
                    <span class="bold"><strong>Accept-Language</strong></span> header to indicate the language that will translate the
                    message. For more information about Accept-Language, refer to <a class="link" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html" target="_blank">http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html</a></p><p>A typical curl API request will be like below:</p><div class="verbatim-wrap"><pre class="screen">curl -i -X GET -H 'Accept-Language: zh' -H 'Content-Type: application/json'
http://glance.openstack.example.org/v2/images/aaa</pre></div><p>Then the response will be like the following:</p><div class="verbatim-wrap"><pre class="screen">HTTP/1.1 404 Not Found
Content-Length: 234
Content-Type: text/html; charset=UTF-8
X-Openstack-Request-Id: req-54d403a0-064e-4544-8faf-4aeef086f45a
Date: Sat, 22 Feb 2014 06:26:26 GMT

&lt;html&gt;
&lt;head&gt;
&lt;title&gt;404 Not Found&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;404 Not Found&lt;/h1&gt;
&amp;#25214;&amp;#19981;&amp;#21040;&amp;#20219;&amp;#20309;&amp;#20855;&amp;#26377;&amp;#26631;&amp;#35782; aaa &amp;#30340;&amp;#26144;&amp;#20687;&lt;br /&gt;&lt;br /&gt;
&lt;/body&gt;
&lt;/html&gt;</pre></div><div id="id-1.3.10.12.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Make sure to have a language package under <code class="literal">/usr/share/locale-langpack/</code> on
                        the target Glance server.</p></div></div></div></div><div class="sect1" id="using-glance-s-client-tools"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Glance’s Client Tools</span> <a title="Permalink" class="permalink" href="#using-glance-s-client-tools">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>using-glance-s-client-tools</li></ul></div></div></div></div><p>The command-line tool and python library for Glance are both installed
            through the python-glanceclient project. Explore the following resources
            for more information:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
              <a class="link" href="http://docs.openstack.org/developer/python-glanceclient/" target="_blank">Official Docs</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://pypi.python.org/pypi/python-glanceclient" target="_blank">Pypi Page</a>
            </p></li><li class="listitem "><p>
              <a class="link" href="http://github.com/openstack/python-glanceclient" target="_blank">GitHub Project</a>
            </p></li></ul></div></div><div class="sect1" id="using-glance-s-metadata-definitions-catalog-public-apis"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Glance’s Metadata Definitions Catalog Public APIs</span> <a title="Permalink" class="permalink" href="#using-glance-s-metadata-definitions-catalog-public-apis">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>using-glance-s-metadata-definitions-catalog-public-apis</li></ul></div></div></div></div><p>A common API hosted by the Glance service for vendors, admins, services, and
            users to meaningfully define available key and value pair and tag metadata.
            The intent is to enable better metadata collaboration across artifacts,
            services, and projects for OpenStack users.</p><p>This is about the definition of the available metadata that can be used on
            different types of resources (images, artifacts, volumes, flavors, aggregates,
            etc). A definition includes the properties type, its key, its description,
            and its constraints. This catalog will not store the values for specific
            instance properties.</p><p>For example, a definition of a virtual CPU topology property for number of
            cores will include the key to use, a description, and value constraints like
            requiring it to be an integer. So, a user, potentially through Horizon, would
            be able to search this catalog to list the available properties they can add to
            a flavor or image. They will see the virtual CPU topology property in the list
            and know that it must be an integer. In the Horizon example, when the user adds
            the property, its key and value will be stored in the service that owns that
            resource (Nova for flavors and in Glance for images).</p><p>Diagram: <a class="link" href="https://wiki.openstack.org/w/images/b/bb/Glance-Metadata-API.png" target="_blank">https://wiki.openstack.org/w/images/b/bb/Glance-Metadata-API.png</a></p><p>Glance Metadata Definitions Catalog implementation started with API version v2.</p><div class="sect2" id="id-1.3.12.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Authentication</span> <a title="Permalink" class="permalink" href="#id-1.3.12.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Glance depends on Keystone and the OpenStack Identity API to handle
                authentication of clients. You must obtain an authentication token from
                Keystone send it along with all API requests to Glance through the
                <code class="literal">X-Auth-Token</code> header. Glance will communicate back to Keystone to verify
                the token validity and obtain your identity credentials.</p><p>See <a class="link" href="https://docs.openstack.org/glance/pike/admin/authentication.html#authentication" target="_blank">Authentication With Keystone</a>
                for more information on integrating with Keystone.</p></div><div class="sect2" id="using-v2-x"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using v2.X</span> <a title="Permalink" class="permalink" href="#using-v2-x">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>using-v2-x</li></ul></div></div></div></div><p>For the purpose of examples, assume there is a Glance API server running
                at the URL <code class="literal">http://glance.openstack.example.org</code> on the default port 80.</p><div class="sect3" id="list-available-namespaces"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Available Namespaces</span> <a title="Permalink" class="permalink" href="#list-available-namespaces">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-available-namespaces</li></ul></div></div></div></div><p>We want to see a list of available namespaces that the authenticated user
                    has access to. This includes namespaces owned by the user,
                    namespaces shared with the user and public namespaces.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v2/metadefs/namespaces</code>
                    to retrieve this list of available namespaces.
                    The data is returned as a JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "namespaces": [
      {
          "namespace": "MyNamespace",
          "display_name": "My User Friendly Namespace",
          "description": "My description",
          "visibility": "public",
          "protected": true,
          "owner": "The Test Owner",
          "self": "/v2/metadefs/namespaces/MyNamespace",
          "schema": "/v2/schemas/metadefs/namespace",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z",
          "resource_type_associations": [
              {
                  "name": "OS::Nova::Aggregate",
                  "created_at": "2014-08-28T17:13:06Z",
                  "updated_at": "2014-08-28T17:13:06Z"
              },
              {
                  "name": "OS::Nova::Flavor",
                  "prefix": "aggregate_instance_extra_specs:",
                  "created_at": "2014-08-28T17:13:06Z",
                  "updated_at": "2014-08-28T17:13:06Z"
              }
          ]
      }
  ],
  "first": "/v2/metadefs/namespaces?sort_key=created_at&amp;sort_dir=asc",
  "schema": "/v2/schemas/metadefs/namespaces"
}</pre></div><div id="id-1.3.12.8.3.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Listing namespaces will only show the summary of each namespace including
                        counts and resource type associations. Detailed responses including all its
                        objects definitions, property definitions will only be available on
                        each individual GET namespace request.</p></div></div><div class="sect3" id="filtering-namespaces-lists"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Filtering Namespaces Lists</span> <a title="Permalink" class="permalink" href="#filtering-namespaces-lists">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>filtering-namespaces-lists</li></ul></div></div></div></div><p><code class="literal">GET /v2/metadefs/namespaces</code> requests take query parameters that serve to
                    filter the returned list of namespaces. The following
                    list details these query parameters.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">resource_types=RESOURCE_TYPES</code>
                </p><p>Filters namespaces having a <code class="literal">resource_types</code> within the list of
                            comma separated <code class="literal">RESOURCE_TYPES</code>.</p></li></ul></div><p>GET resource also accepts additional query parameters:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">sort_key=KEY</code>
                </p><p>Results will be ordered by the specified sort attribute <code class="literal">KEY</code>. Accepted
                            values include <code class="literal">namespace</code>, <code class="literal">created_at</code> (default) and <code class="literal">updated_at</code>.</p></li><li class="listitem "><p>
                  <code class="literal">sort_dir=DIR</code>
                </p><p>Results will be sorted in the direction <code class="literal">DIR</code>. Accepted values are <code class="literal">asc</code>
                            for ascending or <code class="literal">desc</code> (default) for descending.</p></li><li class="listitem "><p>
                  <code class="literal">marker=NAMESPACE</code>
                </p><p>A namespace identifier marker may be specified. When present only
                            namespaces which occur after the identifier <code class="literal">NAMESPACE</code> will be listed,
                            for example the namespaces which have a <code class="literal">sort_key</code> later than that of the marker
                            <code class="literal">NAMESPACE</code> in the <code class="literal">sort_dir</code> direction.</p></li><li class="listitem "><p>
                  <code class="literal">limit=LIMIT</code>
                </p><p>When present the maximum number of results returned will not exceed <code class="literal">LIMIT</code>.</p></li></ul></div><div id="id-1.3.12.8.4.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If the specified <code class="literal">LIMIT</code> exceeds the operator defined limit (<code class="literal">api_limit_max</code>)
                        then the number of results returned may be less than <code class="literal">LIMIT</code>.</p></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                  <code class="literal">visibility=PUBLIC</code>
                </p><p>An admin user may use the <code class="literal">visibility</code> parameter to control which results are
                            returned (<code class="literal">PRIVATE</code> or <code class="literal">PUBLIC</code>).</p></li></ul></div></div><div class="sect3" id="retrieve-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Retrieve Namespace</span> <a title="Permalink" class="permalink" href="#retrieve-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>retrieve-namespace</li></ul></div></div></div></div><p>We want to see a more detailed information about a namespace that the
                    authenticated user has access to. The detail includes the properties, objects,
                    and resource type associations.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}</code>
                    to retrieve the namespace details.
                    The data is returned as a JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "namespace": "MyNamespace",
  "display_name": "My User Friendly Namespace",
  "description": "My description",
  "visibility": "public",
  "protected": true,
  "owner": "The Test Owner",
  "schema": "/v2/schemas/metadefs/namespace",
  "resource_type_associations": [
      {
          "name": "OS::Glance::Image",
          "prefix": "hw_",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z"
      },
      {
          "name": "OS::Cinder::Volume",
          "prefix": "hw_",
          "properties_target": "image",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z"
      },
      {
          "name": "OS::Nova::Flavor",
          "prefix": "filter1:",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z"
      }
  ],
  "properties": {
      "nsprop1": {
          "title": "My namespace property1",
          "description": "More info here",
          "type": "boolean",
          "default": true
      },
      "nsprop2": {
          "title": "My namespace property2",
          "description": "More info here",
          "type": "string",
          "default": "value1"
      }
  },
  "objects": [
      {
          "name": "object1",
          "description": "my-description",
          "self": "/v2/metadefs/namespaces/MyNamespace/objects/object1",
          "schema": "/v2/schemas/metadefs/object",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z",
          "required": [],
          "properties": {
              "prop1": {
                  "title": "My object1 property1",
                  "description": "More info here",
                  "type": "array",
                  "items": {
                      "type": "string"
                  }
              }
          }
      },
      {
          "name": "object2",
          "description": "my-description",
          "self": "/v2/metadefs/namespaces/MyNamespace/objects/object2",
          "schema": "/v2/schemas/metadefs/object",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z",
          "properties": {
              "prop1": {
                  "title": "My object2 property1",
                  "description": "More info here",
                  "type": "integer",
                  "default": 20
              }
          }
      }
  ]
}</pre></div></div><div class="sect3" id="retrieve-available-resource-types"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Retrieve available Resource Types</span> <a title="Permalink" class="permalink" href="#retrieve-available-resource-types">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>retrieve-available-resource-types</li></ul></div></div></div></div><p>We want to see the list of all resource types that are available in Glance.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v2/metadefs/resource_types</code>
                    to retrieve all resource types.</p><p>The data is returned as a JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "resource_types": [
      {
          "created_at": "2014-08-28T17:13:04Z",
          "name": "OS::Glance::Image",
          "updated_at": "2014-08-28T17:13:04Z"
      },
      {
          "created_at": "2014-08-28T17:13:04Z",
          "name": "OS::Cinder::Volume",
          "updated_at": "2014-08-28T17:13:04Z"
      },
      {
          "created_at": "2014-08-28T17:13:04Z",
          "name": "OS::Nova::Flavor",
          "updated_at": "2014-08-28T17:13:04Z"
      },
      {
          "created_at": "2014-08-28T17:13:04Z",
          "name": "OS::Nova::Aggregate",
          "updated_at": "2014-08-28T17:13:04Z"
      },
      {
          "created_at": "2014-08-28T17:13:04Z",
          "name": "OS::Nova::Server",
          "updated_at": "2014-08-28T17:13:04Z"
      }
  ]
}</pre></div></div><div class="sect3" id="retrieve-resource-types-associated-with-a-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Retrieve Resource Types associated with a Namespace</span> <a title="Permalink" class="permalink" href="#retrieve-resource-types-associated-with-a-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>retrieve-resource-types-associated-with-a-namespace</li></ul></div></div></div></div><p>We want to see the list of resource types that are associated for a specific
                    namespace.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/resource_types</code>
                    to retrieve resource types.</p><p>The data is returned as a JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "resource_type_associations" : [
      {
         "name" : "OS::Glance::Image",
         "prefix" : "hw_",
         "created_at": "2014-08-28T17:13:04Z",
         "updated_at": "2014-08-28T17:13:04Z"
      },
      {
         "name" :"OS::Cinder::Volume",
         "prefix" : "hw_",
         "properties_target" : "image",
         "created_at": "2014-08-28T17:13:04Z",
         "updated_at": "2014-08-28T17:13:04Z"
      },
      {
         "name" : "OS::Nova::Flavor",
         "prefix" : "hw:",
         "created_at": "2014-08-28T17:13:04Z",
         "updated_at": "2014-08-28T17:13:04Z"
      }
  ]
}</pre></div></div><div class="sect3" id="add-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add Namespace</span> <a title="Permalink" class="permalink" href="#add-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>add-namespace</li></ul></div></div></div></div><p>We want to create a new namespace that can contain the properties, objects,
                    etc.</p><p>We issue a <code class="literal">POST</code> request to add an namespace to Glance:</p><div class="verbatim-wrap"><pre class="screen">POST http://glance.openstack.example.org/v2/metadefs/namespaces/</pre></div><p>The input data is an JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "namespace": "MyNamespace",
  "display_name": "My User Friendly Namespace",
  "description": "My description",
  "visibility": "public",
  "protected": true
}</pre></div><div id="id-1.3.12.8.8.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Optionally properties, objects and resource type associations could be
                        added in the same input. See GET Namespace output above (input will be
                        similar).</p></div></div><div class="sect3" id="update-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update Namespace</span> <a title="Permalink" class="permalink" href="#update-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>update-namespace</li></ul></div></div></div></div><p>We want to update an existing namespace.</p><p>We issue a <code class="literal">PUT</code> request to update an namespace to Glance:</p><div class="verbatim-wrap"><pre class="screen">PUT http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}</pre></div><p>The input data is similar to Add Namespace.</p></div><div class="sect3" id="delete-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete Namespace</span> <a title="Permalink" class="permalink" href="#delete-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>delete-namespace</li></ul></div></div></div></div><p>We want to delete an existing namespace including all its objects,
                    properties etc.</p><p>We issue a <code class="literal">DELETE</code> request to delete an namespace to Glance:</p><div class="verbatim-wrap"><pre class="screen">DELETE http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}</pre></div></div><div class="sect3" id="associate-resource-type-with-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Associate Resource Type with Namespace</span> <a title="Permalink" class="permalink" href="#associate-resource-type-with-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>associate-resource-type-with-namespace</li></ul></div></div></div></div><p>We want to associate a resource type with an existing namespace.</p><p>We issue a <code class="literal">POST</code> request to associate resource type to Glance:</p><div class="verbatim-wrap"><pre class="screen">POST http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/resource_types</pre></div><p>The input data is an JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
        "name" :"OS::Cinder::Volume",
        "prefix" : "hw_",
        "properties_target" : "image",
        "created_at": "2014-08-28T17:13:04Z",
        "updated_at": "2014-08-28T17:13:04Z"
}</pre></div></div><div class="sect3" id="remove-resource-type-associated-with-a-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Remove Resource Type associated with a Namespace</span> <a title="Permalink" class="permalink" href="#remove-resource-type-associated-with-a-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>remove-resource-type-associated-with-a-namespace</li></ul></div></div></div></div><p>We want to de-associate namespace from a resource type.</p><p>We issue a <code class="literal">DELETE</code> request to de-associate namespace resource type to
                    Glance:</p><div class="verbatim-wrap"><pre class="screen">DELETE http://glance.openstack.example.org/v2//metadefs/namespaces/{namespace}/resource_types/{resource_type}</pre></div></div><div class="sect3" id="list-objects-in-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List Objects in Namespace</span> <a title="Permalink" class="permalink" href="#list-objects-in-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>list-objects-in-namespace</li></ul></div></div></div></div><p>We want to see the list of meta definition objects in a specific namespace.</p><p>We issue a <code class="literal">GET</code> request to <code class="literal">http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/objects</code>
                    to retrieve objects.</p><p>The data is returned as a JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
      "objects": [
      {
          "name": "object1",
          "description": "my-description",
          "self": "/v2/metadefs/namespaces/MyNamespace/objects/object1",
          "schema": "/v2/schemas/metadefs/object",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z",
          "required": [],
          "properties": {
              "prop1": {
                  "title": "My object1 property1",
                  "description": "More info here",
                  "type": "array",
                  "items": {
                      "type": "string"
                  }
              }
          }
      },
      {
          "name": "object2",
          "description": "my-description",
          "self": "/v2/metadefs/namespaces/MyNamespace/objects/object2",
          "schema": "/v2/schemas/metadefs/object",
          "created_at": "2014-08-28T17:13:06Z",
          "updated_at": "2014-08-28T17:13:06Z",
          "properties": {
              "prop1": {
                  "title": "My object2 property1",
                  "description": "More info here",
                  "type": "integer",
                  "default": 20
              }
          }
      }
  ],
  "schema": "/v2/schemas/metadefs/objects"
}</pre></div></div><div class="sect3" id="add-object-in-a-specific-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add object in a specific namespace</span> <a title="Permalink" class="permalink" href="#add-object-in-a-specific-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>add-object-in-a-specific-namespace</li></ul></div></div></div></div><p>We want to create a new object which can group the properties.</p><p>We issue a <code class="literal">POST</code> request to add object to a namespace in Glance:</p><div class="verbatim-wrap"><pre class="screen">POST http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/objects</pre></div><p>The input data is an JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "name": "StorageQOS",
  "description": "Our available storage QOS.",
  "required": [
      "minIOPS"
  ],
  "properties": {
      "minIOPS": {
          "type": "integer",
          "description": "The minimum IOPs required",
          "default": 100,
          "minimum": 100,
          "maximum": 30000369
      },
      "burstIOPS": {
          "type": "integer",
          "description": "The expected burst IOPs",
          "default": 1000,
          "minimum": 100,
          "maximum": 30000377
      }
  }
}</pre></div></div><div class="sect3" id="update-object-in-a-specific-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update Object in a specific namespace</span> <a title="Permalink" class="permalink" href="#update-object-in-a-specific-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>update-object-in-a-specific-namespace</li></ul></div></div></div></div><p>We want to update an existing object.</p><p>We issue a <code class="literal">PUT</code> request to update an object to Glance:</p><div class="verbatim-wrap"><pre class="screen">PUT http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/objects/{object_name}</pre></div><p>The input data is similar to Add Object.</p></div><div class="sect3" id="delete-object-in-a-specific-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete Object in a specific namespace</span> <a title="Permalink" class="permalink" href="#delete-object-in-a-specific-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>delete-object-in-a-specific-namespace</li></ul></div></div></div></div><p>We want to delete an existing object.</p><p>We issue a <code class="literal">DELETE</code> request to delete object in a namespace to Glance:</p><div class="verbatim-wrap"><pre class="screen">DELETE http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/objects/{object_name}</pre></div></div><div class="sect3" id="add-property-definition-in-a-specific-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add property definition in a specific namespace</span> <a title="Permalink" class="permalink" href="#add-property-definition-in-a-specific-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>add-property-definition-in-a-specific-namespace</li></ul></div></div></div></div><p>We want to create a new property definition in a namespace.</p><p>We issue a <code class="literal">POST</code> request to add property definition to a namespace in
                    Glance:</p><div class="verbatim-wrap"><pre class="screen">POST http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/properties</pre></div><p>The input data is an JSON-encoded mapping in the following format:</p><div class="verbatim-wrap"><pre class="screen">{
  "name": "hypervisor_type",
  "title" : "Hypervisor",
  "type": "array",
  "description": "The type of hypervisor required",
  "items": {
      "type": "string",
      "enum": [
          "hyperv",
          "qemu",
          "kvm"
      ]
  }
}</pre></div></div><div class="sect3" id="update-property-definition-in-a-specific-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update property definition in a specific namespace</span> <a title="Permalink" class="permalink" href="#update-property-definition-in-a-specific-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>update-property-definition-in-a-specific-namespace</li></ul></div></div></div></div><p>We want to update an existing object.</p><p>We issue a <code class="literal">PUT</code> request to update an property definition in a namespace to
                    Glance:</p><div class="verbatim-wrap"><pre class="screen">PUT http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/properties/{property_name}</pre></div><p>The input data is similar to Add property definition.</p></div><div class="sect3" id="delete-property-definition-in-a-specific-namespace"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.2.17 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete property definition in a specific namespace</span> <a title="Permalink" class="permalink" href="#delete-property-definition-in-a-specific-namespace">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>delete-property-definition-in-a-specific-namespace</li></ul></div></div></div></div><p>We want to delete an existing object.</p><p>We issue a <code class="literal">DELETE</code> request to delete property definition in a namespace to
                    Glance:</p><div class="verbatim-wrap"><pre class="screen">DELETE http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}/properties/{property_name}</pre></div></div></div><div class="sect2" id="id-1.3.12.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">API Message Localization</span> <a title="Permalink" class="permalink" href="#id-1.3.12.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Glance supports HTTP message localization. For example, an HTTP client can
                receive API messages in Chinese even if the locale language of the server is
                English.</p><div class="sect3" id="id-1.3.12.9.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.11.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How to use it</span> <a title="Permalink" class="permalink" href="#id-1.3.12.9.3">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To receive localized API messages, the HTTP client needs to specify the
                    <span class="bold"><strong>Accept-Language</strong></span> header to indicate the language to use to translate the
                    message. For more info about Accept-Language, refer <a class="link" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html" target="_blank">http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html</a></p><p>A typical curl API request will be like below:</p><div class="verbatim-wrap"><pre class="screen">curl -i -X GET -H 'Accept-Language: zh' -H 'Content-Type: application/json'
http://glance.openstack.example.org/v2/metadefs/namespaces/{namespace}</pre></div><p>Then the response will be like the following:</p><div class="verbatim-wrap"><pre class="screen">HTTP/1.1 404 Not Found
Content-Length: 234
Content-Type: text/html; charset=UTF-8
X-Openstack-Request-Id: req-54d403a0-064e-4544-8faf-4aeef086f45a
Date: Sat, 22 Feb 2014 06:26:26 GMT

&lt;html&gt;
&lt;head&gt;
&lt;title&gt;404 Not Found&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;404 Not Found&lt;/h1&gt;
&amp;#25214;&amp;#19981;&amp;#21040;&amp;#20219;&amp;#20309;&amp;#20855;&amp;#26377;&amp;#26631;&amp;#35782; aaa &amp;#30340;&amp;#26144;&amp;#20687;&lt;br /&gt;&lt;br /&gt;
&lt;/body&gt;
&lt;/html&gt;</pre></div><div id="id-1.3.12.9.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Ensure there is the language package under <code class="literal">/usr/share/locale-langpack/</code> on
                        the target Glance server.</p></div></div></div></div><div class="sect1" id="image-signature-verification"><div class="titlepage"><div><div><h2 class="title"><span class="number">1.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Signature Verification</span> <a title="Permalink" class="permalink" href="#image-signature-verification">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>image-signature-verification</li></ul></div></div></div></div><p>Glance has the ability to perform image validation using a digital
            signature and asymmetric cryptography. To trigger this, you must define
            specific image properties (described below), and have stored a
            certificate signed with your private key in a local Barbican installation.</p><p>When the image properties exist on an image, Glance will validate
            the uploaded image data against these properties before storing it.
            If validation is unsuccessful, the upload will fail and the image will
            be deleted.</p><p>Additionally, the image properties may be used by other services (for
            example, Nova) to perform data verification when the image is downloaded
            from Glance.</p><div class="sect2" id="id-1.3.13.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Requirements</span> <a title="Permalink" class="permalink" href="#id-1.3.13.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Barbican key manager - See <a class="link" href="http://docs.openstack.org/developer/barbican/setup/devstack.html" target="_blank">http://docs.openstack.org/developer/barbican/setup/devstack.html</a>.</p></div><div class="sect2" id="id-1.3.13.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration</span> <a title="Permalink" class="permalink" href="#id-1.3.13.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The <code class="literal">etc/glance-api.conf</code> can be modified to change keystone endpoint of
                barbican. By default barbican will try to connect to keystone at
                <a class="link" href="http://localhost:5000/v3" target="_blank">http://localhost:5000/v3</a> but if keystone is on another host then this
                should be changed.</p><p>In <code class="literal">glance-api.conf</code> find the following lines:</p><div class="verbatim-wrap"><pre class="screen">[barbican]
auth_endpoint = http://localhost:5000/v3</pre></div><p>Then replace <a class="link" href="http://localhost:5000/v3" target="_blank">http://localhost:5000/v3</a> with the URL of keystone, also adding <code class="literal">/v3</code>
                to the end of it. For example, ‘<a class="link" href="https://192.168.245.9:5000/v3" target="_blank">https://192.168.245.9:5000/v3</a>’.</p><p>Another option in <code class="literal">etc/glance-api.conf</code> which can be configured is which key manager
                to use. By default Glance will use the default key manager defined by the Castellan
                key manager interface, which is currently the Barbican key manager.</p><p>In <code class="literal">glance-api.conf</code> find the following lines:</p><div class="verbatim-wrap"><pre class="screen">[key_manager]
api_class = castellan.key_manager.barbican_key_manager.BarbicanKeyManager</pre></div><p>Then replace the value with the desired key manager class.</p><div id="id-1.3.13.6.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If those lines do not exist then simply add them to the end of the file.</p></div></div><div class="sect2" id="using-the-signature-verification"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.12.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the Signature Verification</span> <a title="Permalink" class="permalink" href="#using-the-signature-verification">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>using-the-signature-verification</li></ul></div></div></div></div><p>An image will need a few properties for signature verification to be enabled,
                these are:</p><div class="verbatim-wrap"><pre class="screen">img_signature
img_signature_hash_method
img_signature_key_type
img_signature_certificate_uuid</pre></div><div class="sect3" id="property-img-signature"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.12.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Property img_signature</span> <a title="Permalink" class="permalink" href="#property-img-signature">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>property-img-signature</li></ul></div></div></div></div><p>This is the signature of your image.</p><div id="id-1.3.13.7.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The max character limit is 255.</p></div></div><div class="sect3" id="property-img-signature-hash-method"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.12.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Property img_signature_hash_method</span> <a title="Permalink" class="permalink" href="#property-img-signature-hash-method">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>property-img-signature-hash-method</li></ul></div></div></div></div><p>Hash methods is the method you hash with.</p><p>Current ones you can use are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>SHA-224</p></li><li class="listitem "><p>SHA-256</p></li><li class="listitem "><p>SHA-384</p></li><li class="listitem "><p>SHA-512</p></li></ul></div></div><div class="sect3" id="property-img-signature-key-type"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.12.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Property img_signature_key_type</span> <a title="Permalink" class="permalink" href="#property-img-signature-key-type">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>property-img-signature-key-type</li></ul></div></div></div></div><p>This is the key_types you can use for your image.</p><p>Current ones you can use are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>RSA-PSS</p></li><li class="listitem "><p>DSA</p></li><li class="listitem "><p>ECC-CURVES</p></li></ul></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>SECT571K1</p></li><li class="listitem "><p>SECT409K1</p></li><li class="listitem "><p>SECT571R1</p></li><li class="listitem "><p>SECT409R1</p></li><li class="listitem "><p>SECP521R1</p></li><li class="listitem "><p>SECP384R1</p></li></ul></div><div id="id-1.3.13.7.6.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>ECC curves - Only keysizes above 384 are included.
                        Not all ECC curves may be supported by the back end.</p></div></div><div class="sect3" id="property-img-signature-certificate-uuid"><div class="titlepage"><div><div><h4 class="title"><span class="number">1.12.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Property img_signature_certificate_uuid</span> <a title="Permalink" class="permalink" href="#property-img-signature-certificate-uuid">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>property-img-signature-certificate-uuid</li></ul></div></div></div></div><p>This is the UUID of the certificate that you upload to Barbican.</p><p>Therefore the type passed to glance is:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>UUID</p></li></ul></div><div id="id-1.3.13.7.7.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The supported certificate types are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>X_509</p></li></ul></div></div></div></div><div class="sect2" id="example-usage"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.12.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example Usage</span> <a title="Permalink" class="permalink" href="#example-usage">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>example-usage</li></ul></div></div></div></div><p>Follow these instructions to create your keys:</p><div class="verbatim-wrap"><pre class="screen">$ openssl genrsa -out private_key.pem 1024
Generating RSA private key, 1024 bit long modulus
...............................................++++++
..++++++
e is 65537 (0x10001)

$ openssl rsa -pubout -in private_key.pem -out public_key.pem
writing RSA key

$ openssl req -new -key private_key.pem -out cert_request.csr
You are about to be asked to enter information that will be incorporated
into your certificate request.

$ openssl x509 -req -days 14 -in cert_request.csr -signkey private_key.pem -out new_cert.crt
Signature ok
subject=/C=AU/ST=Some-State/O=Internet Widgits Pty Ltd
Getting Private key</pre></div><p>Upload your certificate. This only has to be done once as you can use
                the same <code class="literal">Secret href</code> for many images until it expires:</p><div class="verbatim-wrap"><pre class="screen">$ openstack secret store --name test --algorithm RSA --expiration 2016-06-29 --secret-type certificate --payload-content-type "application/octet-stream" --payload-content-encoding base64 --payload "$(base64 new_cert.crt)"
+---------------+-----------------------------------------------------------------------+
| Field         | Value                                                                 |
+---------------+-----------------------------------------------------------------------+
| Secret href   | http://127.0.0.1:9311/v1/secrets/cd7cc675-e573-419c-8fff-33a72734a243 |

$ cert_uuid=cd7cc675-e573-419c-8fff-33a72734a243</pre></div><p>Get an image and create the signature:</p><div class="verbatim-wrap"><pre class="screen">$ echo This is a dodgy image &gt; myimage

$ openssl dgst -sha256 -sign private_key.pem -sigopt rsa_padding_mode:pss -out myimage.signature myimage

$ base64 -w 0 myimage.signature &gt; myimage.signature.b64

$ image_signature=$(cat myimage.signature.b64)</pre></div><div id="id-1.3.13.8.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Using Glance v1 requires <code class="literal">-w 0</code> due to not supporting multiline image properties.
                    Glance v2 does support multiline image properties and does not require <code class="literal">-w 0</code> but may still be used.</p></div><p>Create the image:</p><div class="verbatim-wrap"><pre class="screen">$ glance image-create --name mySignedImage --container-format bare --disk-format qcow2 --property img_signature="$image_signature" --property img_signature_certificate_uuid="$cert_uuid" --property img_signature_hash_method='SHA-256' --property img_signature_key_type='RSA-PSS' &lt; myimage</pre></div><div id="id-1.3.13.8.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Creating the image can fail if validation does not succeed.
                    This will cause the image to be deleted.</p></div></div><div class="sect2" id="other-links"><div class="titlepage"><div><div><h3 class="title"><span class="number">1.12.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Other Links</span> <a title="Permalink" class="permalink" href="#other-links">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-glance.xml</li><li><span class="ds-label">ID: </span>other-links</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <a class="link" href="https://etherpad.openstack.org/p/mitaka-glance-image-signing-instructions" target="_blank">https://etherpad.openstack.org/p/mitaka-glance-image-signing-instructions</a>
              </p></li><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/ops-guide/ops_user_facing_operations.html" target="_blank">http://docs.openstack.org/ops-guide/ops_user_facing_operations.html</a>
              </p></li></ul></div></div></div></div><div class="chapter " id="ironic-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ironic User Guide</span> <a title="Permalink" class="permalink" href="#ironic-user-guide">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>ironic-user-guide</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#why-provision-bare-metal"><span class="number">2.1 </span><span class="name">Why Provision Bare Metal</span></a></span></dt><dt><span class="section"><a href="#conceptual-architecture"><span class="number">2.2 </span><span class="name">Conceptual Architecture</span></a></span></dt><dt><span class="section"><a href="#logical-architecture"><span class="number">2.3 </span><span class="name">Logical Architecture</span></a></span></dt><dt><span class="section"><a href="#key-technologies-for-bare-metal-hosting"><span class="number">2.4 </span><span class="name">Key Technologies for Bare Metal Hosting</span></a></span></dt><dt><span class="section"><a href="#ironic-deployment-architecture"><span class="number">2.5 </span><span class="name">Ironic Deployment Architecture</span></a></span></dt><dt><span class="section"><a href="#understanding-bare-metal-deployment"><span class="number">2.6 </span><span class="name">Understanding Bare Metal Deployment</span></a></span></dt></dl></div></div><p>Ironic is an OpenStack project which provisions bare metal (as opposed to
            virtual) machines. It may be used independently or as part of an OpenStack
            Cloud, and integrates with the OpenStack Identity (keystone), Compute (nova),
            Network (neutron), Image (glance) and Object (swift) services.</p><p>When the Bare Metal service is appropriately configured with the Compute and
            Network services, it is possible to provision both virtual and physical
            machines through the Compute service’s API. However, the set of instance
            actions is limited, arising from the different characteristics of physical
            servers and switch hardware. For example, live migration can not be performed
            on a bare metal instance.</p><p>The community maintains reference drivers that leverage open-source
            technologies (for example, PXE and IPMI) to cover a wide range of hardware. Ironic’s
            pluggable driver architecture also allows hardware vendors to write and
            contribute drivers that may improve performance or add functionality not
            provided by the community drivers.</p><div class="sect1" id="why-provision-bare-metal"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Why Provision Bare Metal</span> <a title="Permalink" class="permalink" href="#why-provision-bare-metal">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>why-provision-bare-metal</li></ul></div></div></div></div><p>The following are a few use-cases for bare metal (physical server) provisioning in
                cloud:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>High-performance computing clusters</p></li><li class="listitem "><p>Computing tasks that require access to hardware devices which can’t be
                        virtualized</p></li><li class="listitem "><p>Database hosting (some databases run poorly in a hypervisor)</p></li><li class="listitem "><p>Single tenant, dedicated hardware for performance, security, dependability
                        and other regulatory requirements</p></li><li class="listitem "><p>Rapidly deploying a cloud infrastructure</p></li></ul></div></div><div class="sect1" id="conceptual-architecture"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Conceptual Architecture</span> <a title="Permalink" class="permalink" href="#conceptual-architecture">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>conceptual-architecture</li></ul></div></div></div></div><p>The following diagram shows the relationships and how all services come into
                play during the provisioning of a physical server.</p><div id="id-1.4.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Ceilometer and Swift can be used with Ironic, but are missing from this diagram.</p></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/conceptual_architecture.png" target="_blank"><img src="images/conceptual_architecture.png" width="" /></a></div></div></div><div class="sect1" id="logical-architecture"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Logical Architecture</span> <a title="Permalink" class="permalink" href="#logical-architecture">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>logical-architecture</li></ul></div></div></div></div><p>The diagram below shows the logical architecture. It shows the basic
                components that form the Ironic service, the relation of Ironic service with
                other OpenStack services and the logical flow of a boot instance request
                resulting in the provisioning of a physical server.</p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/logical_architecture.png" target="_blank"><img src="images/logical_architecture.png" width="" /></a></div></div><p>The Ironic service is composed of the following components:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>A RESTful API service, by which operators and other services may interact
                  with the managed bare metal servers.</p></li><li class="step "><p>A conductor service, which does the bulk of the work. Functionality is
                  exposed via the API service. The Conductor and API services communicate
                  via RPC.</p></li><li class="step "><p>Various drivers that support heterogeneous hardware</p></li><li class="step "><p>A message queue</p></li><li class="step "><p>A database for storing information about the resources. Among other things,
                  this includes the state of the conductors, nodes (physical servers), and
                  drivers.</p></li></ol></div></div><p>As in Figure 1.2. Logical Architecture, a user request to boot an instance is
                passed to the Nova Compute service via Nova API and Nova Scheduler. The Compute
                service hands over this request to the Ironic service, where the request passes
                from the Ironic API, to the Conductor, to a driver to successfully provision a
                physical server for the user.</p><p>Just as the Nova Compute service talks to various OpenStack services like
                Glance, Neutron, or Swift to provision a virtual machine instance, here the
                Ironic service talks to the same OpenStack services for image, network and
                other resource needs to provision a bare metal instance.</p></div><div class="sect1" id="key-technologies-for-bare-metal-hosting"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Key Technologies for Bare Metal Hosting</span> <a title="Permalink" class="permalink" href="#key-technologies-for-bare-metal-hosting">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>key-technologies-for-bare-metal-hosting</li></ul></div></div></div></div><div class="sect2" id="preboot-execution-environment-pxe"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Preboot Execution Environment (PXE)</span> <a title="Permalink" class="permalink" href="#preboot-execution-environment-pxe">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>preboot-execution-environment-pxe</li></ul></div></div></div></div><p>PXE is part of the Wired for Management (WfM) specification developed by Intel
                    and Microsoft. The PXE enables system’s BIOS and network interface card (NIC)
                    to bootstrap a computer from the network in place of a disk. Bootstrapping is
                    the process by which a system loads the OS into local memory so that it can be
                    executed by the processor. This capability of allowing a system to boot over a
                    network simplifies server deployment and server management for administrators.</p></div><div class="sect2" id="dynamic-host-configuration-protocol-dhcp"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dynamic Host Configuration Protocol (DHCP)</span> <a title="Permalink" class="permalink" href="#dynamic-host-configuration-protocol-dhcp">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>dynamic-host-configuration-protocol-dhcp</li></ul></div></div></div></div><p>DHCP is a standardized networking protocol used on Internet Protocol (IP)
                    networks for dynamically distributing network configuration parameters, such
                    as IP addresses for interfaces and services. Using PXE, the BIOS uses DHCP to
                    obtain an IP address for the network interface and to locate the server that
                    stores the network bootstrap program (NBP).</p></div><div class="sect2" id="network-bootstrap-program-nbp"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Network Bootstrap Program (NBP)</span> <a title="Permalink" class="permalink" href="#network-bootstrap-program-nbp">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>network-bootstrap-program-nbp</li></ul></div></div></div></div><p>NBP is equivalent to GRUB (GRand Unified Bootloader) or LILO (LInux LOader) -
                    loaders which are traditionally used in local booting. Like the boot program
                    in a hard drive environment, the NBP is responsible for loading the OS kernel
                    into memory so that the OS can be bootstrapped over a network.</p></div><div class="sect2" id="trivial-file-transfer-protocol-tftp"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Trivial File Transfer Protocol (TFTP)</span> <a title="Permalink" class="permalink" href="#trivial-file-transfer-protocol-tftp">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>trivial-file-transfer-protocol-tftp</li></ul></div></div></div></div><p>TFTP is a simple file transfer protocol that is generally used for automated
                    transfer of configuration or boot files between machines in a local
                    environment.  In a PXE environment, TFTP is used to download NBP over the
                    network using information from the DHCP server.</p></div><div class="sect2" id="intelligent-platform-management-interface-ipmi"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Intelligent Platform Management Interface (IPMI)</span> <a title="Permalink" class="permalink" href="#intelligent-platform-management-interface-ipmi">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>intelligent-platform-management-interface-ipmi</li></ul></div></div></div></div><p>IPMI is a standardized computer system interface used by system administrators
                    for out-of-band management of computer systems and monitoring of their
                    operation. It is a method to manage systems that may be unresponsive or powered
                    off by using only a network connection to the hardware rather than to an
                    operating system.</p></div></div><div class="sect1" id="ironic-deployment-architecture"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ironic Deployment Architecture</span> <a title="Permalink" class="permalink" href="#ironic-deployment-architecture">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>ironic-deployment-architecture</li></ul></div></div></div></div><p>The Ironic RESTful API service is used to enroll hardware that Ironic will
                manage. A cloud administrator usually registers the hardware, specifying their
                attributes such as MAC addresses and IPMI credentials. There can be multiple
                instances of the API service.</p><p>The Ironic conductor service does the bulk of the work.
                For security reasons, it is advisable to place the conductor service on
                an isolated host, since it is the only service that requires access to both
                the data plane and IPMI control plane.</p><p>There can be multiple instances of the conductor service to support
                various class of drivers and also to manage fail over. Instances of the
                conductor service should be on separate nodes. Each conductor can itself run
                many drivers to operate heterogeneous hardware. This is depicted in the
                following figure.</p><p>The API exposes a list of supported drivers and the names of conductor hosts
                servicing them.</p><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/deployment_architecture_2.png" target="_blank"><img src="images/deployment_architecture_2.png" width="" /></a></div></div></div><div class="sect1" id="understanding-bare-metal-deployment"><div class="titlepage"><div><div><h2 class="title"><span class="number">2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Understanding Bare Metal Deployment</span> <a title="Permalink" class="permalink" href="#understanding-bare-metal-deployment">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>understanding-bare-metal-deployment</li></ul></div></div></div></div><p>What happens when a boot instance request comes in? The below diagram walks
                through the steps involved during the provisioning of a bare metal instance.</p><p>These pre-requisites must be met before the deployment process:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Dependent packages to be configured on the Bare Metal service node(s)
                  where ironic-conductor is running like tftp-server, ipmi, or syslinux for
                  bare metal provisioning.</p></li><li class="listitem "><p>Nova must be configured to make use of the bare metal service endpoint
                  and compute driver should be configured to use ironic driver on the Nova
                  compute node(s).</p></li><li class="listitem "><p>Flavors to be created for the available hardware. Nova must know the flavor
                  to boot from.</p></li><li class="listitem "><p>Images to be made available in Glance. Listed below are some image types
                  required for successful bare metal deployment:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">bm-deploy-kernel</code></p></li><li class="listitem "><p><code class="literal">bm-deploy-ramdisk</code></p></li><li class="listitem "><p><code class="literal">user-image</code></p></li><li class="listitem "><p><code class="literal">user-image-vmlinuz</code></p></li><li class="listitem "><p><code class="literal">user-image-initrd</code></p></li></ul></div></li><li class="listitem "><p>Hardware to be enrolled via Ironic RESTful API service.</p></li></ul></div><div class="informalfigure"><div class="mediaobject"><a xmlns="" href="images/deployment_steps.png" target="_blank"><img src="images/deployment_steps.png" width="" /></a></div></div><div class="sect2" id="deploy-process"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploy Process</span> <a title="Permalink" class="permalink" href="#deploy-process">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>deploy-process</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>A boot instance request comes in via the Nova API, through the message
                    queue to the Nova scheduler.</p></li><li class="step "><p>Nova scheduler applies filter and finds the eligible compute node. Nova
                    scheduler uses flavor <code class="literal">extra_specs</code> detail such as <code class="literal">cpu_arch</code>,
                    <code class="literal">baremetal:deploy_kernel_id</code> or <code class="literal">baremetal:deploy_ramdisk_id</code> to match
                    the target physical node.</p></li><li class="step "><p>A spawn task is placed by the driver which contains all information such
                    as which image to boot from. It invokes the <code class="literal">driver.spawn</code> from the
                    virtual layer of Nova compute.</p></li><li class="step "><p>Information about the bare metal node is retrieved from the bare metal
                    database and the node is reserved.</p></li><li class="step "><p>Images from Glance are pulled down to the local disk of the Ironic
                    conductor servicing the bare metal node.</p><ol type="a" class="substeps "><li class="step "><p>For <code class="literal">pxe_*</code> drivers these include all images: both the deploy ramdisk and
                        user instance images.</p></li><li class="step "><p>For <code class="literal">agent_*</code> drivers only the deploy ramdisk is stored locally. Temporary
                        URLs in OpenStack’s Object Storage service are created for user instance images.</p></li></ol></li><li class="step "><p>Virtual interfaces are plugged in and Neutron API updates DHCP port to
                    support PXE/TFTP options.</p></li><li class="step "><p>Nova’s ironic driver issues a deploy request via the Ironic API to the
                    Ironic conductor servicing the bare metal node.</p></li><li class="step "><p>PXE driver prepares tftp bootloader.</p></li><li class="step "><p>The IPMI driver issues command to enable network boot of a node and power it on.</p></li><li class="step "><p>The DHCP boots the deploy ramdisk. Next, depending on the exact driver
                    used, either the conductor copies the image over iSCSI to the physical node
                    (<code class="literal">pxe_*</code> group of drivers) or the deploy ramdisk downloads the image from
                    a temporary URL (<code class="literal">agent_*</code> group of drivers), which can be generated by
                    a variety of object stores. For example, <span class="emphasis"><em>swift</em></span> or <span class="emphasis"><em>radosgw</em></span>, and uploaded
                    to OpenStack’s Object Storage service. In the former case, the conductor
                    connects to the iSCSI end point, partitions volume, <code class="literal">dd</code> the image and
                    closes the iSCSI connection.</p><p>The deployment is done. The Ironic conductor will switch pxe config to service
                    mode and notify ramdisk agent on the successful deployment.</p></li><li class="step "><p>The IPMI driver reboots the bare metal node. There are 2 power
                    cycles during bare metal deployment; the first time when powered-on, the
                    images get deployed as mentioned in step 9. The second time as in this case,
                    after the images are deployed, the node is powered up.</p></li><li class="step "><p>The bare metal node status is updated and the node instance is made available.</p></li></ol></div></div></div><div class="sect2" id="example-1-pxe-boot-and-iscsi-deploy-process"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example 1: PXE Boot and iSCSI Deploy Process</span> <a title="Permalink" class="permalink" href="#example-1-pxe-boot-and-iscsi-deploy-process">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>example-1-pxe-boot-and-iscsi-deploy-process</li></ul></div></div></div></div><p>This process is used with <code class="literal">pxe_*</code> family of drivers.</p><p>(From a <a class="link" href="https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/isn-and-039t-it-ironic-the-bare-metal-cloud" target="_blank">talk</a>
                and <a class="link" href="http://www.slideshare.net/devananda1/isnt-it-ironic-managing-a-bare-metal-cloud-osl-tes-2015" target="_blank">slides</a>).</p></div><div class="sect2" id="example-2-pxe-boot-and-direct-deploy-process"><div class="titlepage"><div><div><h3 class="title"><span class="number">2.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example 2: PXE Boot and Direct Deploy Process</span> <a title="Permalink" class="permalink" href="#example-2-pxe-boot-and-direct-deploy-process">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-ironic.xml</li><li><span class="ds-label">ID: </span>example-2-pxe-boot-and-direct-deploy-process</li></ul></div></div></div></div><p>This process is used with <code class="literal">agent_*</code> family of drivers.</p><p>(From a <a class="link" href="https://www.openstack.org/summit/vancouver-2015/summit-videos/presentation/isn-and-039t-it-ironic-the-bare-metal-cloud" target="_blank">talk</a>
                and <a class="link" href="http://www.slideshare.net/devananda1/isnt-it-ironic-managing-a-bare-metal-cloud-osl-tes-2015" target="_blank">slides</a>).</p></div></div></div><div class="chapter " id="horizon-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Horizon User Guide</span> <a title="Permalink" class="permalink" href="#horizon-user-guide">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-horizon.xml</li><li><span class="ds-label">ID: </span>horizon-user-guide</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#openstack-dashboard-user-documentation"><span class="number">3.1 </span><span class="name">OpenStack Dashboard User Documentation</span></a></span></dt></dl></div></div><p>How to use Horizon in your own projects.</p><div class="sect1" id="openstack-dashboard-user-documentation"><div class="titlepage"><div><div><h2 class="title"><span class="number">3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack Dashboard User Documentation</span> <a title="Permalink" class="permalink" href="#openstack-dashboard-user-documentation">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span>openstack-dashboard-user-documentation</li></ul></div></div></div></div><p>As a cloud end user, you can use the OpenStack dashboard to provision
            your own resources within the limits set by administrators. You can
            modify the examples provided in this section to create other types and
            sizes of server instances.</p><div class="sect2" id="log-in-to-the-dashboard"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Log in to the dashboard</span> <a title="Permalink" class="permalink" href="#log-in-to-the-dashboard">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>log-in-to-the-dashboard</li></ul></div></div></div></div><p>The dashboard is generally installed on the controller node.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Ask the cloud operator for the host name or public IP address from
                    which you can access the dashboard, and for your user name and
                    password. If the cloud supports multi-domain model, you also need to
                    ask for your domain name.</p></li><li class="step "><p>Open a web browser that has JavaScript and cookies enabled.</p><div id="id-1.5.3.3.3.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To use the Virtual Network Computing (VNC) client for the dashboard,
                        your browser must support HTML5 Canvas and HTML5 WebSockets. The VNC
                        client is based on noVNC. For details, see <a class="link" href="https://github.com/kanaka/noVNC/blob/master/README.md" target="_blank">noVNC: HTML5 VNC
                            Client</a>.
                        For a list of supported browsers, see <a class="link" href="https://github.com/kanaka/noVNC/wiki/Browser-support" target="_blank">Browser
                            support</a>.</p></div></li><li class="step "><p>In the address bar, enter the host name or IP address for the
                    dashboard, for example, <code class="literal">https://ipAddressOrHostName/</code>.</p><div id="id-1.5.3.3.3.3.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If a certificate warning appears when you try to access the URL for
                        the first time, a self-signed certificate is in use, which is not
                        considered trustworthy by default. Verify the certificate or add an
                        exception in the browser to bypass the warning.</p></div></li><li class="step "><p>On the <span class="guimenu ">Log In</span> page, enter your user name and password, and
                    click <span class="guimenu ">Sign In</span>. If the cloud supports multi-domain model, you
                    also need to enter your domain name.</p><p>The top of the window displays your user name. You can also access the
                    <span class="guimenu ">Settings</span> tab (<a class="xref" href="#dashboard-settings-tab" title="3.1.1.4. OpenStack dashboard — Settings tab">Section 3.1.1.4, “OpenStack dashboard — Settings tab”</a>) or sign out
                    of the dashboard.</p><p>The visible tabs and functions in the dashboard depend on the access
                    permissions, or roles, of the user you are logged in as.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>If you are logged in as an end user, the <span class="guimenu ">Project</span> tab
                      (<a class="xref" href="#dashboard-project-tab" title="3.1.1.1. OpenStack dashboard — Project tab">Section 3.1.1.1, “OpenStack dashboard — Project tab”</a>) and <span class="guimenu ">Identity</span> tab
                      (<a class="xref" href="#dashboard-identity-tab" title="3.1.1.3. OpenStack dashboard — Identity tab">Section 3.1.1.3, “OpenStack dashboard — Identity tab”</a>) are displayed.</p></li><li class="listitem "><p>If you are logged in as an administrator, the <span class="guimenu ">Project</span> tab
                      (<a class="xref" href="#dashboard-project-tab" title="3.1.1.1. OpenStack dashboard — Project tab">Section 3.1.1.1, “OpenStack dashboard — Project tab”</a>) and <span class="guimenu ">Admin</span> tab
                      (<a class="xref" href="#dashboard-admin-tab" title="3.1.1.2. OpenStack dashboard — Admin tab">Section 3.1.1.2, “OpenStack dashboard — Admin tab”</a>) and <span class="guimenu ">Identity</span> tab
                      (<a class="xref" href="#dashboard-identity-tab" title="3.1.1.3. OpenStack dashboard — Identity tab">Section 3.1.1.3, “OpenStack dashboard — Identity tab”</a>) are displayed.</p></li></ul></div></li></ol></div></div><div id="id-1.5.3.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Some tabs, such as <span class="guimenu ">Orchestration</span> and <span class="guimenu ">Firewalls</span>,
                only appear on the dashboard if they are properly configured.</p></div><div class="sect3" id="dashboard-project-tab"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack dashboard — Project tab</span> <a title="Permalink" class="permalink" href="#dashboard-project-tab">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>dashboard-project-tab</li></ul></div></div></div></div><p>Projects are organizational units in the cloud and are also known as
                tenants or accounts. Each user is a member of one or more projects.
                Within a project, a user creates and manages instances.</p><p>From the <span class="guimenu ">Project</span> tab, you can view and manage the resources in a
                selected project, including instances and images. You can select the project
                from the drop-down menu at the top left. If the cloud supports multi-domain
                model, you can also select the domain from this menu.</p><div class="figure" id="id-1.5.3.3.5.4"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/dashboard_project_tab.png" target="_blank"><img src="images/dashboard_project_tab.png" width="" alt="Figure: Project tab" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 3.1: </span><span class="name">Figure: Project tab </span><a title="Permalink" class="permalink" href="#id-1.5.3.3.5.4">#</a></h6></div></div><p>From the <span class="guimenu ">Project</span> tab, you can access the following categories:</p><div class="sect4" id="compute-tab"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Compute tab</span> <a title="Permalink" class="permalink" href="#compute-tab">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>compute-tab</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Overview</span>: View reports for the project.</p></li><li class="listitem "><p><span class="guimenu ">Instances</span>: View, launch, create a snapshot from, stop, pause,
                            or reboot instances, or connect to them through VNC.</p></li><li class="listitem "><p><span class="guimenu ">Volumes</span>: Use the following tabs to complete these tasks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Volumes</span>: View, create, edit, and delete volumes.</p></li><li class="listitem "><p><span class="guimenu ">Volume Snapshots</span>: View, create, edit, and delete volume
                                    snapshots.</p></li></ul></div></li><li class="listitem "><p><span class="guimenu ">Images</span>: View images and instance snapshots created by project
                            users, plus any images that are publicly available. Create, edit, and
                            delete images, and launch instances from images and snapshots.</p></li><li class="listitem "><p><span class="guimenu ">Access &amp; Security</span>: Use the following tabs to complete these
                            tasks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Security Groups</span>: View, create, edit, and delete security
                                    groups and security group rules.</p></li><li class="listitem "><p><span class="guimenu ">Key Pairs</span>: View, create, edit, import, and delete key pairs.</p></li><li class="listitem "><p><span class="guimenu ">Floating IPs</span>: Allocate an IP address to or release it from a
                                    project.</p></li><li class="listitem "><p><span class="guimenu ">API Access</span>: View API endpoints.</p></li></ul></div></li><li class="listitem "><p><span class="guimenu ">Shares</span>: Use the following tabs to complete these tasks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Shares</span>: View, create, manage, and delete shares.</p></li><li class="listitem "><p><span class="guimenu ">Snapshots</span>: View, manage, and delete volume snapshots.</p></li><li class="listitem "><p><span class="guimenu ">Share Networks</span>: View, manage, and delete share networks.</p></li><li class="listitem "><p><span class="guimenu ">Security Services</span>: View, manage, and delete security services.</p></li></ul></div></li></ul></div></div><div class="sect4" id="network-tab"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Network tab</span> <a title="Permalink" class="permalink" href="#network-tab">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>network-tab</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Network Topology</span>: View the network topology.</p></li><li class="listitem "><p><span class="guimenu ">Networks</span>: Create and manage public and private networks.</p></li><li class="listitem "><p><span class="guimenu ">Routers</span>: Create and manage routers.</p></li><li class="listitem "><p><span class="guimenu ">Load Balancers</span>: Create and manage load balancers.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Pools</span>: Add and manage pools.</p></li><li class="listitem "><p><span class="guimenu ">Members</span>: Add and manage members.</p></li><li class="listitem "><p><span class="guimenu ">Monitors</span>: Add and manage monitors.</p></li></ul></div></li><li class="listitem "><p><span class="guimenu ">Firewalls</span>: Create and manage firewalls.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Firewalls</span>: Create and manage firewalls.</p></li><li class="listitem "><p><span class="guimenu ">Firewall Policies</span>: Add and manage firewall policies.</p></li><li class="listitem "><p><span class="guimenu ">Firewall Rules</span>: Add and manage firewall rules.</p></li></ul></div></li></ul></div></div><div class="sect4" id="orchestration-tab"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Orchestration tab</span> <a title="Permalink" class="permalink" href="#orchestration-tab">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>orchestration-tab</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Stacks</span>: Use the REST API to orchestrate multiple composite
                            cloud applications.</p></li><li class="listitem "><p><span class="guimenu ">Resource Types</span>: Show a list of all the supported resource
                            types for HOT templates.</p></li></ul></div></div><div class="sect4" id="object-store-tab"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.1.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Object Store tab</span> <a title="Permalink" class="permalink" href="#object-store-tab">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>object-store-tab</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Containers</span>: Create and manage containers and objects.</p></li></ul></div></div></div><div class="sect3" id="dashboard-admin-tab"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack dashboard — Admin tab</span> <a title="Permalink" class="permalink" href="#dashboard-admin-tab">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>dashboard-admin-tab</li></ul></div></div></div></div><p>Administrative users can use the <span class="guimenu ">Admin</span> tab to view usage and to
                manage instances, volumes, flavors, images, networks, and so on.</p><div class="figure" id="id-1.5.3.3.6.3"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/dashboard_admin_tab.png" target="_blank"><img src="images/dashboard_admin_tab.png" width="" alt="Figure: Admin tab" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 3.2: </span><span class="name">Figure: Admin tab </span><a title="Permalink" class="permalink" href="#id-1.5.3.3.6.3">#</a></h6></div></div><p>From the <span class="guimenu ">Admin</span> tab, you can access the following category
                to complete these tasks:</p><div class="sect4" id="system-tab"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">System tab</span> <a title="Permalink" class="permalink" href="#system-tab">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>system-tab</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Overview</span>: View basic reports.</p></li><li class="listitem "><p><span class="guimenu ">Resource Usage</span>: Use the following tabs to view the following
                            usages:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Usage Report</span>: View the usage report.</p></li><li class="listitem "><p><span class="guimenu ">Stats</span>: View the statistics of all resources.</p></li></ul></div></li><li class="listitem "><p><span class="guimenu ">Hypervisors</span>: View the hypervisor summary.</p></li><li class="listitem "><p><span class="guimenu ">Host Aggregates</span>: View, create, and edit host aggregates.
                            View the list of availability zones.</p></li><li class="listitem "><p><span class="guimenu ">Instances</span>: View, pause, resume, suspend, migrate, soft or hard
                            reboot, and delete running instances that belong to users of some, but not
                            all, projects. Also, view the log for an instance or access an instance
                            through VNC.</p></li><li class="listitem "><p><span class="guimenu ">Volumes</span>: Use the following tabs to complete these tasks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Volumes</span>: View, create, manage, and delete volumes.</p></li><li class="listitem "><p><span class="guimenu ">Volume Types</span>: View, create, manage, and delete volume types.</p></li><li class="listitem "><p><span class="guimenu ">Volume Snapshots</span>: View, manage, and delete volume snapshots.</p></li></ul></div></li><li class="listitem "><p><span class="guimenu ">Flavors</span>: View, create, edit, view extra specifications for,
                            and delete flavors. A flavor is the size of an instance.</p></li><li class="listitem "><p><span class="guimenu ">Images</span>: View, create, edit properties for, and delete custom
                            images.</p></li><li class="listitem "><p><span class="guimenu ">Networks</span>: View, create, edit properties for, and delete
                            networks.</p></li><li class="listitem "><p><span class="guimenu ">Routers</span>: View, create, edit properties for, and delete routers.</p></li><li class="listitem "><p><span class="guimenu ">Defaults</span>: View default quota values. Quotas are hard-coded in
                            OpenStack Compute and define the maximum allowable size and number of
                            resources.</p></li><li class="listitem "><p><span class="guimenu ">Metadata Definitions</span>: Import namespace and view the metadata
                            information.</p></li><li class="listitem "><p><span class="guimenu ">System Information</span>: Use the following tabs to view the service
                            information:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Services</span>: View a list of the services.</p></li><li class="listitem "><p><span class="guimenu ">Compute Services</span>: View a list of all Compute services.</p></li><li class="listitem "><p><span class="guimenu ">Block Storage Services</span>: View a list of all Block Storage
                                    services.</p></li><li class="listitem "><p><span class="guimenu ">Network Agents</span>: View the network agents.</p></li><li class="listitem "><p><span class="guimenu ">Orchestration Services</span>: View a list of all Orchestration
                                    services.</p></li></ul></div></li><li class="listitem "><p><span class="guimenu ">Shares</span>: Use the following tabs to complete these tasks:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Shares</span>: View, create, manage, and delete shares.</p></li><li class="listitem "><p><span class="guimenu ">Snapshots</span>: View, manage, and delete volume snapshots.</p></li><li class="listitem "><p><span class="guimenu ">Share Networks</span>: View, manage, and delete share networks.</p></li><li class="listitem "><p><span class="guimenu ">Security Services</span>: View, manage, and delete security services.</p></li><li class="listitem "><p><span class="guimenu ">Share Types</span>: View, create, manage, and delete share types.</p></li><li class="listitem "><p><span class="guimenu ">Share Servers</span>: View, manage, and delete share servers.</p></li></ul></div></li></ul></div></div></div><div class="sect3" id="dashboard-identity-tab"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack dashboard — Identity tab</span> <a title="Permalink" class="permalink" href="#dashboard-identity-tab">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>dashboard-identity-tab</li></ul></div></div></div></div><div class="figure" id="id-1.5.3.3.7.2"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/dashboard_identity_tab.png" target="_blank"><img src="images/dashboard_identity_tab.png" width="" alt="Figure:Identity tab" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 3.3: </span><span class="name">Figure:Identity tab </span><a title="Permalink" class="permalink" href="#id-1.5.3.3.7.2">#</a></h6></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Projects</span>: View, create, assign users to, remove users from,
                        and delete projects.</p></li><li class="listitem "><p><span class="guimenu ">Users</span>: View, create, enable, disable, and delete users.</p></li></ul></div></div><div class="sect3" id="dashboard-settings-tab"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">OpenStack dashboard — Settings tab</span> <a title="Permalink" class="permalink" href="#dashboard-settings-tab">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>log-in</li><li><span class="ds-label">ID: </span>dashboard-settings-tab</li></ul></div></div></div></div><div class="figure" id="id-1.5.3.3.8.2"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/dashboard_settings_tab.png" target="_blank"><img src="images/dashboard_settings_tab.png" width="" alt="Figure:Settings tab" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 3.4: </span><span class="name">Figure:Settings tab </span><a title="Permalink" class="permalink" href="#id-1.5.3.3.8.2">#</a></h6></div></div><p>Click the <span class="guimenu ">Settings</span> button from the user drop down menu at the
                top right of any page, you will see the <span class="guimenu ">Settings</span> tab.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">User Settings</span>: View and manage dashboard settings.</p></li><li class="listitem "><p><span class="guimenu ">Change Password</span>: Change the password of the user.</p></li></ul></div></div></div><div class="sect2" id="upload-and-manage-images"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upload and manage images</span> <a title="Permalink" class="permalink" href="#upload-and-manage-images">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-images</li><li><span class="ds-label">ID: </span>upload-and-manage-images</li></ul></div></div></div></div><p>A virtual machine image, referred to in this document simply
            as an image, is a single file that contains a virtual disk that
            has a bootable operating system installed on it. Images are used
            to create virtual machine instances within the cloud. For information
            about creating image files, see the <a class="link" href="https://docs.openstack.org/image-guide/" target="_blank">OpenStack Virtual Machine
                Image Guide</a>.</p><p>Depending on your role, you may have permission to upload and manage
            virtual machine images. Operators might restrict the upload and
            management of images to cloud administrators or operators only. If you
            have the appropriate privileges, you can use the dashboard to upload and
            manage images in the admin project.</p><div id="id-1.5.3.4.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>You can also use the <code class="command">openstack</code> and <code class="command">glance</code>
                command-line clients or the Image service to manage images.</p></div><div class="sect3" id="upload-an-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upload an image</span> <a title="Permalink" class="permalink" href="#upload-an-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-images</li><li><span class="ds-label">ID: </span>upload-an-image</li></ul></div></div></div></div><p>Follow this procedure to upload an image to a project:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Images</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Create Image</span>.</p><p>The <span class="guimenu ">Create An Image</span> dialog box appears.</p><div class="figure" id="id-1.5.3.4.5.3.4.3"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/create_image.png" target="_blank"><img src="images/create_image.png" width="" alt="Dashboard — Create Image" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 3.5: </span><span class="name">Dashboard — Create Image </span><a title="Permalink" class="permalink" href="#id-1.5.3.4.5.3.4.3">#</a></h6></div></div></li><li class="step "><p>Enter the following values:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="31" class="c0" /><col width="33" class="c1" /></colgroup><tbody><tr><td>
                        <p>
                          <span class="guimenu ">Image Name</span>
                        </p>
                      </td><td>
                        <p>Enter a name for the image.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Image Description</span>
                        </p>
                      </td><td>
                        <p>Enter a brief description of
                                            the image.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Image Source</span>
                        </p>
                      </td><td>
                        <p>Choose the image source from
                                            the dropdown list. Your choices
                                            are <span class="guimenu ">Image Location</span>
                                            and <span class="guimenu ">Image File</span>.</p>
                      </td></tr><tr><td>
                        <p><span class="guimenu ">Image File</span> or
                                            <span class="guimenu ">Image Location</span></p>
                      </td><td>
                        <p>Based on your selection for
                                            <span class="guimenu ">Image Source</span>, you
                                            either enter the location URL
                                            of the image in the
                                            <span class="guimenu ">Image Location</span>
                                            field, or browse for the image
                                            file on your file  system and
                                            add it.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Format</span>
                        </p>
                      </td><td>
                        <p>Select the image format (for
                                            example, QCOW2) for the image.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Architecture</span>
                        </p>
                      </td><td>
                        <p>Specify the architecture. For
                                            example, <code class="literal">i386</code> for a 32-bit
                                            architecture or <code class="literal">x86_64</code> for
                                            a 64-bit architecture.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Minimum Disk (GB)</span>
                        </p>
                      </td><td>
                        <p>Leave this field empty.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Minimum RAM (MB)</span>
                        </p>
                      </td><td>
                        <p>Leave this field empty.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Copy Data</span>
                        </p>
                      </td><td>
                        <p>Specify this option to copy
                                            image data to the Image service.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Visibility</span>
                        </p>
                      </td><td>
                        <p>The access permission for the
                                            image.
                                            <code class="literal">Public</code> or <code class="literal">Private</code>.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Protected</span>
                        </p>
                      </td><td>
                        <p>Select this check box to ensure
                                            that only users with
                                            permissions can delete the
                                            image. <code class="literal">Yes</code> or <code class="literal">No</code>.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Image Metadata</span>
                        </p>
                      </td><td>
                        <p>Specify this option to add
                                            resource metadata. The glance
                                            Metadata Catalog provides a list
                                            of metadata image definitions.
                                            (Note: Not all cloud providers
                                            enable this feature.)</p>
                      </td></tr></tbody></table></div></li><li class="step "><p>Click <span class="guimenu ">Create Image</span>.</p><p>The image is queued to be uploaded. It might take some time before
                        the status changes from Queued to Active.</p></li></ol></div></div></div><div class="sect3" id="update-an-image-horizon"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update an image</span> <a title="Permalink" class="permalink" href="#update-an-image-horizon">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-images</li><li><span class="ds-label">ID: </span>update-an-image-horizon</li></ul></div></div></div></div><p>Follow this procedure to update an existing image.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>Select the image that you want to edit.</p></li><li class="step "><p>In the <span class="guimenu ">Actions</span> column, click the menu button and then
                        select <span class="guimenu ">Edit Image</span> from the list.</p></li><li class="step "><p>In the <span class="guimenu ">Edit Image</span> dialog box, you can perform various
                        actions. For example:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Change the name of the image.</p></li><li class="listitem "><p>Select the <span class="guimenu ">Public</span> check box to make the image public.</p></li><li class="listitem "><p>Clear the <span class="guimenu ">Public</span> check box to make the image private.</p></li></ul></div></li><li class="step "><p>Click <span class="guimenu ">Edit Image</span>.</p></li></ol></div></div></div><div class="sect3" id="delete-an-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete an image</span> <a title="Permalink" class="permalink" href="#delete-an-image">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-images</li><li><span class="ds-label">ID: </span>delete-an-image</li></ul></div></div></div></div><p>Deletion of images is permanent and <span class="bold"><strong>cannot</strong></span> be reversed. Only users
                with the appropriate permissions can delete images.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Images</span> category.</p></li><li class="step "><p>Select the images that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Images</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Confirm Delete Images</span> dialog box, click
                        <span class="guimenu ">Delete Images</span> to confirm the deletion.</p></li></ol></div></div></div></div><div class="sect2" id="configure-access-and-security-for-instances"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure access and security for instances</span> <a title="Permalink" class="permalink" href="#configure-access-and-security-for-instances">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>configure-access-and-security-for-instances</li><li><span class="ds-label">ID: </span>configure-access-and-security-for-instances</li></ul></div></div></div></div><p>Before you launch an instance, you should add security group rules to
            enable users to ping and use SSH to connect to the instance. Security
            groups are sets of IP filter rules that define networking access and are
            applied to all instances within a project. To do so, you either add
            rules to the default security group <a class="xref" href="#security-groups-add-rule" title="3.1.3.1. Add a rule to the default security group">Section 3.1.3.1, “Add a rule to the default security group”</a>
            or add a new security group with rules.</p><p>Key pairs are SSH credentials that are injected into an instance when it
            is launched. To use key pair injection, the image that the instance is
            based on must contain the <code class="literal">cloud-init</code> package. Each project should
            have at least one key pair. For more information, see the section
            <a class="xref" href="#keypair-add" title="3.1.3.2. Add a key pair">Section 3.1.3.2, “Add a key pair”</a>.</p><p>If you have generated a key pair with an external tool, you can import
            it into OpenStack. The key pair can be used for multiple instances that
            belong to a project. For more information, see the section
            <a class="xref" href="#dashboard-import-keypair" title="3.1.3.3. Import a key pair">Section 3.1.3.3, “Import a key pair”</a>.</p><div id="id-1.5.3.5.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A key pair belongs to an individual user, not to a project.
                To share a key pair across multiple users, each user
                needs to import that key pair.</p></div><p>When an instance is created in OpenStack, it is automatically assigned a
            fixed IP address in the network to which the instance is assigned. This
            IP address is permanently associated with the instance until the
            instance is terminated. However, in addition to the fixed IP address, a
            floating IP address can also be attached to an instance. Unlike fixed IP
            addresses, floating IP addresses are able to have their associations
            modified at any time, regardless of the state of the instances involved.</p><div class="sect3" id="security-groups-add-rule"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add a rule to the default security group</span> <a title="Permalink" class="permalink" href="#security-groups-add-rule">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>configure-access-and-security-for-instances</li><li><span class="ds-label">ID: </span>security-groups-add-rule</li></ul></div></div></div></div><p>This procedure enables SSH and ICMP (ping) access to instances. The
                rules apply to all instances within a given project, and should be set
                for every project unless there is a reason to prohibit SSH or ICMP
                access to the instances.</p><p>This procedure can be adjusted as necessary to add additional security
                group rules to a project, if your cloud requires them.</p><div id="id-1.5.3.5.7.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>When adding a rule, you must specify the protocol used with the
                    destination port or source port.</p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Access &amp; Security</span> category. The
                        <span class="guimenu ">Security Groups</span> tab shows the security groups that are
                        available for this project.</p></li><li class="step "><p>Select the default security group and click <span class="guimenu ">Manage Rules</span>.</p></li><li class="step "><p>To allow SSH access, click <span class="guimenu ">Add Rule</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Add Rule</span> dialog box, enter the following values:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Rule</strong></span>: <code class="literal">SSH</code></p></li><li class="listitem "><p><span class="bold"><strong>Remote</strong></span>: <code class="literal">CIDR</code></p></li><li class="listitem "><p><span class="bold"><strong>CIDR</strong></span>: <code class="literal">0.0.0.0/0</code></p></li></ul></div><div id="id-1.5.3.5.7.5.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To accept requests from a particular range of IP
                            addresses, specify the IP address block in the
                            <span class="guimenu ">CIDR</span> box.</p></div></li><li class="step "><p>Click <span class="guimenu ">Add</span>.</p><p>Instances will now have SSH port 22 open for requests from any IP
                        address.</p></li><li class="step "><p>To add an ICMP rule, click <span class="guimenu ">Add Rule</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Add Rule</span> dialog box, enter the following values:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="bold"><strong>Rule</strong></span>: <code class="literal">All ICMP</code></p></li><li class="listitem "><p><span class="bold"><strong>Direction</strong></span>: <code class="literal">Ingress</code></p></li><li class="listitem "><p><span class="bold"><strong>Remote</strong></span>: <code class="literal">CIDR</code></p></li><li class="listitem "><p><span class="bold"><strong>CIDR</strong></span>: <code class="literal">0.0.0.0/0</code></p></li></ul></div></li><li class="step "><p>Click <span class="guimenu ">Add</span>.</p><p>Instances will now accept all incoming ICMP packets.</p></li></ol></div></div></div><div class="sect3" id="keypair-add"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add a key pair</span> <a title="Permalink" class="permalink" href="#keypair-add">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>configure-access-and-security-for-instances</li><li><span class="ds-label">ID: </span>keypair-add</li></ul></div></div></div></div><p>Create at least one key pair for each project.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Access &amp; Security</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Key Pairs</span> tab, which shows the key pairs that
                        are available for this project.</p></li><li class="step "><p>Click <span class="guimenu ">Create Key Pair</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Key Pair</span> dialog box, enter a name for your
                        key pair, and click <span class="guimenu ">Create Key Pair</span>.</p></li><li class="step "><p>Respond to the prompt to download the key pair.</p></li></ol></div></div></div><div class="sect3" id="dashboard-import-keypair"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Import a key pair</span> <a title="Permalink" class="permalink" href="#dashboard-import-keypair">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>configure-access-and-security-for-instances</li><li><span class="ds-label">ID: </span>dashboard-import-keypair</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Access &amp; Security</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Key Pairs</span> tab, which shows the key pairs that
                        are available for this project.</p></li><li class="step "><p>Click <span class="guimenu ">Import Key Pair</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Import Key Pair</span> dialog box, enter the name of your
                        key pair, copy the public key into the <span class="guimenu ">Public Key</span> box,
                        and then click <span class="guimenu ">Import Key Pair</span>.</p></li><li class="step "><p>Save the <code class="literal">*.pem</code> file locally.</p></li><li class="step "><p>To change its permissions so that only you can read and write to the
                        file, run the following command:</p><div class="verbatim-wrap"><pre class="screen">$ chmod 0600 yourPrivateKey.pem</pre></div><div id="id-1.5.3.5.9.2.8.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If you are using the Dashboard from a Windows computer, use PuTTYgen
                            to load the <code class="literal">*.pem</code> file and convert and save it as <code class="literal">*.ppk</code>. For
                            more information see the <a class="link" href="http://winscp.net/eng/docs/ui_puttygen" target="_blank">WinSCP web page for
                                PuTTYgen</a>.</p></div></li><li class="step "><p>To make the key pair known to SSH, run the <code class="command">ssh-add</code> command.</p><div class="verbatim-wrap"><pre class="screen">$ ssh-add yourPrivateKey.pem</pre></div></li></ol></div></div><p>The Compute database registers the public key of the key pair.</p><p>The Dashboard lists the key pair on the <span class="guimenu ">Access &amp; Security</span> tab.</p></div><div class="sect3" id="allocate-a-floating-ip-address-to-an-instance"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Allocate a floating IP address to an instance</span> <a title="Permalink" class="permalink" href="#allocate-a-floating-ip-address-to-an-instance">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>configure-access-and-security-for-instances</li><li><span class="ds-label">ID: </span>allocate-a-floating-ip-address-to-an-instance</li></ul></div></div></div></div><p>When an instance is created in OpenStack, it is automatically assigned a
                fixed IP address in the network to which the instance is assigned. This
                IP address is permanently associated with the instance until the
                instance is terminated.</p><p>However, in addition to the fixed IP address, a floating IP address can
                also be attached to an instance. Unlike fixed IP addresses, floating IP
                addresses can have their associations modified at any time, regardless
                of the state of the instances involved. This procedure details the
                reservation of a floating IP address from an existing pool of addresses
                and the association of that address with a specific instance.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Access &amp; Security</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Floating IPs</span> tab, which shows the floating IP
                        addresses allocated to instances.</p></li><li class="step "><p>Click <span class="guimenu ">Allocate IP To Project</span>.</p></li><li class="step "><p>Choose the pool from which to pick the IP address.</p></li><li class="step "><p>Click <span class="guimenu ">Allocate IP</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Floating IPs</span> list, click <span class="guimenu ">Associate</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Manage Floating IP Associations</span> dialog box,
                        choose the following options:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>The <span class="guimenu ">IP Address</span> field is filled automatically,
                                but you can add a new IP address by clicking the
                                <span class="guimenu ">+</span> button.</p></li><li class="listitem "><p>In the <span class="guimenu ">Port to be associated</span> field, select a port
                                from the list.</p><p>The list shows all the instances with their fixed IP addresses.</p></li></ul></div></li><li class="step "><p>Click <span class="guimenu ">Associate</span>.</p></li></ol></div></div><div id="id-1.5.3.5.10.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To disassociate an IP address from an instance, click the
                    <span class="guimenu ">Disassociate</span> button.</p></div><p>To release the floating IP address back into the floating IP pool, click
                the <span class="guimenu ">Release Floating IP</span> option in the <span class="guimenu ">Actions</span> column.</p></div></div><div class="sect2" id="launch-and-manage-instances"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch and manage instances</span> <a title="Permalink" class="permalink" href="#launch-and-manage-instances">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>launch-instances</li><li><span class="ds-label">ID: </span>launch-and-manage-instances</li></ul></div></div></div></div><p>Instances are virtual machines that run inside the cloud.
            You can launch an instance from the following sources:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Images uploaded to the Image service.</p></li><li class="listitem "><p>Image that you have copied to a persistent volume. The instance
                    launches from the volume, which is provided by the <code class="literal">cinder-volume</code>
                    API through iSCSI.</p></li><li class="listitem "><p>Instance snapshot that you took.</p></li></ul></div><div class="sect3" id="launch-an-instance"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch an instance</span> <a title="Permalink" class="permalink" href="#launch-an-instance">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>launch-instances</li><li><span class="ds-label">ID: </span>launch-an-instance</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Instances</span> category.</p><p>The dashboard shows the instances with its name, its private and
                        floating IP addresses, size, status, task, power state, and so on.</p></li><li class="step "><p>Click <span class="guimenu ">Launch Instance</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Launch Instance</span> dialog box, specify the following values:</p><p><span class="guimenu ">Details</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.3.1"><span class="term ">Instance Name</span></dt><dd><p>Assign a name to the virtual machine.</p></dd><dt id="id-1.5.3.6.4.2.5.3.2"><span class="term ">Availability Zone</span></dt><dd><p>By default, this value is set to the availability zone given by the
                                    cloud provider (for example, <code class="literal">us-west</code> or <code class="literal">apac-south</code>). For some
                                    cases, it could be <code class="literal">nova</code>.</p><div id="id-1.5.3.6.4.2.5.3.2.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The name you assign here becomes the initial host name of the server.
                                        If the name is longer than 63 characters, the Compute service
                                        truncates it automatically to ensure dnsmasq works correctly.</p><p>After the server is built, if you change the server name in the API
                                        or change the host name directly, the names are not updated in the
                                        dashboard.</p><p>Server names are not guaranteed to be unique when created so you
                                        could have two instances with the same host name.</p></div></dd><dt id="id-1.5.3.6.4.2.5.3.3"><span class="term ">Count</span></dt><dd><p>To launch multiple instances, enter a value greater than <code class="literal">1</code>. The
                                    default is <code class="literal">1</code>.</p></dd></dl></div><p><span class="guimenu ">Source</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.5.1"><span class="term ">Instance Boot Source</span></dt><dd><p>Your options are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.5.1.2.2.1"><span class="term ">Boot from image</span></dt><dd><p>If you choose this option, a new field for <span class="guimenu ">Image Name</span>
                                                displays. You can select the image from the list.</p></dd><dt id="id-1.5.3.6.4.2.5.5.1.2.2.2"><span class="term ">Boot from snapshot</span></dt><dd><p>If you choose this option, a new field for <span class="guimenu ">Instance
                                                    Snapshot</span> displays. You can select the snapshot from the list.</p></dd><dt id="id-1.5.3.6.4.2.5.5.1.2.2.3"><span class="term ">Boot from volume</span></dt><dd><p>If you choose this option, a new field for <span class="guimenu ">Volume</span>
                                                displays. You can select the volume from the list.</p></dd><dt id="id-1.5.3.6.4.2.5.5.1.2.2.4"><span class="term ">Boot from image (creates a new volume)</span></dt><dd><p>With this option, you can boot from an image and create a volume
                                                by entering the <span class="guimenu ">Device Size</span> and <span class="guimenu ">Device
                                                    Name</span> for your volume. Click the <span class="guimenu ">Delete Volume on
                                                    Instance Delete</span> option to delete the volume on deleting the
                                                instance.</p></dd><dt id="id-1.5.3.6.4.2.5.5.1.2.2.5"><span class="term ">Boot from volume snapshot (creates a new volume)</span></dt><dd><p>Using this option, you can boot from a volume snapshot and create
                                                a new volume by choosing <span class="guimenu ">Volume Snapshot</span> from a list
                                                and adding a <span class="guimenu ">Device Name</span> for your volume. Click the
                                                <span class="guimenu ">Delete Volume on Instance Delete</span> option to delete the
                                                volume on deleting the instance.</p></dd></dl></div></dd><dt id="id-1.5.3.6.4.2.5.5.2"><span class="term ">Image Name</span></dt><dd><p>This field changes based on your previous selection. If you have
                                    chosen to launch an instance using an image, the <span class="guimenu ">Image Name</span>
                                    field displays. Select the image name from the dropdown list.</p></dd><dt id="id-1.5.3.6.4.2.5.5.3"><span class="term ">Instance Snapshot</span></dt><dd><p>This field changes based on your previous selection. If you have
                                    chosen to launch an instance using a snapshot, the
                                    <span class="guimenu ">Instance Snapshot</span> field displays.
                                    Select the snapshot name from the dropdown list.</p></dd><dt id="id-1.5.3.6.4.2.5.5.4"><span class="term ">Volume</span></dt><dd><p>This field changes based on your previous selection. If you have
                                    chosen to launch an instance using a volume, the <span class="guimenu ">Volume</span>
                                    field displays. Select the volume name from the dropdown list.
                                    If you want to delete the volume on instance delete,
                                    check the <span class="guimenu ">Delete Volume on Instance Delete</span> option.</p></dd></dl></div><p><span class="guimenu ">Flavor</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.7.1"><span class="term ">Flavor</span></dt><dd><p>Specify the size of the instance to launch.</p><div id="id-1.5.3.6.4.2.5.7.1.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The flavor is selected based on the size of the image selected
                                        for launching an instance. For example, while creating an image, if
                                        you have entered the value in the <span class="guimenu ">Minimum RAM (MB)</span> field
                                        as 2048, then on selecting the image, the default flavor is
                                        <code class="literal">m1.small</code>.</p></div></dd></dl></div><p><span class="guimenu ">Networks</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.9.1"><span class="term ">Selected Networks</span></dt><dd><p>To add a network to the instance, click the <span class="guimenu ">+</span> in the
                                    <span class="guimenu ">Available</span> field.</p></dd></dl></div><p><span class="guimenu ">Network Ports</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.11.1"><span class="term ">Ports</span></dt><dd><p>Activate the ports that you want to assign to the instance.</p></dd></dl></div><p><span class="guimenu ">Security Groups</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.13.1"><span class="term ">Security Groups</span></dt><dd><p>Activate the security groups that you want to assign to the instance.</p><p>Security groups are a kind of cloud firewall that define which
                                    incoming network traffic is forwarded to instances.</p><p>If you have not created any security groups, you can assign
                                    only the default security group to the instance.</p></dd></dl></div><p><span class="guimenu ">Key Pair</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.15.1"><span class="term ">Key Pair</span></dt><dd><p>Specify a key pair.</p><p>If the image uses a static root password or a static key set
                                    (neither is recommended), you do not need to provide a key pair
                                    to launch the instance.</p></dd></dl></div><p><span class="guimenu ">Configuration</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.17.1"><span class="term ">Customization Script Source</span></dt><dd><p>Specify a customization script that runs after your instance
                                    launches.</p></dd></dl></div><p><span class="guimenu ">Metadata</span> tab</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.6.4.2.5.19.1"><span class="term ">Available Metadata</span></dt><dd><p>Add Metadata items to your instance.</p></dd></dl></div></li><li class="step "><p>Click <span class="guimenu ">Launch Instance</span>.</p><p>The instance starts on a compute node in the cloud.</p></li></ol></div></div><div id="id-1.5.3.6.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If you did not provide a key pair, security groups, or rules, users
                    can access the instance only from inside the cloud through VNC. Even
                    pinging the instance is not possible without an ICMP rule configured.</p></div><p>You can also launch an instance from the <span class="guimenu ">Images</span> or
                <span class="guimenu ">Volumes</span> category when you launch an instance from
                an image or a volume respectively.</p><p>When you launch an instance from an image, OpenStack creates a local
                copy of the image on the compute node where the instance starts.</p><p>For details on creating images, see <a class="link" href="https://docs.openstack.org/image-guide/create-images-manually.html" target="_blank">Creating images
                    manually</a>
                in the <span class="emphasis"><em>OpenStack Virtual Machine Image Guide</em></span>.</p><p>When you launch an instance from a volume, note the following steps:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>To select the volume from which to launch, launch an instance from
                        an arbitrary image on the volume. The arbitrary image that you select
                        does not boot. Instead, it is replaced by the image on the volume that
                        you choose in the next steps.</p><p>To boot a Xen image from a volume, the image you launch in must be
                        the same type, fully virtualized or paravirtualized, as the one on
                        the volume.</p></li><li class="listitem "><p>Select the volume or volume snapshot from which to boot. Enter a
                        device name. Enter <code class="literal">vda</code> for KVM images or <code class="literal">xvda</code> for Xen images.</p></li></ul></div><div id="id-1.5.3.6.4.9" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>When running QEMU without support for the hardware virtualization, set
                    <code class="literal">cpu_mode="none"</code> alongside <code class="literal">virt_type=qemu</code> in
                    <code class="literal">/etc/nova/nova-compute.conf</code> to solve the following error:</p><div class="verbatim-wrap"><pre class="screen">libvirtError: unsupported configuration: CPU mode 'host-model'
for ``x86_64`` qemu domain on ``x86_64`` host is not supported by hypervisor</pre></div></div></div><div class="sect3" id="connect-to-your-instance-by-using-ssh"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Connect to your instance by using SSH</span> <a title="Permalink" class="permalink" href="#connect-to-your-instance-by-using-ssh">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>launch-instances</li><li><span class="ds-label">ID: </span>connect-to-your-instance-by-using-ssh</li></ul></div></div></div></div><p>To use SSH to connect to your instance, use the downloaded keypair
                file.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Copy the IP address for your instance.</p></li><li class="step "><p>Use the <code class="command">ssh</code> command to make a secure connection to the instance.</p></li><li class="step "><p>At the prompt, type <code class="literal">yes</code>.</p></li></ol></div></div><p>It is also possible to SSH into an instance without an SSH keypair, if the
                administrator has enabled root password injection.  For more information
                about root password injection, see <a class="link" href="https://docs.openstack.org/nova/latest/admin/admin-password-injection.html" target="_blank">Injecting the administrator password</a>
                in the <span class="emphasis"><em>OpenStack Administrator Guide</em></span>.</p></div><div class="sect3" id="track-usage-for-instances"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Track usage for instances</span> <a title="Permalink" class="permalink" href="#track-usage-for-instances">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>launch-instances</li><li><span class="ds-label">ID: </span>track-usage-for-instances</li></ul></div></div></div></div><p>You can track usage for instances for each project. You can track costs
                per month by showing meters like number of vCPUs, disks, RAM, and
                uptime for all your instances.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Overview</span> category.</p></li><li class="step "><p>To query the instance usage for a month, select a month and click
                        <span class="guimenu ">Submit</span>.</p></li><li class="step "><p>To download a summary, click <span class="guimenu ">Download CSV Summary</span>.</p></li></ol></div></div></div><div class="sect3" id="create-an-instance-snapshot"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create an instance snapshot</span> <a title="Permalink" class="permalink" href="#create-an-instance-snapshot">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>launch-instances</li><li><span class="ds-label">ID: </span>create-an-instance-snapshot</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click the <span class="guimenu ">Instances</span> category.</p></li><li class="step "><p>Select the instance from which to create a snapshot.</p></li><li class="step "><p>In the actions column, click <span class="guimenu ">Create Snapshot</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Snapshot</span> dialog box, enter a name for the
                        snapshot, and click <span class="guimenu ">Create Snapshot</span>.</p><p>The <span class="guimenu ">Images</span> category shows the instance snapshot.</p></li></ol></div></div><p>To launch an instance from the snapshot, select the snapshot and click
                <span class="guimenu ">Launch</span>. Proceed with launching an instance.</p></div><div class="sect3" id="manage-an-instance"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.4.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage an instance</span> <a title="Permalink" class="permalink" href="#manage-an-instance">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>launch-instances</li><li><span class="ds-label">ID: </span>manage-an-instance</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Instances</span> category.</p></li><li class="step "><p>Select an instance.</p></li><li class="step "><p>In the menu list in the actions column, select the state.</p><p>You can resize or rebuild an instance. You can also choose to view
                        the instance console log, edit instance or the security groups.
                        Depending on the current state of the instance, you can pause,
                        resume, suspend, soft or hard reboot, or terminate it.</p></li></ol></div></div></div></div><div class="sect2" id="create-and-manage-networks"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage networks</span> <a title="Permalink" class="permalink" href="#create-and-manage-networks">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>create-networks</li><li><span class="ds-label">ID: </span>create-and-manage-networks</li></ul></div></div></div></div><p>The OpenStack Networking service provides a scalable system for managing
            the network connectivity within an OpenStack cloud deployment. It can
            easily and quickly react to changing network needs (for example,
            creating and assigning new IP addresses).</p><p>Networking in OpenStack is complex. This section provides the basic
            instructions for creating a network and a router. For detailed
            information about managing networks, refer to the <a class="link" href="https://docs.openstack.org/neutron/latest/admin/" target="_blank">OpenStack Networking Guide</a>.</p><div class="sect3" id="create-a-network"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a network</span> <a title="Permalink" class="permalink" href="#create-a-network">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>create-networks</li><li><span class="ds-label">ID: </span>create-a-network</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Network</span> tab and
                        click <span class="guimenu ">Networks</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Create Network</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Network</span> dialog box, specify the following values.</p><p><span class="guimenu ">Network</span> tab</p><p><span class="guimenu ">Network Name</span>: Specify a name to identify the network.</p><p><span class="guimenu ">Shared</span>: Share the network with other projects. Non admin users
                        are not allowed to set shared option.</p><p><span class="guimenu ">Admin State</span>: The state to start the network in.</p><p><span class="guimenu ">Create Subnet</span>: Select this check box to create a subnet</p><p>You do not have to specify a subnet when you create a network, but if
                        you do not specify a subnet, the network can not be attached to an instance.</p><p><span class="guimenu ">Subnet</span> tab</p><p><span class="guimenu ">Subnet Name</span>: Specify a name for the subnet.</p><p><span class="guimenu ">Network Address</span>: Specify the IP address for the subnet.</p><p><span class="guimenu ">IP Version</span>: Select IPv4 or IPv6.</p><p><span class="guimenu ">Gateway IP</span>: Specify an IP address for a specific gateway. This
                        parameter is optional.</p><p><span class="guimenu ">Disable Gateway</span>: Select this check box to disable a gateway IP
                        address.</p><p><span class="guimenu ">Subnet Details</span> tab</p><p><span class="guimenu ">Enable DHCP</span>: Select this check box to enable DHCP.</p><p><span class="guimenu ">Allocation Pools</span>: Specify IP address pools.</p><p><span class="guimenu ">DNS Name Servers</span>: Specify a name for the DNS server.</p><p><span class="guimenu ">Host Routes</span>: Specify the IP address of host routes.</p></li><li class="step "><p>Click <span class="guimenu ">Create</span>.</p><p>The dashboard shows the network on the <span class="guimenu ">Networks</span> tab.</p></li></ol></div></div></div><div class="sect3" id="create-a-router"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a router</span> <a title="Permalink" class="permalink" href="#create-a-router">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>create-networks</li><li><span class="ds-label">ID: </span>create-a-router</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Network</span> tab and
                        click <span class="guimenu ">Routers</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Create Router</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Router</span> dialog box, specify a name for the router
                        and <span class="guimenu ">External Network</span>, and click <span class="guimenu ">Create Router</span>.</p><p>The new router is now displayed in the <span class="guimenu ">Routers</span> tab.</p></li><li class="step "><p>To connect a private network to the newly created router, perform the
                        following steps:</p><ol type="a" class="substeps "><li class="step "><p>On the <span class="guimenu ">Routers</span> tab, click the name of the router.</p></li><li class="step "><p>On the <span class="guimenu ">Router Details</span> page, click the <span class="guimenu ">Interfaces</span>
                                tab, then click <span class="guimenu ">Add Interface</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Add Interface</span> dialog box, select a <span class="guimenu ">Subnet</span>.</p><p>Optionally, in the <span class="guimenu ">Add Interface</span> dialog box, set an
                                <span class="guimenu ">IP Address</span> for the router interface for the selected subnet.</p><p>If you choose not to set the <span class="guimenu ">IP Address</span> value, then by
                                default OpenStack Networking uses the first host IP address in the
                                subnet.</p><p>The <span class="guimenu ">Router Name</span> and <span class="guimenu ">Router ID</span> fields are
                                automatically updated.</p></li></ol></li><li class="step "><p>Click <span class="guimenu ">Add Interface</span>.</p></li></ol></div></div><p>You have successfully created the router. You can view the new topology
                from the <span class="guimenu ">Network Topology</span> tab.</p></div><div class="sect3" id="create-a-port"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a port</span> <a title="Permalink" class="permalink" href="#create-a-port">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>create-networks</li><li><span class="ds-label">ID: </span>create-a-port</li></ul></div></div></div></div><div id="id-1.5.3.7.6.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg" /><h6>Warning</h6><p>Creating and managing ports requires administrator privileges.
                    Contact an administrator before adding or changing ports.</p></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop-down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Admin</span> tab, click <span class="guimenu ">Networks</span> category.</p></li><li class="step "><p>Click on the <span class="guimenu ">Network Name</span> of the network in which the port
                        has to be created.</p></li><li class="step "><p>In the <span class="guimenu ">Create Port</span> dialog box, specify the following values.</p><p><span class="guimenu ">Name</span>: Specify name to identify the port.</p><p><span class="guimenu ">Device ID</span>: Device ID attached to the port.</p><p><span class="guimenu ">Device Owner</span>: Device owner attached to the port.</p><p><span class="guimenu ">Binding Host</span>: The ID of the host where the port is allocated.</p><p><span class="guimenu ">Binding VNIC Type</span>: Select the VNIC type that is bound to the
                        neutron port.</p></li><li class="step "><p>Click <span class="guimenu ">Create Port</span>.</p><p>The new port is now displayed in the <span class="guimenu ">Ports</span> list.</p></li></ol></div></div></div></div><div class="sect2" id="create-and-manage-object-containers"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage object containers</span> <a title="Permalink" class="permalink" href="#create-and-manage-object-containers">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-containers</li><li><span class="ds-label">ID: </span>create-and-manage-object-containers</li></ul></div></div></div></div><p>OpenStack Object Storage (swift) is used for redundant, scalable data storage
            using clusters of standardized servers to store petabytes of accessible data.
            It is a long-term storage system for large amounts of static data which can be
            retrieved and updated.</p><p>OpenStack Object Storage provides a distributed, API-accessible storage
            platform that can be integrated directly into an application or used to
            store any type of file, including VM images, backups, archives, or media
            files. In the OpenStack dashboard, you can only manage containers and
            objects.</p><p>In OpenStack Object Storage, containers provide storage for objects in a
            manner similar to a Windows folder or Linux file directory, though they
            cannot be nested. An object in OpenStack consists of the file to be
            stored in the container and any accompanying metadata.</p><div class="sect3" id="create-a-container"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a container</span> <a title="Permalink" class="permalink" href="#create-a-container">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-containers</li><li><span class="ds-label">ID: </span>create-a-container</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Object Store</span> tab and
                        click <span class="guimenu ">Containers</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Container</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Create Container</span> dialog box, enter a name for the
                        container, and then click <span class="guimenu ">Create</span>.</p></li></ol></div></div><p>You have successfully created a container.</p><div id="id-1.5.3.8.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To delete a container, click the <span class="guimenu ">More</span> button and select
                    <span class="guimenu ">Delete Container</span>.</p></div></div><div class="sect3" id="upload-an-object"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Upload an object</span> <a title="Permalink" class="permalink" href="#upload-an-object">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-containers</li><li><span class="ds-label">ID: </span>upload-an-object</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Object Store</span> tab and
                        click <span class="guimenu ">Containers</span> category.</p></li><li class="step "><p>Select the container in which you want to store your object.</p></li><li class="step "><p>Click the <span class="guimenu ">Upload File</span> icon.</p><p>The <span class="guimenu ">Upload File To Container: &lt;name&gt;</span> dialog box
                        appears.
                        <code class="literal">&lt;name&gt;</code> is the name of the container to which you are uploading
                        the object.</p></li><li class="step "><p>Enter a name for the object.</p></li><li class="step "><p>Browse to and select the file that you want to upload.</p></li><li class="step "><p>Click <span class="guimenu ">Upload File</span>.</p></li></ol></div></div><p>You have successfully uploaded an object to the container.</p><div id="id-1.5.3.8.6.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To delete an object, click the <span class="guimenu ">More button</span> and select
                    <span class="guimenu ">Delete Object</span>.</p></div></div><div class="sect3" id="manage-an-object"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage an object</span> <a title="Permalink" class="permalink" href="#manage-an-object">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-containers</li><li><span class="ds-label">ID: </span>manage-an-object</li></ul></div></div></div></div><p>
            <span class="bold"><strong>To edit an object</strong></span>
          </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Object Store</span> tab and
                        click <span class="guimenu ">Containers</span> category.</p></li><li class="step "><p>Select the container in which you want to store your object.</p></li><li class="step "><p>Click the menu button and choose <span class="guimenu ">Edit</span> from the dropdown list.</p><p>The <span class="guimenu ">Edit Object</span> dialog box is displayed.</p></li><li class="step "><p>Browse to and select the file that you want to upload.</p></li><li class="step "><p>Click <span class="guimenu ">Update Object</span>.</p></li></ol></div></div><div id="id-1.5.3.8.7.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>To delete an object, click the menu button and select
                    <span class="guimenu ">Delete Object</span>.</p></div><p>
            <span class="bold"><strong>To copy an object from one container to another</strong></span>
          </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Object Store</span> tab and
                        click <span class="guimenu ">Containers</span> category.</p></li><li class="step "><p>Select the container in which you want to store your object.</p></li><li class="step "><p>Click the menu button and choose <span class="guimenu ">Copy</span> from the dropdown list.</p></li><li class="step "><p>In the <span class="guimenu ">Copy Object</span> launch dialog box, enter the following
                        values:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><span class="guimenu ">Destination Container</span>: Choose the destination container from
                                the list.</p></li><li class="listitem "><p><span class="guimenu ">Path</span>: Specify a path in which the new copy should be stored
                                inside of the selected container.</p></li><li class="listitem "><p><span class="guimenu ">Destination object name</span>: Enter a name for the object in the
                                new container.</p></li></ul></div></li><li class="step "><p>Click <span class="guimenu ">Copy Object</span>.</p></li></ol></div></div><p>
            <span class="bold"><strong>To create a metadata-only object without a file</strong></span>
          </p><p>You can create a new object in container without a file available and
                can upload the file later when it is ready. This temporary object acts a
                place-holder for a new object, and enables the user to share object
                metadata and URL info in advance.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Object Store</span> tab and
                        click <span class="guimenu ">Containers</span> category.</p></li><li class="step "><p>Select the container in which you want to store your object.</p></li><li class="step "><p>Click <span class="guimenu ">Upload Object</span>.</p><p>The <span class="guimenu ">Upload Object To Container</span>: <code class="literal">&lt;name&gt;</code> dialog box is
                        displayed.</p><p><code class="literal">&lt;name&gt;</code> is the name of the container to which you are uploading
                        the object.</p></li><li class="step "><p>Enter a name for the object.</p></li><li class="step "><p>Click <span class="guimenu ">Update Object</span>.</p></li></ol></div></div><p>
            <span class="bold"><strong>To create a pseudo-folder</strong></span>
          </p><p>Pseudo-folders are similar to folders in your desktop operating system.
                They are virtual collections defined by a common prefix on the object’s
                name.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Object Store</span> tab and
                        click <span class="guimenu ">Containers</span> category.</p></li><li class="step "><p>Select the container in which you want to store your object.</p></li><li class="step "><p>Click <span class="guimenu ">Create Pseudo-folder</span>.</p><p>The <span class="guimenu ">Create Pseudo-Folder in Container</span><code class="literal">&lt;name&gt;</code> dialog box
                        is displayed. <code class="literal">&lt;name&gt;</code> is the name of the container to which you
                        are uploading the object.</p></li><li class="step "><p>Enter a name for the pseudo-folder.</p><p>A slash (/) character is used as the delimiter for pseudo-folders in
                        Object Storage.</p></li><li class="step "><p>Click <span class="guimenu ">Create</span>.</p></li></ol></div></div></div></div><div class="sect2" id="create-and-manage-volumes"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage volumes</span> <a title="Permalink" class="permalink" href="#create-and-manage-volumes">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>create-and-manage-volumes</li></ul></div></div></div></div><p>Volumes are block storage devices that you attach to instances to enable
            persistent storage. You can attach a volume to a running instance or
            detach a volume and attach it to another instance at any time. You can
            also create a snapshot from or delete a volume. Only administrative
            users can create volume types.</p><div class="sect3" id="create-a-volume"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a volume</span> <a title="Permalink" class="permalink" href="#create-a-volume">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>create-a-volume</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Create Volume</span>.</p><p>In the dialog box that opens, enter or select the following values.</p><p><span class="guimenu ">Volume Name</span>: Specify a name for the volume.</p><p><span class="guimenu ">Description</span>: Optionally, provide a brief description for the
                        volume.</p><p><span class="guimenu ">Volume Source</span>: Select one of the following options:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>No source, empty volume: Creates an empty volume. An empty volume does
                                not contain a file system or a partition table.</p></li><li class="listitem "><p>Snapshot: If you choose this option, a new field for
                                <span class="guimenu ">Use snapshot as a source</span> displays. You can select the
                                snapshot from the list.</p></li><li class="listitem "><p>Image: If you choose this option, a new field for <span class="guimenu ">Use image
                                    as a source</span> displays. You can select the image from the list.</p></li><li class="listitem "><p>Volume: If you choose this option, a new field for
                                <span class="guimenu ">Use volume as a source</span> displays. You can select the volume
                                from the list. Options to use a snapshot or a volume as the source for a
                                volume are displayed only if there are existing snapshots or volumes.</p></li></ul></div><p><span class="guimenu ">Type</span>: Leave this field blank.</p><p><span class="guimenu ">Size (GB)</span>: The size of the volume in gibibytes (GiB).</p><p><span class="guimenu ">Availability Zone</span>: Select the Availability Zone from the list.
                        By default, this value is set to the availability zone given by the cloud
                        provider (for example, <code class="literal">us-west</code> or <code class="literal">apac-south</code>). For some cases,
                        it could be <code class="literal">nova</code>.</p></li><li class="step "><p>Click <span class="guimenu ">Create Volume</span>.</p></li></ol></div></div><p>The dashboard shows the volume on the <span class="guimenu ">Volumes</span> tab.</p></div><div class="sect3" id="attach-a-volume-to-an-instance-dash"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Attach a volume to an instance</span> <a title="Permalink" class="permalink" href="#attach-a-volume-to-an-instance-dash">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>attach-a-volume-to-an-instance-dash</li></ul></div></div></div></div><p>After you create one or more volumes, you can attach them to instances.
                You can attach a volume to one instance at a time.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Select the volume to add to an instance and click
                        <span class="guimenu ">Manage Attachments</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Manage Volume Attachments</span> dialog box, select an instance.</p></li><li class="step "><p>Enter the name of the device from which the volume is accessible by
                        the instance.</p><div id="id-1.5.3.9.4.3.6.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>The actual device name might differ from the volume name because
                            of hypervisor settings.</p></div></li><li class="step "><p>Click <span class="guimenu ">Attach Volume</span>.</p><p>The dashboard shows the instance to which the volume is now attached
                        and the device name.</p></li></ol></div></div><p>You can view the status of a volume in the Volumes tab of the dashboard.
                The volume is either Available or In-Use.</p><p>Now you can log in to the instance and mount, format, and use the disk.</p></div><div class="sect3" id="detach-a-volume-from-an-instance"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Detach a volume from an instance</span> <a title="Permalink" class="permalink" href="#detach-a-volume-from-an-instance">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>detach-a-volume-from-an-instance</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click the <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Select the volume and click <span class="guimenu ">Manage Attachments</span>.</p></li><li class="step "><p>Click <span class="guimenu ">Detach Volume</span> and confirm your changes.</p></li></ol></div></div><p>A message indicates whether the action was successful.</p></div><div class="sect3" id="create-a-snapshot-from-a-volume"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a snapshot from a volume</span> <a title="Permalink" class="permalink" href="#create-a-snapshot-from-a-volume">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>create-a-snapshot-from-a-volume</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Select a volume from which to create a snapshot.</p></li><li class="step "><p>In the <span class="guimenu ">Actions</span> column, click <span class="guimenu ">Create Snapshot</span>.</p></li><li class="step "><p>In the dialog box that opens, enter a snapshot name and a brief
                        description.</p></li><li class="step "><p>Confirm your changes.</p><p>The dashboard shows the new volume snapshot in Volume Snapshots tab.</p></li></ol></div></div></div><div class="sect3" id="edit-a-volume"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.7.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit a volume</span> <a title="Permalink" class="permalink" href="#edit-a-volume">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>edit-a-volume</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Select the volume that you want to edit.</p></li><li class="step "><p>In the <span class="guimenu ">Actions</span> column, click <span class="guimenu ">Edit Volume</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Edit Volume</span> dialog box, update the name and description
                        of the volume.</p></li><li class="step "><p>Click <span class="guimenu ">Edit Volume</span>.</p><div id="id-1.5.3.9.7.2.7.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>You can extend a volume by using the <span class="guimenu ">Extend Volume</span>
                            option available in the <span class="guimenu ">More</span> dropdown list and entering the
                            new value for volume size.</p></div></li></ol></div></div></div><div class="sect3" id="delete-a-volume"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.7.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a volume</span> <a title="Permalink" class="permalink" href="#delete-a-volume">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-volumes</li><li><span class="ds-label">ID: </span>delete-a-volume</li></ul></div></div></div></div><p>When you delete an instance, the data in its attached volumes is not
                deleted.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Compute</span> tab and
                        click <span class="guimenu ">Volumes</span> category.</p></li><li class="step "><p>Select the check boxes for the volumes that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Volumes</span> and confirm your choice.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div></div><div class="sect2" id="create-and-manage-shares"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage shares</span> <a title="Permalink" class="permalink" href="#create-and-manage-shares">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>create-and-manage-shares</li></ul></div></div></div></div><p>Shares are file storage that you provide access to instances. You can allow
            access to a share to a running instance or deny access to a share and allow
            access to it to another instance at any time. You can also delete a share.
            You can create snapshot from a share if the driver supports it. Only
            administrative users can create share types.</p><div class="sect3" id="create-a-share"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a share</span> <a title="Permalink" class="permalink" href="#create-a-share">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>create-a-share</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Click <span class="guimenu ">Create Share</span>.</p><p>In the dialog box that opens, enter or select the following values.</p><p><span class="guimenu ">Share Name</span>: Specify a name for the share.</p><p><span class="guimenu ">Description</span>: Optionally, provide a brief description for the
                        share.</p><p><span class="guimenu ">Share Type</span>: Choose a share type.</p><p><span class="guimenu ">Size (GB)</span>: The size of the share in gibibytes (GiB).</p><p><span class="guimenu ">Share Protocol</span>: Select NFS, CIFS, GlusterFS, or HDFS.</p><p><span class="guimenu ">Share Network</span>: Choose a share network.</p><p><span class="guimenu ">Metadata</span>: Enter metadata for the share creation if needed.</p></li><li class="step "><p>Click <span class="guimenu ">Create Share</span>.</p></li></ol></div></div><p>The dashboard shows the share on the <span class="guimenu ">Shares</span> tab.</p></div><div class="sect3" id="delete-a-share"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a share</span> <a title="Permalink" class="permalink" href="#delete-a-share">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>delete-a-share</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Select the check boxes for the shares that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Shares</span> and confirm your choice.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="allow-access"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Allow access</span> <a title="Permalink" class="permalink" href="#allow-access">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>allow-access</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Go to the share that you want to allow access and choose
                        <span class="guimenu ">Manage Rules</span> from Actions.</p></li><li class="step "><p>Click <span class="guimenu ">Add rule</span>.</p><p><span class="guimenu ">Access Type</span>: Choose ip, user, or cert.</p><p><span class="guimenu ">Access Level</span>: Choose read-write or read-only.</p><p><span class="guimenu ">Access To</span>: Fill in Access To field.</p></li><li class="step "><p>Click <span class="guimenu ">Add Rule</span>.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="deny-access"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deny access</span> <a title="Permalink" class="permalink" href="#deny-access">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>deny-access</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Go to the share that you want to deny access and choose
                        <span class="guimenu ">Manage Rules</span> from Actions.</p></li><li class="step "><p>Choose the rule you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete rule</span> and confirm your choice.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="edit-share-metadata"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit share metadata</span> <a title="Permalink" class="permalink" href="#edit-share-metadata">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>edit-share-metadata</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Go to the share that you want to edit and choose
                        <span class="guimenu ">Edit Share Metadata</span> from Actions.</p></li><li class="step "><p><span class="guimenu ">Metadata</span>: To add share metadata, use key=value. To unset
                        metadata, use key.</p></li><li class="step "><p>Click <span class="guimenu ">Edit Share Metadata</span>.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="edit-share"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit share</span> <a title="Permalink" class="permalink" href="#edit-share">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>edit-share</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Go to the share that you want to edit and choose <span class="guimenu ">Edit Share</span> from
                        Actions.</p></li><li class="step "><p><span class="guimenu ">Share Name</span>: Enter a new share name.</p></li><li class="step "><p><span class="guimenu ">Description</span>: Enter a new description.</p></li><li class="step "><p>Click <span class="guimenu ">Edit Share</span>.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="extend-share"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Extend share</span> <a title="Permalink" class="permalink" href="#extend-share">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>extend-share</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, and click <span class="guimenu ">Shares</span>.</p></li><li class="step "><p>Go to the share that you want to edit and choose <span class="guimenu ">Extend Share</span>
                        from Actions.</p></li><li class="step "><p><span class="guimenu ">New Size (GB)</span>: Enter new size.</p></li><li class="step "><p>Click <span class="guimenu ">Extend Share</span>.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="create-share-network"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create share network</span> <a title="Permalink" class="permalink" href="#create-share-network">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>create-share-network</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, click <span class="guimenu ">Shares</span>,
                        and click <span class="guimenu ">Share Networks</span>.</p></li><li class="step "><p>Click <span class="guimenu ">Create Share Network</span>.</p><p>In the dialog box that opens, enter or select the following values.</p><p><span class="guimenu ">Name</span>: Specify a name for the share network.</p><p><span class="guimenu ">Description</span>: Optionally, provide a brief description for the
                        share network.</p><p><span class="guimenu ">Neutron Net</span>: Choose a neutron network.</p><p><span class="guimenu ">Neutron Subnet</span>: Choose a neutron subnet.</p></li><li class="step "><p>Click <span class="guimenu ">Create Share Network</span>.</p></li></ol></div></div><p>The dashboard shows the share network on the <span class="guimenu ">Share Networks</span> tab.</p></div><div class="sect3" id="delete-a-share-network"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a share network</span> <a title="Permalink" class="permalink" href="#delete-a-share-network">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>delete-a-share-network</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, click <span class="guimenu ">Shares</span>, and
                        click <span class="guimenu ">Share Networks</span>.</p></li><li class="step "><p>Select the check boxes for the share networks that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Share Networks</span> and confirm your choice.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="edit-share-network"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit share network</span> <a title="Permalink" class="permalink" href="#edit-share-network">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>edit-share-network</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, click <span class="guimenu ">Shares</span>, and
                        click <span class="guimenu ">Share Networks</span>.</p></li><li class="step "><p>Go to the share network that you want to edit and choose
                        <span class="guimenu ">Edit Share Network</span> from Actions.</p></li><li class="step "><p><span class="guimenu ">Name</span>: Enter a new share network name.</p></li><li class="step "><p><span class="guimenu ">Description</span>: Enter a new description.</p></li><li class="step "><p>Click <span class="guimenu ">Edit Share Network</span>.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="create-security-service"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create security service</span> <a title="Permalink" class="permalink" href="#create-security-service">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>create-security-service</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, click <span class="guimenu ">Shares</span>,
                        and click <span class="guimenu ">Security Services</span>.</p></li><li class="step "><p>Click <span class="guimenu ">Create Security Service</span>.</p><p>In the dialog box that opens, enter or select the following values.</p><p><span class="guimenu ">Name</span>: Specify a name for the security service.</p><p><span class="guimenu ">DNS IP</span>: Enter the DNS IP address.</p><p><span class="guimenu ">Server</span>: Enter the server name.</p><p><span class="guimenu ">Domain</span>: Enter the domain name.</p><p><span class="guimenu ">User</span>: Enter the user name.</p><p><span class="guimenu ">Password</span>: Enter the password.</p><p><span class="guimenu ">Confirm Password</span>: Enter the password again to confirm.</p><p><span class="guimenu ">Type</span>: Choose the type from Active Directory, LDAP, or Kerberos.</p><p><span class="guimenu ">Description</span>: Optionally, provide a brief description for the
                        security service.</p></li><li class="step "><p>Click <span class="guimenu ">Create Security Service</span>.</p></li></ol></div></div><p>The dashboard shows the security service on the <span class="guimenu ">Security Services</span>
                tab.</p></div><div class="sect3" id="delete-a-security-service"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a security service</span> <a title="Permalink" class="permalink" href="#delete-a-security-service">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>delete-a-security-service</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, click <span class="guimenu ">Shares</span>, and
                        click <span class="guimenu ">Security Services</span>.</p></li><li class="step "><p>Select the check boxes for the security services that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Security Services</span> and confirm your choice.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div><div class="sect3" id="edit-security-service"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.8.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Edit security service</span> <a title="Permalink" class="permalink" href="#edit-security-service">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-shares</li><li><span class="ds-label">ID: </span>edit-security-service</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard, choose a project, click <span class="guimenu ">Shares</span>,
                        and click <span class="guimenu ">Security Services</span>.</p></li><li class="step "><p>Go to the security service that you want to edit and choose
                        <span class="guimenu ">Edit Security Service</span> from Actions.</p></li><li class="step "><p><span class="guimenu ">Name</span>: Enter a new security service name.</p></li><li class="step "><p><span class="guimenu ">Description</span>: Enter a new description.</p></li><li class="step "><p>Click <span class="guimenu ">Edit Security Service</span>.</p><p>A message indicates whether the action was successful.</p></li></ol></div></div></div></div><div class="sect2" id="launch-and-manage-stacks"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch and manage stacks</span> <a title="Permalink" class="permalink" href="#launch-and-manage-stacks">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>stacks</li><li><span class="ds-label">ID: </span>launch-and-manage-stacks</li></ul></div></div></div></div><p>OpenStack Orchestration is a service that you can use to
            orchestrate multiple composite cloud applications. This
            service supports the use of both the Amazon Web Services (AWS)
            CloudFormation template format through both a Query API that
            is compatible with CloudFormation and the native OpenStack
            Heat Orchestration Template (HOT) format through a REST API.</p><p>These flexible template languages enable application
            developers to describe and automate the deployment of
            infrastructure, services, and applications. The templates
            enable creation of most OpenStack resource types, such as
            instances, floating IP addresses, volumes, security groups,
            and users. Once created, the resources are referred to as
            stacks.</p><p>The template languages are described in the <a class="link" href="https://docs.openstack.org/heat/latest/template_guide/" target="_blank">Template Guide</a>.</p><div class="sect3" id="launch-a-stack"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Launch a stack</span> <a title="Permalink" class="permalink" href="#launch-a-stack">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>stacks</li><li><span class="ds-label">ID: </span>launch-a-stack</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Orchestration</span> tab and
                        click <span class="guimenu ">Stacks</span> category.</p></li><li class="step "><p>Click <span class="guimenu ">Launch Stack</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Select Template</span> dialog box, specify the
                        following values:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="39" class="c0" /><col width="31" class="c1" /></colgroup><tbody><tr><td>
                        <p>
                          <span class="guimenu ">Template Source</span>
                        </p>
                      </td><td>
                        <p>Choose the source of the
                                            template from the list.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Template URL/File/Data</span>
                        </p>
                      </td><td>
                        <p>Depending on the source that
                                            you select, enter the URL,
                                            browse to the file location,
                                            or directly include the
                                            template.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Environment Source</span>
                        </p>
                      </td><td>
                        <p>Choose the source of the
                                            environment from the list.
                                            The environment files contain
                                            additional settings for the
                                            stack.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Environment File/Data</span>
                        </p>
                      </td><td>
                        <p>Depending on the source that
                                            you select, browse to the
                                            file location, directly
                                            include the environment</p>
                      </td></tr></tbody></table></div></li><li class="step "><p>Click <span class="guimenu ">Next</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Launch Stack</span> dialog box, specify the
                        following values:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="33" class="c0" /><col width="33" class="c1" /></colgroup><tbody><tr><td>
                        <p>
                          <span class="guimenu ">Stack Name</span>
                        </p>
                      </td><td>
                        <p>Enter a name to identify
                                            the stack.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Creation Timeout</span>
                          <span class="guimenu ">(minutes)</span>
                        </p>
                      </td><td>
                        <p>Specify the number of minutes
                                            that can elapse before the
                                            launch of the stack times out.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Rollback On Failure</span>
                        </p>
                      </td><td>
                        <p>Select this check box if you
                                            want the service to roll back
                                            changes if the stack fails to
                                            launch.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">Password for user</span>
                          <span class="guimenu ">“demo”</span>
                        </p>
                      </td><td>
                        <p>Specify the password that
                                            the default user uses when the
                                            stack is created.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">DBUsername</span>
                        </p>
                      </td><td>
                        <p>Specify the name of the
                                            database user.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">LinuxDistribution</span>
                        </p>
                      </td><td>
                        <p>Specify the Linux distribution
                                            that is used in the stack.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">DBRootPassword</span>
                        </p>
                      </td><td>
                        <p>Specify the root password for
                                            the database.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">KeyName</span>
                        </p>
                      </td><td>
                        <p>Specify the name of the key pair
                                            to use to log in to the stack.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">DBName</span>
                        </p>
                      </td><td>
                        <p>Specify the name of the
                                            database.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">DBPassword</span>
                        </p>
                      </td><td>
                        <p>Specify the password of the
                                            database.</p>
                      </td></tr><tr><td>
                        <p>
                          <span class="guimenu ">InstanceType</span>
                        </p>
                      </td><td>
                        <p>Specify the flavor for the
                                            instance.</p>
                      </td></tr></tbody></table></div></li><li class="step "><p>Click <span class="guimenu ">Launch</span> to create a stack. The <span class="guimenu ">Stacks</span>
                        tab shows the stack.</p></li></ol></div></div><p>After the stack is created, click on the stack name to see the
                following details:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.11.5.4.1"><span class="term ">Topology</span></dt><dd><p>The topology of the stack.</p></dd><dt id="id-1.5.3.11.5.4.2"><span class="term ">Overview</span></dt><dd><p>The parameters and details of the stack.</p></dd><dt id="id-1.5.3.11.5.4.3"><span class="term ">Resources</span></dt><dd><p>The resources used by the stack.</p></dd><dt id="id-1.5.3.11.5.4.4"><span class="term ">Events</span></dt><dd><p>The events related to the stack.</p></dd><dt id="id-1.5.3.11.5.4.5"><span class="term ">Template</span></dt><dd><p>The template for the stack.</p></dd></dl></div></div><div class="sect3" id="manage-a-stack"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manage a stack</span> <a title="Permalink" class="permalink" href="#manage-a-stack">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>stacks</li><li><span class="ds-label">ID: </span>manage-a-stack</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Orchestration</span> tab and
                        click <span class="guimenu ">Stacks</span> category.</p></li><li class="step "><p>Select the stack that you want to update.</p></li><li class="step "><p>Click <span class="guimenu ">Change Stack Template</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Select Template</span> dialog box, select the
                        new template source or environment source.</p></li><li class="step "><p>Click <span class="guimenu ">Next</span>.</p><p>The <span class="guimenu ">Update Stack Parameters</span> window appears.</p></li><li class="step "><p>Enter new values for any parameters that you want to update.</p></li><li class="step "><p>Click <span class="guimenu ">Update</span>.</p></li></ol></div></div></div><div class="sect3" id="delete-a-stack"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a stack</span> <a title="Permalink" class="permalink" href="#delete-a-stack">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>stacks</li><li><span class="ds-label">ID: </span>delete-a-stack</li></ul></div></div></div></div><p>When you delete a stack, you cannot undo this action.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>Select the appropriate project from the drop down menu at the top left.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Orchestration</span> tab and
                        click <span class="guimenu ">Stacks</span> category.</p></li><li class="step "><p>Select the stack that you want to delete.</p></li><li class="step "><p>Click <span class="guimenu ">Delete Stack</span>.</p></li><li class="step "><p>In the confirmation dialog box, click <span class="guimenu ">Delete Stack</span>
                        to confirm the deletion.</p></li></ol></div></div></div></div><div class="sect2" id="create-and-manage-databases"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create and manage databases</span> <a title="Permalink" class="permalink" href="#create-and-manage-databases">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>create-and-manage-databases</li></ul></div></div></div></div><p>The Database service provides scalable and reliable cloud provisioning
            functionality for both relational and non-relational database engines.
            Users can quickly and easily use database features without the burden of
            handling complex administrative tasks.</p><div class="sect3" id="dashboard-create-db-instance"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a database instance</span> <a title="Permalink" class="permalink" href="#dashboard-create-db-instance">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>dashboard-create-db-instance</li></ul></div></div></div></div><p><span class="bold"><strong>Prerequisites.</strong></span> Before you create a database instance, you need to
                configure a default datastore and make sure you have an appropriate
                flavor for the type of database instance you want.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
                <span class="bold"><strong>Configure a default datastore.</strong></span>
              </p><p>Because the dashboard does not let you choose a specific datastore to
                        use with an instance, you need to configure a default datastore. The
                        dashboard then uses the default datastore to create the instance.</p><ol type="a" class="substeps "><li class="step "><p>Add the following line to <code class="literal">/etc/trove/trove.conf</code>:</p><div class="verbatim-wrap"><pre class="screen">default_datastore = DATASTORE_NAME</pre></div><p>Replace <code class="literal">DATASTORE_NAME</code> with the name that the administrative
                                user set when issuing the <code class="command">trove-manage</code> command to create the
                                datastore. You can use the trove <code class="command">datastore-list</code> command to
                                display the datastores that are available in your environment.</p><p>For example, if your MySQL data store name is set to <code class="literal">mysql</code>,
                                your entry would look like this:</p><div class="verbatim-wrap"><pre class="screen">default_datastore = mysql</pre></div></li><li class="step "><p>Restart Database services on the controller node:</p><div class="verbatim-wrap"><pre class="screen"># service trove-api restart
# service trove-taskmanager restart
# service trove-conductor restart</pre></div></li></ol></li><li class="step "><p>
                <span class="bold"><strong>Verify flavor.</strong></span>
              </p><p>Make sure an appropriate flavor exists for the type of
                        database instance you want.</p></li></ol></div></div><p><span class="bold"><strong>Create database instance.</strong></span> Once you have configured a default
                datastore and verified that you have an appropriate flavor, you can
                create a database instance.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>From the CURRENT PROJECT on the <span class="guimenu ">Project</span> tab, select the
                        appropriate project.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Database</span> tab and
                        click <span class="guimenu ">Instances</span> category.  This lists the instances that
                        already exist in your environment.</p></li><li class="step "><p>Click <span class="guimenu ">Launch Instance</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Launch Database</span> dialog box, specify the following values.</p><p>Details</p><p><span class="guimenu ">Database Name</span>: Specify a name for the database instance.</p><p><span class="guimenu ">Flavor</span>: Select an appropriate flavor for the instance.</p><p><span class="guimenu ">Volume Size</span>: Select a volume size. Volume size is expressed in
                        GB.</p><p><span class="guimenu ">Initialize Databases</span>: Initial Database</p><p>Optionally provide a comma separated list of databases to create, for
                        example:</p><p><code class="literal">database1</code>, <code class="literal">database2</code>, <code class="literal">database3</code></p><p><span class="guimenu ">Initial Admin User</span>: Create an initial admin user. This user will
                        have access to all the databases you create.</p><p><span class="guimenu ">Password</span>: Specify a password associated with the initial admin
                        user you just named.</p><p><span class="guimenu ">Host</span>: Optionally, allow the user to connect only from this host.
                        If you do not specify a host, this user will be allowed to connect from
                        anywhere.</p></li><li class="step "><p>Click the <span class="guimenu ">Launch</span> button. The new database instance appears in
                        the databases list.</p></li></ol></div></div></div><div class="sect3" id="backup-and-restore-a-database"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Backup and restore a database</span> <a title="Permalink" class="permalink" href="#backup-and-restore-a-database">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>backup-and-restore-a-database</li></ul></div></div></div></div><p>You can use Database services to backup a database and store the backup
                artifact in the Object Storage service. Later on, if the original
                database is damaged, you can use the backup artifact to restore the
                database. The restore process creates a database instance.</p><p>This example shows you how to back up and restore a MySQL database.</p><div class="sect4" id="to-backup-the-database-instance"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.10.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To backup the database instance</span> <a title="Permalink" class="permalink" href="#to-backup-the-database-instance">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>to-backup-the-database-instance</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>From the CURRENT PROJECT on the <span class="guimenu ">Project</span> tab, select the
                            appropriate project.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Database</span> tab and
                            click <span class="guimenu ">Instances</span> category. This displays the existing
                            instances in your system.</p></li><li class="step "><p>Click <span class="guimenu ">Create Backup</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Backup Database</span> dialog box, specify the following
                            values:</p><p>Name</p><p>Specify a name for the backup.</p><p>Database Instance</p><p>Select the instance you want to back up.</p></li><li class="step "><p>Click <span class="guimenu ">Backup</span>. The new backup appears in the backup list.</p></li></ol></div></div></div><div class="sect4" id="to-restore-a-database-instance"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.10.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To restore a database instance</span> <a title="Permalink" class="permalink" href="#to-restore-a-database-instance">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>to-restore-a-database-instance</li></ul></div></div></div></div><p>Now assume that your original database instance is damaged and you
                    need to restore it. You do the restore by using your backup to create
                    a new database instance.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>From the CURRENT PROJECT on the <span class="guimenu ">Project</span> tab, select the
                            appropriate project.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Database</span> tab and
                            click <span class="guimenu ">Backups</span> category. This lists the available backups.</p></li><li class="step "><p>Check the backup you want to use and click <span class="guimenu ">Restore Backup</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Launch Database</span> dialog box, specify the values you
                            want for the new database instance.</p></li><li class="step "><p>Click the <span class="guimenu ">Restore From Database</span> tab and make sure that this
                            new instance is based on the correct backup.</p></li><li class="step "><p>Click <span class="guimenu ">Launch</span>.</p><p>The new instance appears in the database instances list.</p></li></ol></div></div></div></div><div class="sect3" id="update-a-database-instance"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.10.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update a database instance</span> <a title="Permalink" class="permalink" href="#update-a-database-instance">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>update-a-database-instance</li></ul></div></div></div></div><p>You can change various characteristics of a database instance,
                such as its volume size and flavor.</p><div class="sect4" id="to-change-the-volume-size-of-an-instance"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.10.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To change the volume size of an instance</span> <a title="Permalink" class="permalink" href="#to-change-the-volume-size-of-an-instance">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>to-change-the-volume-size-of-an-instance</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>From the CURRENT PROJECT on the <span class="guimenu ">Project</span> tab, select the
                            appropriate project.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Database</span> tab and
                            click <span class="guimenu ">Instances</span> category. This displays the existing
                            instances in your system.</p></li><li class="step "><p>Check the instance you want to work with.
                            In the <span class="guimenu ">Actions</span> column, expand the drop down menu
                            and select <span class="guimenu ">Resize Volume</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Resize Database Volume</span> dialog box,
                            fill in the <span class="guimenu ">New Size</span> field with an integer indicating
                            the new size you want for the instance. Express the size in GB, and
                            note that the new size must be larger than the current size.</p></li><li class="step "><p>Click <span class="guimenu ">Resize Database Volume</span>.</p></li></ol></div></div></div><div class="sect4" id="to-change-the-flavor-of-an-instance"><div class="titlepage"><div><div><h5 class="title"><span class="number">3.1.10.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">To change the flavor of an instance</span> <a title="Permalink" class="permalink" href="#to-change-the-flavor-of-an-instance">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>databases</li><li><span class="ds-label">ID: </span>to-change-the-flavor-of-an-instance</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the dashboard.</p></li><li class="step "><p>From the CURRENT PROJECT on the <span class="guimenu ">Project</span> tab, select the
                            appropriate project.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the <span class="guimenu ">Database</span> tab and
                            click <span class="guimenu ">Instances</span> category. This displays the existing
                            instances in your system.</p></li><li class="step "><p>Check the instance you want to work with. In the
                            <span class="guimenu ">Actions</span> column, expand the drop down menu and
                            select <span class="guimenu ">Resize Instance</span>.</p></li><li class="step "><p>In the <span class="guimenu ">Resize Database Instance</span> dialog box,
                            expand the drop down menu in the <span class="guimenu ">New Flavor</span> field.
                            Select the new flavor you want for the instance.</p></li><li class="step "><p>Click <span class="guimenu ">Resize Database Instance</span>.</p></li></ol></div></div></div></div></div><div class="sect2" id="view-and-manage-load-balancers-v2"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View and manage load balancers v2</span> <a title="Permalink" class="permalink" href="#view-and-manage-load-balancers-v2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-lbaasv2</li><li><span class="ds-label">ID: </span>view-and-manage-load-balancers-v2</li></ul></div></div></div></div><p>Load-Balancer-as-a-Service (LBaaS) enables networking to distribute incoming
            requests evenly among designated instances. This distribution ensures that
            the workload is shared predictably among instances and enables more effective
            use of system resources. Use one of these load-balancing methods to distribute
            incoming requests:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Round robin: Rotates requests evenly between multiple instances.</p></li><li class="listitem "><p>Source IP: Requests from a unique source IP address are consistently
                    directed to the same instance.</p></li><li class="listitem "><p>Least connections: Allocates requests to the instance with the
                    least number of active connections.</p></li></ul></div><p>As an end user, you can create and manage load balancers and related
            objects for users in various projects. You can also delete load balancers
            and related objects.</p><p>LBaaS v2 has several new concepts to understand:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.5.3.13.6.1"><span class="term ">Load balancer</span></dt><dd><p>The load balancer occupies a neutron network port and
                        has an IP address assigned from a subnet.</p></dd><dt id="id-1.5.3.13.6.2"><span class="term ">Listener</span></dt><dd><p>Each port that listens for traffic on a particular load balancer is
                        configured separately and tied to the load balancer. Multiple listeners can
                        be associated with the same load balancer.</p></dd><dt id="id-1.5.3.13.6.3"><span class="term ">Pool</span></dt><dd><p>A pool is a group of hosts that sits behind the load balancer and
                        serves traffic through the load balancer.</p></dd><dt id="id-1.5.3.13.6.4"><span class="term ">Member</span></dt><dd><p>Members are the actual IP addresses that receive traffic from
                        the load balancer. Members are associated with pools.</p></dd><dt id="id-1.5.3.13.6.5"><span class="term ">Health monitor</span></dt><dd><p>Members may go offline from time to time and health monitors
                        diverts traffic away from members that are not responding properly.
                        Health monitors are associated with pools.</p></dd></dl></div><div class="sect3" id="view-existing-load-balancers"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View existing load balancers</span> <a title="Permalink" class="permalink" href="#view-existing-load-balancers">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-lbaasv2</li><li><span class="ds-label">ID: </span>view-existing-load-balancers</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the OpenStack dashboard.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the
                        <span class="guimenu ">Network</span> tab, and click the
                        <span class="guimenu ">Load Balancers</span> category.</p><p>This view shows the list of existing load balancers. To view details
                        of any of the load balancers, click on the specific load balancer.</p></li></ol></div></div></div><div class="sect3" id="create-a-load-balancer"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.11.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create a load balancer</span> <a title="Permalink" class="permalink" href="#create-a-load-balancer">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-lbaasv2</li><li><span class="ds-label">ID: </span>create-a-load-balancer</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Log in to the OpenStack dashboard.</p></li><li class="step "><p>On the <span class="guimenu ">Project</span> tab, open the
                        <span class="guimenu ">Network</span> tab, and click the
                        <span class="guimenu ">Load Balancers</span> category.</p></li><li class="step "><p>Click the <span class="guimenu ">Create Load Balancer</span> button.</p><p>Use the concepts described in the overview section to fill in
                        the necessary information about the load balancer you want to create.</p><p>Keep in mind, the health checks routinely run against each instance
                        within a target load balancer and the result of the health check is
                        used to determine if the instance receives new connections.</p></li></ol></div></div><div id="id-1.5.3.13.8.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>A message indicates whether the action succeeded.</p></div></div><div class="sect3" id="delete-a-load-balancer"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.11.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete a load balancer</span> <a title="Permalink" class="permalink" href="#delete-a-load-balancer">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>manage-lbaasv2</li><li><span class="ds-label">ID: </span>delete-a-load-balancer</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>Select the load balancer you want to delete
                        and click the <span class="guimenu ">Delete Load Balancer</span> button.</p><p>To be deleted successfully, a load balancer must not
                        have any listeners or pools associated with
                        it. The delete action is also available in the
                        <span class="guimenu ">Actions</span> column for the individual load balancers.</p></li></ul></div></div></div></div><div class="sect2" id="supported-browsers"><div class="titlepage"><div><div><h3 class="title"><span class="number">3.1.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported Browsers</span> <a title="Permalink" class="permalink" href="#supported-browsers">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>browser_support</li><li><span class="ds-label">ID: </span>supported-browsers</li></ul></div></div></div></div><p>Horizon is primarily tested and supported on the latest version of Firefox,
            the latest version of Chrome, and IE9+. Issues related to Safari and Opera will
            also be considered.</p><p>This page aims to informally document what that means for different releases,
            everyone is warmly encouraged to update this page based on the versions they’ve
            tested with.</p><p>Legend:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Very good: Very well tested, should work as expected</p></li><li class="listitem "><p>Good: Moderately tested, should look nice and work fine, maybe a few visual
                    hiccups</p></li><li class="listitem "><p>Poor: Doesn’t look good</p></li><li class="listitem "><p>Broken: Essential functionality not working (link to bug in the notes)</p></li><li class="listitem "><p>No: Not supported</p></li></ul></div><div class="sect3" id="kilo"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.12.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kilo</span> <a title="Permalink" class="permalink" href="#kilo">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>browser_support</li><li><span class="ds-label">ID: </span>kilo</li></ul></div></div></div></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="20" class="c0" /><col width="20" class="c1" /><col width="30" class="c2" /></colgroup><thead><tr><th> </th><th>
                    <p>Status</p>
                  </th><th>
                    <p>Notes</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Firefox</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>31+. (Earlier versions?)</p>
                  </td></tr><tr><td>
                    <p>Firefox ESR</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>31+</p>
                  </td></tr><tr><td>
                    <p>Chrome</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>43.0.2357.81</p>
                  </td></tr><tr><td>
                    <p>IE 11</p>
                  </td><td>
                    <p>Good?</p>
                  </td><td> </td></tr><tr><td>
                    <p>IE 10</p>
                  </td><td>
                    <p>Good?</p>
                  </td><td> </td></tr><tr><td>
                    <p>IE 9</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>IE 8 and below</p>
                  </td><td>
                    <p>Not supported.</p>
                  </td><td> </td></tr><tr><td>
                    <p>Safari</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>Opera</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr></tbody></table></div></div><div class="sect3" id="juno"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.12.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Juno</span> <a title="Permalink" class="permalink" href="#juno">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>browser_support</li><li><span class="ds-label">ID: </span>juno</li></ul></div></div></div></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="20" class="c0" /><col width="20" class="c1" /><col width="30" class="c2" /></colgroup><thead><tr><th> </th><th>
                    <p>Status</p>
                  </th><th>
                    <p>Notes</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Firefox</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>31+. (Earlier versions?)</p>
                  </td></tr><tr><td>
                    <p>Firefox ESR</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>Chrome</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>Versions?</p>
                  </td></tr><tr><td>
                    <p>IE 11</p>
                  </td><td>
                    <p>Good?</p>
                  </td><td>
                    <p><a class="link" href="https://bugs.launchpad.net/horizon/+bugs?field.tag=ie" target="_blank">Open IE Bugs</a>.</p>
                  </td></tr><tr><td>
                    <p>IE 10</p>
                  </td><td>
                    <p>Good?</p>
                  </td><td>
                    <p><a class="link" href="https://bugs.launchpad.net/horizon/+bugs?field.tag=ie" target="_blank">Open IE Bugs</a>.</p>
                  </td></tr><tr><td>
                    <p>IE 9</p>
                  </td><td>
                    <p>?</p>
                  </td><td>
                    <p><a class="link" href="https://bugs.launchpad.net/horizon/+bugs?field.tag=ie" target="_blank">Open IE Bugs</a>.</p>
                  </td></tr><tr><td>
                    <p>IE 8 and below</p>
                  </td><td>
                    <p>Not supported.</p>
                  </td><td>
                    <p>No.</p>
                  </td></tr><tr><td>
                    <p>Safari</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>Opera</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr></tbody></table></div></div><div class="sect3" id="icehouse"><div class="titlepage"><div><div><h4 class="title"><span class="number">3.1.12.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Icehouse</span> <a title="Permalink" class="permalink" href="#icehouse">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>browser_support</li><li><span class="ds-label">ID: </span>icehouse</li></ul></div></div></div></div><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="20" class="c0" /><col width="17" class="c1" /><col width="38" class="c2" /></colgroup><thead><tr><th> </th><th>
                    <p>Status</p>
                  </th><th>
                    <p>Notes</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Firefox</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>Versions?</p>
                  </td></tr><tr><td>
                    <p>Firefox ESR</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>Windows 24.7.0 ESR</p>
                  </td></tr><tr><td>
                    <p>Chrome</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>Windows Version 36, RHEL version 27.0</p>
                  </td></tr><tr><td>
                    <p>Chromium</p>
                  </td><td>
                    <p>Very good</p>
                  </td><td>
                    <p>version 31.0</p>
                  </td></tr><tr><td>
                    <p>IE 11</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>IE 10</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>IE 9</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>IE 8 and below</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>Safari</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr><tr><td>
                    <p>Opera</p>
                  </td><td>
                    <p>?</p>
                  </td><td> </td></tr></tbody></table></div></div></div></div></div><div class="chapter " id="keystone-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Keystone User Guide</span> <a title="Permalink" class="permalink" href="#keystone-user-guide">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-keystone.xml</li><li><span class="ds-label">ID: </span>keystone-user-guide</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#user-documentation"><span class="number">4.1 </span><span class="name">User Documentation</span></a></span></dt></dl></div></div><p>This section contains the documentation for end-users of keystone.</p><div class="sect1" id="user-documentation"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">User Documentation</span> <a title="Permalink" class="permalink" href="#user-documentation">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span>user-documentation</li></ul></div></div></div></div><p>An end user can find the specific API documentation here, <a class="link" href="https://developer.openstack.org/api-ref/identity/v3" target="_blank">OpenStack’s Identity API</a>.</p><div id="id-1.6.3.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Following are some API examples using curl. These examples are not
                automatically generated. They can be outdated as things change and are subject
                to regular updates and changes.</p></div><div class="sect2" id="api-examples-using-curl"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">API Examples using Curl</span> <a title="Permalink" class="permalink" href="#api-examples-using-curl">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>api-examples-using-curl</li></ul></div></div></div></div><div class="sect3" id="v3-api-examples-using-curl"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">v3 API Examples Using Curl</span> <a title="Permalink" class="permalink" href="#v3-api-examples-using-curl">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>v3-api-examples-using-curl</li></ul></div></div></div></div><div class="sect4" id="tokens"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Tokens</span> <a title="Permalink" class="permalink" href="#tokens">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>tokens</li></ul></div></div></div></div><div class="sect5" id="default-scope"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Default scope</span> <a title="Permalink" class="permalink" href="#default-scope">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>default-scope</li></ul></div></div></div></div><p>Get a token with default scope (may be unscoped):</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -i \
  -H "Content-Type: application/json" \
  -d '
{ "auth": {
    "identity": {
      "methods": ["password"],
      "password": {
        "user": {
          "name": "admin",
          "domain": { "id": "default" },
          "password": "adminpwd"
        }
      }
    }
  }
}' \
  "http://localhost:5000/v3/auth/tokens" ; echo</pre></div><p>Example response:</p><div class="verbatim-wrap highlight bash"><pre class="screen">HTTP/1.1 201 Created
X-Subject-Token: MIIFvgY...
Vary: X-Auth-Token
Content-Type: application/json
Content-Length: 1025
Date: Tue, 10 Jun 2014 20:55:16 GMT

{
  "token": {
    "methods": ["password"],
    "roles": [{
      "id": "9fe2ff9ee4384b1894a90878d3e92bab",
      "name": "_member_"
    }, {
      "id": "c703057be878458588961ce9a0ce686b",
      "name": "admin"
    }],
    "expires_at": "2014-06-10T2:55:16.806001Z",
    "project": {
      "domain": {
        "id": "default",
        "name": "Default"
      },
      "id": "8538a3f13f9541b28c2620eb19065e45",
      "name": "admin"
    },
    "catalog": [{
      "endpoints": [{
        "url": "http://localhost:3537/v2.0",
        "region": "RegionOne",
        "interface": "admin",
        "id": "29beb2f1567642eb810b042b6719ea88"
      }, {
        "url": "http://localhost:5000/v2.0",
        "region": "RegionOne",
        "interface": "internal",
        "id": "8707e3735d4415c97ae231b4841eb1c"
      }, {
        "url": "http://localhost:5000/v2.0",
        "region": "RegionOne",
        "interface": "public",
        "id": "ef303187fc8d41668f25199c298396a5"
      }],
      "type": "identity",
      "id": "bd73972c0e14fb69bae8ff76e112a90",
      "name": "keystone"
    }],
    "extras": {},
    "user": {
      "domain": {
        "id": "default",
        "name": "Default"
      },
      "id": "3ec3164f750146be97f21559ee4d9c51",
      "name": "admin"
    },
    "audit_ids": ["yRt0UrxJSs6-WYJgwEMMmg"],
    "issued_at": "201406-10T20:55:16.806027Z"
  }
}</pre></div></div><div class="sect5" id="project-scoped"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Project-scoped</span> <a title="Permalink" class="permalink" href="#project-scoped">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>project-scoped</li></ul></div></div></div></div><p>Get a project-scoped token:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -i \
  -H "Content-Type: application/json" \
  -d '
{ "auth": {
    "identity": {
      "methods": ["password"],
      "password": {
        "user": {
          "name": "admin",
          "domain": { "id": "default" },
          "password": "adminpwd"
        }
      }
    },
    "scope": {
      "project": {
        "name": "demo",
        "domain": { "id": "default" }
      }
    }
  }
}' \
  "http://localhost:5000/v3/auth/tokens" ; echo</pre></div><p>Example response:</p><div class="verbatim-wrap highlight bash"><pre class="screen">HTTP/1.1 201 Created
X-Subject-Token: MIIFfQ...
Vary: X-Auth-Token
Content-Type: application/json
Content-Length: 960
Date: Tue, 10 Jun 2014 20:40:14 GMT

{
  "token": {
    "audit_ids": ["ECwrVNWbSCqmEgPnu0YCRw"],
    "methods": ["password"],
    "roles": [{
      "id": "c703057be878458588961ce9a0ce686b",
      "name": "admin"
    }],
    "expires_at": "2014-06-10T21:40:14.360795Z",
    "project": {
      "domain": {
        "id": "default",
        "name": "Default"
      },
      "id": "3d4c2c82bd5948f0bcab0cf3a7c9b48c",
      "name": "demo"
    },
    "catalog": [{
      "endpoints": [{
        "url": "http://localhost:35357/v2.0",
        "region": "RegionOne",
        "interface": "admin",
        "id": "29beb2f1567642eb810b042b6719ea88"
      }, {
        "url": "http://localhost:5000/v2.0",
        "region": "RegionOne",
        "interface": "internal",
        "id": "87057e3735d4415c97ae231b4841eb1c"
      }, {
        "url": "http://localhost:5000/v2.0",
        "region": "RegionOne",
        "interface": "public",
        "id": "ef303187fc8d41668f25199c298396a5"
      }],
      "type": "identity",
      "id": "bd7397d2c0e14fb69bae8ff76e112a90",
      "name": "keystone"
    }],
    "extras": {},
    "user": {
      "domain": {
        "id": "default",
        "name": "Default"
      },
      "id": "3ec3164f750146be97f21559ee4d9c51",
      "name": "admin"
    },
    "issued_at": "2014-06-10T20:40:14.360822Z"
  }
}</pre></div></div><div class="sect5" id="domain-scoped"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Domain-Scoped</span> <a title="Permalink" class="permalink" href="#domain-scoped">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>domain-scoped</li></ul></div></div></div></div><p>Get a domain-scoped token:</p><div id="id-1.6.3.4.2.2.4.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p> Ensure you have a role-assignment on the domain first.</p></div><div class="verbatim-wrap highlight bash"><pre class="screen">curl -i \
  -H "Content-Type: application/json" \
  -d '
{ "auth": {
    "identity": {
      "methods": ["password"],
      "password": {
        "user": {
          "name": "admin",
          "domain": { "id": "default" },
          "password": "adminpwd"
        }
      }
    },
    "scope": {
      "domain": {
        "id": "default"
      }
    }
  }
}' \
  "http://localhost:5000/v3/auth/tokens" ; echo</pre></div><p>Example response:</p><div class="verbatim-wrap highlight bash"><pre class="screen">HTTP/1.1 201 Created
X-Subject-Token: MIIFNg...
Vary: X-Auth-Token
Content-Type: application/json
Content-Length: 889
Date: Tue, 10 Jun 2014 20:52:59 GMT

{
  "token": {
    "domain": {
      "id": "default",
      "name": "Default"
    },
    "methods": ["password"],
    "roles": [{
      "id": "c703057be878458588961ce9a0ce686b",
      "name": "admin"
    }],
    "expires_at": "2014-06-10T21:52:58.852167Z",
    "catalog": [{
      "endpoints": [{
        "url": "http://localhost:35357/v2.0",
        "region": "RegionOne",
        "interface": "admin",
        "id": "29beb2f1567642eb810b042b6719ea88"
      }, {
        "url": "http://localhost:5000/v2.0",
        "region": "RegionOne",
        "interface": "internal",
        "id": "87057e3735d4415c97ae231b4841eb1c"
      }, {
        "url": "http://localhost:5000/v2.0",
        "region": "RegionOne",
        "interface": "public",
        "id": "ef303187fc8d41668f25199c298396a5"
      }],
      "type": "identity",
      "id": "bd7397d2c0e14fb69bae8ff76e112a90",
      "name": "keystone"
    }],
    "extras": {},
    "user": {
      "domain": {
        "id": "default",
        "name": "Default"
      },
      "id": "3ec3164f750146be97f21559ee4d9c51",
      "name": "admin"
    },
    "audit_ids": ["Xpa6Uyn-T9S6mTREudUH3w"],
    "issued_at": "2014-06-10T20:52:58.852194Z"
  }
}</pre></div></div><div class="sect5" id="getting-a-token-from-a-token"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Getting a token from a token</span> <a title="Permalink" class="permalink" href="#getting-a-token-from-a-token">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>getting-a-token-from-a-token</li></ul></div></div></div></div><p>Get a token from a token:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -i \
  -H "Content-Type: application/json" \
  -d '
{ "auth": {
    "identity": {
      "methods": ["token"],
      "token": {
        "id": "'$OS_TOKEN'"
      }
    }
  }
}' \
  "http://localhost:5000/v3/auth/tokens" ; echo</pre></div><p>Example response:</p><div class="verbatim-wrap highlight bash"><pre class="screen">HTTP/1.1 201 Created
X-Subject-Token: MIIFxw...
Vary: X-Auth-Token
Content-Type: application/json
Content-Length: 1034
Date: Tue, 10 Jun 2014 21:00:05 GMT

{
  "token": {
    "methods": ["token", "password"],
    "expires_at": "2015-05-28T07:43:44.808209Z",
    "extras": {},
    "user": {
      "domain": {
        "id": "default",
        "name": "Default"
      },
      "id": "753867c25c3340ffad1abc22d488c31a",
      "name": "admin"
    },
    "audit_ids": ["ZE0OPSuzTmCXHo0eIOYltw",
      "xxIQCkHOQOywL0oY6CTppQ"
    ],
    "issued_at": "2015-05-28T07:19:23.763532Z"
  }
}</pre></div><div id="id-1.6.3.4.2.2.5.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>If a scope was included in the request body, then this would get a token
                      with the new scope.</p></div></div><div class="sect5" id="delete-v3-auth-tokens"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DELETE /v3/auth/tokens</span> <a title="Permalink" class="permalink" href="#delete-v3-auth-tokens">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>delete-v3-auth-tokens</li></ul></div></div></div></div><p>Revoke a token:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -i -X DELETE \
  -H "X-Auth-Token: $OS_TOKEN" \
  -H "X-Subject-Token: $OS_TOKEN" \
  "http://localhost:5000/v3/auth/tokens"</pre></div><p>If there’s no error then the response is empty.</p></div></div><div class="sect4" id="domains"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Domains</span> <a title="Permalink" class="permalink" href="#domains">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>domains</li></ul></div></div></div></div><div class="sect5" id="get-v3-domains"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /v3/domains</span> <a title="Permalink" class="permalink" href="#get-v3-domains">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-v3-domains</li></ul></div></div></div></div><p>List domains:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
  -H "X-Auth-Token: $OS_TOKEN" \
  "http://localhost:5000/v3/domains" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "domains": [
        {
            "description": "Owns users and tenants (i.e. projects) available on Identity API v2.",
            "enabled": true,
            "id": "default",
            "links": {
                "self": "http://identity-server:5000/v3/domains/default"
            },
            "name": "Default"
        }
    ],
    "links": {
        "next": null,
        "previous": null,
        "self": "http://identity-server:5000/v3/domains"
    }
}</pre></div></div><div class="sect5" id="post-v3-domains"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">POST /v3/domains</span> <a title="Permalink" class="permalink" href="#post-v3-domains">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>post-v3-domains</li></ul></div></div></div></div><p>Create a domain:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
  -H "X-Auth-Token: $OS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{ "domain": { "name": "newdomain"}}' \
  "http://localhost:5000/v3/domains" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "domain": {
        "enabled": true,
        "id": "3a5140aecd974bf08041328b53a62458",
        "links": {
            "self": "http://identity-server:5000/v3/domains/3a5140aecd974bf08041328b53a62458"
        },
        "name": "newdomain"
    }
}</pre></div></div></div><div class="sect4" id="projects"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Projects</span> <a title="Permalink" class="permalink" href="#projects">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>projects</li></ul></div></div></div></div><div class="sect5" id="get-v3-projects"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /v3/projects</span> <a title="Permalink" class="permalink" href="#get-v3-projects">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-v3-projects</li></ul></div></div></div></div><p>List projects:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
 -H "X-Auth-Token: $OS_TOKEN" \
 "http://localhost:5000/v3/projects" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "links": {
        "next": null,
        "previous": null,
        "self": "http://localhost:5000/v3/projects"
    },
    "projects": [
        {
            "description": null,
            "domain_id": "default",
            "enabled": true,
            "id": "3d4c2c82bd5948f0bcab0cf3a7c9b48c",
            "links": {
                "self": "http://localhost:5000/v3/projects/3d4c2c82bd5948f0bcab0cf3a7c9b48c"
            },
            "name": "demo"
        }
    ]
}</pre></div></div><div class="sect5" id="patch-v3-projects-id"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">PATCH /v3/projects/{id}</span> <a title="Permalink" class="permalink" href="#patch-v3-projects-id">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>patch-v3-projects-id</li></ul></div></div></div></div><p>Disable a project:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s -X PATCH \
  -H "X-Auth-Token: $OS_TOKEN" \
  -H "Content-Type: application/json" \
  -d '
{
  "project": {
      "enabled": false
    }
}'\
  "http://localhost:5000/v3/projects/$PROJECT_ID"  | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "project": {
        "description": null,
        "domain_id": "default",
        "enabled": false,
        "extra": {},
        "id": "3d4c2c82bd5948f0bcab0cf3a7c9b48c",
        "links": {
            "self": "http://localhost:5000/v3/projects/3d4c2c82bd5948f0bcab0cf3a7c9b48c"
        },
        "name": "demo"
    }
}</pre></div></div></div><div class="sect4" id="get-v3-services"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /v3/services</span> <a title="Permalink" class="permalink" href="#get-v3-services">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-v3-services</li></ul></div></div></div></div><p>List the services:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
  -H "X-Auth-Token: $OS_TOKEN" \
  "http://localhost:5000/v3/services" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "links": {
        "next": null,
        "previous": null,
        "self": "http://localhost:5000/v3/services"
    },
    "services": [
        {
            "description": "Keystone Identity Service",
            "enabled": true,
            "id": "bd7397d2c0e14fb69bae8ff76e112a90",
            "links": {
                "self": "http://localhost:5000/v3/services/bd7397d2c0e14fb69bae8ff76e112a90"
            },
            "name": "keystone",
            "type": "identity"
        }
    ]
}</pre></div></div><div class="sect4" id="get-v3-endpoints"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /v3/endpoints</span> <a title="Permalink" class="permalink" href="#get-v3-endpoints">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-v3-endpoints</li></ul></div></div></div></div><p>List the endpoints:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
 -H "X-Auth-Token: $OS_TOKEN" \
 "http://localhost:5000/v3/endpoints" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "endpoints": [
        {
            "enabled": true,
            "id": "29beb2f1567642eb810b042b6719ea88",
            "interface": "admin",
            "links": {
                "self": "http://localhost:5000/v3/endpoints/29beb2f1567642eb810b042b6719ea88"
            },
            "region": "RegionOne",
            "service_id": "bd7397d2c0e14fb69bae8ff76e112a90",
            "url": "http://localhost:35357/v2.0"
        }
    ],
    "links": {
        "next": null,
        "previous": null,
        "self": "http://localhost:5000/v3/endpoints"
    }
}</pre></div></div><div class="sect4" id="users"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Users</span> <a title="Permalink" class="permalink" href="#users">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>users</li></ul></div></div></div></div><div class="sect5" id="get-v3-users"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /v3/users</span> <a title="Permalink" class="permalink" href="#get-v3-users">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-v3-users</li></ul></div></div></div></div><p>List users:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
 -H "X-Auth-Token: $OS_TOKEN" \
 "http://localhost:5000/v3/users" | python -mjson.tool</pre></div></div><div class="sect5" id="post-v3-users"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">POST /v3/users</span> <a title="Permalink" class="permalink" href="#post-v3-users">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>post-v3-users</li></ul></div></div></div></div><p>Create a user:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
 -H "X-Auth-Token: $OS_TOKEN" \
 -H "Content-Type: application/json" \
 -d '{"user": {"name": "newuser", "password": "changeme"}}' \
 "http://localhost:5000/v3/users" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "user": {
        "domain_id": "default",
        "enabled": true,
        "id": "ec8fc20605354edd91873f2d66bf4fc4",
        "links": {
            "self": "http://identity-server:5000/v3/users/ec8fc20605354edd91873f2d66bf4fc4"
        },
        "name": "newuser"
    }
}</pre></div></div><div class="sect5" id="get-v3-users-user-id"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /v3/users/{user_id}</span> <a title="Permalink" class="permalink" href="#get-v3-users-user-id">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-v3-users-user-id</li></ul></div></div></div></div><p>Show details for a user:</p><div class="verbatim-wrap highlight bash"><pre class="screen">USER_ID=ec8fc20605354edd91873f2d66bf4fc4

curl -s \
 -H "X-Auth-Token: $OS_TOKEN" \
 "http://localhost:5000/v3/users/$USER_ID" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "user": {
        "domain_id": "default",
        "enabled": true,
        "id": "ec8fc20605354edd91873f2d66bf4fc4",
        "links": {
            "self": "http://localhost:5000/v3/users/ec8fc20605354edd91873f2d66bf4fc4"
        },
        "name": "newuser"
    }
}</pre></div></div><div class="sect5" id="post-v3-users-user-id-password"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">POST /v3/users/{user_id}/password</span> <a title="Permalink" class="permalink" href="#post-v3-users-user-id-password">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>post-v3-users-user-id-password</li></ul></div></div></div></div><p>Change password using the default policy; this can be done as the user:</p><div class="verbatim-wrap highlight bash"><pre class="screen">USER_ID=b7793000f8d84c79af4e215e9da78654
ORIG_PASS=userpwd
NEW_PASS=newuserpwd

curl \
 -H "X-Auth-Token: $OS_TOKEN" \
 -H "Content-Type: application/json" \
 -d '{ "user": {"password": "'$NEW_PASS'", "original_password": "'$ORIG_PASS'"} }' \
 "http://localhost:5000/v3/users/$USER_ID/password"</pre></div><div id="id-1.6.3.4.2.7.5.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>This command will not print anything if the request was successful.</p></div></div><div class="sect5" id="patch-v3-users-user-id"><div class="titlepage"><div><div><h6 class="title"><span class="number">4.1.1.1.6.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">PATCH /v3/users/{user_id}</span> <a title="Permalink" class="permalink" href="#patch-v3-users-user-id">#</a></h6><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>patch-v3-users-user-id</li></ul></div></div></div></div><p>Reset password using the default policy; this requires admin:</p><div class="verbatim-wrap highlight bash"><pre class="screen">USER_ID=b7793000f8d84c79af4e215e9da78654
NEW_PASS=newuserpwd

curl -s -X PATCH \
 -H "X-Auth-Token: $OS_TOKEN" \
 -H "Content-Type: application/json" \
 -d '{ "user": {"password": "'$NEW_PASS'"} }' \
 "http://localhost:5000/v3/users/$USER_ID" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "user": {
        "default_project_id": "3d4c2c82bd5948f0bcab0cf3a7c9b48c",
        "domain_id": "default",
        "email": "demo@example.com",
        "enabled": true,
        "extra": {
            "email": "demo@example.com"
        },
        "id": "269348fdd9374b8885da1418e0730af1",
        "links": {
            "self": "http://localhost:5000/v3/users/269348fdd9374b8885da1418e0730af1"
        },
        "name": "demo"
    }
}</pre></div></div></div><div class="sect4" id="put-v3-projects-project-id-groups-group-id-roles-role-id"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">PUT /v3/projects/{project_id}/groups/{group_id}/roles/{role_id}</span> <a title="Permalink" class="permalink" href="#put-v3-projects-project-id-groups-group-id-roles-role-id">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>put-v3-projects-project-id-groups-group-id-roles-role-id</li></ul></div></div></div></div><p>Create group role assignment on project:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s -X PUT \
 -H "X-Auth-Token: $OS_TOKEN" \
 "http://localhost:5000/v3/projects/$PROJECT_ID/groups/$GROUP_ID/roles/$ROLE_ID" |
   python -mjson.tool</pre></div><p>There’s no data in the response if the operation is successful.</p></div><div class="sect4" id="post-v3-os-trust-trusts"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.1.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">POST /v3/OS-TRUST/trusts</span> <a title="Permalink" class="permalink" href="#post-v3-os-trust-trusts">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>post-v3-os-trust-trusts</li></ul></div></div></div></div><p>Create a trust:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s \
 -H "X-Auth-Token: $OS_TOKEN" \
 -H "Content-Type: application/json" \
 -d '
{ "trust": {
    "expires_at": "2014-12-30T23:59:59.999999Z",
    "impersonation": false,
    "project_id": "'$PROJECT_ID'",
    "roles": [
        { "name": "admin" }
      ],
    "trustee_user_id": "'$DEMO_USER_ID'",
    "trustor_user_id": "'$ADMIN_USER_ID'"
}}'\
 "http://localhost:5000/v3/OS-TRUST/trusts" | python -mjson.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "trust": {
        "expires_at": "2014-12-30T23:59:59.999999Z",
        "id": "394998fa61f14736b1f0c1f322882949",
        "impersonation": false,
        "links": {
            "self": "http://localhost:5000/v3/OS-TRUST/trusts/394998fa61f14736b1f0c1f322882949"
        },
        "project_id": "3d4c2c82bd5948f0bcab0cf3a7c9b48c",
        "remaining_uses": null,
        "roles": [
            {
                "id": "c703057be878458588961ce9a0ce686b",
                "links": {
                    "self": "http://localhost:5000/v3/roles/c703057be878458588961ce9a0ce686b"
                },
                "name": "admin"
            }
        ],
        "roles_links": {
            "next": null,
            "previous": null,
            "self": "http://localhost:5000/v3/OS-TRUST/trusts/394998fa61f14736b1f0c1f322882949/roles"
        },
        "trustee_user_id": "269348fdd9374b8885da1418e0730af1",
        "trustor_user_id": "3ec3164f750146be97f21559ee4d9c51"
    }
}</pre></div></div></div><div class="sect3" id="service-api-examples-using-curl"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Service API Examples Using Curl</span> <a title="Permalink" class="permalink" href="#service-api-examples-using-curl">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>service-api-examples-using-curl</li></ul></div></div></div></div><p>The service API is defined to be a subset of the Admin API and runs on port
                5000 by default.</p><div class="sect4" id="get"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /</span> <a title="Permalink" class="permalink" href="#get">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get</li></ul></div></div></div></div><p>This call is identical to that documented for the Admin API, except
                    that it uses port 5000 by default instead of port 35357:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl "http://0.0.0.0:5000"</pre></div><p>or:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl "http://0.0.0.0:5000/v2.0/"</pre></div><p>See the <a class="xref" href="#admin-api-examples-using-curl" title="4.1.1.3. Admin API Examples Using Curl">Section 4.1.1.3, “Admin API Examples Using Curl”</a> for more info.</p></div><div class="sect4" id="get-extensions"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /extensions</span> <a title="Permalink" class="permalink" href="#get-extensions">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-extensions</li></ul></div></div></div></div><p>This call is identical to that documented for the Admin API.</p></div><div class="sect4" id="post-tokens"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">POST /tokens</span> <a title="Permalink" class="permalink" href="#post-tokens">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>post-tokens</li></ul></div></div></div></div><p>This call is identical to that documented for the Admin API.</p></div><div class="sect4" id="get-tenants"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tenants</span> <a title="Permalink" class="permalink" href="#get-tenants">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-tenants</li></ul></div></div></div></div><p>List all of the tenants your token can access:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:887665443383838" \
   "http://localhost:5000/v2.0/tenants"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "tenants_links": [],
    "tenants": [
        {
            "enabled": true,
            "description": "None",
            "name": "customer-x",
            "id": "1"
        }
    ]
}</pre></div></div></div><div class="sect3" id="admin-api-examples-using-curl"><div class="titlepage"><div><div><h4 class="title"><span class="number">4.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Admin API Examples Using Curl</span> <a title="Permalink" class="permalink" href="#admin-api-examples-using-curl">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>admin-api-examples-using-curl</li></ul></div></div></div></div><p>These examples assume a default port value of 35357, and depend on the
                <code class="literal">sampledata</code> bundled with keystone.</p><div class="sect4" id="id1"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /</span> <a title="Permalink" class="permalink" href="#id1">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>id1</li></ul></div></div></div></div><p>Discover API version information, links to documentation (PDF, HTML, WADL),
                    and supported media types:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl "http://0.0.0.0:35357"</pre></div><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "versions": {
        "values": [
            {
                "id": "v3.4",
                "links": [
                    {
                        "href": "http://127.0.0.1:35357/v3/",
                        "rel": "self"
                    }
                ],
                "media-types": [
                    {
                        "base": "application/json",
                        "type": "application/vnd.openstack.identity-v3+json"
                    }
                ],
                "status": "stable",
                "updated": "2015-03-30T00:00:00Z"
            },
            {
                "id": "v2.0",
                "links": [
                    {
                        "href": "http://127.0.0.1:35357/v2.0/",
                        "rel": "self"
                    },
                    {
                        "href": "https://docs.openstack.org/",
                        "rel": "describedby",
                        "type": "text/html"
                    }
                ],
                "media-types": [
                    {
                        "base": "application/json",
                        "type": "application/vnd.openstack.identity-v2.0+json"
                    }
                ],
                "status": "stable",
                "updated": "2014-04-17T00:00:00Z"
            }
        ]
    }
}</pre></div><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl "http://0.0.0.0:35357/v2.0/"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "version": {
        "id": "v2.0",
        "links": [
            {
                "href": "http://127.0.0.1:35357/v2.0/",
                "rel": "self"
            },
            {
                "href": "https://docs.openstack.org/",
                "rel": "describedby",
                "type": "text/html"
            }
        ],
        "media-types": [
            {
                "base": "application/json",
                "type": "application/vnd.openstack.identity-v2.0+json"
            }
        ],
        "status": "stable",
        "updated": "2014-04-17T00:00:00Z"
    }
}</pre></div></div><div class="sect4" id="id2"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /extensions</span> <a title="Permalink" class="permalink" href="#id2">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>id2</li></ul></div></div></div></div><p>Discover the API extensions enabled at the endpoint:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl "http://localhost:35357/v2.0/extensions/"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "extensions":{
        "values":[]
    }
}</pre></div></div><div class="sect4" id="id3"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">POST /tokens</span> <a title="Permalink" class="permalink" href="#id3">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>id3</li></ul></div></div></div></div><p>Authenticate by exchanging credentials for an access token:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -d '
   {"auth": {
      "tenantName": "customer-x",
      "passwordCredentials": {
        "username": "joeuser",
        "password": "secret"
       }
     }
   }' \
   -H "Content-type: application/json" \
   "http://localhost:35357/v2.0/tokens"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "access":{
        "token":{
            "expires":"2012-02-05T00:00:00",
            "id":"887665443383838",
            "tenant":{
                "id":"1",
                "name":"customer-x"
            }
        },
        "serviceCatalog":[
            {
                "endpoints":[
                {
                    "adminURL":"http://swift.admin-nets.local:8080/",
                    "region":"RegionOne",
                    "internalURL":"http://127.0.0.1:8080/v1/AUTH_1",
                    "publicURL":"http://swift.publicinternets.com/v1/AUTH_1"
                }
                ],
                "type":"object-store",
                "name":"swift"
            },
            {
                "endpoints":[
                {
                    "adminURL":"http://cdn.admin-nets.local/v1.1/1",
                    "region":"RegionOne",
                    "internalURL":"http://127.0.0.1:7777/v1.1/1",
                    "publicURL":"http://cdn.publicinternets.com/v1.1/1"
                }
                ],
                "type":"object-store",
                "name":"cdn"
            }
        ],
        "user":{
            "id":"1",
            "roles":[
                {
                "tenantId":"1",
                "id":"3",
                "name":"Member"
                }
            ],
            "name":"joeuser"
        }
    }
}</pre></div><div id="id-1.6.3.4.4.5.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>Take note of the value <code class="literal">[‘access’][‘token’][‘id’]</code> value produced here
                    (<code class="literal">887665443383838</code>, above), as you can use it in the calls below.</p></div></div><div class="sect4" id="get-tokens-token-id"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tokens/{token_id}</span> <a title="Permalink" class="permalink" href="#get-tokens-token-id">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-tokens-token-id</li></ul></div></div></div></div><div id="id-1.6.3.4.4.6.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg" /><h6>Note</h6><p>This call refers to a token known to be valid, <code class="literal">887665443383838</code> in this case.</p></div><p>Validate a token:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/tokens/887665443383838"</pre></div><p>If the token is valid, returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "access":{
        "token":{
            "expires":"2012-02-05T00:00:00",
            "id":"887665443383838",
            "tenant":{
                "id":"1",
                "name":"customer-x"
            }
        },
        "user":{
            "name":"joeuser",
            "tenantName":"customer-x",
            "id":"1",
            "roles":[
                {
                    "serviceId":"1",
                    "id":"3",
                    "name":"Member"
                }
            ],
            "tenantId":"1"
        }
    }
}</pre></div></div><div class="sect4" id="head-tokens-token-id"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">HEAD /tokens/{token_id}</span> <a title="Permalink" class="permalink" href="#head-tokens-token-id">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>head-tokens-token-id</li></ul></div></div></div></div><p>This is a high-performance variant of the GET call documented above, which
                    by definition, returns no response body:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -I -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/tokens/887665443383838"</pre></div><p>This returns <code class="literal">200</code>, indicating the token is valid:</p><div class="verbatim-wrap"><pre class="screen">HTTP/1.1 200 OK
Content-Length: 0
Content-Type: None
Date: Tue, 08 Nov 2011 23:07:44 GMT</pre></div></div><div class="sect4" id="get-tokens-token-id-endpoints"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tokens/{token_id}/endpoints</span> <a title="Permalink" class="permalink" href="#get-tokens-token-id-endpoints">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-tokens-token-id-endpoints</li></ul></div></div></div></div><p>List all endpoints for a token:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/tokens/887665443383838/endpoints"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "endpoints_links": [
        {
            "href": "http://127.0.0.1:35357/tokens/887665443383838/endpoints?'marker=5&amp;limit=10'",
            "rel": "next"
        }
    ],
    "endpoints": [
        {
            "internalURL": "http://127.0.0.1:8080/v1/AUTH_1",
            "name": "swift",
            "adminURL": "http://swift.admin-nets.local:8080/",
            "region": "RegionOne",
            "tenantId": 1,
            "type": "object-store",
            "id": 1,
            "publicURL": "http://swift.publicinternets.com/v1/AUTH_1"
        },
        {
            "internalURL": "http://localhost:8774/v1.0",
            "name": "nova_compat",
            "adminURL": "http://127.0.0.1:8774/v1.0",
            "region": "RegionOne",
            "tenantId": 1,
            "type": "compute",
            "id": 2,
            "publicURL": "http://nova.publicinternets.com/v1.0/"
        },
        {
            "internalURL": "http://localhost:8774/v1.1",
            "name": "nova",
            "adminURL": "http://127.0.0.1:8774/v1.1",
            "region": "RegionOne",
            "tenantId": 1,
            "type": "compute",
            "id": 3,
            "publicURL": "http://nova.publicinternets.com/v1.1/
        },
        {
            "internalURL": "http://127.0.0.1:9292/v1.1/",
            "name": "glance",
            "adminURL": "http://nova.admin-nets.local/v1.1/",
            "region": "RegionOne",
            "tenantId": 1,
            "type": "image",
            "id": 4,
            "publicURL": "http://glance.publicinternets.com/v1.1/"
        },
        {
            "internalURL": "http://127.0.0.1:7777/v1.1/1",
            "name": "cdn",
            "adminURL": "http://cdn.admin-nets.local/v1.1/1",
            "region": "RegionOne",
            "tenantId": 1,
            "type": "object-store",
            "id": 5,
            "publicURL": "http://cdn.publicinternets.com/v1.1/1"
        }
    ]
}</pre></div></div><div class="sect4" id="id4"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tenants</span> <a title="Permalink" class="permalink" href="#id4">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>id4</li></ul></div></div></div></div><p>List all of the tenants in the system (requires an Admin <code class="literal">X-Auth-Token</code>):</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/tenants"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "tenants_links": [],
    "tenants": [
        {
            "enabled": false,
            "description": "None",
            "name": "project-y",
            "id": "3"
        },
        {
            "enabled": true,
            "description": "None",
            "name": "ANOTHER:TENANT",
            "id": "2"
        },
        {
            "enabled": true,
            "description": "None",
            "name": "customer-x",
            "id": "1"
        }
    ]
}</pre></div></div><div class="sect4" id="get-tenants-tenant-id"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tenants/{tenant_id}</span> <a title="Permalink" class="permalink" href="#get-tenants-tenant-id">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-tenants-tenant-id</li></ul></div></div></div></div><p>Retrieve information about a tenant, by tenant ID:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/tenants/1"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "tenant":{
        "enabled":true,
        "description":"None",
        "name":"customer-x",
        "id":"1"
    }
}</pre></div></div><div class="sect4" id="get-tenants-tenant-id-users-user-id-roles"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tenants/{tenant_id}/users/{user_id}/roles</span> <a title="Permalink" class="permalink" href="#get-tenants-tenant-id-users-user-id-roles">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-tenants-tenant-id-users-user-id-roles</li></ul></div></div></div></div><p>List the roles a user has been granted on a tenant:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/tenants/1/users/1/roles"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "roles_links":[],
    "roles":[
        {
            "id":"3",
            "name":"Member"
        }
    ]
}</pre></div></div><div class="sect4" id="get-users-user-id"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /users/{user_id}</span> <a title="Permalink" class="permalink" href="#get-users-user-id">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-users-user-id</li></ul></div></div></div></div><p>Retrieve information about a user, by user ID:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ curl -H "X-Auth-Token:999888777666" \
   "http://localhost:35357/v2.0/users/1"</pre></div><p>Returns:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "user":{
        "tenantId":"1",
        "enabled":true,
        "id":"1",
        "name":"joeuser"
    }
}</pre></div></div><div class="sect4" id="get-tokens-revoked"><div class="titlepage"><div><div><h5 class="title"><span class="number">4.1.1.3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GET /tokens/revoked</span> <a title="Permalink" class="permalink" href="#get-tokens-revoked">#</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>../api_curl_examples</li><li><span class="ds-label">ID: </span>get-tokens-revoked</li></ul></div></div></div></div><p>Get the revocation list:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -s -H "X-Auth-Token: $OS_TOKEN" \
  "http://localhost:35357/v2.0/tokens/revoked" |
 jq -r .signed |
 openssl cms -verify \
  -certfile /etc/keystone/ssl/certs/signing_cert.pem \
  -CAfile /etc/keystone/ssl/certs/ca.pem \
  -inform PEM \
  -nosmimecap -nodetach -nocerts -noattr 2&gt;/dev/null |
 python -m json.tool</pre></div><p>Example response:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "revoked": [
        {
            "expires": "2014-06-10T21:40:14Z",
            "id": "e6e2b5c9092751f88d2bcd30b09777a9"
        },
        {
            "expires": "2014-06-10T21:47:29Z",
            "id": "883ef5d610bd1c68fbaa8ac528aa9f17"
        },
        {
            "expires": "2014-06-10T21:51:52Z",
            "id": "41775ff4838f8f406b7bad28bea0dde6"
        }
    ]
}</pre></div></div></div></div></div></div><div class="chapter " id="magnum-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Magnum User Documentation</span> <a title="Permalink" class="permalink" href="#magnum-user-guide">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-magnum.xml</li><li><span class="ds-label">ID: </span>magnum-user-guide</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#id-1.7.2"><span class="number">5.1 </span><span class="name">Introduction</span></a></span></dt><dt><span class="section"><a href="#id-1.7.3"><span class="number">5.2 </span><span class="name">Terminology</span></a></span></dt><dt><span class="section"><a href="#id-1.7.4"><span class="number">5.3 </span><span class="name">Overview</span></a></span></dt><dt><span class="section"><a href="#id-1.7.5"><span class="number">5.4 </span><span class="name">ClusterTemplate</span></a></span></dt><dt><span class="section"><a href="#id-1.7.6"><span class="number">5.5 </span><span class="name">Cluster</span></a></span></dt><dt><span class="section"><a href="#id-1.7.7"><span class="number">5.6 </span><span class="name">Python Client</span></a></span></dt><dt><span class="section"><a href="#id-1.7.8"><span class="number">5.7 </span><span class="name">Horizon Interface</span></a></span></dt><dt><span class="section"><a href="#id-1.7.9"><span class="number">5.8 </span><span class="name">Cluster Drivers</span></a></span></dt><dt><span class="section"><a href="#id-1.7.10"><span class="number">5.9 </span><span class="name">Cluster Type Definition</span></a></span></dt><dt><span class="section"><a href="#id-1.7.11"><span class="number">5.10 </span><span class="name">Heat Stack Templates</span></a></span></dt><dt><span class="section"><a href="#id-1.7.12"><span class="number">5.11 </span><span class="name">Choosing a COE</span></a></span></dt><dt><span class="section"><a href="#id-1.7.13"><span class="number">5.12 </span><span class="name">Native Clients</span></a></span></dt><dt><span class="section"><a href="#id-1.7.14"><span class="number">5.13 </span><span class="name">Kubernetes</span></a></span></dt><dt><span class="section"><a href="#id-1.7.15"><span class="number">5.14 </span><span class="name">Swarm</span></a></span></dt><dt><span class="section"><a href="#id-1.7.16"><span class="number">5.15 </span><span class="name">Mesos</span></a></span></dt><dt><span class="section"><a href="#id-1.7.17"><span class="number">5.16 </span><span class="name">Transport Layer Security</span></a></span></dt><dt><span class="section"><a href="#id-1.7.18"><span class="number">5.17 </span><span class="name">Networking</span></a></span></dt><dt><span class="section"><a href="#id-1.7.19"><span class="number">5.18 </span><span class="name">High Availability</span></a></span></dt><dt><span class="section"><a href="#id-1.7.20"><span class="number">5.19 </span><span class="name">Scaling</span></a></span></dt><dt><span class="section"><a href="#id-1.7.21"><span class="number">5.20 </span><span class="name">Storage</span></a></span></dt><dt><span class="section"><a href="#id-1.7.22"><span class="number">5.21 </span><span class="name">Image Management</span></a></span></dt><dt><span class="section"><a href="#id-1.7.23"><span class="number">5.22 </span><span class="name">Notification</span></a></span></dt><dt><span class="section"><a href="#id-1.7.24"><span class="number">5.23 </span><span class="name">Container Monitoring</span></a></span></dt><dt><span class="section"><a href="#id-1.7.25"><span class="number">5.24 </span><span class="name">Kubernetes External Load Balancer</span></a></span></dt><dt><span class="section"><a href="#id-1.7.26"><span class="number">5.25 </span><span class="name">Terminology</span></a></span></dt><dt><span class="section"><a href="#id-1.7.27"><span class="number">5.26 </span><span class="name">Overview</span></a></span></dt><dt><span class="section"><a href="#id-1.7.28"><span class="number">5.27 </span><span class="name">ClusterTemplate</span></a></span></dt><dt><span class="section"><a href="#id-1.7.29"><span class="number">5.28 </span><span class="name">Cluster</span></a></span></dt><dt><span class="section"><a href="#id-1.7.30"><span class="number">5.29 </span><span class="name">Python Client</span></a></span></dt><dt><span class="section"><a href="#id-1.7.31"><span class="number">5.30 </span><span class="name">Horizon Interface</span></a></span></dt><dt><span class="section"><a href="#id-1.7.32"><span class="number">5.31 </span><span class="name">Cluster Drivers</span></a></span></dt><dt><span class="section"><a href="#id-1.7.33"><span class="number">5.32 </span><span class="name">Cluster Type Definition</span></a></span></dt><dt><span class="section"><a href="#id-1.7.34"><span class="number">5.33 </span><span class="name">Heat Stack Templates</span></a></span></dt><dt><span class="section"><a href="#id-1.7.35"><span class="number">5.34 </span><span class="name">Choosing a COE</span></a></span></dt><dt><span class="section"><a href="#id-1.7.36"><span class="number">5.35 </span><span class="name">Native Clients</span></a></span></dt><dt><span class="section"><a href="#id-1.7.37"><span class="number">5.36 </span><span class="name">Kubernetes</span></a></span></dt><dt><span class="section"><a href="#id-1.7.38"><span class="number">5.37 </span><span class="name">Swarm</span></a></span></dt><dt><span class="section"><a href="#id-1.7.39"><span class="number">5.38 </span><span class="name">Mesos</span></a></span></dt><dt><span class="section"><a href="#id-1.7.40"><span class="number">5.39 </span><span class="name">Transport Layer Security</span></a></span></dt><dt><span class="section"><a href="#id-1.7.41"><span class="number">5.40 </span><span class="name">Networking</span></a></span></dt><dt><span class="section"><a href="#id-1.7.42"><span class="number">5.41 </span><span class="name">High Availability</span></a></span></dt><dt><span class="section"><a href="#id-1.7.43"><span class="number">5.42 </span><span class="name">Scaling</span></a></span></dt><dt><span class="section"><a href="#id-1.7.44"><span class="number">5.43 </span><span class="name">Storage</span></a></span></dt><dt><span class="section"><a href="#id-1.7.45"><span class="number">5.44 </span><span class="name">Image Management</span></a></span></dt><dt><span class="section"><a href="#id-1.7.46"><span class="number">5.45 </span><span class="name">Notification</span></a></span></dt><dt><span class="section"><a href="#id-1.7.47"><span class="number">5.46 </span><span class="name">Container Monitoring</span></a></span></dt><dt><span class="section"><a href="#id-1.7.48"><span class="number">5.47 </span><span class="name">Kubernetes External Load Balancer</span></a></span></dt></dl></div></div><div class="sect1" id="id-1.7.2"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Introduction</span> <a title="Permalink" class="permalink" href="#id-1.7.2">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This guide is intended for users who use Magnum to deploy and manage clusters
            of hosts for a Container Orchestration Engine.  It describes the infrastructure
            that Magnum creates and how to work with them.</p><p>Section 1-3 describe Magnum itself, including an overview, the CLI and
            Horizon interface.  Section 4-9 describe the Container Orchestration
            Engine (COE) supported along with a guide on how to select one that
            best meets your needs and how to develop a driver for a new COE.
            Section 10-15 describe the low level OpenStack infrastructure that is
            created and managed by Magnum to support the COE’s.</p></div><div class="sect1" id="id-1.7.3"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Terminology</span> <a title="Permalink" class="permalink" href="#id-1.7.3">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.3.2.1"><span class="term ">Cluster (previously Bay)</span></dt><dd><p>A cluster is the construct in which Magnum launches container orchestration
                        engines. After a cluster has been created the user is able to add containers
                        to it either directly, or in the case of the Kubernetes container
                        orchestration engine within pods - a logical construct specific to that
                        implementation. A cluster is created based on a ClusterTemplate.</p></dd><dt id="id-1.7.3.2.2"><span class="term ">ClusterTemplate (previously BayModel)</span></dt><dd><p>A ClusterTemplate in Magnum is roughly equivalent to a flavor in Nova. It
                        acts as a template that defines options such as the container orchestration
                        engine, keypair and image for use when Magnum is creating clusters using
                        the given ClusterTemplate.</p></dd><dt id="id-1.7.3.2.3"><span class="term ">Container Orchestration Engine (COE)</span></dt><dd><p>A container orchestration engine manages the lifecycle of one or more
                        containers, logically represented in Magnum as a cluster. Magnum supports a
                        number of container orchestration engines, each with their own pros and cons,
                        including Docker Swarm, Kubernetes, and Mesos.</p></dd></dl></div></div><div class="sect1" id="id-1.7.4"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Overview</span> <a title="Permalink" class="permalink" href="#id-1.7.4">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum is an OpenStack API service developed by the OpenStack Containers Team
            making container orchestration engines (COE) such as Docker Swarm, Kubernetes
            and Apache Mesos available as the first class resources in OpenStack.</p><p>Magnum uses Heat to orchestrate an OS image which contains Docker and COE
            and runs that image in either virtual machines or bare metal in a cluster
            configuration.</p><p>Magnum offers complete life-cycle management of COEs in an
            OpenStack environment, integrated with other OpenStack services for a seamless
            experience for OpenStack users who wish to run containers in an OpenStack
            environment.</p><p>Following are few salient features of Magnum:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Standard API based complete life-cycle management for Container Clusters</p></li><li class="listitem "><p>Multi-tenancy for container clusters</p></li><li class="listitem "><p>Choice of COE: Kubernetes, Swarm, Mesos, DC/OS</p></li><li class="listitem "><p>Choice of container cluster deployment model: VM or Bare-metal</p></li><li class="listitem "><p>Keystone-based multi-tenant security and auth management</p></li><li class="listitem "><p>Neutron based multi-tenant network control and isolation</p></li><li class="listitem "><p>Cinder based volume service for containers</p></li><li class="listitem "><p>Integrated with OpenStack: SSO experience for cloud users</p></li><li class="listitem "><p>Secure container cluster access (TLS enabled)</p></li></ul></div><p>More details: <a class="link" href="https://wiki.openstack.org/wiki/Magnum" target="_blank">Magnum Project Wiki</a></p></div><div class="sect1" id="id-1.7.5"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">ClusterTemplate</span> <a title="Permalink" class="permalink" href="#id-1.7.5">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A ClusterTemplate (previously known as BayModel) is a collection of parameters
            to describe how a cluster can be constructed.  Some parameters are relevant to
            the infrastructure of the cluster, while others are for the particular COE.  In
            a typical workflow, a user would create a ClusterTemplate, then create one or
            more clusters using the ClusterTemplate.  A cloud provider can also define a
            number of ClusterTemplates and provide them to the users.  A ClusterTemplate
            cannot be updated or deleted if a cluster using this ClusterTemplate still
            exists.</p><p>The definition and usage of the parameters of a ClusterTemplate are as follows.
            They are loosely grouped as: mandatory, infrastructure, COE specific.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.5.4.1"><span class="term ">&lt;name&gt;</span></dt><dd><p>Name of the ClusterTemplate to create.  The name does not have to be
                        unique.  If multiple ClusterTemplates have the same name, you will need to
                        use the UUID to select the ClusterTemplate when creating a cluster or
                        updating, deleting a ClusterTemplate.  If a name is not specified, a random
                        name will be generated using a string and a number, for example
                        “pi-13-model”.</p></dd><dt id="id-1.7.5.4.2"><span class="term ">–coe &lt;coe&gt;</span></dt><dd><p>Specify the Container Orchestration Engine to use.  Supported
                        COE’s include ‘kubernetes’, ‘swarm’, ‘mesos’.  If your environment
                        has additional cluster drivers installed, refer to the cluster driver
                        documentation for the new COE names.  This is a mandatory parameter
                        and there is no default value.</p></dd><dt id="id-1.7.5.4.3"><span class="term ">–image &lt;image&gt;</span></dt><dd><p>The name or UUID of the base image in Glance to boot the servers for
                        the cluster.  The image must have the attribute ‘os_distro’ defined
                        as appropriate for the cluster driver.  For the currently supported
                        images, the os_distro names are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="10" class="c1" /><col width="21" class="c2" /></colgroup><thead><tr><th>
                        <p>COE</p>
                      </th><th>
                        <p>os-distro</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Kubernetes</p>
                      </td><td>
                        <p>Fedora-atomic, CoreOS</p>
                      </td></tr><tr><td>
                        <p>Swarm</p>
                      </td><td>
                        <p>Fedora-atomic</p>
                      </td></tr><tr><td>
                        <p>Mesos</p>
                      </td><td>
                        <p>Ubuntu</p>
                      </td></tr></tbody></table></div><p>This is a mandatory parameter and there is no default value.</p></dd><dt id="id-1.7.5.4.4"><span class="term ">–keypair &lt;keypair&gt;</span></dt><dd><p>The name of the SSH keypair to configure in the cluster servers
                        for ssh access.  You will need the key to be able to ssh to the
                        servers in the cluster.  The login name is specific to the cluster
                        driver. If keypair is not provided in template it will be required at
                        Cluster create. This value will be overridden by any keypair value that
                        is provided during Cluster create.</p></dd><dt id="id-1.7.5.4.5"><span class="term ">–external-network &lt;external-network&gt;</span></dt><dd><p>The name or network ID of a Neutron network to provide connectivity
                        to the external internet for the cluster.  This network must be an
                        external network, i.e. its attribute ‘router:external’ must be
                        ‘True’.  The servers in the cluster will be connected to a private
                        network and Magnum will create a router between this private network
                        and the external network.  This will allow the servers to download
                        images, access discovery service, etc, and the containers to install
                        packages, etc.  In the opposite direction, floating IP’s will be
                        allocated from the external network to provide access from the
                        external internet to servers and the container services hosted in
                        the cluster.  This is a mandatory parameter and there is no default
                        value.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.5.5.1"><span class="term ">
              <code class="option">--public</code>
            </span></dt><dd><p>Access to a ClusterTemplate is normally limited to the admin, owner or users
                        within the same tenant as the owners.  Setting this flag
                        makes the ClusterTemplate public and accessible by other users.  The default
                        is not public.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.5.6.1"><span class="term ">–server-type &lt;server-type&gt;</span></dt><dd><p>The servers in the cluster can be VM or baremetal.  This parameter selects
                        the type of server to create for the cluster.  The default is ‘vm’. Possible
                        values are ‘vm’, ‘bm’.</p></dd><dt id="id-1.7.5.6.2"><span class="term ">–network-driver &lt;network-driver&gt;</span></dt><dd><p>The name of a network driver for providing the networks for the
                        containers.  Note that this is different and separate from the Neutron
                        network for the cluster.  The operation and networking model are specific
                        to the particular driver. Supported network drivers and the default driver are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="11" class="c1" /><col width="17" class="c2" /><col width="8" class="c3" /></colgroup><thead><tr><th>
                        <p>COE</p>
                      </th><th>
                        <p>Network-Driver</p>
                      </th><th>
                        <p>Default</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Kubernetes</p>
                      </td><td>
                        <p>Flannel</p>
                      </td><td>
                        <p>Flannel</p>
                      </td></tr><tr><td>
                        <p>Swarm</p>
                      </td><td>
                        <p>Docker, Flannel</p>
                      </td><td>
                        <p>Flannel</p>
                      </td></tr><tr><td>
                        <p>Mesos</p>
                      </td><td>
                        <p>Docker</p>
                      </td><td>
                        <p>Docker</p>
                      </td></tr></tbody></table></div></dd><dt id="id-1.7.5.6.3"><span class="term ">–volume-driver &lt;volume-driver&gt;</span></dt><dd><p>The name of a volume driver for managing the persistent storage for
                        the containers.  The functionality supported are specific to the
                        driver.  Supported volume drivers and the default driver are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="13" class="c2" /><col width="11" class="c3" /></colgroup><thead><tr><th>
                        <p>COE</p>
                      </th><th>
                        <p>Volume-Driver</p>
                      </th><th>
                        <p>Default</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Kubernetes</p>
                      </td><td>
                        <p>Cinder</p>
                      </td><td>
                        <p>No Driver</p>
                      </td></tr><tr><td>
                        <p>Swarm</p>
                      </td><td>
                        <p>Rexray</p>
                      </td><td>
                        <p>No Driver</p>
                      </td></tr><tr><td>
                        <p>Mesos</p>
                      </td><td>
                        <p>Rexray</p>
                      </td><td>
                        <p>No Driver</p>
                      </td></tr></tbody></table></div></dd><dt id="id-1.7.5.6.4"><span class="term ">–dns-nameserver &lt;dns-nameserver&gt;</span></dt><dd><p>The DNS nameserver for the servers and containers in the cluster to use.
                        This is configured in the private Neutron network for the cluster.  The
                        default is ‘8.8.8.8’.</p></dd><dt id="id-1.7.5.6.5"><span class="term ">–flavor &lt;flavor&gt;</span></dt><dd><p>The nova flavor id for booting the node servers.  The default
                        is ‘m1.small’.</p></dd><dt id="id-1.7.5.6.6"><span class="term ">–master-flavor &lt;master-flavor&gt;</span></dt><dd><p>The nova flavor id for booting the master or manager servers.  The
                        default is ‘m1.small’.</p></dd><dt id="id-1.7.5.6.7"><span class="term ">–http-proxy &lt;http-proxy&gt;</span></dt><dd><p>The IP address for a proxy to use when direct http access from the
                        servers to sites on the external internet is blocked.  This may
                        happen in certain countries or enterprises, and the proxy allows the
                        servers and containers to access these sites.  The format is a URL
                        including a port number.  The default is ‘None’.</p></dd><dt id="id-1.7.5.6.8"><span class="term ">–https-proxy &lt;https-proxy&gt;</span></dt><dd><p>The IP address for a proxy to use when direct https access from the
                        servers to sites on the external internet is blocked.  This may
                        happen in certain countries or enterprises, and the proxy allows the
                        servers and containers to access these sites.  The format is a URL
                        including a port number.  The default is ‘None’.</p></dd><dt id="id-1.7.5.6.9"><span class="term ">–no-proxy &lt;no-proxy&gt;</span></dt><dd><p>When a proxy server is used, some sites should not go through the
                        proxy and should be accessed normally.  In this case, you can
                        specify these sites as a comma separated list of IP’s.  The default
                        is ‘None’.</p></dd><dt id="id-1.7.5.6.10"><span class="term ">–docker-volume-size &lt;docker-volume-size&gt;</span></dt><dd><p>If specified, container images will be stored in a cinder volume of the
                        specified size in GB. Each cluster node will have a volume attached of
                        the above size. If not specified, images will be stored in the compute
                        instance’s local disk. For the ‘devicemapper’ storage driver, the minimum
                        value is 3GB. For the ‘overlay’ storage driver, the minimum value is 1GB.
                        This value can be overridden at cluster creation.</p></dd><dt id="id-1.7.5.6.11"><span class="term ">–docker-storage-driver &lt;docker-storage-driver&gt;</span></dt><dd><p>The name of a driver to manage the storage for the images and the
                        container’s writable layer.  The supported drivers are ‘devicemapper’
                        and ‘overlay’.  The default is ‘devicemapper’.</p></dd><dt id="id-1.7.5.6.12"><span class="term ">–labels &lt;KEY1=VALUE1,KEY2=VALUE2;KEY3=VALUE3…&gt;</span></dt><dd><p>Arbitrary labels in the form of key=value pairs.  The accepted keys
                        and valid values are defined in the cluster drivers.  They are used as a
                        way to pass additional parameters that are specific to a cluster driver.
                        Refer to the subsection on labels for a list of the supported
                        key/value pairs and their usage.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.5.7.1"><span class="term ">
              <code class="option">--tls-disabled</code>
            </span></dt><dd><p>Transport Layer Security (TLS) is normally enabled to secure the
                        cluster.  In some cases, users may want to disable TLS in the cluster,
                        for instance during development or to troubleshoot certain problems.
                        Specifying this parameter will disable TLS so that users can access
                        the COE endpoints without a certificate.  The default is TLS
                        enabled.</p></dd><dt id="id-1.7.5.7.2"><span class="term ">
              <code class="option">--registry-enabled</code>
            </span></dt><dd><p>Docker images by default are pulled from the public Docker registry,
                        but in some cases, users may want to use a private registry.  This
                        option provides an alternative registry based on the Registry V2:
                        Magnum will create a local registry in the cluster backed by swift to
                        host the images.  Refer to
                        <a class="link" href="https://github.com/docker/distribution" target="_blank">Docker Registry 2.0</a>
                        for more details.  The default is to use the public registry.</p></dd><dt id="id-1.7.5.7.3"><span class="term ">
              <code class="option">--master-lb-enabled</code>
            </span></dt><dd><p>Since multiple masters may exist in a cluster, a load balancer is
                        created to provide the API endpoint for the cluster and to direct
                        requests to the masters.  In some cases, such as when the LBaaS
                        service is not available, this option can be set to ‘false’ to
                        create a cluster without the load balancer.  In this case, one of the
                        masters will serve as the API endpoint.  The default is ‘true’,
                        i.e. to create the load balancer for the cluster.</p></dd></dl></div><div class="sect2" id="id-1.7.5.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Labels</span> <a title="Permalink" class="permalink" href="#id-1.7.5.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Labels is a general method to specify supplemental parameters that are
                specific to certain COE or associated with certain options.  Their
                format is key/value pair and their meaning is interpreted by the
                drivers that uses them.  The drivers do validate the key/value pairs.
                Their usage is explained in details in the appropriate sections,
                however, since there are many possible labels, the following table
                provides a summary to help give a clearer picture.  The label keys in
                the table are linked to more details elsewhere in the user guide.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="39" class="c1" /><col width="20" class="c2" /><col width="15" class="c3" /></colgroup><thead><tr><th>
                    <p>label key</p>
                  </th><th>
                    <p>label value</p>
                  </th><th>
                    <p>default</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>
                      <code class="literal">flannel-network-cidr</code>
                    </p>
                  </td><td>
                    <p>IPv4 CIDR</p>
                  </td><td>
                    <p>10.100.0.0/16</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">flannel-backend</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>udp</p></li><li class="listitem "><p>vxlan</p></li><li class="listitem "><p>host-gw</p></li></ul></div>
                  </td><td>
                    <p>udp</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">flannel-network-subnetlen</code>
                    </p>
                  </td><td>
                    <p>size of subnet to
                                    assign to node</p>
                  </td><td>
                    <p>24</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">rexray-preempt</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>true</p></li><li class="listitem "><p>false</p></li></ul></div>
                  </td><td>
                    <p>false</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-isolation</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>filesystem/posix</p></li><li class="listitem "><p>filesystem/linux</p></li><li class="listitem "><p>filesystem/shared</p></li><li class="listitem "><p>posix/cpu</p></li><li class="listitem "><p>posix/mem</p></li><li class="listitem "><p>posix/disk</p></li><li class="listitem "><p>cgroups/cpu</p></li><li class="listitem "><p>cgroups/mem</p></li><li class="listitem "><p>docker/runtime</p></li><li class="listitem "><p>namespaces/pid</p></li></ul></div>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-image-providers</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>appc</p></li><li class="listitem "><p>docker</p></li><li class="listitem "><p>appc,docker</p></li></ul></div>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-work-dir</code>
                    </p>
                  </td><td>
                    <p>(directory name)</p>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-executor-env-variables</code>
                    </p>
                  </td><td>
                    <p>(file name)</p>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">swarm-strategy</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>spread</p></li><li class="listitem "><p>binpack</p></li><li class="listitem "><p>random</p></li></ul></div>
                  </td><td>
                    <p>spread</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">admission-control-list</code>
                    </p>
                  </td><td>
                    <p>see below</p>
                  </td><td>
                    <p>see below</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">prometheus-monitoring</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>true</p></li><li class="listitem "><p>false</p></li></ul></div>
                  </td><td>
                    <p>false</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">grafana-admin-passwd</code>
                    </p>
                  </td><td>
                    <p>(any string)</p>
                  </td><td>
                    <p>“admin”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">kube-tag</code>
                    </p>
                  </td><td>
                    <p>see below</p>
                  </td><td>
                    <p>see below</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">kube-dashboard-enabled</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>true</p></li><li class="listitem "><p>false</p></li></ul></div>
                  </td><td>
                    <p>true</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">"docker-volume-type</code>
                    </p>
                  </td><td>
                    <p>see below</p>
                  </td><td>
                    <p>see below</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">etcd-volume-size</code>
                    </p>
                  </td><td>
                    <p>etcd storage
                                    volume size</p>
                  </td><td>
                    <p>0</p>
                  </td></tr></tbody></table></div></div></div><div class="sect1" id="id-1.7.6"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster</span> <a title="Permalink" class="permalink" href="#id-1.7.6">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A cluster (previously known as bay) is an instance of the ClusterTemplate
            of a COE.  Magnum deploys a cluster by referring to the attributes
            defined in the particular ClusterTemplate as well as a few additional
            parameters for the cluster.  Magnum deploys the orchestration templates
            provided by the cluster driver to create and configure all the necessary
            infrastructure.  When ready, the cluster is a fully operational COE that
            can host containers.</p><div class="sect2" id="id-1.7.6.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Infrastructure</span> <a title="Permalink" class="permalink" href="#id-1.7.6.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The infrastructure of the cluster consists of the resources provided by
                the various OpenStack services.  Existing infrastructure, including
                infrastructure external to OpenStack, can also be used by the cluster,
                such as DNS, public network, public discovery service, Docker registry.
                The actual resources created depends on the COE type and the options
                specified; therefore you need to refer to the cluster driver documentation
                of the COE for specific details.  For instance, the option
                ‘–master-lb-enabled’ in the ClusterTemplate will cause a load balancer pool
                along with the health monitor and floating IP to be created.  It is
                important to distinguish resources in the IaaS level from resources in
                the PaaS level.  For instance, the infrastructure networking in
                OpenStack IaaS is different and separate from the container networking
                in Kubernetes or Swarm PaaS.</p><p>Typical infrastructure includes the following.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.6.3.4.1"><span class="term ">Servers</span></dt><dd><p>The servers host the containers in the cluster and these servers can be
                            VM or bare metal.  VM’s are provided by Nova.  Since multiple VM’s
                            are hosted on a physical server, the VM’s provide the isolation
                            needed for containers between different tenants running on the same
                            physical server.  Bare metal servers are provided by Ironic and are
                            used when peak performance with virtually no overhead is needed for
                            the containers.</p></dd><dt id="id-1.7.6.3.4.2"><span class="term ">Identity</span></dt><dd><p>Keystone provides the authentication and authorization for managing
                            the cluster infrastructure.</p></dd><dt id="id-1.7.6.3.4.3"><span class="term ">Network</span></dt><dd><p>Networking among the servers is provided by Neutron.  Since COE
                            currently are not multi-tenant, isolation for multi-tenancy on the
                            networking level is done by using a private network for each cluster.
                            As a result, containers belonging to one tenant will not be
                            accessible to containers or servers of another tenant.  Other
                            networking resources may also be used, such as load balancer and
                            routers.  Networking among containers can be provided by Kuryr if
                            needed.</p></dd><dt id="id-1.7.6.3.4.4"><span class="term ">Storage</span></dt><dd><p>Cinder provides the block storage that can be used to host the
                            containers and as persistent storage for the containers.</p></dd><dt id="id-1.7.6.3.4.5"><span class="term ">Security</span></dt><dd><p>Barbican provides the storage of secrets such as certificates used
                            for Transport Layer Security (TLS) within the cluster.</p></dd></dl></div></div><div class="sect2" id="id-1.7.6.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Life cycle</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The set of life cycle operations on the cluster is one of the key value
                that Magnum provides, enabling clusters to be managed painlessly on
                OpenStack.  The current operations are the basic CRUD operations, but
                more advanced operations are under discussion in the community and
                will be implemented as needed.</p><p><span class="bold"><strong>NOTE</strong></span> The OpenStack resources created for a cluster are fully
                accessible to the cluster owner.  Care should be taken when modifying or
                reusing these resources to avoid impacting Magnum operations in
                unexpected manners.  For instance, if you launch your own Nova
                instance on the cluster private network, Magnum would not be aware of this
                instance.  Therefore, the cluster-delete operation will fail because
                Magnum would not delete the extra Nova instance and the private Neutron
                network cannot be removed while a Nova instance is still attached.</p><p><span class="bold"><strong>NOTE</strong></span> Currently Heat nested templates are used to create the
                resources; therefore if an error occurs, you can troubleshoot through
                Heat.  For more help on Heat stack troubleshooting, refer to the
            <a class="link" href="https://github.com/openstack/magnum/blob/master/doc/source/troubleshooting-guide.rst#heat-stacks" target="_blank">Troubleshooting Guide</a>.</p><div class="sect3" id="id-1.7.6.4.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><span class="bold"><strong>NOTE</strong></span> bay-&lt;command&gt; are the deprecated versions of these commands and are
                    still support in current release. They will be removed in a future version.
                    Any references to the term bay will be replaced in the parameters when using
                    the ‘bay’ versions of the commands. For example, in ‘bay-create’ –baymodel
                    is used as the baymodel parameter for this command instead of
                    –cluster-template.</p><p>The ‘cluster-create’ command deploys a cluster, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create mycluster \
                  --cluster-template mytemplate \
                  --node-count 8 \
                  --master-count 3</pre></div><p>The ‘cluster-create’ operation is asynchronous; therefore you can initiate
                    another ‘cluster-create’ operation while the current cluster is being created.
                    If the cluster fails to be created, the infrastructure created so far may
                    be retained or deleted depending on the particular orchestration
                    engine.  As a common practice, a failed cluster is retained during
                    development for troubleshooting, but they are automatically deleted in
                    production.  The current cluster drivers use Heat templates and the
                    resources of a failed ‘cluster-create’ are retained.</p><p>The definition and usage of the parameters for ‘cluster-create’ are as
                    follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.6.4.5.7.1"><span class="term ">&lt;name&gt;</span></dt><dd><p>Name of the cluster to create.  If a name is not specified, a random
                                name will be generated using a string and a number, for example
                                “gamma-7-cluster”.</p></dd><dt id="id-1.7.6.4.5.7.2"><span class="term ">–cluster-template &lt;cluster-template&gt;</span></dt><dd><p>The ID or name of the ClusterTemplate to use.  This is a mandatory
                                parameter.  Once a ClusterTemplate is used to create a cluster, it cannot
                                be deleted or modified until all clusters that use the ClusterTemplate have
                                been deleted.</p></dd><dt id="id-1.7.6.4.5.7.3"><span class="term ">–keypair &lt;keypair&gt;</span></dt><dd><p>The name of the SSH keypair to configure in the cluster servers
                                for ssh access.  You will need the key to be able to ssh to the
                                servers in the cluster.  The login name is specific to the cluster
                                driver. If keypair is not provided it will attempt to use the value in
                                the ClusterTemplate. If the ClusterTemplate is also missing a keypair value
                                then an error will be returned.  The keypair value provided here will
                                override the keypair value from the ClusterTemplate.</p></dd><dt id="id-1.7.6.4.5.7.4"><span class="term ">–node-count &lt;node-count&gt;</span></dt><dd><p>The number of servers that will serve as node in the cluster.
                                The default is 1.</p></dd><dt id="id-1.7.6.4.5.7.5"><span class="term ">–master-count &lt;master-count&gt;</span></dt><dd><p>The number of servers that will serve as master for the cluster.
                                The default is 1.  Set to more than 1 master to enable High
                                Availability.  If the option ‘–master-lb-enabled’ is specified in
                                the ClusterTemplate, the master servers will be placed in a load balancer
                                pool.</p></dd><dt id="id-1.7.6.4.5.7.6"><span class="term ">–discovery-url &lt;discovery-url&gt;</span></dt><dd><p>The custom discovery url for node discovery.  This is used by the
                                COE to discover the servers that have been created to host the
                                containers.  The actual discovery mechanism varies with the COE.  In
                                some cases, Magnum fills in the server info in the discovery
                                service.  In other cases, if the discovery-url is not specified,
                                Magnum will use the public discovery service at:</p><div class="verbatim-wrap"><pre class="screen">https://discovery.etcd.io</pre></div><p>In this case, Magnum will generate a unique url here for each cluster
                                and store the info for the servers.</p></dd><dt id="id-1.7.6.4.5.7.7"><span class="term ">–timeout &lt;timeout&gt;</span></dt><dd><p>The timeout for cluster creation in minutes. The value expected is a
                                positive integer and the default is 60 minutes.  If the timeout is
                                reached during cluster-create, the operation will be aborted and the
                                cluster status will be set to ‘CREATE_FAILED’.</p></dd></dl></div></div><div class="sect3" id="id-1.7.6.4.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ‘cluster-list’ command lists all the clusters that belong to the tenant,
                    for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-list</pre></div></div><div class="sect3" id="id-1.7.6.4.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Show</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ‘cluster-show’ command prints all the details of a cluster, for
                    example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-show mycluster</pre></div><p>The properties include those not specified by users that have been
                    assigned default values and properties from new resources that
                    have been created for the cluster.</p></div><div class="sect3" id="id-1.7.6.4.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A cluster can be modified using the ‘cluster-update’ command, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-update mycluster replace node_count=8</pre></div><p>The parameters are positional and their definition and usage are as
                    follows.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.6.4.8.5.1"><span class="term ">&lt;cluster&gt;</span></dt><dd><p>This is the first parameter, specifying the UUID or name of the cluster
                                to update.</p></dd><dt id="id-1.7.6.4.8.5.2"><span class="term ">&lt;op&gt;</span></dt><dd><p>This is the second parameter, specifying the desired change to be
                                made to the cluster attributes.  The allowed changes are ‘add’,
                                ‘replace’ and ‘remove’.</p></dd><dt id="id-1.7.6.4.8.5.3"><span class="term ">&lt;attribute=value&gt;</span></dt><dd><p>This is the third parameter, specifying the targeted attributes in
                                the cluster as a list separated by blank space.  To add or replace an
                                attribute, you need to specify the value for the attribute.  To
                                remove an attribute, you only need to specify the name of the
                                attribute.  Currently the only attribute that can be replaced or
                                removed is ‘node_count’.  The attributes ‘name’, ‘master_count’ and
                                ‘discovery_url’ cannot be replaced or delete.  The table below
                                summarizes the possible change to a cluster.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="15" class="c1" /><col width="5" class="c2" /><col width="18" class="c3" /><col width="23" class="c4" /></colgroup><thead><tr><th>
                            <p>Attribute</p>
                          </th><th>
                            <p>add</p>
                          </th><th>
                            <p>replace</p>
                          </th><th>
                            <p>remove</p>
                          </th></tr></thead><tbody><tr><td>
                            <p>node_count</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>add/remove nodes</p>
                          </td><td>
                            <p>reset to default of 1</p>
                          </td></tr><tr><td>
                            <p>master_count</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td></tr><tr><td>
                            <p>name</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td></tr><tr><td>
                            <p>discovery_url</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td></tr></tbody></table></div></dd></dl></div><p>The ‘cluster-update’ operation cannot be initiated when another operation
                    is in progress.</p><p><span class="bold"><strong>NOTE:</strong></span> The attribute names in cluster-update are slightly different
                    from the corresponding names in the cluster-create command: the dash ‘-‘
                    is replaced by an underscore ‘_’.  For instance, ‘node-count’ in
                    cluster-create is ‘node_count’ in cluster-update.</p></div><div class="sect3" id="id-1.7.6.4.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scale</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Scaling a cluster means adding servers to or removing servers from the cluster.
                    Currently, this is done through the ‘cluster-update’ operation by modifying
                    the node-count attribute, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-update mycluster replace node_count=2</pre></div><p>When some nodes are removed, Magnum will attempt to find nodes with no
                    containers to remove.  If some nodes with containers must be removed,
                    Magnum will log a warning message.</p></div><div class="sect3" id="id-1.7.6.4.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.5.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete</span> <a title="Permalink" class="permalink" href="#id-1.7.6.4.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ‘cluster-delete’ operation removes the cluster by deleting all resources
                    such as servers, network, storage;  for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-delete mycluster</pre></div><p>The only parameter for the cluster-delete command is the ID or name of the
                    cluster to delete.  Multiple clusters can be specified, separated by a blank
                    space.</p><p>If the operation fails, there may be some remaining resources that
                    have not been deleted yet.  In this case, you can troubleshoot through
                    Heat.  If the templates are deleted manually in Heat, you can delete
                    the cluster in Magnum to clean up the cluster from Magnum database.</p><p>The ‘cluster-delete’ operation can be initiated when another operation is
                    still in progress.</p></div></div></div><div class="sect1" id="id-1.7.7"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Python Client</span> <a title="Permalink" class="permalink" href="#id-1.7.7">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2" id="id-1.7.7.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installation</span> <a title="Permalink" class="permalink" href="#id-1.7.7.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Follow the instructions in the OpenStack Installation Guide to enable the
                repositories for your distribution:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/liberty/install-guide-rdo/" target="_blank">RHEL/CentOS/Fedora</a>
              </p></li><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/liberty/install-guide-ubuntu/" target="_blank">Ubuntu/Debian</a>
              </p></li><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/liberty/install-guide-obs/" target="_blank">openSUSE/SUSE Linux Enterprise</a>
              </p></li></ul></div><p>Install using distribution packages for RHEL/CentOS/Fedora:</p><div class="verbatim-wrap"><pre class="screen">$ sudo yum install python-magnumclient</pre></div><p>Install using distribution packages for Ubuntu/Debian:</p><div class="verbatim-wrap"><pre class="screen">$ sudo apt-get install python-magnumclient</pre></div><p>Install using distribution packages for OpenSuSE and SuSE Enterprise Linux:</p><div class="verbatim-wrap"><pre class="screen">$ sudo zypper install python-magnumclient</pre></div></div><div class="sect2" id="id-1.7.7.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Verifying installation</span> <a title="Permalink" class="permalink" href="#id-1.7.7.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Execute the <code class="literal">magnum</code> command with the <code class="literal">–version</code> argument to confirm that the
                client is installed and in the system path:</p><div class="verbatim-wrap"><pre class="screen">$ magnum --version
1.1.0</pre></div><p>Note that the version returned may differ from the above, 1.1.0 was the latest
                available version at the time of writing.</p></div><div class="sect2" id="id-1.7.7.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the command-line client</span> <a title="Permalink" class="permalink" href="#id-1.7.7.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Refer to the <a class="link" href="http://docs.openstack.org/cli-reference/magnum.html" target="_blank">OpenStack Command-Line Interface Reference</a> for a full list of the
                commands supported by the <code class="literal">magnum</code> command-line client.</p></div></div><div class="sect1" id="id-1.7.8"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Horizon Interface</span> <a title="Permalink" class="permalink" href="#id-1.7.8">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum provides a Horizon plugin so that users can access the Container
            Infrastructure Management service through the OpenStack browser-based
            graphical UI.  The plugin is available from
          <a class="link" href="https://github.com/openstack/magnum-ui" target="_blank">magnum-ui</a>.  It is not
            installed by default in the standard Horizon service, but you can
            follow the instruction for <a class="link" href="http://docs.openstack.org/developer/horizon/tutorials/plugin.html#installing-your-plugin" target="_blank">installing a Horizon plugin</a>.</p><p>In Horizon, the container infrastructure panel is part of the
            ‘Project’ view and it currently supports the following operations:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>View list of cluster templates</p></li><li class="listitem "><p>View details of a cluster template</p></li><li class="listitem "><p>Create a cluster template</p></li><li class="listitem "><p>Delete a cluster template</p></li><li class="listitem "><p>View list of clusters</p></li><li class="listitem "><p>View details of a cluster</p></li><li class="listitem "><p>Create a cluster</p></li><li class="listitem "><p>Delete a cluster</p></li><li class="listitem "><p>Get the Certificate Authority for a cluster</p></li><li class="listitem "><p>Sign a user key and obtain a signed certificate for accessing the secured
                    COE API endpoint in a cluster.</p></li></ul></div><p>Other operations are not yet supported and the CLI should be used for these.</p></div><div class="sect1" id="id-1.7.9"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster Drivers</span> <a title="Permalink" class="permalink" href="#id-1.7.9">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A cluster driver is a collection of python code, heat templates, scripts,
            images, and documents for a particular COE on a particular
            distro.  Magnum presents the concept of ClusterTemplates and clusters.  The
            implementation for a particular cluster type is provided by the cluster driver.
            In other words, the cluster driver provisions and manages the infrastructure
            for the COE.  Magnum includes default drivers for the following
            COE and distro pairs:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="12" class="c1" /><col width="15" class="c2" /></colgroup><thead><tr><th>
                  <p>COE</p>
                </th><th>
                  <p>distro</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Kubernetes</p>
                </td><td>
                  <p>Fedora Atomic</p>
                </td></tr><tr><td>
                  <p>Kubernetes</p>
                </td><td>
                  <p>CoreOS</p>
                </td></tr><tr><td>
                  <p>Swarm</p>
                </td><td>
                  <p>Fedora Atomic</p>
                </td></tr><tr><td>
                  <p>Mesos</p>
                </td><td>
                  <p>Ubuntu</p>
                </td></tr></tbody></table></div><p>Magnum is designed to accommodate new cluster drivers to support custom
            COE’s and this section describes how a new cluster driver can be
            constructed and enabled in Magnum.</p><div class="sect2" id="id-1.7.9.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Directory structure</span> <a title="Permalink" class="permalink" href="#id-1.7.9.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum expects the components to be organized in the following
                directory structure under the directory ‘drivers’:</p><div class="verbatim-wrap"><pre class="screen">COE_Distro/
   image/
   templates/
   api.py
   driver.py
   monitor.py
   scale.py
   template_def.py
   version.py</pre></div><p>The minimum required components are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.9.5.5.1"><span class="term ">driver.py</span></dt><dd><p>Python code that implements the controller operations for
                            the particular COE.  The driver must implement:
                            Currently supported:
                            <code class="literal">cluster_create</code>, <code class="literal">cluster_update</code>, <code class="literal">cluster_delete</code>.</p></dd><dt id="id-1.7.9.5.5.2"><span class="term ">templates</span></dt><dd><p>A directory of orchestration templates for managing the lifecycle
                            of clusters, including creation, configuration, update, and deletion.
                            Currently only Heat templates are supported, but in the future
                            other orchestration mechanism such as Ansible may be supported.</p></dd><dt id="id-1.7.9.5.5.3"><span class="term ">template_def.py</span></dt><dd><p>Python code that maps the parameters from the ClusterTemplate to the
                            input parameters for the orchestration and invokes
                            the orchestration in the templates directory.</p></dd><dt id="id-1.7.9.5.5.4"><span class="term ">version.py</span></dt><dd><p>Tracks the latest version of the driver in this directory.
                            This is defined by a <code class="literal">version</code> attribute and is represented in the
                            form of <code class="literal">1.0.0</code>. It should also include a <code class="literal">Driver</code> attribute with
                            descriptive name such as <code class="literal">fedora_swarm_atomic</code>.</p></dd></dl></div><p>The remaining components are optional:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.9.5.7.1"><span class="term ">image</span></dt><dd><p>Instructions for obtaining or building an image suitable for the COE.</p></dd><dt id="id-1.7.9.5.7.2"><span class="term ">api.py</span></dt><dd><p>Python code to interface with the COE.</p></dd><dt id="id-1.7.9.5.7.3"><span class="term ">monitor.py</span></dt><dd><p>Python code to monitor the resource utilization of the cluster.</p></dd><dt id="id-1.7.9.5.7.4"><span class="term ">scale.py</span></dt><dd><p>Python code to scale the cluster by adding or removing nodes.</p></dd></dl></div></div><div class="sect2" id="id-1.7.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Sample cluster driver</span> <a title="Permalink" class="permalink" href="#id-1.7.9.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To help developers in creating new COE drivers, a minimal cluster driver
                is provided as an example.  The ‘docker’ cluster driver will simply deploy
                a single VM running Ubuntu with the latest Docker version installed.
                It is not a true cluster, but the simplicity will help to illustrate
                the key concepts.</p><p>
            <span class="emphasis"><em>To be filled in</em></span>
          </p></div><div class="sect2" id="id-1.7.9.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing a cluster driver</span> <a title="Permalink" class="permalink" href="#id-1.7.9.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
            <span class="emphasis"><em>To be filled in</em></span>
          </p></div></div><div class="sect1" id="id-1.7.10"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster Type Definition</span> <a title="Permalink" class="permalink" href="#id-1.7.10">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are three key pieces to a Cluster Type Definition:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Heat Stack template - The HOT file that Magnum will use to generate a
                    cluster using a Heat Stack.</p></li><li class="step "><p>Template definition - Magnum’s interface for interacting with the Heat
                    template.</p></li><li class="step "><p>Definition Entry Point - Used to advertise the available Cluster Types.</p></li></ol></div></div><div class="sect2" id="id-1.7.10.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Heat Stack Template</span> <a title="Permalink" class="permalink" href="#id-1.7.10.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Heat Stack Template is where most of the real work happens. The result of
                the Heat Stack Template should be a full Container Orchestration Environment.</p></div><div class="sect2" id="id-1.7.10.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.9.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Template Definition</span> <a title="Permalink" class="permalink" href="#id-1.7.10.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Template definitions are a mapping of Magnum object attributes and Heat
                template parameters, along with Magnum consumable template outputs. A
                Cluster Type Definition indicates which Cluster Types it can provide.
                Cluster Types are how Magnum determines which of the enabled Cluster
                Type Definitions it will use for a given cluster.</p></div><div class="sect2" id="id-1.7.10.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.9.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Definition Entry Point</span> <a title="Permalink" class="permalink" href="#id-1.7.10.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Entry points are a standard discovery and import mechanism for Python objects.
                Each Template Definition should have an Entry Point in the
                <code class="literal">magnum.template_definitions</code> group. This example exposes it’s Template
                Definition as <code class="literal">example_template = example_template:ExampleTemplate</code> in the
                <code class="literal">magnum.template_definitions</code> group.</p></div><div class="sect2" id="id-1.7.10.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.9.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing Cluster Templates</span> <a title="Permalink" class="permalink" href="#id-1.7.10.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Because Cluster Type Definitions are basically Python projects, they can be
                worked with like any other Python project. They can be cloned from version
                control and installed or uploaded to a package index and installed via
                utilities such as pip.</p><p>Enabling a Cluster Type is as simple as adding it’s Entry Point to the
                <code class="literal">enabled_definitions</code> config option in magnum.conf.:</p><div class="verbatim-wrap"><pre class="screen"># Setup python environment and install Magnum

$ virtualenv .venv
$ source .venv/bin/active
(.venv)$ git clone https://github.com/openstack/magnum.git
(.venv)$ cd magnum
(.venv)$ python setup.py install

# List installed templates, notice default templates are enabled

(.venv)$ magnum-template-manage list-templates
Enabled Templates
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
Disabled Templates

# Install example template

(.venv)$ cd contrib/templates/example
(.venv)$ python setup.py install

# List installed templates, notice example template is disabled

(.venv)$ magnum-template-manage list-templates
Enabled Templates
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
Disabled Templates
  example_template: /home/example/.venv/local/lib/python2.7/site-packages/ExampleTemplate-0.1-py2.7.egg/example_template/example.yaml

# Enable example template by setting enabled_definitions in magnum.conf

(.venv)$ sudo mkdir /etc/magnum
(.venv)$ sudo bash -c "cat &gt; /etc/magnum/magnum.conf &lt;&lt; END_CONF
[bay]
enabled_definitions=magnum_vm_atomic_k8s,magnum_vm_coreos_k8s,example_template
END_CONF"

# List installed templates, notice example template is now enabled

(.venv)$ magnum-template-manage list-templates
Enabled Templates
  example_template: /home/example/.venv/local/lib/python2.7/site-packages/ExampleTemplate-0.1-py2.7.egg/example_template/example.yaml
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
Disabled Templates

# Use --details argument to get more details about each template

(.venv)$ magnum-template-manage list-templates --details
Enabled Templates
  example_template: /home/example/.venv/local/lib/python2.7/site-packages/ExampleTemplate-0.1-py2.7.egg/example_template/example.yaml
     Server_Type  OS       CoE
     vm         example  example_coe
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
     Server_Type   OS             CoE
     vm        fedora-atomic  kubernetes
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
     Server_Type  OS      CoE
     vm         coreos  kubernetes
Disabled Templates</pre></div></div></div><div class="sect1" id="id-1.7.11"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Heat Stack Templates</span> <a title="Permalink" class="permalink" href="#id-1.7.11">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Heat Stack Templates are what Magnum passes to Heat to generate a cluster. For
            each ClusterTemplate resource in Magnum, a Heat stack is created to arrange all
            of the cloud resources needed to support the container orchestration
            environment. These Heat stack templates provide a mapping of Magnum object
            attributes to Heat template parameters, along with Magnum consumable stack
            outputs. Magnum passes the Heat Stack Template to the Heat service to create a
            Heat stack. The result is a full Container Orchestration Environment.</p></div><div class="sect1" id="id-1.7.12"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Choosing a COE</span> <a title="Permalink" class="permalink" href="#id-1.7.12">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum supports a variety of COE options, and allows more to be added over time
            as they gain popularity. As an operator, you may choose to support the full
            variety of options, or you may want to offer a subset of the available choices.
            Given multiple choices, your users can run one or more clusters, and each may
            use a different COE. For example, I might have multiple clusters that use
            Kubernetes, and just one cluster that uses Swarm. All of these clusters can
            run concurrently, even though they use different COE software.</p><p>Choosing which COE to use depends on what tools you want to use to manage your
            containers once you start your app. If you want to use the Docker tools, you
            may want to use the Swarm cluster type. Swarm will spread your containers
            across the various nodes in your cluster automatically. It does not monitor
            the health of your containers, so it can’t restart them for you if they stop.
            It will not automatically scale your app for you (as of Swarm version 1.2.2).
            You may view this as a plus. If you prefer to manage your application yourself,
            you might prefer swarm over the other COE options.</p><p>Kubernetes (as of v1.2) is more sophisticated than Swarm (as of v1.2.2). It
            offers an attractive YAML file description of a pod, which is a grouping of
            containers that run together as part of a distributed application. This file
            format allows you to model your application deployment using a declarative
            style. It has support for auto scaling and fault recovery, as well as features
            that allow for sophisticated software deployments, including canary deploys
            and blue/green deploys. Kubernetes is very popular, especially for web
            applications.</p><p>Apache Mesos is a COE that has been around longer than Kubernetes or Swarm. It
            allows for a variety of different frameworks to be used along with it,
            including Marathon, Aurora, Chronos, Hadoop, and <a class="link" href="http://mesos.apache.org/documentation/latest/frameworks/" target="_blank">a number of others.</a></p><p>The Apache Mesos framework design can be used to run alternate COE software
            directly on Mesos. Although this approach is not widely used yet, it may soon
            be possible to run Mesos with Kubernetes and Swarm as frameworks, allowing
            you to share the resources of a cluster between multiple different COEs. Until
            this option matures, we encourage Magnum users to create multiple clusters, and
            use the COE in each cluster that best fits the anticipated workload.</p><p>Finding the right COE for your workload is up to you, but Magnum offers you a
            choice to select among the prevailing leading options. Once you decide, see
            the next sections for examples of how to create a cluster with your desired
            COE.</p></div><div class="sect1" id="id-1.7.13"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Native Clients</span> <a title="Permalink" class="permalink" href="#id-1.7.13">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum preserves the native user experience with a COE and does not
            provide a separate API or client.  This means you will need to use the
            native client for the particular cluster type to interface with the
            clusters.  In the typical case, there are two clients to consider:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.13.3.1"><span class="term ">COE level</span></dt><dd><p>This is the orchestration or management level such as Kubernetes,
                        Swarm, Mesos and its frameworks.</p></dd><dt id="id-1.7.13.3.2"><span class="term ">Container level</span></dt><dd><p>This is the low level container operation.  Currently it is
                        Docker for all clusters.</p></dd></dl></div><p>The clients can be CLI and/or browser-based.  You will need to refer
            to the documentation for the specific native client and appropriate
            version for details, but following are some pointers for reference.</p><p>Kubernetes CLI is the tool ‘kubectl’, which can be simply copied from
            a node in the cluster or downloaded from the Kubernetes release.  For
            instance, if the cluster is running Kubernetes release 1.2.0, the
            binary for ‘kubectl’ can be downloaded as and set up locally as
            follows:</p><div class="verbatim-wrap"><pre class="screen">curl -O https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/kubectl</pre></div><p>Kubernetes also provides a browser UI. If the cluster has the
            Kubernetes Dashboard running; it can be accessed using:</p><div class="verbatim-wrap"><pre class="screen">eval $(magnum cluster-config &lt;cluster-name&gt;)
kubectl proxy

The browser can be accessed at http://localhost:8001/ui</pre></div><p>For Swarm, the main CLI is ‘docker’, along with associated tools
            such as ‘docker-compose’, etc.  Specific version of the binaries can
            be obtained from the <a class="link" href="https://docs.docker.com/engine/installation/binaries/" target="_blank">Docker Engine installation</a>.</p><p>Mesos cluster uses the Marathon framework.</p><p>Depending on the client requirement, you may need to use a version of
            the client that matches the version in the cluster.  To determine the
            version of the COE and container, use the command ‘cluster-show’ and
            look for the attribute <span class="emphasis"><em>coe_version</em></span> and <span class="emphasis"><em>container_version</em></span>:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-show k8s-cluster
+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | 04952c60-a338-437f-a7e7-d016d1d00e65                       |
| stack_id           | b7bf72ce-b08e-4768-8201-e63a99346898                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2016-07-25T23:14:06+00:00                                  |
| updated_at         | 2016-07-25T23:14:10+00:00                                  |
| create_timeout     | 60                                                         |
| coe_version        | v1.2.0                                                     |
| api_address        | https://192.168.19.86:6443                                 |
| cluster_template_id| da2825a0-6d09-4208-b39e-b2db666f1118                       |
| master_addresses   | ['192.168.19.87']                                          |
| node_count         | 1                                                          |
| node_addresses     | ['192.168.19.88']                                          |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | https://discovery.etcd.io/3b7fb09733429d16679484673ba3bfd5 |
| name               | k8s-cluster                                                |
+--------------------+------------------------------------------------------------+</pre></div></div><div class="sect1" id="id-1.7.14"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes</span> <a title="Permalink" class="permalink" href="#id-1.7.14">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Kubernetes uses a range of terminology that we refer to in this guide. We
            define these common terms for your reference:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.14.3.1"><span class="term ">Pod</span></dt><dd><p>When using the Kubernetes container orchestration engine, a pod is the
                        smallest deployable unit that can be created and managed. A pod is a
                        co-located group of application containers that run with a shared context.
                        When using Magnum, pods are created and managed within clusters. Refer to the
                <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/pods.html" target="_blank">pods section</a> in the <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/" target="_blank">Kubernetes
                            User Guide</a> for more information.</p></dd><dt id="id-1.7.14.3.2"><span class="term ">Replication controller</span></dt><dd><p>A replication controller is used to ensure that at any given time a certain
                        number of replicas of a pod are running. Pods are automatically created and
                        deleted by the replication controller as necessary based on a template to
                        ensure that the defined number of replicas exist. Refer to the <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/replication-controller.html" target="_blank">replication
                            controller section</a> in
                        the <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/" target="_blank">Kubernetes User Guide</a> for more information.</p></dd><dt id="id-1.7.14.3.3"><span class="term ">Service</span></dt><dd><p>A service is an additional layer of abstraction provided by the Kubernetes
                        container orchestration engine which defines a logical set of pods and a
                        policy for accessing them. This is useful because pods are created and
                        deleted by a replication controller, for example, other pods needing to
                        discover them can do so via the service abstraction. Refer to the
                        <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/services.html" target="_blank">services section</a> in the
                        <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/" target="_blank">Kubernetes User Guide</a> for more information.</p></dd></dl></div><p>When Magnum deploys a Kubernetes cluster, it uses parameters defined in the
            ClusterTemplate and specified on the cluster-create command, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create k8s-cluster-template \
                           --image fedora-atomic-latest \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 5 \
                           --network-driver flannel \
                           --coe kubernetes

magnum cluster-create k8s-cluster \
                      --cluster-template k8s-cluster-template \
                      --master-count 3 \
                      --node-count 8</pre></div><p>Following are further details relevant to a Kubernetes cluster:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.14.7.1"><span class="term ">Number of masters (master-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as master in the cluster.  Having more than one will provide high
                        availability.  The masters will be in a load balancer pool and the
                        virtual IP address (VIP) of the load balancer will serve as the
                        Kubernetes API endpoint.  For external access, a floating IP
                        associated with this VIP is available and this is the endpoint
                        shown for Kubernetes in the ‘cluster-show’ command.</p></dd><dt id="id-1.7.14.7.2"><span class="term ">Number of nodes (node-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as node in the cluster to host the users’ pods.  The nodes are registered
                        in Kubernetes using the Nova instance name.</p></dd><dt id="id-1.7.14.7.3"><span class="term ">Network driver (network-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the network driver.
                        The supported and default network driver is ‘flannel’, an overlay
                        network providing a flat network for all pods.</p></dd><dt id="id-1.7.14.7.4"><span class="term ">Volume driver (volume-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the volume driver.  The supported
                        volume driver is ‘cinder’, allowing Cinder volumes to be mounted in
                        containers for use as persistent storage.  Data written to these volumes
                        will persist after the container exits and can be accessed again from other
                        containers, while data written to the union file system hosting the container
                        will be deleted.</p></dd><dt id="id-1.7.14.7.5"><span class="term ">Storage driver (docker-storage-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the Docker storage driver.  The
                        supported storage drivers are ‘devicemapper’ and ‘overlay’, with
                        ‘devicemapper’ being the default.</p></dd><dt id="id-1.7.14.7.6"><span class="term ">Image (image)</span></dt><dd><p>Specified in the ClusterTemplate to indicate the image to boot the servers.
                        The image binary is loaded in Glance with the attribute
                        ‘os_distro = fedora-atomic’.
                        Current supported images are Fedora Atomic (download from <a class="link" href="https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images" target="_blank">Fedora</a> )
                        and CoreOS (download from <a class="link" href="http://beta.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2" target="_blank">CoreOS</a> )</p></dd><dt id="id-1.7.14.7.7"><span class="term ">TLS (tls-disabled)</span></dt><dd><p>Transport Layer Security is enabled by default, so you need a key and
                        signed certificate to access the Kubernetes API and CLI.  Magnum
                        handles its own key and certificate when interfacing with the
                        Kubernetes cluster.  In development mode, TLS can be disabled.  Refer to
                        the ‘Transport Layer Security’_ section for more details.</p></dd><dt id="id-1.7.14.7.8"><span class="term ">What runs on the servers</span></dt><dd><p>The servers for Kubernetes master host containers in the ‘kube-system’
                        name space to run the Kubernetes proxy, scheduler and controller manager.
                        The masters will not host users’ pods.  Kubernetes API server, docker
                        daemon, etcd and flannel run as systemd services.  The servers for
                        Kubernetes node also host a container in the ‘kube-system’ name space
                        to run the Kubernetes proxy, while Kubernetes kubelet, docker daemon
                        and flannel run as systemd services.</p></dd><dt id="id-1.7.14.7.9"><span class="term ">Log into the servers</span></dt><dd><p>You can log into the master servers using the login ‘fedora’ and the
                        keypair specified in the ClusterTemplate.</p></dd></dl></div><p>In addition to the common attributes in the ClusterTemplate, you can specify
            the following attributes that are specific to Kubernetes by using the
            labels attribute.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.14.9.1"><span class="term "></span></dt><dd><p>This label corresponds to Kubernetes parameter for the API server ‘–admission-control’.
                        For more details, refer to the <a class="link" href="https://kubernetes.io/docs/admin/admission-controllers//" target="_blank">Admission Controllers</a>.
                        The default value corresponds to the one recommended in this doc
                        for our current Kubernetes version.</p></dd><dt id="id-1.7.14.9.2"><span class="term "></span></dt><dd><p>This label sets the size of a volume holding the etcd storage data.
                        The default value is 0, meaning the etcd data is not persisted (no volume).</p></dd><dt id="id-1.7.14.9.3"><span class="term "></span></dt><dd><p>This label allows users to select <a class="link" href="https://hub.docker.com/r/openstackmagnum/kubernetes-apiserver/tags/" target="_blank">a specific Kubernetes release,
                            based on its container tag</a>.
                        If unset, the current Magnum version’s default Kubernetes release is
                        installed.</p></dd><dt id="id-1.7.14.9.4"><span class="term "></span></dt><dd><p>This label triggers the deployment of the kubernetes dashboard.
                        The default value is 1, meaning it will be enabled.</p></dd></dl></div><div class="sect2" id="id-1.7.14.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.13.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">External load balancer for services</span> <a title="Permalink" class="permalink" href="#id-1.7.14.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>All Kubernetes pods and services created in the cluster are assigned IP
                addresses on a private container network so they can access each other
                and the external internet.  However, these IP addresses are not
                accessible from an external network.</p><p>To publish a service endpoint externally so that the service can be
                accessed from the external network, Kubernetes provides the external
                load balancer feature.  This is done by simply specifying in the
                service manifest the attribute “type: LoadBalancer”.  Magnum enables
                and configures the Kubernetes plugin for OpenStack so that it can
                interface with Neutron and manage the necessary networking resources.</p><p>When the service is created, Kubernetes will add an external load
                balancer in front of the service so that the service will have an
                external IP address in addition to the internal IP address on the
                container network.  The service endpoint can then be accessed with
                this external IP address.  Kubernetes handles all the life cycle
                operations when pods are modified behind the service and when the
                service is deleted.</p><p>Refer to the document <a class="link" href="https://github.com/openstack/magnum/blob/master/doc/source/dev/kubernetes-load-balancer.rst" target="_blank">Kubernetes external load balancer</a>
                for more details.</p></div></div><div class="sect1" id="id-1.7.15"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swarm</span> <a title="Permalink" class="permalink" href="#id-1.7.15">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A Swarm cluster is a pool of servers running Docker daemon that is
            managed as a single Docker host.  One or more Swarm managers accepts
            the standard Docker API and manage this pool of servers.
            Magnum deploys a Swarm cluster using parameters defined in
            the ClusterTemplate and specified on the ‘cluster-create’ command, for
            example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create swarm-cluster-template \
                           --image fedora-atomic-latest \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 5 \
                           --coe swarm

magnum cluster-create swarm-cluster \
                  --cluster-template swarm-cluster-template \
                  --master-count 3 \
                  --node-count 8</pre></div><p>Following are further details relevant to Swarm:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.15.5.1"><span class="term ">What runs on the servers</span></dt><dd><p>There are two types of servers in the Swarm cluster: managers and nodes.
                        The Docker daemon runs on all servers.  On the servers for manager,
                        the Swarm manager is run as a Docker container on port 2376 and this
                        is initiated by the systemd service swarm-manager.  Etcd is also run
                        on the manager servers for discovery of the node servers in the cluster.
                        On the servers for node, the Swarm agent is run as a Docker
                        container on port 2375 and this is initiated by the systemd service
                        swarm-agent.  On start up, the agents will register themselves in
                        etcd and the managers will discover the new node to manage.</p></dd><dt id="id-1.7.15.5.2"><span class="term ">Number of managers (master-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as managers in the cluster.  Having more than one will provide high
                        availability.  The managers will be in a load balancer pool and the
                        load balancer virtual IP address (VIP) will serve as the Swarm API
                        endpoint.  A floating IP associated with the load balancer VIP will
                        serve as the external Swarm API endpoint.  The managers accept
                        the standard Docker API and perform the corresponding operation on the
                        servers in the pool.  For instance, when a new container is created,
                        the managers will select one of the servers based on some strategy
                        and schedule the containers there.</p></dd><dt id="id-1.7.15.5.3"><span class="term ">Number of nodes (node-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as nodes in the cluster to host your Docker containers.  These servers
                        will register themselves in etcd for discovery by the managers, and
                        interact with the managers.  Docker daemon is run locally to host
                        containers from users.</p></dd><dt id="id-1.7.15.5.4"><span class="term ">Network driver (network-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the network driver.  The supported
                        drivers are ‘docker’ and ‘flannel’, with ‘docker’ as the default.
                        With the ‘docker’ driver, containers are connected to the ‘docker0’
                        bridge on each node and are assigned local IP address.  With the
                        ‘flannel’ driver, containers are connected to a flat overlay network
                        and are assigned IP address by Flannel.</p></dd><dt id="id-1.7.15.5.5"><span class="term ">Volume driver (volume-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the volume driver to provide
                        persistent storage for containers.  The supported volume driver is
                        ‘rexray’.  The default is no volume driver.  When ‘rexray’ or other
                        volume driver is deployed, you can use the Docker ‘volume’ command to
                        create, mount, unmount, delete volumes in containers.  Cinder block
                        storage is used as the backend to support this feature.</p></dd><dt id="id-1.7.15.5.6"><span class="term ">Storage driver (docker-storage-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the Docker storage driver.  The
                        supported storage driver are ‘devicemapper’ and ‘overlay’, with
                        ‘devicemapper’ being the default.</p></dd><dt id="id-1.7.15.5.7"><span class="term ">Image (image)</span></dt><dd><p>Specified in the ClusterTemplate to indicate the image to boot the servers
                        for the Swarm manager and node.
                        The image binary is loaded in Glance with the attribute
                        ‘os_distro = fedora-atomic’.
                        Current supported image is Fedora Atomic (download from <a class="link" href="https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images" target="_blank">Fedora</a> )</p></dd><dt id="id-1.7.15.5.8"><span class="term ">TLS (tls-disabled)</span></dt><dd><p>Transport Layer Security is enabled by default to secure the Swarm API for
                        access by both the users and Magnum.  You will need a key and a
                        signed certificate to access the Swarm API and CLI.  Magnum
                        handles its own key and certificate when interfacing with the
                        Swarm cluster.  In development mode, TLS can be disabled.  Refer to
                        the ‘Transport Layer Security’_ section for details on how to create your
                        key and have Magnum sign your certificate.</p></dd><dt id="id-1.7.15.5.9"><span class="term ">Log into the servers</span></dt><dd><p>You can log into the manager and node servers with the account ‘fedora’ and
                        the keypair specified in the ClusterTemplate.</p></dd></dl></div><p>In addition to the common attributes in the ClusterTemplate, you can specify
            the following attributes that are specific to Swarm by using the
            labels attribute.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.15.7.1"><span class="term "></span></dt><dd><p>This label corresponds to Swarm parameter for master ‘–strategy’.
                        For more details, refer to the <a class="link" href="https://docs.docker.com/swarm/scheduler/strategy/" target="_blank">Swarm Strategy</a>.
                        Valid values for this label are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>spread</p></li><li class="listitem "><p>binpack</p></li><li class="listitem "><p>random</p></li></ul></div></dd></dl></div></div><div class="sect1" id="id-1.7.16"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.15 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Mesos</span> <a title="Permalink" class="permalink" href="#id-1.7.16">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A Mesos cluster consists of a pool of servers running as Mesos slaves,
            managed by a set of servers running as Mesos masters.  Mesos manages
            the resources from the slaves but does not itself deploy containers.
            Instead, one of more Mesos frameworks running on the Mesos cluster would
            accept user requests on their own endpoint, using their particular
            API.  These frameworks would then negotiate the resources with Mesos
            and the containers are deployed on the servers where the resources are
            offered.</p><p>Magnum deploys a Mesos cluster using parameters defined in the ClusterTemplate
            and specified on the ‘cluster-create’ command, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create mesos-cluster-template \
                       --image ubuntu-mesos \
                       --keypair testkey \
                       --external-network public \
                       --dns-nameserver 8.8.8.8 \
                       --flavor m1.small \
                       --coe mesos

magnum cluster-create mesos-cluster \
                  --cluster-template mesos-cluster-template \
                  --master-count 3 \
                  --node-count 8</pre></div><p>Following are further details relevant to Mesos:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.16.6.1"><span class="term ">What runs on the servers</span></dt><dd><p>There are two types of servers in the Mesos cluster: masters and slaves.
                        The Docker daemon runs on all servers.  On the servers for master,
                        the Mesos master is run as a process on port 5050 and this is
                        initiated by the upstart service ‘mesos-master’.  Zookeeper is also
                        run on the master servers, initiated by the upstart service
                        ‘zookeeper’.  Zookeeper is used by the master servers for electing
                        the leader among the masters, and by the slave servers and
                        frameworks to determine the current leader.  The framework Marathon
                        is run as a process on port 8080 on the master servers, initiated by
                        the upstart service ‘marathon’.  On the servers for slave, the Mesos
                        slave is run as a process initiated by the upstart service
                        ‘mesos-slave’.</p></dd><dt id="id-1.7.16.6.2"><span class="term ">Number of master (master-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers
                        will run as masters in the cluster.  Having more than one will provide
                        high availability.  If the load balancer option is specified, the
                        masters will be in a load balancer pool and the load balancer
                        virtual IP address (VIP) will serve as the Mesos API endpoint.  A
                        floating IP associated with the load balancer VIP will serve as the
                        external Mesos API endpoint.</p></dd><dt id="id-1.7.16.6.3"><span class="term ">Number of agents (node-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers
                        will run as Mesos slave in the cluster.  Docker daemon is run locally to
                        host containers from users.  The slaves report their available
                        resources to the master and accept request from the master to deploy
                        tasks from the frameworks.  In this case, the tasks will be to
                        run Docker containers.</p></dd><dt id="id-1.7.16.6.4"><span class="term ">Network driver (network-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the network driver.  Currently
                        ‘docker’ is the only supported driver: containers are connected to
                        the ‘docker0’ bridge on each node and are assigned local IP address.</p></dd><dt id="id-1.7.16.6.5"><span class="term ">Volume driver (volume-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the volume driver to provide
                        persistent storage for containers.  The supported volume driver is
                        ‘rexray’.  The default is no volume driver.  When ‘rexray’ or other
                        volume driver is deployed, you can use the Docker ‘volume’ command to
                        create, mount, unmount, delete volumes in containers.  Cinder block
                        storage is used as the backend to support this feature.</p></dd><dt id="id-1.7.16.6.6"><span class="term ">Storage driver (docker-storage-driver)</span></dt><dd><p>This is currently not supported for Mesos.</p></dd></dl></div><p>Image (image)</p><p>Specified in the ClusterTemplate to indicate the image to boot the servers
                for the Mesos master and slave.  The image binary is loaded in
                Glance with the attribute ‘os_distro = ubuntu’.  You can download
                the <a class="link" href="https://fedorapeople.org/groups/magnum/ubuntu-mesos-latest.qcow2" target="_blank">ready-built
		image</a>.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.16.9.1"><span class="term ">TLS (tls-disabled)</span></dt><dd><p>Transport Layer Security is currently not implemented yet for Mesos.</p></dd><dt id="id-1.7.16.9.2"><span class="term ">Log into the servers</span></dt><dd><p>You can log into the manager and node servers with the account
                        ‘ubuntu’ and the keypair specified in the ClusterTemplate.</p></dd></dl></div><p>In addition to the common attributes in the baymodel, you can specify
            the following attributes that are specific to Mesos by using the
            labels attribute.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.16.11.1"><span class="term "></span></dt><dd><p>When the volume driver ‘rexray’ is used, you can mount a data volume
                        backed by Cinder to a host to be accessed by a container.  In this
                        case, the label ‘rexray_preempt’ can optionally be set to True or
                        False to enable any host to take control of the volume regardless of
                        whether other hosts are using the volume.  This will in effect
                        unmount the volume from the current host and remount it on the new
                        host.  If this label is set to false, then rexray will ensure data
                        safety for locking the volume before remounting.  The default value
                        is False.</p></dd><dt id="id-1.7.16.11.2"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter for slave
                        ‘–isolation’.  The isolators are needed to provide proper isolation
                        according to the runtime configurations specified in the container
                        image.  For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a>
                        and the <a class="link" href="http://mesos.apache.org/documentation/latest/container-image/" target="_blank">Mesos container image support</a>.
                        Valid values for this label are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>filesystem/posix</p></li><li class="listitem "><p>filesystem/linux</p></li><li class="listitem "><p>filesystem/shared</p></li><li class="listitem "><p>posix/cpu</p></li><li class="listitem "><p>posix/mem</p></li><li class="listitem "><p>posix/disk</p></li><li class="listitem "><p>cgroups/cpu</p></li><li class="listitem "><p>cgroups/mem</p></li><li class="listitem "><p>docker/runtime</p></li><li class="listitem "><p>namespaces/pid</p></li></ul></div></dd><dt id="id-1.7.16.11.3"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter for agent
                        ‘–image_providers’, which tells Mesos containerizer what
                        types of container images are allowed.
                        For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a> and
                        the <a class="link" href="http://mesos.apache.org/documentation/latest/container-image/" target="_blank">Mesos container image support</a>.
                        Valid values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>appc</p></li><li class="listitem "><p>docker</p></li><li class="listitem "><p>appc,docker</p></li></ul></div></dd><dt id="id-1.7.16.11.4"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter ‘–work_dir’ for slave.
                        For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a>.
                        Valid value is a directory path to use as the work directory for
                        the framework, for example:</p><div class="verbatim-wrap"><pre class="screen">mesos_slave_work_dir=/tmp/mesos</pre></div></dd><dt id="id-1.7.16.11.5"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter for slave
                        ‘–executor_environment_variables’, which passes additional
                        environment variables to the executor and subsequent tasks.
                        For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a>.
                        Valid value is the name of a JSON file, for example:</p><div class="verbatim-wrap"><pre class="screen">mesos_slave_executor_env_variables=/home/ubuntu/test.json</pre></div><p>The JSON file should contain environment variables, for example:</p><div class="verbatim-wrap"><pre class="screen">{
   "PATH": "/bin:/usr/bin",
   "LD_LIBRARY_PATH": "/usr/local/lib"
}</pre></div><p>By default the executor will inherit the slave’s environment
                        variables.</p></dd></dl></div><div class="sect2" id="id-1.7.16.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.15.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Building Mesos image</span> <a title="Permalink" class="permalink" href="#id-1.7.16.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The boot image for Mesos cluster is an Ubuntu 14.04 base image with the
                following middleware pre-installed:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">docker</code>
              </p></li><li class="listitem "><p>
                <code class="literal">zookeeper</code>
              </p></li><li class="listitem "><p>
                <code class="literal">mesos</code>
              </p></li><li class="listitem "><p>
                <code class="literal">marathon</code>
              </p></li></ul></div><p>The cluster driver provides two ways to create this image, as follows.</p><div class="sect3" id="id-1.7.16.12.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.15.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Diskimage-builder</span> <a title="Permalink" class="permalink" href="#id-1.7.16.12.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To run the <a class="link" href="http://docs.openstack.org/developer/diskimage-builder" target="_blank">diskimage-builder</a> tool
                    manually, use the provided <a class="link" href="http://git.openstack.org/cgit/openstack/magnum/tree/magnum/drivers/mesos_ubuntu_v1/image/mesos/" target="_blank">elements</a>.
                    Following are the typical steps to use the diskimage-builder tool on
                    an Ubuntu server:</p><div class="verbatim-wrap"><pre class="screen">$ sudo apt-get update
$ sudo apt-get install git qemu-utils python-pip
$ sudo pip install diskimage-builder

$ git clone https://git.openstack.org/openstack/magnum
$ git clone https://git.openstack.org/openstack/dib-utils.git
$ git clone https://git.openstack.org/openstack/tripleo-image-elements.git
$ git clone https://git.openstack.org/openstack/heat-templates.git
$ export PATH="${PWD}/dib-utils/bin:$PATH"
$ export ELEMENTS_PATH=tripleo-image-elements/elements:heat-templates/hot/software-config/elements:magnum/magnum/drivers/mesos_ubuntu_v1/image/mesos
$ export DIB_RELEASE=trusty

$ disk-image-create ubuntu vm docker mesos \
    os-collect-config os-refresh-config os-apply-config \
    heat-config heat-config-script \
    -o ubuntu-mesos.qcow2</pre></div></div><div class="sect3" id="id-1.7.16.12.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.15.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dockerfile</span> <a title="Permalink" class="permalink" href="#id-1.7.16.12.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To build the image as above but within a Docker container, use the
                    provided <a class="link" href="http://git.openstack.org/cgit/openstack/magnum/tree/magnum/drivers/mesos_ubuntu_v1/image/Dockerfile" target="_blank">Dockerfile</a>.
                    The output image will be saved as ‘/tmp/ubuntu-mesos.qcow2’.
                    Following are the typical steps to run a Docker container to build the image:</p><div class="verbatim-wrap"><pre class="screen">$ git clone https://git.openstack.org/openstack/magnum
$ cd magnum/magnum/drivers/mesos_ubuntu_v1/image
$ sudo docker build -t magnum/mesos-builder .
$ sudo docker run -v /tmp:/output --rm -ti --privileged magnum/mesos-builder
...
Image file /output/ubuntu-mesos.qcow2 created...</pre></div></div></div><div class="sect2" id="id-1.7.16.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.15.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Marathon</span> <a title="Permalink" class="permalink" href="#id-1.7.16.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Marathon is a Mesos framework for long running applications.  Docker
                containers can be deployed via Marathon’s REST API.  To get the
                endpoint for Marathon, run the cluster-show command and look for the
                property ‘api_address’.  Marathon’s endpoint is port 8080 on this IP
                address, so the web console can be accessed at:</p><div class="verbatim-wrap"><pre class="screen">http://&lt;api_address&gt;:8080/</pre></div><p>Refer to Marathon documentation for details on running applications.
                For example, you can ‘post’ a JSON app description to
                <code class="literal">http://&lt;api_address&gt;:8080/apps</code> to deploy a Docker container:</p><div class="verbatim-wrap"><pre class="screen">$ cat &gt; app.json &lt;&lt; END
{
  "container": {
    "type": "DOCKER",
    "docker": {
      "image": "libmesos/ubuntu"
    }
  },
  "id": "ubuntu",
  "instances": 1,
  "cpus": 0.5,
  "mem": 512,
  "uris": [],
  "cmd": "while sleep 10; do date -u +%T; done"
}
END
$ API_ADDRESS=$(magnum cluster-show mesos-cluster | awk '/ api_address /{print $4}')
$ curl -X POST -H "Content-Type: application/json" \
    http://${API_ADDRESS}:8080/v2/apps -d@app.json</pre></div></div></div><div class="sect1" id="id-1.7.17"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.16 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Transport Layer Security</span> <a title="Permalink" class="permalink" href="#id-1.7.17">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum uses TLS to secure communication between a cluster’s services and
            the outside world.  TLS is a complex subject, and many guides on it
            exist already.  This guide will not attempt to fully describe TLS, but
            instead will only cover the necessary steps to get a client set up to
            talk to a cluster with TLS. A more in-depth guide on TLS can be found in
            the <a class="link" href="https://www.feistyduck.com/books/openssl-cookbook/" target="_blank">OpenSSL Cookbook</a> by Ivan Ristić.</p><p>TLS is employed at 3 points in a cluster:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>By Magnum to communicate with the cluster API endpoint</p></li><li class="step "><p>By the cluster worker nodes to communicate with the master nodes</p></li><li class="step "><p>By the end-user when they use the native client libraries to
                    interact with the cluster.  This applies to both a CLI or a program
                    that uses a client for the particular cluster.  Each client needs a
                    valid certificate to authenticate and communicate with a cluster.</p></li></ol></div></div><p>The first two cases are implemented internally by Magnum and are not
            exposed to the users, while the last case involves the users and is
            described in more details below.</p><div class="sect2" id="id-1.7.17.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.16.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying a secure cluster</span> <a title="Permalink" class="permalink" href="#id-1.7.17.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Current TLS support is summarized below:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="12" class="c1" /><col width="13" class="c2" /></colgroup><thead><tr><th>
                    <p>COE</p>
                  </th><th>
                    <p>TLS support</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Kubernetes</p>
                  </td><td>
                    <p>yes</p>
                  </td></tr><tr><td>
                    <p>Swarm</p>
                  </td><td>
                    <p>yes</p>
                  </td></tr><tr><td>
                    <p>Mesos</p>
                  </td><td>
                    <p>no</p>
                  </td></tr></tbody></table></div><p>For cluster type with TLS support, e.g. Kubernetes and Swarm, TLS is
                enabled by default.  To disable TLS in Magnum, you can specify the
                parameter ‘–tls-disabled’ in the ClusterTemplate.  Please note it is not
                recommended to disable TLS due to security reasons.</p><p>In the following example, Kubernetes is used to illustrate a secure
                cluster, but the steps are similar for other cluster types that have TLS
                support.</p><p>First, create a ClusterTemplate; by default TLS is enabled in
                Magnum, therefore it does not need to be specified via a parameter:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create secure-kubernetes \
                           --keypair default \
                           --external-network public \
                           --image fedora-atomic-latest \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 3 \
                           --coe kubernetes \
                           --network-driver flannel

+-----------------------+--------------------------------------+
| Property              | Value                                |
+-----------------------+--------------------------------------+
| insecure_registry     | None                                 |
| http_proxy            | None                                 |
| updated_at            | None                                 |
| master_flavor_id      | None                                 |
| uuid                  | 5519b24a-621c-413c-832f-c30424528b31 |
| no_proxy              | None                                 |
| https_proxy           | None                                 |
| tls_disabled          | False                                |
| keypair_id            | time4funkey                          |
| public                | False                                |
| labels                | {}                                   |
| docker_volume_size    | 5                                    |
| server_type           | vm                                   |
| external_network_id   | public                               |
| cluster_distro        | fedora-atomic                        |
| image_id              | fedora-atomic-latest                 |
| volume_driver         | None                                 |
| registry_enabled      | False                                |
| docker_storage_driver | devicemapper                         |
| apiserver_port        | None                                 |
| name                  | secure-kubernetes                    |
| created_at            | 2016-07-25T23:09:50+00:00            |
| network_driver        | flannel                              |
| fixed_network         | None                                 |
| coe                   | kubernetes                           |
| flavor_id             | m1.small                             |
| dns_nameserver        | 8.8.8.8                              |
+-----------------------+--------------------------------------+</pre></div><p>Now create a cluster. Use the ClusterTemplate name as a template for cluster
                creation:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create secure-k8s-cluster \
                      --cluster-template secure-kubernetes \
                      --node-count 1

+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_IN_PROGRESS                                         |
| uuid               | 3968ffd5-678d-4555-9737-35f191340fda                       |
| stack_id           | c96b66dd-2109-4ae2-b510-b3428f1e8761                       |
| status_reason      | None                                                       |
| created_at         | 2016-07-25T23:14:06+00:00                                  |
| updated_at         | None                                                       |
| create_timeout     | 0                                                          |
| api_address        | None                                                       |
| coe_version        | -                                                          |
| cluster_template_id| 5519b24a-621c-413c-832f-c30424528b31                       |
| master_addresses   | None                                                       |
| node_count         | 1                                                          |
| node_addresses     | None                                                       |
| master_count       | 1                                                          |
| container_version  | -                                                          |
| discovery_url      | https://discovery.etcd.io/ba52a8178e7364d43a323ee4387cf28e |
| name               | secure-k8s-cluster                                          |
+--------------------+------------------------------------------------------------+</pre></div><p>Now run cluster-show command to get the details of the cluster and verify that
                the api_address is ‘https’:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-show secure-k8scluster
+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | 04952c60-a338-437f-a7e7-d016d1d00e65                       |
| stack_id           | b7bf72ce-b08e-4768-8201-e63a99346898                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2016-07-25T23:14:06+00:00                                  |
| updated_at         | 2016-07-25T23:14:10+00:00                                  |
| create_timeout     | 60                                                         |
| coe_version        | v1.2.0                                                     |
| api_address        | https://192.168.19.86:6443                                 |
| cluster_template_id| da2825a0-6d09-4208-b39e-b2db666f1118                       |
| master_addresses   | ['192.168.19.87']                                          |
| node_count         | 1                                                          |
| node_addresses     | ['192.168.19.88']                                          |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | https://discovery.etcd.io/3b7fb09733429d16679484673ba3bfd5 |
| name               | secure-k8s-cluster                                          |
+--------------------+------------------------------------------------------------+</pre></div><p>You can see the api_address contains https in the URL, showing that
                the Kubernetes services are configured securely with SSL certificates
                and now any communication to kube-apiserver will be over https.</p></div><div class="sect2" id="id-1.7.17.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.16.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Interfacing with a secure cluster</span> <a title="Permalink" class="permalink" href="#id-1.7.17.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To communicate with the API endpoint of a secure cluster, you will need so
                supply 3 SSL artifacts:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Your client key</p></li><li class="step "><p>A certificate for your client key that has been signed by a
                        Certificate Authority (CA)</p></li><li class="step "><p>The certificate of the CA</p></li></ol></div></div><p>There are two ways to obtain these 3 artifacts.</p><div class="sect3" id="id-1.7.17.7.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.16.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Automated</span> <a title="Permalink" class="permalink" href="#id-1.7.17.7.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum provides the command ‘cluster-config’ to help the user in setting
                    up the environment and artifacts for TLS, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-config swarm-cluster --dir myclusterconfig</pre></div><p>This will display the necessary environment variables, which you
                    can add to your environment:</p><div class="verbatim-wrap"><pre class="screen">export DOCKER_HOST=tcp://172.24.4.5:2376
export DOCKER_CERT_PATH=myclusterconfig
export DOCKER_TLS_VERIFY=True</pre></div><p>And the artifacts are placed in the directory specified:</p><div class="verbatim-wrap"><pre class="screen">ca.pem
cert.pem
key.pem</pre></div><p>You can now use the native client to interact with the COE.
                    The variables and artifacts are unique to the cluster.</p><p>The parameters for ‘bay-config’ are as follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.17.7.5.10.1"><span class="term ">–dir &lt;dirname&gt;</span></dt><dd><p>Directory to save the certificate and config files.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.17.7.5.11.1"><span class="term ">
                  <code class="option">--force</code>
                </span></dt><dd><p>Overwrite existing files in the directory specified.</p></dd></dl></div></div><div class="sect3" id="id-1.7.17.7.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.16.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manual</span> <a title="Permalink" class="permalink" href="#id-1.7.17.7.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can create the key and certificates manually using the following steps.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.17.7.6.3.1"><span class="term ">Client Key</span></dt><dd><p>Your personal private key is essentially a cryptographically generated
                                string of bytes. It should be protected in the same manner as a
                                password. To generate an RSA key, you can use the ‘genrsa’ command of
                                the ‘openssl’ tool:</p><div class="verbatim-wrap"><pre class="screen">openssl genrsa -out key.pem 4096</pre></div><p>This command generates a 4096 byte RSA key at key.pem.</p></dd><dt id="id-1.7.17.7.6.3.2"><span class="term ">Signed Certificate</span></dt><dd><p>To authenticate your key, you need to have it signed by a CA.  First
                                generate the Certificate Signing Request (CSR).  The CSR will be
                                used by Magnum to generate a signed certificate that you will use to
                                communicate with the cluster.  To generate a CSR, openssl requires a
                                config file that specifies a few values.  Using the example template
                                below, you can fill in the ‘CN’ value with your name and save it as
                                client.conf:</p><div class="verbatim-wrap"><pre class="screen">$ cat &gt; client.conf &lt;&lt; END
[req]
distinguished_name = req_distinguished_name
req_extensions     = req_ext
prompt = no
[req_distinguished_name]
CN = Your Name
[req_ext]
extendedKeyUsage = clientAuth
END</pre></div><p>Once you have client.conf, you can run the openssl ‘req’ command to
                                generate the CSR:</p><div class="verbatim-wrap"><pre class="screen">openssl req -new -days 365 \
    -config client.conf \
    -key key.pem \
    -out client.csr</pre></div><p>Now that you have your client CSR, you can use the Magnum CLI to
                                send it off to Magnum to get it signed:</p><div class="verbatim-wrap"><pre class="screen">magnum ca-sign --cluster secure-k8s-cluster --csr client.csr &gt; cert.pem</pre></div></dd><dt id="id-1.7.17.7.6.3.3"><span class="term ">Certificate Authority</span></dt><dd><p>The final artifact you need to retrieve is the CA certificate for
                                the cluster. This is used by your native client to ensure you are only
                                communicating with hosts that Magnum set up:</p><div class="verbatim-wrap"><pre class="screen">magnum ca-show --cluster secure-k8s-cluster &gt; ca.pem</pre></div></dd><dt id="id-1.7.17.7.6.3.4"><span class="term ">Rotate Certificate</span></dt><dd><p>To rotate the CA certificate for a cluster and invalidate all user
                                certificates, you can use the following command:</p><div class="verbatim-wrap"><pre class="screen">magnum ca-rotate --cluster secure-k8s-cluster</pre></div></dd></dl></div></div></div><div class="sect2" id="id-1.7.17.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.16.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">User Examples</span> <a title="Permalink" class="permalink" href="#id-1.7.17.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Here are some examples for using the CLI on a secure Kubernetes and
                Swarm cluster.  You can perform all the TLS set up automatically by:</p><div class="verbatim-wrap"><pre class="screen">eval $(magnum cluster-config &lt;cluster-name&gt;)</pre></div><p>Or you can perform the manual steps as described above and specify
                the TLS options on the CLI.  The SSL artifacts are assumed to be
                saved in local files as follows:</p><div class="verbatim-wrap"><pre class="screen">- key.pem: your SSL key
- cert.pem: signed certificate
- ca.pem: certificate for cluster CA</pre></div><p>For Kubernetes, you need to get ‘kubectl’, a kubernetes CLI tool, to
                communicate with the cluster:</p><div class="verbatim-wrap"><pre class="screen">curl -O https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/kubectl</pre></div><p>Now let’s run some ‘kubectl’ commands to check the secure communication.
                If you used ‘cluster-config’, then you can simply run the ‘kubectl’ command
                without having to specify the TLS options since they have been defined
                in the environment:</p><div class="verbatim-wrap"><pre class="screen">kubectl version
Client Version: version.Info{Major:"1", Minor:"0", GitVersion:"v1.2.0", GitCommit:"cffae0523cfa80ddf917aba69f08508b91f603d5", GitTreeState:"clean"}
Server Version: version.Info{Major:"1", Minor:"0", GitVersion:"v1.2.0", GitCommit:"cffae0523cfa80ddf917aba69f08508b91f603d5", GitTreeState:"clean"}</pre></div><p>You can specify the TLS options manually as follows:</p><div class="verbatim-wrap"><pre class="screen">KUBERNETES_URL=$(magnum cluster-show secure-k8s-cluster |
                 awk '/ api_address /{print $4}')
kubectl version --certificate-authority=ca.pem \
                --client-key=key.pem \
                --client-certificate=cert.pem -s $KUBERNETES_URL

kubectl create -f redis-master.yaml --certificate-authority=ca.pem \
                                    --client-key=key.pem \
                                    --client-certificate=cert.pem -s $KUBERNETES_URL

pods/test2

kubectl get pods --certificate-authority=ca.pem \
                 --client-key=key.pem \
                 --client-certificate=cert.pem -s $KUBERNETES_URL
NAME           READY     STATUS    RESTARTS   AGE
redis-master   2/2       Running   0          1m</pre></div><p>Beside using the environment variables, you can also configure ‘kubectl’
                to remember the TLS options:</p><div class="verbatim-wrap"><pre class="screen">kubectl config set-cluster secure-k8s-cluster --server=${KUBERNETES_URL} \
    --certificate-authority=${PWD}/ca.pem
kubectl config set-credentials client --certificate-authority=${PWD}/ca.pem \
    --client-key=${PWD}/key.pem --client-certificate=${PWD}/cert.pem
kubectl config set-context secure-k8scluster --cluster=secure-k8scluster --user=client
kubectl config use-context secure-k8scluster</pre></div><p>Then you can use ‘kubectl’ commands without the certificates:</p><div class="verbatim-wrap"><pre class="screen">kubectl get pods
NAME           READY     STATUS    RESTARTS   AGE
redis-master   2/2       Running   0          1m</pre></div><p>Access to Kubernetes User Interface:</p><div class="verbatim-wrap"><pre class="screen">curl -L ${KUBERNETES_URL}/ui --cacert ca.pem --key key.pem \
    --cert cert.pem</pre></div><p>You may also set up ‘kubectl’ proxy which will use your client
                certificates to allow you to browse to a local address to use the UI
                without installing a certificate in your browser:</p><div class="verbatim-wrap"><pre class="screen">kubectl proxy --api-prefix=/ --certificate-authority=ca.pem --client-key=key.pem \
              --client-certificate=cert.pem -s $KUBERNETES_URL</pre></div><p>You can then open <a class="link" href="http://localhost:8001/ui" target="_blank">http://localhost:8001/ui</a> in your browser.</p><p>The examples for Docker are similar.  With ‘cluster-config’ set up,
                you can just run docker commands without TLS options.  To specify the
                TLS options manually:</p><div class="verbatim-wrap"><pre class="screen">docker -H tcp://192.168.19.86:2376 --tlsverify \
       --tlscacert ca.pem \
       --tlskey key.pem \
       --tlscert cert.pem \
       info</pre></div></div><div class="sect2" id="id-1.7.17.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.16.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storing the certificates</span> <a title="Permalink" class="permalink" href="#id-1.7.17.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum generates and maintains a certificate for each cluster so that it
                can also communicate securely with the cluster.  As a result, it is
                necessary to store the certificates in a secure manner.  Magnum
                provides the following methods for storing the certificates and this
                is configured in /etc/magnum/magnum.conf in the section [certificates]
                with the parameter ‘cert_manager_type’.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Barbican:
                        Barbican is a service in OpenStack for storing secrets.  It is used
                        by Magnum to store the certificates when cert_manager_type is
                        configured as:</p><div class="verbatim-wrap"><pre class="screen">cert_manager_type = barbican</pre></div><p>This is the recommended configuration for a production environment.
                        Magnum will interface with Barbican to store and retrieve
                        certificates, delegating the task of securing the certificates to
                        Barbican.</p></li><li class="step "><p>Magnum database:
                        In some cases, a user may want an alternative to storing the
                        certificates that does not require Barbican.  This can be a
                        development environment, or a private cloud that has been secured
                        by other means.  Magnum can store the certificates in its own
                        database; this is done with the configuration:</p><div class="verbatim-wrap"><pre class="screen">cert_manager_type = x509keypair</pre></div><p>This storage mode is only as secure as the controller server that
                        hosts the database for the OpenStack services.</p></li><li class="step "><p>Local store:
                        As another alternative that does not require Barbican, Magnum can
                        simply store the certificates on the local host filesystem where the
                        conductor is running, using the configuration:</p><div class="verbatim-wrap"><pre class="screen">cert_manager_type = local</pre></div><p>Note that this mode is only supported when there is a single Magnum
                        conductor running since the certificates are stored locally.  The
                        ‘local’ mode is not recommended for a production environment.</p></li></ol></div></div><p>For the nodes, the certificates for communicating with the masters are
                stored locally and the nodes are assumed to be secured.</p></div></div><div class="sect1" id="id-1.7.18"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.17 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking</span> <a title="Permalink" class="permalink" href="#id-1.7.18">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are two components that make up the networking in a cluster.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The Neutron infrastructure for the cluster: this includes the
                    private network, subnet, ports, routers, load balancers, etc.</p></li><li class="step "><p>The networking model presented to the containers: this is what the
                    containers see in communicating with each other and to the external
                    world. Typically this consists of a driver deployed on each node.</p></li></ol></div></div><p>The two components are deployed and managed separately.  The Neutron
            infrastructure is the integration with OpenStack; therefore, it
            is stable and more or less similar across different COE
            types.  The networking model, on the other hand, is specific to the
            COE type and is still under active development in the various
            COE communities, for example,
            <a class="link" href="https://github.com/docker/libnetwork" target="_blank">Docker libnetwork</a> and
            <a class="link" href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/design/networking.md" target="_blank">Kubernetes Container Networking</a>.
            As a result, the implementation for the networking models is evolving and
            new models are likely to be introduced in the future.</p><p>For the Neutron infrastructure, the following configuration can
            be set in the ClusterTemplate:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.18.6.1"><span class="term ">external-network</span></dt><dd><p>The external Neutron network ID to connect to this cluster. This
                        is used to connect the cluster to the external internet, allowing
                        the nodes in the cluster to access external URL for discovery, image
                        download, etc.  If not specified, the default value is “public” and this
                        is valid for a typical devstack.</p></dd><dt id="id-1.7.18.6.2"><span class="term ">fixed-network</span></dt><dd><p>The Neutron network to use as the private network for the cluster nodes.
                        If not specified, a new Neutron private network will be created.</p></dd><dt id="id-1.7.18.6.3"><span class="term ">dns-nameserver</span></dt><dd><p>The DNS nameserver to use for this cluster.  This is an IP address for
                        the server and it is used to configure the Neutron subnet of the
                        cluster (dns_nameservers).  If not specified, the default DNS is
                        8.8.8.8, the publicly available DNS.</p></dd><dt id="id-1.7.18.6.4"><span class="term ">http-proxy, https-proxy, no-proxy</span></dt><dd><p>The proxy for the nodes in the cluster, to be used when the cluster is
                        behind a firewall and containers cannot access URL’s on the external
                        internet directly.  For the parameter http-proxy and https-proxy, the
                        value to provide is a URL and it will be set in the environment
                        variable HTTP_PROXY and HTTPS_PROXY respectively in the nodes.  For
                        the parameter no-proxy, the value to provide is an IP or list of IP’s
                        separated by comma.  Likewise, the value will be set in the
                        environment variable NO_PROXY in the nodes.</p></dd></dl></div><p>For the networking model to the container, the following configuration
            can be set in the ClusterTemplate:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.18.8.1"><span class="term ">network-driver</span></dt><dd><p>The network driver name for instantiating container networks.
                        Currently, the following network drivers are supported:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="8" class="c1" /><col width="13" class="c2" /><col width="11" class="c3" /><col width="13" class="c4" /></colgroup><thead><tr><th>
                        <p>Driver</p>
                      </th><th>
                        <p>Kubernetes</p>
                      </th><th>
                        <p>Swarm</p>
                      </th><th>
                        <p>Mesos</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Flannel</p>
                      </td><td>
                        <p>supported</p>
                      </td><td>
                        <p>supported</p>
                      </td><td>
                        <p>unsupported</p>
                      </td></tr><tr><td>
                        <p>Docker</p>
                      </td><td>
                        <p>unsupported</p>
                      </td><td>
                        <p>supported</p>
                      </td><td>
                        <p>supported</p>
                      </td></tr></tbody></table></div><p>If not specified, the default driver is Flannel for Kubernetes, and
                        Docker for Swarm and Mesos.</p></dd></dl></div><p>Particular network driver may require its own set of parameters for
            configuration, and these parameters are specified through the labels
            in the ClusterTemplate.  Labels are arbitrary key=value pairs.</p><p>When Flannel is specified as the network driver, the following
            optional labels can be added:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.18.11.1"><span class="term "></span></dt><dd><p>IPv4 network in CIDR format to use for the entire Flannel network.
                        If not specified, the default is 10.100.0.0/16.</p></dd><dt id="id-1.7.18.11.2"><span class="term "></span></dt><dd><p>The size of the subnet allocated to each host. If not specified, the
                        default is 24.</p></dd><dt id="id-1.7.18.11.3"><span class="term "></span></dt><dd><p>The type of backend for Flannel.  Possible values are <span class="emphasis"><em>udp, vxlan,
                            host-gw</em></span>.  If not specified, the default is <span class="emphasis"><em>udp</em></span>.  Selecting the
                        best backend depends on your networking.  Generally, <span class="emphasis"><em>udp</em></span> is
                        the most generally supported backend since there is little
                        requirement on the network, but it typically offers the lowest
                        performance.  The <span class="emphasis"><em>vxlan</em></span> backend performs better, but requires
                        vxlan support in the kernel so the image used to provision the
                        nodes needs to include this support.  The <span class="emphasis"><em>host-gw</em></span> backend offers
                        the best performance since it does not actually encapsulate
                        messages, but it requires all the nodes to be on the same L2
                        network.  The private Neutron network that Magnum creates does
                        meet this requirement;  therefore if the parameter <span class="emphasis"><em>fixed_network</em></span>
                        is not specified in the ClusterTemplate, <span class="emphasis"><em>host-gw</em></span> is the best choice for
                        the Flannel backend.</p></dd></dl></div></div><div class="sect1" id="id-1.7.19"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.18 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">High Availability</span> <a title="Permalink" class="permalink" href="#id-1.7.19">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
          <span class="emphasis"><em>To be filled in</em></span>
        </p></div><div class="sect1" id="id-1.7.20"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.19 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scaling</span> <a title="Permalink" class="permalink" href="#id-1.7.20">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2" id="id-1.7.20.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.19.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Performance tuning for periodic task</span> <a title="Permalink" class="permalink" href="#id-1.7.20.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum’s periodic task performs a <code class="literal">stack-get</code> operation on the Heat stack
                underlying each of its clusters. If you have a large amount of clusters this
                can create considerable load on the Heat API. To reduce that load you can
                configure Magnum to perform one global <code class="literal">stack-list</code> per periodic task instead
                of one per cluster. This is disabled by default, both from the Heat and Magnum
                side since it causes a security issue, though: any user in any tenant holding
                the <code class="literal">admin</code> role can perform a global <code class="literal">stack-list</code> operation if Heat is
                configured to allow it for Magnum. If you want to enable it nonetheless,
                proceed as follows:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Set <code class="literal">periodic_global_stack_list</code> in magnum.conf to <code class="literal">True</code>
                        (<code class="literal">False</code> by default).</p></li><li class="step "><p>Update heat policy to allow magnum list stacks. To this end, edit your heat
                        policy file, usually etc/heat/policy.json``:</p><div class="verbatim-wrap highlight ini"><pre class="screen">...
stacks:global_index: "rule:context_is_admin",</pre></div><p>Now restart heat.</p></li></ol></div></div></div><div class="sect2" id="id-1.7.20.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.19.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Containers and nodes</span> <a title="Permalink" class="permalink" href="#id-1.7.20.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Scaling containers and nodes refers to increasing or decreasing
                allocated system resources.  Scaling is a broad topic and involves
                many dimensions.  In the context of Magnum in this guide, we consider
                the following issues:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Scaling containers and scaling cluster nodes (infrastructure)</p></li><li class="listitem "><p>Manual and automatic scaling</p></li></ul></div><p>Since this is an active area of development, a complete solution
                covering all issues does not exist yet, but partial solutions are
                emerging.</p><p>Scaling containers involves managing the number of instances of the
                container by replicating or deleting instances.  This can be used to
                respond to change in the workload being supported by the application;
                in this case, it is typically driven by certain metrics relevant to the
                application such as response time, etc.  Other use cases include
                rolling upgrade, where a new version of a service can gradually be
                scaled up while the older version is gradually scaled down.  Scaling
                containers is supported at the COE level and is specific to each COE
                as well as the version of the COE.  You will need to refer to the
                documentation for the proper COE version for full details, but
                following are some pointers for reference.</p><p>For Kubernetes, pods are scaled manually by setting the count in the
                replication controller.  Kubernetes version 1.3 and later also
                supports <a class="link" href="http://blog.kubernetes.io/2016/07/autoscaling-in-kubernetes.html" target="_blank">autoscaling</a>.
                For Docker, the tool ‘Docker Compose’ provides the command
                <a class="link" href="https://docs.docker.com/compose/reference/scale/" target="_blank">docker-compose scale</a> which lets you
                manually set the number of instances of a container.  For Swarm
                version 1.12 and later, services can also be scaled manually through
                the command <a class="link" href="https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/" target="_blank">docker service scale</a>.
                Automatic scaling for Swarm is not yet available.  Mesos manages the
                resources and does not support scaling directly; instead, this is
                provided by frameworks running within Mesos.  With the Marathon
                framework currently supported in the Mesos cluster, you can use the
                <a class="link" href="https://mesosphere.github.io/marathon/docs/application-basics.html" target="_blank">scale operation</a>
                on the Marathon UI or through a REST API call to manually set the
                attribute ‘instance’ for a container.</p><p>Scaling the cluster nodes involves managing the number of nodes in the
                cluster by adding more nodes or removing nodes.  There is no direct
                correlation between the number of nodes and the number of containers
                that can be hosted since the resources consumed (memory, CPU, etc)
                depend on the containers.  However, if a certain resource is exhausted
                in the cluster, adding more nodes would add more resources for hosting
                more containers.  As part of the infrastructure management, Magnum
                supports manual scaling through the attribute ‘node_count’ in the
                cluster, so you can scale the cluster simply by changing this
                attribute:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-update mycluster replace node_count=2</pre></div><p>Adding nodes to a cluster is straightforward: Magnum deploys
                additional VMs or baremetal servers through the heat templates and
                invokes the COE-specific mechanism for registering the new nodes to
                update the available resources in the cluster.  Afterward, it is up to
                the COE or user to re-balance the workload by launching new container
                instances or re-launching dead instances on the new nodes.</p><p>Removing nodes from a cluster requires some more care to ensure
                continuous operation of the containers since the nodes being removed
                may be actively hosting some containers.  Magnum performs a simple
                heuristic that is specific to the COE to find the best node candidates
                for removal, as follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.20.3.12.1"><span class="term ">Kubernetes</span></dt><dd><p>Magnum scans the pods in the namespace ‘Default’ to determine the
                            nodes that are <span class="emphasis"><em>not</em></span> hosting any (empty nodes).  If the number of
                            nodes to be removed is equal or less than the number of these empty
                            nodes, these nodes will be removed from the cluster.  If the number
                            of nodes to be removed is larger than the number of empty nodes, a
                            warning message will be sent to the Magnum log and the empty nodes
                            along with additional nodes will be removed from the cluster.  The
                            additional nodes are selected randomly and the pods running on them
                            will be deleted without warning.  For this reason, a good practice
                            is to manage the pods through the replication controller so that the
                            deleted pods will be relaunched elsewhere in the cluster.  Note also
                            that even when only the empty nodes are removed, there is no
                            guarantee that no pod will be deleted because there is no locking to
                            ensure that Kubernetes will not launch new pods on these nodes after
                            Magnum has scanned the pods.</p></dd><dt id="id-1.7.20.3.12.2"><span class="term ">Swarm</span></dt><dd><p>No node selection heuristic is currently supported.  If you decrease
                            the node_count, a node will be chosen by magnum without
                            consideration of what containers are running on the selected node.</p></dd><dt id="id-1.7.20.3.12.3"><span class="term ">Mesos</span></dt><dd><p>Magnum scans the running tasks on Marathon server to determine the
                            nodes on which there is <span class="emphasis"><em>no</em></span> task running (empty nodes). If the
                            number of nodes to be removed is equal or less than the number of
                            these empty nodes, these nodes will be removed from the cluster.
                            If the number of nodes to be removed is larger than the number of
                            empty nodes, a warning message will be sent to the Magnum log and
                            the empty nodes along with additional nodes will be removed from the
                            cluster. The additional nodes are selected randomly and the containers
                            running on them will be deleted without warning. Note that even when
                            only the empty nodes are removed, there is no guarantee that no
                            container will be deleted because there is no locking to ensure that
                            Mesos will not launch new containers on these nodes after Magnum
                            has scanned the tasks.</p></dd></dl></div><p>Currently, scaling containers and scaling cluster nodes are handled
                separately, but in many use cases, there are interactions between the
                two operations.  For instance, scaling up the containers may exhaust
                the available resources in the cluster, thereby requiring scaling up
                the cluster nodes as well.  Many complex issues are involved in
                managing this interaction.  A presentation at the OpenStack Tokyo
                Summit 2015 covered some of these issues along with some early
                proposals, <a class="link" href="https://www.openstack.org/summit/tokyo-2015/videos/presentation/exploring-magnum-and-senlin-integration-for-autoscaling-containers" target="_blank">Exploring Magnum and Senlin integration for autoscaling
                    containers</a>.
                This remains an active area of discussion and research.</p></div></div><div class="sect1" id="id-1.7.21"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.20 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storage</span> <a title="Permalink" class="permalink" href="#id-1.7.21">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Currently Cinder provides the block storage to the containers, and the
            storage is made available in two ways: as ephemeral storage and as
            persistent storage.</p><div class="sect2" id="id-1.7.21.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.20.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ephemeral storage</span> <a title="Permalink" class="permalink" href="#id-1.7.21.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The filesystem for the container consists of multiple layers from the
                image and a top layer that holds the modification made by the
                container.  This top layer requires storage space and the storage is
                configured in the Docker daemon through a number of storage options.
                When the container is removed, the storage allocated to the particular
                container is also deleted.</p><p>Magnum can manage the containers’ filesystem in two ways, storing them
                on the local disk of the compute instances or in a separate Cinder block
                volume for each node in the cluster, mounts it to the node and
                configures it to be used as ephemeral storage.  Users can specify the
                size of the Cinder volume with the ClusterTemplate attribute
                ‘docker-volume-size’. Currently the block size is fixed at cluster
                creation time, but future lifecycle operations may allow modifying the
                block size during the life of the cluster.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.21.3.4.1"><span class="term "></span></dt><dd><p>For drivers that support additional volumes for container storage, a
                            label named ‘docker_volume_type’ is exposed so that users can select
                            different cinder volume types for their volumes. The default volume
                            <span class="emphasis"><em>must</em></span> be set in ‘default_docker_volume_type’ in the ‘cinder’ section
                            of magnum.conf, an obvious value is the default volume type set in
                            cinder.conf of your cinder deployment . Please note, that
                            docker_volume_type refers to a cinder volume type and it is unrelated
                            to docker or kubernetes volumes.</p></dd></dl></div><p>Both local disk and the Cinder block storage can be used with a number
                of Docker storage drivers available.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>‘devicemapper’: When used with a dedicated Cinder volume it is
                        configured using direct-lvm and offers very good performance. If it’s
                        used with the compute instance’s local disk uses a loopback device
                        offering poor performance and it’s not recommended for production
                        environments. Using the ‘devicemapper’ driver does allow the use of
                        SELinux.</p></li><li class="listitem "><p>‘overlay’ When used with a dedicated Cinder volume offers as good
                        or better performance than devicemapper. If used on the local disk of
                        the compute instance (especially with high IOPS drives) you can get
                        significant performance gains. However, for kernel versions less than
                        4.9, SELinux must be disabled inside the containers resulting in worse
                        container isolation, although it still runs in enforcing mode on the
                        cluster compute instances.</p></li></ul></div></div><div class="sect2" id="id-1.7.21.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.20.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Persistent storage</span> <a title="Permalink" class="permalink" href="#id-1.7.21.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In some use cases, data read/written by a container needs to persist
                so that it can be accessed later.  To persist the data, a Cinder
                volume with a filesystem on it can be mounted on a host and be made
                available to the container, then be unmounted when the container exits.</p><p>Docker provides the ‘volume’ feature for this purpose: the user
                invokes the ‘volume create’ command, specifying a particular volume
                driver to perform the actual work.  Then this volume can be mounted
                when a container is created.  A number of third-party volume drivers
                support OpenStack Cinder as the backend, for example Rexray and
                Flocker.  Magnum currently supports Rexray as the volume driver for
                Swarm and Mesos.  Other drivers are being considered.</p><p>Kubernetes allows a previously created Cinder block to be mounted to
                a pod and this is done by specifying the block ID in the pod YAML file.
                When the pod is scheduled on a node, Kubernetes will interface with
                Cinder to request the volume to be mounted on this node, then
                Kubernetes will launch the Docker container with the proper options to
                make the filesystem on the Cinder volume accessible to the container
                in the pod.  When the pod exits, Kubernetes will again send a request
                to Cinder to unmount the volume’s filesystem, making it available to be
                mounted on other nodes.</p><p>Magnum supports these features to use Cinder as persistent storage
                using the ClusterTemplate attribute ‘volume-driver’ and the support matrix
                for the COE types is summarized as follows:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="8" class="c1" /><col width="13" class="c2" /><col width="13" class="c3" /><col width="13" class="c4" /></colgroup><thead><tr><th>
                    <p>Driver</p>
                  </th><th>
                    <p>Kubernetes</p>
                  </th><th>
                    <p>Swarm</p>
                  </th><th>
                    <p>Mesos</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>cinder</p>
                  </td><td>
                    <p>supported</p>
                  </td><td>
                    <p>unsupported</p>
                  </td><td>
                    <p>unsupported</p>
                  </td></tr><tr><td>
                    <p>rexray</p>
                  </td><td>
                    <p>unsupported</p>
                  </td><td>
                    <p>supported</p>
                  </td><td>
                    <p>supported</p>
                  </td></tr></tbody></table></div><p>Following are some examples for using Cinder as persistent storage.</p><div class="sect3" id="id-1.7.21.4.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.20.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Cinder in Kubernetes</span> <a title="Permalink" class="permalink" href="#id-1.7.21.4.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><span class="bold"><strong>NOTE:</strong></span> This feature requires Kubernetes version 1.5.0 or above.
                    The public Fedora image from Atomic currently meets this requirement.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the ClusterTemplate.</p><p>Specify ‘cinder’ as the volume-driver for Kubernetes:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create k8s-cluster-template \
                           --image fedora-23-atomic-7 \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 5 \
                           --network-driver flannel \
                           --coe kubernetes \
                           --volume-driver cinder</pre></div></li><li class="step "><p>Create the cluster:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create k8s-cluster \
                      --cluster-template k8s-cluster-template \
                      --node-count 1</pre></div></li></ol></div></div><p>Kubernetes is now ready to use Cinder for persistent storage.
                    Following is an example illustrating how Cinder is used in a pod.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the cinder volume:</p><div class="verbatim-wrap"><pre class="screen">cinder create --display-name=test-repo 1

XML:ID=$(cinder create --display-name=test-repo 1 | awk -F'|' '$2~/^[[:space:]]*id/ {print $3}')</pre></div><p>The command will generate the volume with a ID. The volume ID will be
                            specified in Step 2.</p></li><li class="step "><p>Create a pod in this cluster and mount this cinder volume to the pod.
                            Create a file (e.g nginx-cinder.yaml) describing the pod:</p><div class="verbatim-wrap"><pre class="screen">cat &gt; nginx-cinder.yaml &lt;&lt; END
apiVersion: v1
kind: Pod
metadata:
  name: aws-web
spec:
  containers:
    - name: web
      image: nginx
      ports:
        - name: web
          containerPort: 80
          hostPort: 8081
          protocol: TCP
      volumeMounts:
        - name: html-volume
          mountPath: "/usr/share/nginx/html"
  volumes:
    - name: html-volume
      cinder:
        # Enter the volume ID below
        volumeID: $ID
        fsType: ext4
END</pre></div></li></ol></div></div><p><span class="bold"><strong>NOTE:</strong></span> The Cinder volume ID needs to be configured in the YAML file
                    so the existing Cinder volume can be mounted in a pod by specifying
                    the volume ID in the pod manifest as follows:</p><div class="verbatim-wrap"><pre class="screen">volumes:
- name: html-volume
  cinder:
    volumeID: $ID
    fsType: ext4</pre></div><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>Create the pod by the normal Kubernetes interface:</p><div class="verbatim-wrap"><pre class="screen">kubectl create -f nginx-cinder.yaml</pre></div></li></ul></div></div><p>You can start a shell in the container to check that the mountPath exists,
                    and on an OpenStack client you can run the command ‘cinder list’ to verify
                    that the cinder volume status is ‘in-use’.</p></div><div class="sect3" id="id-1.7.21.4.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.20.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Cinder in Swarm</span> <a title="Permalink" class="permalink" href="#id-1.7.21.4.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
              <span class="emphasis"><em>To be filled in</em></span>
            </p></div><div class="sect3" id="id-1.7.21.4.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.20.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Cinder in Mesos</span> <a title="Permalink" class="permalink" href="#id-1.7.21.4.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the ClusterTemplate.</p><p>Specify ‘rexray’ as the volume-driver for Mesos.  As an option, you
                            can specify in a label the attributes ‘rexray_preempt’ to enable
                            any host to take control of a volume regardless if other
                            hosts are using the volume. If this is set to false, the driver
                            will ensure data safety by locking the volume:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create mesos-cluster-template \
                           --image ubuntu-mesos \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --master-flavor m1.magnum \
                           --docker-volume-size 4 \
                           --tls-disabled \
                           --flavor m1.magnum \
                           --coe mesos \
                           --volume-driver rexray \
                           --labels rexray-preempt=true</pre></div></li><li class="step "><p>Create the Mesos cluster:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create mesos-cluster \
                      --cluster-template mesos-cluster-template \
                      --node-count 1</pre></div></li><li class="step "><p>Create the cinder volume and configure this cluster:</p><div class="verbatim-wrap"><pre class="screen">cinder create --display-name=redisdata 1</pre></div><p>Create the following file</p><div class="verbatim-wrap"><pre class="screen">cat &gt; mesos.json &lt;&lt; END
{
  "id": "redis",
  "container": {
    "docker": {
    "image": "redis",
    "network": "BRIDGE",
    "portMappings": [
      { "containerPort": 80, "hostPort": 0, "protocol": "tcp"}
    ],
    "parameters": [
       { "key": "volume-driver", "value": "rexray" },
       { "key": "volume", "value": "redisdata:/data" }
    ]
    }
 },
 "cpus": 0.2,
 "mem": 32.0,
 "instances": 1
}
END</pre></div></li></ol></div></div><p><span class="bold"><strong>NOTE:</strong></span> When the Mesos cluster is created using this ClusterTemplate, the
                    Mesos cluster will be configured so that a filesystem on an existing cinder
                    volume can be mounted in a container by configuring the parameters to mount
                    the cinder volume in the JSON file</p><div class="verbatim-wrap"><pre class="screen">"parameters": [
   { "key": "volume-driver", "value": "rexray" },
   { "key": "volume", "value": "redisdata:/data" }
]</pre></div><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>Create the container using Marathon REST API</p><div class="verbatim-wrap"><pre class="screen">MASTER_IP=$(magnum cluster-show mesos-cluster | awk '/ api_address /{print $4}')
curl -X POST -H "Content-Type: application/json" \
http://${MASTER_IP}:8080/v2/apps -d@mesos.json</pre></div></li></ul></div></div><p>You can log into the container to check that the mountPath exists, and
                    you can run the command ‘cinder list’ to verify that your cinder
                    volume status is ‘in-use’.</p></div></div></div><div class="sect1" id="id-1.7.22"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.21 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Management</span> <a title="Permalink" class="permalink" href="#id-1.7.22">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When a COE is deployed, an image from Glance is used to boot the nodes
            in the cluster and then the software will be configured and started on
            the nodes to bring up the full cluster.  An image is based on a
            particular distro such as Fedora, Ubuntu, etc, and is prebuilt with
            the software specific to the COE such as Kubernetes, Swarm, Mesos.
            The image is tightly coupled with the following in Magnum:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Heat templates to orchestrate the configuration.</p></li><li class="step "><p>Template definition to map ClusterTemplate parameters to Heat
                    template parameters.</p></li><li class="step "><p>Set of scripts to configure software.</p></li></ol></div></div><p>Collectively, they constitute the driver for a particular COE and a
            particular distro; therefore, developing a new image needs to be done
            in conjunction with developing these other components.  Image can be
            built by various methods such as diskimagebuilder, or in some case, a
            distro image can be used directly.  A number of drivers and the
            associated images is supported in Magnum as reference implementation.
            In this section, we focus mainly on the supported images.</p><p>All images must include support for cloud-init and the heat software
            configuration utility:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>os-collect-config</p></li><li class="listitem "><p>os-refresh-config</p></li><li class="listitem "><p>os-apply-config</p></li><li class="listitem "><p>heat-config</p></li><li class="listitem "><p>heat-config-script</p></li></ul></div><p>Additional software are described as follows.</p><div class="sect2" id="id-1.7.22.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.21.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes on Fedora Atomic</span> <a title="Permalink" class="permalink" href="#id-1.7.22.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image can be downloaded from the <a class="link" href="https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images/" target="_blank">public Atomic site</a>
                or can be built locally using diskimagebuilder.  Details can be found in the
                <a class="link" href="https://github.com/openstack/magnum/tree/master/magnum/elements/fedora-atomic" target="_blank">fedora-atomic element</a>
                The image currently has the following OS/software:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="11" class="c2" /></colgroup><thead><tr><th>
                    <p>OS/software</p>
                  </th><th>
                    <p>version</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Fedora</p>
                  </td><td>
                    <p>26</p>
                  </td></tr><tr><td>
                    <p>Docker</p>
                  </td><td>
                    <p>1.13.1</p>
                  </td></tr><tr><td>
                    <p>Kubernetes</p>
                  </td><td>
                    <p>1.7.4</p>
                  </td></tr><tr><td>
                    <p>etcd</p>
                  </td><td>
                    <p>3.1.3</p>
                  </td></tr><tr><td>
                    <p>Flannel</p>
                  </td><td>
                    <p>0.7.0</p>
                  </td></tr></tbody></table></div><p>The following software are managed as systemd services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kube-apiserver</p></li><li class="listitem "><p>kubelet</p></li><li class="listitem "><p>etcd</p></li><li class="listitem "><p>flannel (if specified as network driver)</p></li><li class="listitem "><p>docker</p></li></ul></div><p>The following software are managed as Docker containers:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kube-controller-manager</p></li><li class="listitem "><p>kube-scheduler</p></li><li class="listitem "><p>kube-proxy</p></li></ul></div><p>The login for this image is <span class="emphasis"><em>fedora</em></span>.</p></div><div class="sect2" id="id-1.7.22.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.21.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes on CoreOS</span> <a title="Permalink" class="permalink" href="#id-1.7.22.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>CoreOS publishes a <a class="link" href="http://beta.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2" target="_blank">stock image</a>
                that is being used to deploy Kubernetes.
                This image has the following OS/software:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="11" class="c2" /></colgroup><thead><tr><th>
                    <p>OS/software</p>
                  </th><th>
                    <p>version</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>CoreOS</p>
                  </td><td>
                    <p>4.3.6</p>
                  </td></tr><tr><td>
                    <p>Docker</p>
                  </td><td>
                    <p>1.9.1</p>
                  </td></tr><tr><td>
                    <p>Kubernetes</p>
                  </td><td>
                    <p>1.0.6</p>
                  </td></tr><tr><td>
                    <p>etcd</p>
                  </td><td>
                    <p>2.2.3</p>
                  </td></tr><tr><td>
                    <p>Flannel</p>
                  </td><td>
                    <p>0.5.5</p>
                  </td></tr></tbody></table></div><p>The following software are managed as systemd services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kubelet</p></li><li class="listitem "><p>flannel (if specified as network driver)</p></li><li class="listitem "><p>docker</p></li><li class="listitem "><p>etcd</p></li></ul></div><p>The following software are managed as Docker containers:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kube-apiserver</p></li><li class="listitem "><p>kube-controller-manager</p></li><li class="listitem "><p>kube-scheduler</p></li><li class="listitem "><p>kube-proxy</p></li></ul></div><p>The login for this image is <span class="emphasis"><em>core</em></span>.</p></div><div class="sect2" id="id-1.7.22.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.21.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes on Ironic</span> <a title="Permalink" class="permalink" href="#id-1.7.22.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image is built manually using diskimagebuilder.  The scripts and
                instructions are included in <a class="link" href="https://github.com/openstack/magnum/tree/master/magnum/templates/kubernetes/elements" target="_blank">Magnum code repo</a>.
                Currently Ironic is not fully supported yet, therefore more details will be
                provided when this driver has been fully tested.</p></div><div class="sect2" id="id-1.7.22.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.21.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swarm on Fedora Atomic</span> <a title="Permalink" class="permalink" href="#id-1.7.22.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image is the same as the image for Kubernetes on Fedora
	  Atomic described above.  The login for this image is <span class="emphasis"><em>fedora</em></span>.</p></div><div class="sect2" id="id-1.7.22.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.21.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Mesos on Ubuntu</span> <a title="Permalink" class="permalink" href="#id-1.7.22.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image is built manually using diskimagebuilder.
                The Fedora site hosts the current image <a class="link" href="https://fedorapeople.org/groups/magnum/ubuntu-mesos-latest.qcow2" target="_blank">ubuntu-mesos-latest.qcow2</a>.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="11" class="c2" /></colgroup><thead><tr><th>
                    <p>OS/software</p>
                  </th><th>
                    <p>version</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Ubuntu</p>
                  </td><td>
                    <p>14.04</p>
                  </td></tr><tr><td>
                    <p>Docker</p>
                  </td><td>
                    <p>1.8.1</p>
                  </td></tr><tr><td>
                    <p>Mesos</p>
                  </td><td>
                    <p>0.25.0</p>
                  </td></tr><tr><td>
                    <p>Marathon</p>
                  </td><td>
                    <p>0.11.1</p>
                  </td></tr></tbody></table></div></div></div><div class="sect1" id="id-1.7.23"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.22 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notification</span> <a title="Permalink" class="permalink" href="#id-1.7.23">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum provides notifications about usage data so that 3rd party applications
            can use the data for auditing, billing, monitoring, or quota purposes. This
            document describes the current inclusions and exclusions for Magnum
            notifications.</p><p>Magnum uses Cloud Auditing Data Federation (<a class="link" href="http://www.dmtf.org/standards/cadf" target="_blank">CADF</a>) Notification as its
            notification format for better support of auditing, details about CADF are
            documented below.</p><div class="sect2" id="id-1.7.23.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.22.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Auditing with CADF</span> <a title="Permalink" class="permalink" href="#id-1.7.23.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum uses the <a class="link" href="http://docs.openstack.org/developer/pycadf" target="_blank">PyCADF</a> library to emit CADF notifications, these events
                adhere to the DMTF <a class="link" href="http://www.dmtf.org/standards/cadf" target="_blank">CADF</a> specification. This standard provides auditing
                capabilities for compliance with security, operational, and business processes
                and supports normalized and categorized event data for federation and
                aggregation.</p><p>Below table describes the event model components and semantics for
                each component:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="17" class="c1" /><col width="58" class="c2" /></colgroup><thead><tr><th>
                    <p>model component</p>
                  </th><th>
                    <p>CADF Definition</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>OBSERVER</p>
                  </td><td>
                    <p>The RESOURCE that generates the CADF Event Record based
                                    on its observation (directly or indirectly) of the
                                    Actual Event.</p>
                  </td></tr><tr><td>
                    <p>INITIATOR</p>
                  </td><td>
                    <p>The RESOURCE that initiated, originated, or instigated
                                    the event’s ACTION, according to the OBSERVER.</p>
                  </td></tr><tr><td>
                    <p>ACTION</p>
                  </td><td>
                    <p>The operation or activity the INITIATOR has performed,
                                    has attempted to perform or has pending against the
                                    event’s TARGET, according to the OBSERVER.</p>
                  </td></tr><tr><td>
                    <p>TARGET</p>
                  </td><td>
                    <p>The RESOURCE against which the ACTION of a CADF Event
                                    Record was performed, attempted, or is pending,
                                    according to the OBSERVER.</p>
                  </td></tr><tr><td>
                    <p>OUTCOME</p>
                  </td><td>
                    <p>The result or status of the ACTION against the TARGET,
                                    according to the OBSERVER.</p>
                  </td></tr></tbody></table></div><p>The <code class="literal">payload</code> portion of a CADF Notification is a CADF <code class="literal">event</code>, which
                is represented as a JSON dictionary. For example:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "typeURI": "http://schemas.dmtf.org/cloud/audit/1.0/event",
    "initiator": {
        "typeURI": "service/security/account/user",
        "host": {
            "agent": "curl/7.22.0(x86_64-pc-linux-gnu)",
            "address": "127.0.0.1"
        },
        "id": "&lt;initiator_id&gt;"
    },
    "target": {
        "typeURI": "&lt;target_uri&gt;",
        "id": "openstack:1c2fc591-facb-4479-a327-520dade1ea15"
    },
    "observer": {
        "typeURI": "service/security",
        "id": "openstack:3d4a50a9-2b59-438b-bf19-c231f9c7625a"
    },
    "eventType": "activity",
    "eventTime": "2014-02-14T01:20:47.932842+00:00",
    "action": "&lt;action&gt;",
    "outcome": "success",
    "id": "openstack:f5352d7b-bee6-4c22-8213-450e7b646e9f",
}</pre></div><p>Where the following are defined:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">&lt;initiator_id&gt;</code>: ID of the user that performed the operation</p></li><li class="listitem "><p><code class="literal">&lt;target_uri&gt;</code>: CADF specific target URI, (i.e.:  data/security/project)</p></li><li class="listitem "><p><code class="literal">&lt;action&gt;</code>: The action being performed, typically:
                        <code class="literal">&lt;operation&gt;</code>. <code class="literal">&lt;resource_type&gt;</code></p></li></ul></div><p>Additionally there may be extra keys present depending on the operation being
                performed, these will be discussed below.</p><p>Note, the <code class="literal">eventType</code> property of the CADF payload is different from the
                <code class="literal">event_type</code> property of a notifications. The former (<code class="literal">eventType</code>) is a
                CADF keyword which designates the type of event that is being measured, this
                can be: <code class="literal">activity</code>, <code class="literal">monitor</code> or <code class="literal">control</code>. Whereas the latter
                (<code class="literal">event_type</code>) is described in previous sections as:
                <code class="literal">magnum.&lt;resource_type&gt;.&lt;operation&gt;</code></p></div><div class="sect2" id="id-1.7.23.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.22.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported Events</span> <a title="Permalink" class="permalink" href="#id-1.7.23.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following table displays the corresponding relationship between resource
                types and operations. The bay type is deprecated and will be removed in a
                future version. Cluster is the new equivalent term.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="15" class="c1" /><col width="28" class="c2" /><col width="25" class="c3" /></colgroup><thead><tr><th>
                    <p>resource type</p>
                  </th><th>
                    <p>supported operations</p>
                  </th><th>
                    <p>typeURI</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>bay</p>
                  </td><td>
                    <p>create, update, delete</p>
                  </td><td>
                    <p>service/magnum/bay</p>
                  </td></tr><tr><td>
                    <p>cluster</p>
                  </td><td>
                    <p>create, update, delete</p>
                  </td><td>
                    <p>service/magnum/cluster</p>
                  </td></tr></tbody></table></div></div><div class="sect2" id="id-1.7.23.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.22.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example Notification - Cluster Create</span> <a title="Permalink" class="permalink" href="#id-1.7.23.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following is an example of a notification that is sent when a cluster is
                created. This example can be applied for any <code class="literal">create</code>, <code class="literal">update</code> or
                <code class="literal">delete</code> event that is seen in the table above. The <code class="literal">&lt;action&gt;</code> and
                <code class="literal">typeURI</code> fields will be change.</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "event_type": "magnum.cluster.created",
    "message_id": "0156ee79-b35f-4cef-ac37-d4a85f231c69",
    "payload": {
        "typeURI": "http://schemas.dmtf.org/cloud/audit/1.0/event",
        "initiator": {
            "typeURI": "service/security/account/user",
            "id": "c9f76d3c31e142af9291de2935bde98a",
            "user_id": "0156ee79-b35f-4cef-ac37-d4a85f231c69",
            "project_id": "3d4a50a9-2b59-438b-bf19-c231f9c7625a"
        },
        "target": {
            "typeURI": "service/magnum/cluster",
            "id": "openstack:1c2fc591-facb-4479-a327-520dade1ea15"
        },
        "observer": {
            "typeURI": "service/magnum/cluster",
            "id": "openstack:3d4a50a9-2b59-438b-bf19-c231f9c7625a"
        },
        "eventType": "activity",
        "eventTime": "2015-05-20T01:20:47.932842+00:00",
        "action": "create",
        "outcome": "success",
        "id": "openstack:f5352d7b-bee6-4c22-8213-450e7b646e9f",
        "resource_info": "671da331c47d4e29bb6ea1d270154ec3"
    }
    "priority": "INFO",
    "publisher_id": "magnum.host1234",
    "timestamp": "2016-05-20 15:03:45.960280"
}</pre></div></div></div><div class="sect1" id="id-1.7.24"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.23 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Container Monitoring</span> <a title="Permalink" class="permalink" href="#id-1.7.24">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The offered monitoring stack relies on the following set of containers and
            services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>cAdvisor</p></li><li class="listitem "><p>Node Exporter</p></li><li class="listitem "><p>Prometheus</p></li><li class="listitem "><p>Grafana</p></li></ul></div><p>To setup this monitoring stack, users are given two configurable labels in
            the Magnum cluster template’s definition:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.24.5.1"><span class="term "></span></dt><dd><p>This label accepts a boolean value. If <span class="emphasis"><em>True</em></span>, the monitoring stack will be
                        setup. By default <span class="emphasis"><em>prometheus_monitoring = False</em></span>.</p></dd><dt id="id-1.7.24.5.2"><span class="term "></span></dt><dd><p>This label lets users create their own <span class="emphasis"><em>admin</em></span> user password for the Grafana
                        interface. It expects a string value. By default it is set to <span class="emphasis"><em>admin</em></span>.</p></dd></dl></div><div class="sect2" id="id-1.7.24.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.23.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Container Monitoring in Kubernetes</span> <a title="Permalink" class="permalink" href="#id-1.7.24.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By default, all Kubernetes clusters already contain <span class="emphasis"><em>cAdvisor</em></span> integrated
                with the <span class="emphasis"><em>Kubelet</em></span> binary. Its container monitoring data can be accessed on
                a node level basis through <span class="emphasis"><em>http://NODE_IP:4194</em></span>.</p><p>Node Exporter is part of the above mentioned monitoring stack as it can be
                used to export machine metrics. Such functionality also work on a node level
                which means that when <code class="literal">prometheus-monitoring</code> is <span class="emphasis"><em>True</em></span>, the Kubernetes nodes
                will be populated with an additional manifest under
                <span class="emphasis"><em>/etc/kubernetes/manifests</em></span>. Node Exporter is then automatically picked up
                and launched as a regular Kubernetes POD.</p><p>To aggregate and complement all the existing monitoring metrics and add a
                built-in visualization layer, Prometheus is used. It is launched by the
                Kubernetes master node(s) as a <span class="emphasis"><em>Service</em></span> within a <span class="emphasis"><em>Deployment</em></span> with one
                replica and it relies on a <span class="emphasis"><em>ConfigMap</em></span> where the Prometheus configuration
                (prometheus.yml) is defined. This configuration uses Prometheus native
                support for service discovery in Kubernetes clusters,
                <span class="emphasis"><em>kubernetes_sd_configs</em></span>. The respective manifests can be found in
                <span class="emphasis"><em>/srv/kubernetes/monitoring/</em></span> on the master nodes and once the service is
                up and running, Prometheus UI can be accessed through port 9090.</p><p>Finally, for custom plotting and enhanced metric aggregation and
                visualization, Prometheus can be integrated with Grafana as it provides
                native compliance for Prometheus data sources. Also Grafana is deployed as
                a <span class="emphasis"><em>Service</em></span> within a <span class="emphasis"><em>Deployment</em></span> with one replica. The default user is
                <span class="emphasis"><em>admin</em></span> and the password is setup according to <code class="literal">grafana-admin-passwd</code>.
                There is also a default Grafana dashboard provided with this installation,
                from the official <a class="link" href="https://grafana.net/dashboards" target="_blank">Grafana dashboards’ repository</a>. The Prometheus data
                source is automatically added to Grafana once it is up and running, pointing
                to <span class="emphasis"><em>http://prometheus:9090</em></span> through <span class="emphasis"><em>Proxy</em></span>. The respective manifests can
                also be found in <span class="emphasis"><em>/srv/kubernetes/monitoring/</em></span> on the master nodes and once
                the service is running, the Grafana dashboards can be accessed through port
                3000.</p><p>For both Prometheus and Grafana, there is an assigned <span class="emphasis"><em>systemd</em></span> service
                called <span class="emphasis"><em>kube-enable-monitoring</em></span>.</p></div></div><div class="sect1" id="id-1.7.25"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.24 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes External Load Balancer</span> <a title="Permalink" class="permalink" href="#id-1.7.25">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In a Kubernetes cluster, all masters and minions are connected to a private
            Neutron subnet, which in turn is connected by a router to the public network.
            This allows the nodes to access each other and the external internet.</p><p>All Kubernetes pods and services created in the cluster are connected to a
            private container network which by default is Flannel, an overlay network that
            runs on top of the Neutron private subnet.  The pods and services are assigned
            IP addresses from this container network and they can access each other and
            the external internet.  However, these IP addresses are not accessible from an
            external network.</p><p>To publish a service endpoint externally so that the service can be accessed
            from the external network, Kubernetes provides the external load balancer
            feature.  This is done by simply specifying the attribute “type: LoadBalancer”
            in the service manifest.  When the service is created, Kubernetes will add an
            external load balancer in front of the service so that the service will have
            an external IP address in addition to the internal IP address on the container
            network.  The service endpoint can then be accessed with this external IP
            address.  Refer to the <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer" target="_blank">Kubernetes service document</a> for more details.</p><p>A Kubernetes cluster deployed by Magnum will have all the necessary
            configuration required for the external load balancer.  This document describes
            how to use this feature.</p><div class="sect2" id="id-1.7.25.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.24.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Steps for the cluster administrator</span> <a title="Permalink" class="permalink" href="#id-1.7.25.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Because the Kubernetes master needs to interface with OpenStack to create and
                manage the Neutron load balancer, we need to provide a credential for
                Kubernetes to use.</p><p>In the current implementation, the cluster administrator needs to manually
                perform this step.  We are looking into several ways to let Magnum automate
                this step in a secure manner.  This means that after the Kubernetes cluster is
                initially deployed, the load balancer support is disabled.  If the
                administrator does not want to enable this feature, no further action is
                required.  All the services will be created normally; services that specify the
                load balancer will also be created successfully, but a load balancer will not
                be created.</p><p>Note that different versions of Kubernetes require different versions of
                Neutron LBaaS plugin running on the OpenStack instance:</p><div class="verbatim-wrap"><pre class="screen">============================  ==============================
Kubernetes Version on Master  Neutron LBaaS Version Required
============================  ==============================
1.2                           LBaaS v1
1.3 or later                  LBaaS v2
============================  ==============================</pre></div><p>Before enabling the Kubernetes load balancer feature, confirm that the
                OpenStack instance is running the required version of Neutron LBaaS plugin.
                To determine if your OpenStack instance is running LBaaS v1, try running
                the following command from your OpenStack control node:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-pool-list</pre></div><p>Or look for the following configuration in neutron.conf or
                neutron_lbaas.conf:</p><div class="verbatim-wrap"><pre class="screen">service_provider = LOADBALANCER:Haproxy:neutron_lbaas.services.loadbalancer.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default</pre></div><p>To determine if your OpenStack instance is running LBaaS v2, try running
                the following command from your OpenStack control node:</p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-pool-list</pre></div><p>Or look for the following configuration in neutron.conf or
                neutron_lbaas.conf:</p><div class="verbatim-wrap"><pre class="screen">service_plugins = neutron.plugins.services.agent_loadbalancer.plugin.LoadBalancerPluginv2</pre></div><p>To configure LBaaS v1 or v2, refer to the Neutron documentation.</p><p>Before deleting the Kubernetes cluster, make sure to
                delete all the services that created load balancers. Because the Neutron
                objects created by Kubernetes are not managed by Heat, they will not be
                deleted by Heat and this will cause the cluster-delete operation to fail. If
                this occurs, delete the neutron objects manually (lb-pool, lb-vip, lb-member,
                lb-healthmonitor) and then run cluster-delete again.</p></div><div class="sect2" id="id-1.7.25.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.24.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Steps for the users</span> <a title="Permalink" class="permalink" href="#id-1.7.25.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This feature requires the OpenStack cloud provider to be enabled.
                To do so, enable the cinder support (–volume-driver cinder).</p><p>For the user, publishing the service endpoint externally involves the following
                2 steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Specify “type: LoadBalancer” in the service manifest</p></li><li class="step "><p>After the service is created, associate a floating IP with the VIP of the
                        load balancer pool.</p></li></ol></div></div><p>The following example illustrates how to create an external endpoint for
                a pod running nginx.</p><p>Create a file (e.g nginx.yaml) describing a pod running nginx:</p><div class="verbatim-wrap"><pre class="screen">apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
   app: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80</pre></div><p>Create a file (e.g nginx-service.yaml) describing a service for the nginx pod:</p><div class="verbatim-wrap"><pre class="screen">apiVersion: v1
kind: Service
metadata:
  name: nginxservice
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
  selector:
    app: nginx
  type: LoadBalancer</pre></div><p>Please refer to the <a class="link" href="https://docs.openstack.org/developer/magnum/userguide.html" target="_blank">quickstart</a> guide on how to connect to Kubernetes running on the launched
                cluster. Assuming a Kubernetes cluster named k8sclusterv1 has been created,
                deploy the pod and service using following commands:</p><div class="verbatim-wrap"><pre class="screen">kubectl create -f nginx.yaml

kubectl create -f nginx-service.yaml</pre></div><p>For more details on verifying the load balancer in OpenStack, refer to the
                following section on how it works.</p><p>Next, associate a floating IP to the load balancer.  This can be done easily
                on Horizon by navigating to:</p><div class="verbatim-wrap"><pre class="screen">Compute -&gt; Access &amp; Security -&gt; Floating IPs</pre></div><p>Click on “Allocate IP To Project” and then on “Associate” for the new floating
                IP.</p><p>Alternatively, associating a floating IP can be done on the command line by
                allocating a floating IP, finding the port of the VIP, and associating the
                floating IP to the port.
                The commands shown below are for illustration purpose and assume
                that there is only one service with load balancer running in the cluster and
                no other load balancers exist except for those created for the cluster.</p><p>First create a floating IP on the public network:</p><div class="verbatim-wrap"><pre class="screen">neutron floatingip-create public

Created a new floatingip:

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    |                                      |
| floating_ip_address | 172.24.4.78                          |
| floating_network_id | 4808eacb-e1a0-40aa-97b6-ecb745af2a4d |
| id                  | b170eb7a-41d0-4c00-9207-18ad1c30fecf |
| port_id             |                                      |
| router_id           |                                      |
| status              | DOWN                                 |
| tenant_id           | 012722667dc64de6bf161556f49b8a62     |
+---------------------+--------------------------------------+</pre></div><p>Note the floating IP 172.24.4.78 that has been allocated.  The ID for this
                floating IP is shown above, but it can also be queried by:</p><div class="verbatim-wrap"><pre class="screen">FLOATING_XML:ID=$(neutron floatingip-list | grep "172.24.4.78" | awk '{print $2}')</pre></div><p>Next find the VIP for the load balancer:</p><div class="verbatim-wrap"><pre class="screen">VIP_XML:ID=$(neutron lb-vip-list | grep TCP | grep -v pool | awk '{print $2}')</pre></div><p>Find the port for this VIP:</p><div class="verbatim-wrap"><pre class="screen">PORT_XML:ID=$(neutron lb-vip-show $VIP_ID | grep port_id | awk '{print $4}')</pre></div><p>Finally associate the floating IP with the port of the VIP:</p><div class="verbatim-wrap"><pre class="screen">neutron floatingip-associate $FLOATING_ID $PORT_ID</pre></div><p>The endpoint for nginx can now be accessed on a browser at this floating IP:</p><div class="verbatim-wrap"><pre class="screen">http://172.24.4.78:80</pre></div><p>Alternatively, you can check for the nginx ‘welcome’ message by:</p><div class="verbatim-wrap"><pre class="screen">curl http://172.24.4.78:80</pre></div><p>NOTE: it is not necessary to indicate port :80 here but it is shown to
                correlate with the port that was specified in the service manifest.</p></div><div class="sect2" id="id-1.7.25.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.24.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How it works</span> <a title="Permalink" class="permalink" href="#id-1.7.25.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Kubernetes is designed to work with different Clouds such as Google Compute
                Engine (GCE), Amazon Web Services (AWS), and OpenStack;  therefore, different
                load balancers need to be created on the particular Cloud for the services.
                This is done through a plugin for each Cloud and the OpenStack plugin was
                developed by Angus Lees:</p><div class="verbatim-wrap"><pre class="screen">https://github.com/kubernetes/kubernetes/blob/release-1.0/pkg/cloudprovider/openstack/openstack.go</pre></div><p>When the Kubernetes components kube-apiserver and kube-controller-manager start
                up, they will use the credential provided to authenticate a client
                to interface with OpenStack.</p><p>When a service with load balancer is created, the plugin code will interface
                with Neutron in this sequence:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create lb-pool for the Kubernetes service</p></li><li class="step "><p>Create lb-member for the minions</p></li><li class="step "><p>Create lb-healthmonitor</p></li><li class="step "><p>Create lb-vip on the private network of the Kubernetes cluster</p></li></ol></div></div><p>These Neutron objects can be verified as follows.  For the load balancer pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-pool-list
+--------------------------------------+--------------------------------------------------+----------+-------------+----------+----------------+--------+
| id                                   | name                                             | provider | lb_method   | protocol | admin_state_up | status |
+--------------------------------------+--------------------------------------------------+----------+-------------+----------+----------------+--------+
| 241357b3-2a8f-442e-b534-bde7cd6ba7e4 | a1f03e40f634011e59c9efa163eae8ab                 | haproxy  | ROUND_ROBIN | TCP      | True           | ACTIVE |
| 82b39251-1455-4eb6-a81e-802b54c2df29 | k8sclusterv1-iypacicrskib-api_pool-fydshw7uvr7h  | haproxy  | ROUND_ROBIN | HTTP     | True           | ACTIVE |
| e59ea983-c6e8-4cec-975d-89ade6b59e50 | k8sclusterv1-iypacicrskib-etcd_pool-qbpo43ew2m3x | haproxy  | ROUND_ROBIN | HTTP     | True           | ACTIVE |
+--------------------------------------+--------------------------------------------------+----------+-------------+----------+----------------+--------+</pre></div><p>Note that 2 load balancers already exist to implement high availability for the
                cluster (api and ectd). The new load balancer for the Kubernetes service uses
                the TCP protocol and has a name assigned by Kubernetes.</p><p>For the members of the pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-member-list
+--------------------------------------+----------+---------------+--------+----------------+--------+
| id                                   | address  | protocol_port | weight | admin_state_up | status |
+--------------------------------------+----------+---------------+--------+----------------+--------+
| 9ab7dcd7-6e10-4d9f-ba66-861f4d4d627c | 10.0.0.5 |          8080 |      1 | True           | ACTIVE |
| b179c1ad-456d-44b2-bf83-9cdc127c2b27 | 10.0.0.5 |          2379 |      1 | True           | ACTIVE |
| f222b60e-e4a9-4767-bc44-ffa66ec22afe | 10.0.0.6 |         31157 |      1 | True           | ACTIVE |
+--------------------------------------+----------+---------------+--------+----------------+--------+</pre></div><p>Again, 2 members already exist for high availability and they serve the master
                node at 10.0.0.5. The new member serves the minion at 10.0.0.6, which hosts the
                Kubernetes service.</p><p>For the monitor of the pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-healthmonitor-list
+--------------------------------------+------+----------------+
| id                                   | type | admin_state_up |
+--------------------------------------+------+----------------+
| 381d3d35-7912-40da-9dc9-b2322d5dda47 | TCP  | True           |
| 67f2ae8f-ffc6-4f86-ba5f-1a135f4af85c | TCP  | True           |
| d55ff0f3-9149-44e7-9b52-2e055c27d1d3 | TCP  | True           |
+--------------------------------------+------+----------------+</pre></div><p>For the VIP of the pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-vip-list
+--------------------------------------+----------------------------------+----------+----------+----------------+--------+
| id                                   | name                             | address  | protocol | admin_state_up | status |
+--------------------------------------+----------------------------------+----------+----------+----------------+--------+
| 9ae2ebfb-b409-4167-9583-4a3588d2ff42 | api_pool.vip                     | 10.0.0.3 | HTTP     | True           | ACTIVE |
| c318aec6-8b7b-485c-a419-1285a7561152 | a1f03e40f634011e59c9efa163eae8ab | 10.0.0.7 | TCP      | True           | ACTIVE |
| fc62cf40-46ad-47bd-aa1e-48339b95b011 | etcd_pool.vip                    | 10.0.0.4 | HTTP     | True           | ACTIVE |
+--------------------------------------+----------------------------------+----------+----------+----------------+--------+</pre></div><p>Note that the VIP is created on the private network of the cluster;  therefore
                it has an internal IP address of 10.0.0.7.  This address is also associated as
                the “external address” of the Kubernetes service.  You can verify this in
                Kubernetes by running following command:</p><div class="verbatim-wrap"><pre class="screen">kubectl get services
NAME           LABELS                                    SELECTOR    IP(S)            PORT(S)
kubernetes     component=apiserver,provider=kubernetes   &lt;none&gt;      10.254.0.1       443/TCP
nginxservice   app=nginx                                 app=nginx   10.254.122.191   80/TCP
                                                                     10.0.0.7</pre></div><p>On GCE, the networking implementation gives the load balancer an external
                address automatically. On OpenStack, we need to take the additional step of
                associating a floating IP to the load balancer.</p></div></div><div class="sect1" id="id-1.7.26"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.25 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Terminology</span> <a title="Permalink" class="permalink" href="#id-1.7.26">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#terminology</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.26.2.1"><span class="term ">Cluster (previously Bay)</span></dt><dd><p>A cluster is the construct in which Magnum launches container orchestration
                        engines. After a cluster has been created the user is able to add containers
                        to it either directly, or in the case of the Kubernetes container
                        orchestration engine within pods - a logical construct specific to that
                        implementation. A cluster is created based on a ClusterTemplate.</p></dd><dt id="id-1.7.26.2.2"><span class="term ">ClusterTemplate (previously BayModel)</span></dt><dd><p>A ClusterTemplate in Magnum is roughly equivalent to a flavor in Nova. It
                        acts as a template that defines options such as the container orchestration
                        engine, keypair and image for use when Magnum is creating clusters using
                        the given ClusterTemplate.</p></dd><dt id="id-1.7.26.2.3"><span class="term ">Container Orchestration Engine (COE)</span></dt><dd><p>A container orchestration engine manages the lifecycle of one or more
                        containers, logically represented in Magnum as a cluster. Magnum supports a
                        number of container orchestration engines, each with their own pros and cons,
                        including Docker Swarm, Kubernetes, and Mesos.</p></dd></dl></div></div><div class="sect1" id="id-1.7.27"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.26 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Overview</span> <a title="Permalink" class="permalink" href="#id-1.7.27">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#overview</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum is an OpenStack API service developed by the OpenStack Containers Team
            making container orchestration engines (COE) such as Docker Swarm, Kubernetes
            and Apache Mesos available as the first class resources in OpenStack.</p><p>Magnum uses Heat to orchestrate an OS image which contains Docker and COE
            and runs that image in either virtual machines or bare metal in a cluster
            configuration.</p><p>Magnum offers complete life-cycle management of COEs in an
            OpenStack environment, integrated with other OpenStack services for a seamless
            experience for OpenStack users who wish to run containers in an OpenStack
            environment.</p><p>Following are few salient features of Magnum:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Standard API based complete life-cycle management for Container Clusters</p></li><li class="listitem "><p>Multi-tenancy for container clusters</p></li><li class="listitem "><p>Choice of COE: Kubernetes, Swarm, Mesos, DC/OS</p></li><li class="listitem "><p>Choice of container cluster deployment model: VM or Bare-metal</p></li><li class="listitem "><p>Keystone-based multi-tenant security and auth management</p></li><li class="listitem "><p>Neutron based multi-tenant network control and isolation</p></li><li class="listitem "><p>Cinder based volume service for containers</p></li><li class="listitem "><p>Integrated with OpenStack: SSO experience for cloud users</p></li><li class="listitem "><p>Secure container cluster access (TLS enabled)</p></li></ul></div><p>More details: <a class="link" href="https://wiki.openstack.org/wiki/Magnum" target="_blank">Magnum Project Wiki</a></p></div><div class="sect1" id="id-1.7.28"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.27 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">ClusterTemplate</span> <a title="Permalink" class="permalink" href="#id-1.7.28">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#clustertemplate</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A ClusterTemplate (previously known as BayModel) is a collection of parameters
            to describe how a cluster can be constructed.  Some parameters are relevant to
            the infrastructure of the cluster, while others are for the particular COE.  In
            a typical workflow, a user would create a ClusterTemplate, then create one or
            more clusters using the ClusterTemplate.  A cloud provider can also define a
            number of ClusterTemplates and provide them to the users.  A ClusterTemplate
            cannot be updated or deleted if a cluster using this ClusterTemplate still
            exists.</p><p>The definition and usage of the parameters of a ClusterTemplate are as follows.
            They are loosely grouped as: mandatory, infrastructure, COE specific.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.28.4.1"><span class="term ">&lt;name&gt;</span></dt><dd><p>Name of the ClusterTemplate to create.  The name does not have to be
                        unique.  If multiple ClusterTemplates have the same name, you will need to
                        use the UUID to select the ClusterTemplate when creating a cluster or
                        updating, deleting a ClusterTemplate.  If a name is not specified, a random
                        name will be generated using a string and a number, for example
                        “pi-13-model”.</p></dd><dt id="id-1.7.28.4.2"><span class="term ">–coe &lt;coe&gt;</span></dt><dd><p>Specify the Container Orchestration Engine to use.  Supported
                        COE’s include ‘kubernetes’, ‘swarm’, ‘mesos’.  If your environment
                        has additional cluster drivers installed, refer to the cluster driver
                        documentation for the new COE names.  This is a mandatory parameter
                        and there is no default value.</p></dd><dt id="id-1.7.28.4.3"><span class="term ">–image &lt;image&gt;</span></dt><dd><p>The name or UUID of the base image in Glance to boot the servers for
                        the cluster.  The image must have the attribute ‘os_distro’ defined
                        as appropriate for the cluster driver.  For the currently supported
                        images, the os_distro names are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="10" class="c1" /><col width="21" class="c2" /></colgroup><thead><tr><th>
                        <p>COE</p>
                      </th><th>
                        <p>os-distro</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Kubernetes</p>
                      </td><td>
                        <p>Fedora-atomic, CoreOS</p>
                      </td></tr><tr><td>
                        <p>Swarm</p>
                      </td><td>
                        <p>Fedora-atomic</p>
                      </td></tr><tr><td>
                        <p>Mesos</p>
                      </td><td>
                        <p>Ubuntu</p>
                      </td></tr></tbody></table></div><p>This is a mandatory parameter and there is no default value.</p></dd><dt id="id-1.7.28.4.4"><span class="term ">–keypair &lt;keypair&gt;</span></dt><dd><p>The name of the SSH keypair to configure in the cluster servers
                        for ssh access.  You will need the key to be able to ssh to the
                        servers in the cluster.  The login name is specific to the cluster
                        driver. If keypair is not provided in template it will be required at
                        Cluster create. This value will be overridden by any keypair value that
                        is provided during Cluster create.</p></dd><dt id="id-1.7.28.4.5"><span class="term ">–external-network &lt;external-network&gt;</span></dt><dd><p>The name or network ID of a Neutron network to provide connectivity
                        to the external internet for the cluster.  This network must be an
                        external network, i.e. its attribute ‘router:external’ must be
                        ‘True’.  The servers in the cluster will be connected to a private
                        network and Magnum will create a router between this private network
                        and the external network.  This will allow the servers to download
                        images, access discovery service, etc, and the containers to install
                        packages, etc.  In the opposite direction, floating IP’s will be
                        allocated from the external network to provide access from the
                        external internet to servers and the container services hosted in
                        the cluster.  This is a mandatory parameter and there is no default
                        value.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.28.5.1"><span class="term ">
              <code class="option">--public</code>
            </span></dt><dd><p>Access to a ClusterTemplate is normally limited to the admin, owner or users
                        within the same tenant as the owners.  Setting this flag
                        makes the ClusterTemplate public and accessible by other users.  The default
                        is not public.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.28.6.1"><span class="term ">–server-type &lt;server-type&gt;</span></dt><dd><p>The servers in the cluster can be VM or baremetal.  This parameter selects
                        the type of server to create for the cluster.  The default is ‘vm’. Possible
                        values are ‘vm’, ‘bm’.</p></dd><dt id="id-1.7.28.6.2"><span class="term ">–network-driver &lt;network-driver&gt;</span></dt><dd><p>The name of a network driver for providing the networks for the
                        containers.  Note that this is different and separate from the Neutron
                        network for the cluster.  The operation and networking model are specific
                        to the particular driver.  Supported network drivers and the default driver are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="11" class="c1" /><col width="17" class="c2" /><col width="8" class="c3" /></colgroup><thead><tr><th>
                        <p>COE</p>
                      </th><th>
                        <p>Network-Driver</p>
                      </th><th>
                        <p>Default</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Kubernetes</p>
                      </td><td>
                        <p>Flannel</p>
                      </td><td>
                        <p>Flannel</p>
                      </td></tr><tr><td>
                        <p>Swarm</p>
                      </td><td>
                        <p>Docker, Flannel</p>
                      </td><td>
                        <p>Flannel</p>
                      </td></tr><tr><td>
                        <p>Mesos</p>
                      </td><td>
                        <p>Docker</p>
                      </td><td>
                        <p>Docker</p>
                      </td></tr></tbody></table></div></dd><dt id="id-1.7.28.6.3"><span class="term ">–volume-driver &lt;volume-driver&gt;</span></dt><dd><p>The name of a volume driver for managing the persistent storage for
                        the containers.  The functionality supported are specific to the
                        driver.  Supported volume drivers and the default driver are:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="13" class="c2" /><col width="11" class="c3" /></colgroup><thead><tr><th>
                        <p>COE</p>
                      </th><th>
                        <p>Volume-Driver</p>
                      </th><th>
                        <p>Default</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Kubernetes</p>
                      </td><td>
                        <p>Cinder</p>
                      </td><td>
                        <p>No Driver</p>
                      </td></tr><tr><td>
                        <p>Swarm</p>
                      </td><td>
                        <p>Rexray</p>
                      </td><td>
                        <p>No Driver</p>
                      </td></tr><tr><td>
                        <p>Mesos</p>
                      </td><td>
                        <p>Rexray</p>
                      </td><td>
                        <p>No Driver</p>
                      </td></tr></tbody></table></div></dd><dt id="id-1.7.28.6.4"><span class="term ">–dns-nameserver &lt;dns-nameserver&gt;</span></dt><dd><p>The DNS nameserver for the servers and containers in the cluster to use.
                        This is configured in the private Neutron network for the cluster.  The
                        default is ‘8.8.8.8’.</p></dd><dt id="id-1.7.28.6.5"><span class="term ">–flavor &lt;flavor&gt;</span></dt><dd><p>The nova flavor id for booting the node servers.  The default
                        is ‘m1.small’.</p></dd><dt id="id-1.7.28.6.6"><span class="term ">–master-flavor &lt;master-flavor&gt;</span></dt><dd><p>The nova flavor id for booting the master or manager servers.  The
                        default is ‘m1.small’.</p></dd><dt id="id-1.7.28.6.7"><span class="term ">–http-proxy &lt;http-proxy&gt;</span></dt><dd><p>The IP address for a proxy to use when direct http access from the
                        servers to sites on the external internet is blocked.  This may
                        happen in certain countries or enterprises, and the proxy allows the
                        servers and containers to access these sites.  The format is a URL
                        including a port number.  The default is ‘None’.</p></dd><dt id="id-1.7.28.6.8"><span class="term ">–https-proxy &lt;https-proxy&gt;</span></dt><dd><p>The IP address for a proxy to use when direct https access from the
                        servers to sites on the external internet is blocked.  This may
                        happen in certain countries or enterprises, and the proxy allows the
                        servers and containers to access these sites.  The format is a URL
                        including a port number.  The default is ‘None’.</p></dd><dt id="id-1.7.28.6.9"><span class="term ">–no-proxy &lt;no-proxy&gt;</span></dt><dd><p>When a proxy server is used, some sites should not go through the
                        proxy and should be accessed normally.  In this case, you can
                        specify these sites as a comma separated list of IP’s.  The default
                        is ‘None’.</p></dd><dt id="id-1.7.28.6.10"><span class="term ">–docker-volume-size &lt;docker-volume-size&gt;</span></dt><dd><p>If specified, container images will be stored in a cinder volume of the
                        specified size in GB. Each cluster node will have a volume attached of
                        the above size. If not specified, images will be stored in the compute
                        instance’s local disk. For the ‘devicemapper’ storage driver, the minimum
                        value is 3GB. For the ‘overlay’ storage driver, the minimum value is 1GB.
                        This value can be overridden at cluster creation.</p></dd><dt id="id-1.7.28.6.11"><span class="term ">–docker-storage-driver &lt;docker-storage-driver&gt;</span></dt><dd><p>The name of a driver to manage the storage for the images and the
                        container’s writable layer.  The supported drivers are ‘devicemapper’
                        and ‘overlay’.  The default is ‘devicemapper’.</p></dd><dt id="id-1.7.28.6.12"><span class="term ">–labels &lt;KEY1=VALUE1,KEY2=VALUE2;KEY3=VALUE3…&gt;</span></dt><dd><p>Arbitrary labels in the form of key=value pairs.  The accepted keys
                        and valid values are defined in the cluster drivers.  They are used as a
                        way to pass additional parameters that are specific to a cluster driver.
                        Refer to the subsection on labels for a list of the supported
                        key/value pairs and their usage.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.28.7.1"><span class="term ">
              <code class="option">--tls-disabled</code>
            </span></dt><dd><p>Transport Layer Security (TLS) is normally enabled to secure the
                        cluster.  In some cases, users may want to disable TLS in the cluster,
                        for instance during development or to troubleshoot certain problems.
                        Specifying this parameter will disable TLS so that users can access
                        the COE endpoints without a certificate.  The default is TLS
                        enabled.</p></dd><dt id="id-1.7.28.7.2"><span class="term ">
              <code class="option">--registry-enabled</code>
            </span></dt><dd><p>Docker images by default are pulled from the public Docker registry,
                        but in some cases, users may want to use a private registry.  This
                        option provides an alternative registry based on the Registry V2:
                        Magnum will create a local registry in the cluster backed by swift to
                        host the images.  Refer to
                        <a class="link" href="https://github.com/docker/distribution" target="_blank">Docker Registry 2.0</a>
                        for more details.  The default is to use the public registry.</p></dd><dt id="id-1.7.28.7.3"><span class="term ">
              <code class="option">--master-lb-enabled</code>
            </span></dt><dd><p>Since multiple masters may exist in a cluster, a load balancer is
                        created to provide the API endpoint for the cluster and to direct
                        requests to the masters.  In some cases, such as when the LBaaS
                        service is not available, this option can be set to ‘false’ to
                        create a cluster without the load balancer.  In this case, one of the
                        masters will serve as the API endpoint.  The default is ‘true’,
                        i.e. to create the load balancer for the cluster.</p></dd></dl></div><div class="sect2" id="id-1.7.28.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.27.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Labels</span> <a title="Permalink" class="permalink" href="#id-1.7.28.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#clustertemplate</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Labels is a general method to specify supplemental parameters that are
                specific to certain COE or associated with certain options.  Their
                format is key/value pair and their meaning is interpreted by the
                drivers that uses them.  The drivers do validate the key/value pairs.
                Their usage is explained in details in the appropriate sections,
                however, since there are many possible labels, the following table
                provides a summary to help give a clearer picture.  The label keys in
                the table are linked to more details elsewhere in the user guide.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="39" class="c1" /><col width="20" class="c2" /><col width="15" class="c3" /></colgroup><thead><tr><th>
                    <p>label key</p>
                  </th><th>
                    <p>label value</p>
                  </th><th>
                    <p>default</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>
                      <code class="literal">flannel-network-cidr</code>
                    </p>
                  </td><td>
                    <p>IPv4 CIDR</p>
                  </td><td>
                    <p>10.100.0.0/16</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">flannel-backend</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>udp</p></li><li class="listitem "><p>vxlan</p></li><li class="listitem "><p>host-gw</p></li></ul></div>
                  </td><td>
                    <p>udp</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">flannel-network-subnetlen</code>
                    </p>
                  </td><td>
                    <p>size of subnet to
                                    assign to node</p>
                  </td><td>
                    <p>24</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">rexray-preempt</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>true</p></li><li class="listitem "><p>false</p></li></ul></div>
                  </td><td>
                    <p>false</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-isolation</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>filesystem/posix</p></li><li class="listitem "><p>filesystem/linux</p></li><li class="listitem "><p>filesystem/shared</p></li><li class="listitem "><p>posix/cpu</p></li><li class="listitem "><p>posix/mem</p></li><li class="listitem "><p>posix/disk</p></li><li class="listitem "><p>cgroups/cpu</p></li><li class="listitem "><p>cgroups/mem</p></li><li class="listitem "><p>docker/runtime</p></li><li class="listitem "><p>namespaces/pid</p></li></ul></div>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-image-providers</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>appc</p></li><li class="listitem "><p>docker</p></li><li class="listitem "><p>appc,docker</p></li></ul></div>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-work-dir</code>
                    </p>
                  </td><td>
                    <p>(directory name)</p>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">mesos-slave-executor-env-variables</code>
                    </p>
                  </td><td>
                    <p>(file name)</p>
                  </td><td>
                    <p>“”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">swarm-strategy</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>spread</p></li><li class="listitem "><p>binpack</p></li><li class="listitem "><p>random</p></li></ul></div>
                  </td><td>
                    <p>spread</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">admission-control-list</code>
                    </p>
                  </td><td>
                    <p>see below</p>
                  </td><td>
                    <p>see below</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">prometheus-monitoring</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>true</p></li><li class="listitem "><p>false</p></li></ul></div>
                  </td><td>
                    <p>false</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">grafana-admin-passwd</code>
                    </p>
                  </td><td>
                    <p>(any string)</p>
                  </td><td>
                    <p>“admin”</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">kube-tag</code>
                    </p>
                  </td><td>
                    <p>see below</p>
                  </td><td>
                    <p>see below</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">kube-dashboard-enabled</code>
                    </p>
                  </td><td>
                    <div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>true</p></li><li class="listitem "><p>false</p></li></ul></div>
                  </td><td>
                    <p>true</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">docker-volume-type</code>
                    </p>
                  </td><td>
                    <p>see below</p>
                  </td><td>
                    <p>see below</p>
                  </td></tr><tr><td>
                    <p>
                      <code class="literal">etcd-volume-size</code>
                    </p>
                  </td><td>
                    <p>etcd storage
                                    volume size</p>
                  </td><td>
                    <p>0</p>
                  </td></tr></tbody></table></div></div></div><div class="sect1" id="id-1.7.29"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.28 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster</span> <a title="Permalink" class="permalink" href="#id-1.7.29">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A cluster (previously known as bay) is an instance of the ClusterTemplate
            of a COE.  Magnum deploys a cluster by referring to the attributes
            defined in the particular ClusterTemplate as well as a few additional
            parameters for the cluster.  Magnum deploys the orchestration templates
            provided by the cluster driver to create and configure all the necessary
            infrastructure.  When ready, the cluster is a fully operational COE that
            can host containers.</p><div class="sect2" id="id-1.7.29.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.28.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Infrastructure</span> <a title="Permalink" class="permalink" href="#id-1.7.29.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The infrastructure of the cluster consists of the resources provided by
                the various OpenStack services.  Existing infrastructure, including
                infrastructure external to OpenStack, can also be used by the cluster,
                such as DNS, public network, public discovery service, Docker registry.
                The actual resources created depends on the COE type and the options
                specified; therefore you need to refer to the cluster driver documentation
                of the COE for specific details.  For instance, the option
                ‘–master-lb-enabled’ in the ClusterTemplate will cause a load balancer pool
                along with the health monitor and floating IP to be created.  It is
                important to distinguish resources in the IaaS level from resources in
                the PaaS level.  For instance, the infrastructure networking in
                OpenStack IaaS is different and separate from the container networking
                in Kubernetes or Swarm PaaS.</p><p>Typical infrastructure includes the following.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.29.3.4.1"><span class="term ">Servers</span></dt><dd><p>The servers host the containers in the cluster and these servers can be
                            VM or bare metal.  VM’s are provided by Nova.  Since multiple VM’s
                            are hosted on a physical server, the VM’s provide the isolation
                            needed for containers between different tenants running on the same
                            physical server.  Bare metal servers are provided by Ironic and are
                            used when peak performance with virtually no overhead is needed for
                            the containers.</p></dd><dt id="id-1.7.29.3.4.2"><span class="term ">Identity</span></dt><dd><p>Keystone provides the authentication and authorization for managing
                            the cluster infrastructure.</p></dd><dt id="id-1.7.29.3.4.3"><span class="term ">Network</span></dt><dd><p>Networking among the servers is provided by Neutron.  Since COE
                            currently are not multi-tenant, isolation for multi-tenancy on the
                            networking level is done by using a private network for each cluster.
                            As a result, containers belonging to one tenant will not be
                            accessible to containers or servers of another tenant.  Other
                            networking resources may also be used, such as load balancer and
                            routers.  Networking among containers can be provided by Kuryr if
                            needed.</p></dd><dt id="id-1.7.29.3.4.4"><span class="term ">Storage</span></dt><dd><p>Cinder provides the block storage that can be used to host the
                            containers and as persistent storage for the containers.</p></dd><dt id="id-1.7.29.3.4.5"><span class="term ">Security</span></dt><dd><p>Barbican provides the storage of secrets such as certificates used
                            for Transport Layer Security (TLS) within the cluster.</p></dd></dl></div></div><div class="sect2" id="id-1.7.29.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.28.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Life cycle</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The set of life cycle operations on the cluster is one of the key value
                that Magnum provides, enabling clusters to be managed painlessly on
                OpenStack.  The current operations are the basic CRUD operations, but
                more advanced operations are under discussion in the community and
                will be implemented as needed.</p><p><span class="bold"><strong>NOTE</strong></span> The OpenStack resources created for a cluster are fully
                accessible to the cluster owner.  Care should be taken when modifying or
                reusing these resources to avoid impacting Magnum operations in
                unexpected manners.  For instance, if you launch your own Nova
                instance on the cluster private network, Magnum would not be aware of this
                instance.  Therefore, the cluster-delete operation will fail because
                Magnum would not delete the extra Nova instance and the private Neutron
                network cannot be removed while a Nova instance is still attached.</p><p><span class="bold"><strong>NOTE</strong></span> Currently Heat nested templates are used to create the
                resources; therefore if an error occurs, you can troubleshoot through
                Heat.  For more help on Heat stack troubleshooting, refer to the
                <a class="link" href="https://github.com/openstack/magnum/blob/master/doc/source/troubleshooting-guide.rst#heat-stacks" target="_blank">Troubleshooting Guide</a>.</p><div class="sect3" id="id-1.7.29.4.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.28.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><span class="bold"><strong>NOTE</strong></span> bay-&lt;command&gt; are the deprecated versions of these commands and are
                    still support in current release. They will be removed in a future version.
                    Any references to the term bay will be replaced in the parameters when using
                    the ‘bay’ versions of the commands. For example, in ‘bay-create’ –baymodel
                    is used as the baymodel parameter for this command instead of
                    –cluster-template.</p><p>The ‘cluster-create’ command deploys a cluster, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create mycluster \
                  --cluster-template mytemplate \
                  --node-count 8 \
                  --master-count 3</pre></div><p>The ‘cluster-create’ operation is asynchronous; therefore you can initiate
                    another ‘cluster-create’ operation while the current cluster is being created.
                    If the cluster fails to be created, the infrastructure created so far may
                    be retained or deleted depending on the particular orchestration
                    engine.  As a common practice, a failed cluster is retained during
                    development for troubleshooting, but they are automatically deleted in
                    production.  The current cluster drivers use Heat templates and the
                    resources of a failed ‘cluster-create’ are retained.</p><p>The definition and usage of the parameters for ‘cluster-create’ are as
                    follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.29.4.5.7.1"><span class="term ">&lt;name&gt;</span></dt><dd><p>Name of the cluster to create.  If a name is not specified, a random
                                name will be generated using a string and a number, for example
                                “gamma-7-cluster”.</p></dd><dt id="id-1.7.29.4.5.7.2"><span class="term ">–cluster-template &lt;cluster-template&gt;</span></dt><dd><p>The ID or name of the ClusterTemplate to use.  This is a mandatory
                                parameter.  Once a ClusterTemplate is used to create a cluster, it cannot
                                be deleted or modified until all clusters that use the ClusterTemplate have
                                been deleted.</p></dd><dt id="id-1.7.29.4.5.7.3"><span class="term ">–keypair &lt;keypair&gt;</span></dt><dd><p>The name of the SSH keypair to configure in the cluster servers
                                for ssh access.  You will need the key to be able to ssh to the
                                servers in the cluster.  The login name is specific to the cluster
                                driver. If keypair is not provided it will attempt to use the value in
                                the ClusterTemplate. If the ClusterTemplate is also missing a keypair value
                                then an error will be returned.  The keypair value provided here will
                                override the keypair value from the ClusterTemplate.</p></dd><dt id="id-1.7.29.4.5.7.4"><span class="term ">–node-count &lt;node-count&gt;</span></dt><dd><p>The number of servers that will serve as node in the cluster.
                                The default is 1.</p></dd><dt id="id-1.7.29.4.5.7.5"><span class="term ">–master-count &lt;master-count&gt;</span></dt><dd><p>The number of servers that will serve as master for the cluster.
                                The default is 1.  Set to more than 1 master to enable High
                                Availability.  If the option ‘–master-lb-enabled’ is specified in
                                the ClusterTemplate, the master servers will be placed in a load balancer
                                pool.</p></dd><dt id="id-1.7.29.4.5.7.6"><span class="term ">–discovery-url &lt;discovery-url&gt;</span></dt><dd><p>The custom discovery url for node discovery.  This is used by the
                                COE to discover the servers that have been created to host the
                                containers.  The actual discovery mechanism varies with the COE.  In
                                some cases, Magnum fills in the server info in the discovery
                                service.  In other cases, if the discovery-url is not specified,
                                Magnum will use the public discovery service at:</p><div class="verbatim-wrap"><pre class="screen">https://discovery.etcd.io</pre></div><p>In this case, Magnum will generate a unique url here for each cluster
                                and store the info for the servers.</p></dd><dt id="id-1.7.29.4.5.7.7"><span class="term ">–timeout &lt;timeout&gt;</span></dt><dd><p>The timeout for cluster creation in minutes. The value expected is a
                                positive integer and the default is 60 minutes.  If the timeout is
                                reached during cluster-create, the operation will be aborted and the
                                cluster status will be set to ‘CREATE_FAILED’.</p></dd></dl></div></div><div class="sect3" id="id-1.7.29.4.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.28.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">List</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ‘cluster-list’ command lists all the clusters that belong to the tenant,
                    for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-list</pre></div></div><div class="sect3" id="id-1.7.29.4.7"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.28.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Show</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4.7">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ‘cluster-show’ command prints all the details of a cluster, for
                    example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-show mycluster</pre></div><p>The properties include those not specified by users that have been
                    assigned default values and properties from new resources that
                    have been created for the cluster.</p></div><div class="sect3" id="id-1.7.29.4.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.28.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A cluster can be modified using the ‘cluster-update’ command, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-update mycluster replace node_count=8</pre></div><p>The parameters are positional and their definition and usage are as
                    follows.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.29.4.8.5.1"><span class="term ">&lt;cluster&gt;</span></dt><dd><p>This is the first parameter, specifying the UUID or name of the cluster
                                to update.</p></dd><dt id="id-1.7.29.4.8.5.2"><span class="term ">&lt;op&gt;</span></dt><dd><p>This is the second parameter, specifying the desired change to be
                                made to the cluster attributes.  The allowed changes are ‘add’,
                                ‘replace’ and ‘remove’.</p></dd><dt id="id-1.7.29.4.8.5.3"><span class="term ">&lt;attribute=value&gt;</span></dt><dd><p>This is the third parameter, specifying the targeted attributes in
                                the cluster as a list separated by blank space.  To add or replace an
                                attribute, you need to specify the value for the attribute.  To
                                remove an attribute, you only need to specify the name of the
                                attribute.  Currently the only attribute that can be replaced or
                                removed is ‘node_count’.  The attributes ‘name’, ‘master_count’ and
                                ‘discovery_url’ cannot be replaced or delete.  The table below
                                summarizes the possible change to a cluster.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="15" class="c1" /><col width="5" class="c2" /><col width="18" class="c3" /><col width="23" class="c4" /></colgroup><thead><tr><th>
                            <p>Attribute</p>
                          </th><th>
                            <p>add</p>
                          </th><th>
                            <p>replace</p>
                          </th><th>
                            <p>remove</p>
                          </th></tr></thead><tbody><tr><td>
                            <p>node_count</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>add/remove nodes</p>
                          </td><td>
                            <p>reset to default of 1</p>
                          </td></tr><tr><td>
                            <p>master_count</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td></tr><tr><td>
                            <p>name</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td></tr><tr><td>
                            <p>discovery_url</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td><td>
                            <p>no</p>
                          </td></tr></tbody></table></div></dd></dl></div><p>The ‘cluster-update’ operation cannot be initiated when another operation
                    is in progress.</p><p><span class="bold"><strong>NOTE:</strong></span> The attribute names in cluster-update are slightly different
                    from the corresponding names in the cluster-create command: the dash ‘-‘
                    is replaced by an underscore ‘_’.  For instance, ‘node-count’ in
                    cluster-create is ‘node_count’ in cluster-update.</p></div><div class="sect3" id="id-1.7.29.4.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.28.2.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scale</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Scaling a cluster means adding servers to or removing servers from the cluster.
                    Currently, this is done through the ‘cluster-update’ operation by modifying
                    the node-count attribute, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-update mycluster replace node_count=2</pre></div><p>When some nodes are removed, Magnum will attempt to find nodes with no
                    containers to remove.  If some nodes with containers must be removed,
                    Magnum will log a warning message.</p></div><div class="sect3" id="id-1.7.29.4.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.28.2.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Delete</span> <a title="Permalink" class="permalink" href="#id-1.7.29.4.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The ‘cluster-delete’ operation removes the cluster by deleting all resources
                    such as servers, network, storage;  for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-delete mycluster</pre></div><p>The only parameter for the cluster-delete command is the ID or name of the
                    cluster to delete.  Multiple clusters can be specified, separated by a blank
                    space.</p><p>If the operation fails, there may be some remaining resources that
                    have not been deleted yet.  In this case, you can troubleshoot through
                    Heat.  If the templates are deleted manually in Heat, you can delete
                    the cluster in Magnum to clean up the cluster from Magnum database.</p><p>The ‘cluster-delete’ operation can be initiated when another operation is
                    still in progress.</p></div></div></div><div class="sect1" id="id-1.7.30"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.29 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Python Client</span> <a title="Permalink" class="permalink" href="#id-1.7.30">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#python-client</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2" id="id-1.7.30.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.29.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installation</span> <a title="Permalink" class="permalink" href="#id-1.7.30.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#python-client</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Follow the instructions in the OpenStack Installation Guide to enable the
                repositories for your distribution:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/liberty/install-guide-rdo/" target="_blank">RHEL/CentOS/Fedora</a>
              </p></li><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/liberty/install-guide-ubuntu/" target="_blank">Ubuntu/Debian</a>
              </p></li><li class="listitem "><p>
                <a class="link" href="http://docs.openstack.org/liberty/install-guide-obs/" target="_blank">openSUSE/SUSE Linux Enterprise</a>
              </p></li></ul></div><p>Install using distribution packages for RHEL/CentOS/Fedora:</p><div class="verbatim-wrap"><pre class="screen">$ sudo yum install python-magnumclient</pre></div><p>Install using distribution packages for Ubuntu/Debian:</p><div class="verbatim-wrap"><pre class="screen">$ sudo apt-get install python-magnumclient</pre></div><p>Install using distribution packages for OpenSuSE and SuSE Enterprise Linux:</p><div class="verbatim-wrap"><pre class="screen">$ sudo zypper install python-magnumclient</pre></div></div><div class="sect2" id="id-1.7.30.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.29.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Verifying installation</span> <a title="Permalink" class="permalink" href="#id-1.7.30.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#python-client</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Execute the <code class="literal">magnum</code> command with the <code class="literal">–version</code> argument to confirm that the
                client is installed and in the system path:</p><div class="verbatim-wrap"><pre class="screen">$ magnum --version
1.1.0</pre></div><p>Note that the version returned may differ from the above, 1.1.0 was the latest
                available version at the time of writing.</p></div><div class="sect2" id="id-1.7.30.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.29.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the command-line client</span> <a title="Permalink" class="permalink" href="#id-1.7.30.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#python-client</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Refer to the <a class="link" href="http://docs.openstack.org/cli-reference/magnum.html" target="_blank">OpenStack Command-Line Interface Reference</a> for a full list of the
                commands supported by the <code class="literal">magnum</code> command-line client.</p></div></div><div class="sect1" id="id-1.7.31"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.30 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Horizon Interface</span> <a title="Permalink" class="permalink" href="#id-1.7.31">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#horizon-interface</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum provides a Horizon plugin so that users can access the Container
            Infrastructure Management service through the OpenStack browser-based
            graphical UI.  The plugin is available from
            <a class="link" href="https://github.com/openstack/magnum-ui" target="_blank">magnum-ui</a>.  It is not
            installed by default in the standard Horizon service, but you can
            follow the instruction for <a class="link" href="http://docs.openstack.org/developer/horizon/tutorials/plugin.html#installing-your-plugin" target="_blank">installing a Horizon plugin</a>.</p><p>In Horizon, the container infrastructure panel is part of the
            ‘Project’ view and it currently supports the following operations:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>View list of cluster templates</p></li><li class="listitem "><p>View details of a cluster template</p></li><li class="listitem "><p>Create a cluster template</p></li><li class="listitem "><p>Delete a cluster template</p></li><li class="listitem "><p>View list of clusters</p></li><li class="listitem "><p>View details of a cluster</p></li><li class="listitem "><p>Create a cluster</p></li><li class="listitem "><p>Delete a cluster</p></li><li class="listitem "><p>Get the Certificate Authority for a cluster</p></li><li class="listitem "><p>Sign a user key and obtain a signed certificate for accessing the secured
                    COE API endpoint in a cluster.</p></li></ul></div><p>Other operations are not yet supported and the CLI should be used for these.</p></div><div class="sect1" id="id-1.7.32"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.31 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster Drivers</span> <a title="Permalink" class="permalink" href="#id-1.7.32">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-drivers</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A cluster driver is a collection of python code, heat templates, scripts,
            images, and documents for a particular COE on a particular
            distro.  Magnum presents the concept of ClusterTemplates and clusters.  The
            implementation for a particular cluster type is provided by the cluster driver.
            In other words, the cluster driver provisions and manages the infrastructure
            for the COE.  Magnum includes default drivers for the following
            COE and distro pairs:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="12" class="c1" /><col width="15" class="c2" /></colgroup><thead><tr><th>
                  <p>COE</p>
                </th><th>
                  <p>distro</p>
                </th></tr></thead><tbody><tr><td>
                  <p>Kubernetes</p>
                </td><td>
                  <p>Fedora Atomic</p>
                </td></tr><tr><td>
                  <p>Kubernetes</p>
                </td><td>
                  <p>CoreOS</p>
                </td></tr><tr><td>
                  <p>Swarm</p>
                </td><td>
                  <p>Fedora Atomic</p>
                </td></tr><tr><td>
                  <p>Mesos</p>
                </td><td>
                  <p>Ubuntu</p>
                </td></tr></tbody></table></div><p>Magnum is designed to accommodate new cluster drivers to support custom
            COE’s and this section describes how a new cluster driver can be
            constructed and enabled in Magnum.</p><div class="sect2" id="id-1.7.32.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.31.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Directory structure</span> <a title="Permalink" class="permalink" href="#id-1.7.32.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-drivers</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum expects the components to be organized in the following
                directory structure under the directory ‘drivers’:</p><div class="verbatim-wrap"><pre class="screen">COE_Distro/
   image/
   templates/
   api.py
   driver.py
   monitor.py
   scale.py
   template_def.py
   version.py</pre></div><p>The minimum required components are:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.32.5.5.1"><span class="term ">driver.py</span></dt><dd><p>Python code that implements the controller operations for
                            the particular COE.  The driver must implement:
                            Currently supported:
                            <code class="literal">cluster_create</code>, <code class="literal">cluster_update</code>, <code class="literal">cluster_delete</code>.</p></dd><dt id="id-1.7.32.5.5.2"><span class="term ">templates</span></dt><dd><p>A directory of orchestration templates for managing the lifecycle
                            of clusters, including creation, configuration, update, and deletion.
                            Currently only Heat templates are supported, but in the future
                            other orchestration mechanism such as Ansible may be supported.</p></dd><dt id="id-1.7.32.5.5.3"><span class="term ">template_def.py</span></dt><dd><p>Python code that maps the parameters from the ClusterTemplate to the
                            input parameters for the orchestration and invokes
                            the orchestration in the templates directory.</p></dd><dt id="id-1.7.32.5.5.4"><span class="term ">version.py</span></dt><dd><p>Tracks the latest version of the driver in this directory.
                            This is defined by a <code class="literal">version</code> attribute and is represented in the
                            form of <code class="literal">1.0.0</code>. It should also include a <code class="literal">Driver</code> attribute with
                            descriptive name such as <code class="literal">fedora_swarm_atomic</code>.</p></dd></dl></div><p>The remaining components are optional:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.32.5.7.1"><span class="term ">image</span></dt><dd><p>Instructions for obtaining or building an image suitable for the COE.</p></dd><dt id="id-1.7.32.5.7.2"><span class="term ">api.py</span></dt><dd><p>Python code to interface with the COE.</p></dd><dt id="id-1.7.32.5.7.3"><span class="term ">monitor.py</span></dt><dd><p>Python code to monitor the resource utilization of the cluster.</p></dd><dt id="id-1.7.32.5.7.4"><span class="term ">scale.py</span></dt><dd><p>Python code to scale the cluster by adding or removing nodes.</p></dd></dl></div></div><div class="sect2" id="id-1.7.32.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.31.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Sample cluster driver</span> <a title="Permalink" class="permalink" href="#id-1.7.32.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-drivers</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To help developers in creating new COE drivers, a minimal cluster driver
                is provided as an example.  The ‘docker’ cluster driver will simply deploy
                a single VM running Ubuntu with the latest Docker version installed.
                It is not a true cluster, but the simplicity will help to illustrate
                the key concepts.</p><p>
            <span class="emphasis"><em>To be filled in</em></span>
          </p></div><div class="sect2" id="id-1.7.32.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.31.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing a cluster driver</span> <a title="Permalink" class="permalink" href="#id-1.7.32.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-drivers</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
            <span class="emphasis"><em>To be filled in</em></span>
          </p></div></div><div class="sect1" id="id-1.7.33"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.32 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster Type Definition</span> <a title="Permalink" class="permalink" href="#id-1.7.33">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-type-definition</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are three key pieces to a Cluster Type Definition:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Heat Stack template - The HOT file that Magnum will use to generate a
                    cluster using a Heat Stack.</p></li><li class="step "><p>Template definition - Magnum’s interface for interacting with the Heat
                    template.</p></li><li class="step "><p>Definition Entry Point - Used to advertise the available Cluster Types.</p></li></ol></div></div><div class="sect2" id="id-1.7.33.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.32.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Heat Stack Template</span> <a title="Permalink" class="permalink" href="#id-1.7.33.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-type-definition</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The Heat Stack Template is where most of the real work happens. The result of
                the Heat Stack Template should be a full Container Orchestration Environment.</p></div><div class="sect2" id="id-1.7.33.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.32.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Template Definition</span> <a title="Permalink" class="permalink" href="#id-1.7.33.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-type-definition</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Template definitions are a mapping of Magnum object attributes and Heat
                template parameters, along with Magnum consumable template outputs. A
                Cluster Type Definition indicates which Cluster Types it can provide.
                Cluster Types are how Magnum determines which of the enabled Cluster
                Type Definitions it will use for a given cluster.</p></div><div class="sect2" id="id-1.7.33.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.32.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The Definition Entry Point</span> <a title="Permalink" class="permalink" href="#id-1.7.33.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-type-definition</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Entry points are a standard discovery and import mechanism for Python objects.
                Each Template Definition should have an Entry Point in the
                <code class="literal">magnum.template_definitions</code> group. This example exposes it’s Template
                Definition as <code class="literal">example_template = example_template:ExampleTemplate</code> in the
                <code class="literal">magnum.template_definitions</code> group.</p></div><div class="sect2" id="id-1.7.33.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.32.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing Cluster Templates</span> <a title="Permalink" class="permalink" href="#id-1.7.33.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#cluster-type-definition</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Because Cluster Type Definitions are basically Python projects, they can be
                worked with like any other Python project. They can be cloned from version
                control and installed or uploaded to a package index and installed via
                utilities such as pip.</p><p>Enabling a Cluster Type is as simple as adding it’s Entry Point to the
                <code class="literal">enabled_definitions</code> config option in magnum.conf.:</p><div class="verbatim-wrap"><pre class="screen"># Setup python environment and install Magnum

$ virtualenv .venv
$ source .venv/bin/active
(.venv)$ git clone https://github.com/openstack/magnum.git
(.venv)$ cd magnum
(.venv)$ python setup.py install

# List installed templates, notice default templates are enabled

(.venv)$ magnum-template-manage list-templates
Enabled Templates
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
Disabled Templates

# Install example template

(.venv)$ cd contrib/templates/example
(.venv)$ python setup.py install

# List installed templates, notice example template is disabled

(.venv)$ magnum-template-manage list-templates
Enabled Templates
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
Disabled Templates
  example_template: /home/example/.venv/local/lib/python2.7/site-packages/ExampleTemplate-0.1-py2.7.egg/example_template/example.yaml

# Enable example template by setting enabled_definitions in magnum.conf

(.venv)$ sudo mkdir /etc/magnum
(.venv)$ sudo bash -c "cat &gt; /etc/magnum/magnum.conf &lt;&lt; END_CONF
[bay]
enabled_definitions=magnum_vm_atomic_k8s,magnum_vm_coreos_k8s,example_template
END_CONF"

# List installed templates, notice example template is now enabled

(.venv)$ magnum-template-manage list-templates
Enabled Templates
  example_template: /home/example/.venv/local/lib/python2.7/site-packages/ExampleTemplate-0.1-py2.7.egg/example_template/example.yaml
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
Disabled Templates

# Use --details argument to get more details about each template

(.venv)$ magnum-template-manage list-templates --details
Enabled Templates
  example_template: /home/example/.venv/local/lib/python2.7/site-packages/ExampleTemplate-0.1-py2.7.egg/example_template/example.yaml
     Server_Type  OS       CoE
     vm         example  example_coe
  magnum_vm_atomic_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster.yaml
     Server_Type   OS             CoE
     vm        fedora-atomic  kubernetes
  magnum_vm_coreos_k8s: /home/example/.venv/local/lib/python2.7/site-packages/magnum/templates/kubernetes/kubecluster-coreos.yaml
     Server_Type  OS      CoE
     vm         coreos  kubernetes
Disabled Templates</pre></div></div></div><div class="sect1" id="id-1.7.34"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.33 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Heat Stack Templates</span> <a title="Permalink" class="permalink" href="#id-1.7.34">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#heat-stack-templates</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Heat Stack Templates are what Magnum passes to Heat to generate a cluster. For
            each ClusterTemplate resource in Magnum, a Heat stack is created to arrange all
            of the cloud resources needed to support the container orchestration
            environment. These Heat stack templates provide a mapping of Magnum object
            attributes to Heat template parameters, along with Magnum consumable stack
            outputs. Magnum passes the Heat Stack Template to the Heat service to create a
            Heat stack. The result is a full Container Orchestration Environment.</p></div><div class="sect1" id="id-1.7.35"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.34 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Choosing a COE</span> <a title="Permalink" class="permalink" href="#id-1.7.35">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#choosing-a-coe</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum supports a variety of COE options, and allows more to be added over time
            as they gain popularity. As an operator, you may choose to support the full
            variety of options, or you may want to offer a subset of the available choices.
            Given multiple choices, your users can run one or more clusters, and each may
            use a different COE. For example, I might have multiple clusters that use
            Kubernetes, and just one cluster that uses Swarm. All of these clusters can
            run concurrently, even though they use different COE software.</p><p>Choosing which COE to use depends on what tools you want to use to manage your
            containers once you start your app. If you want to use the Docker tools, you
            may want to use the Swarm cluster type. Swarm will spread your containers
            across the various nodes in your cluster automatically. It does not monitor
            the health of your containers, so it can’t restart them for you if they stop.
            It will not automatically scale your app for you (as of Swarm version 1.2.2).
            You may view this as a plus. If you prefer to manage your application yourself,
            you might prefer swarm over the other COE options.</p><p>Kubernetes (as of v1.2) is more sophisticated than Swarm (as of v1.2.2). It
            offers an attractive YAML file description of a pod, which is a grouping of
            containers that run together as part of a distributed application. This file
            format allows you to model your application deployment using a declarative
            style. It has support for auto scaling and fault recovery, as well as features
            that allow for sophisticated software deployments, including canary deploys
            and blue/green deploys. Kubernetes is very popular, especially for web
            applications.</p><p>Apache Mesos is a COE that has been around longer than Kubernetes or Swarm. It
            allows for a variety of different frameworks to be used along with it,
            including Marathon, Aurora, Chronos, Hadoop, and <a class="link" href="http://mesos.apache.org/documentation/latest/frameworks/" target="_blank">a number of others.</a></p><p>The Apache Mesos framework design can be used to run alternate COE software
            directly on Mesos. Although this approach is not widely used yet, it may soon
            be possible to run Mesos with Kubernetes and Swarm as frameworks, allowing
            you to share the resources of a cluster between multiple different COEs. Until
            this option matures, we encourage Magnum users to create multiple clusters, and
            use the COE in each cluster that best fits the anticipated workload.</p><p>Finding the right COE for your workload is up to you, but Magnum offers you a
            choice to select among the prevailing leading options. Once you decide, see
            the next sections for examples of how to create a cluster with your desired
            COE.</p></div><div class="sect1" id="id-1.7.36"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.35 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Native Clients</span> <a title="Permalink" class="permalink" href="#id-1.7.36">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#native-clients</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum preserves the native user experience with a COE and does not
            provide a separate API or client.  This means you will need to use the
            native client for the particular cluster type to interface with the
            clusters.  In the typical case, there are two clients to consider:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.36.3.1"><span class="term ">COE level</span></dt><dd><p>This is the orchestration or management level such as Kubernetes,
                        Swarm, Mesos and its frameworks.</p></dd><dt id="id-1.7.36.3.2"><span class="term ">Container level</span></dt><dd><p>This is the low level container operation.  Currently it is
                        Docker for all clusters.</p></dd></dl></div><p>The clients can be CLI and/or browser-based.  You will need to refer
            to the documentation for the specific native client and appropriate
            version for details, but following are some pointers for reference.</p><p>Kubernetes CLI is the tool ‘kubectl’, which can be simply copied from
            a node in the cluster or downloaded from the Kubernetes release.  For
            instance, if the cluster is running Kubernetes release 1.2.0, the
            binary for ‘kubectl’ can be downloaded as and set up locally as
            follows:</p><div class="verbatim-wrap"><pre class="screen">curl -O https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/kubectl</pre></div><p>Kubernetes also provides a browser UI. If the cluster has the
            Kubernetes Dashboard running; it can be accessed using:</p><div class="verbatim-wrap"><pre class="screen">eval $(magnum cluster-config &lt;cluster-name&gt;)
kubectl proxy

The browser can be accessed at http://localhost:8001/ui</pre></div><p>For Swarm, the main CLI is ‘docker’, along with associated tools
            such as ‘docker-compose’, etc.  Specific version of the binaries can
            be obtained from the <a class="link" href="https://docs.docker.com/engine/installation/binaries/" target="_blank">Docker Engine installation</a>.</p><p>Mesos cluster uses the Marathon framework.</p><p>Depending on the client requirement, you may need to use a version of
            the client that matches the version in the cluster.  To determine the
            version of the COE and container, use the command ‘cluster-show’ and
            look for the attribute <span class="emphasis"><em>coe_version</em></span> and <span class="emphasis"><em>container_version</em></span>:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-show k8s-cluster
+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | 04952c60-a338-437f-a7e7-d016d1d00e65                       |
| stack_id           | b7bf72ce-b08e-4768-8201-e63a99346898                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2016-07-25T23:14:06+00:00                                  |
| updated_at         | 2016-07-25T23:14:10+00:00                                  |
| create_timeout     | 60                                                         |
| coe_version        | v1.2.0                                                     |
| api_address        | https://192.168.19.86:6443                                 |
| cluster_template_id| da2825a0-6d09-4208-b39e-b2db666f1118                       |
| master_addresses   | ['192.168.19.87']                                          |
| node_count         | 1                                                          |
| node_addresses     | ['192.168.19.88']                                          |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | https://discovery.etcd.io/3b7fb09733429d16679484673ba3bfd5 |
| name               | k8s-cluster                                                |
+--------------------+------------------------------------------------------------+</pre></div></div><div class="sect1" id="id-1.7.37"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.36 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes</span> <a title="Permalink" class="permalink" href="#id-1.7.37">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#kubernetes</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Kubernetes uses a range of terminology that we refer to in this guide. We
            define these common terms for your reference:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.37.3.1"><span class="term ">Pod</span></dt><dd><p>When using the Kubernetes container orchestration engine, a pod is the
                        smallest deployable unit that can be created and managed. A pod is a
                        co-located group of application containers that run with a shared context.
                        When using Magnum, pods are created and managed within clusters. Refer to the
                        <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/pods.html" target="_blank">pods section</a> in the <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/" target="_blank">Kubernetes
                            User Guide</a> for more information.</p></dd><dt id="id-1.7.37.3.2"><span class="term ">Replication controller</span></dt><dd><p>A replication controller is used to ensure that at any given time a certain
                        number of replicas of a pod are running. Pods are automatically created and
                        deleted by the replication controller as necessary based on a template to
                        ensure that the defined number of replicas exist. Refer to the <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/replication-controller.html" target="_blank">replication
                            controller section</a> in
                        the <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/" target="_blank">Kubernetes User Guide</a> for more information.</p></dd><dt id="id-1.7.37.3.3"><span class="term ">Service</span></dt><dd><p>A service is an additional layer of abstraction provided by the Kubernetes
                        container orchestration engine which defines a logical set of pods and a
                        policy for accessing them. This is useful because pods are created and
                        deleted by a replication controller, for example, other pods needing to
                        discover them can do so via the service abstraction. Refer to the
                        <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/services.html" target="_blank">services section</a> in the
                        <a class="link" href="http://kubernetes.io/v1.0/docs/user-guide/" target="_blank">Kubernetes User Guide</a> for more information.</p></dd></dl></div><p>When Magnum deploys a Kubernetes cluster, it uses parameters defined in the
            ClusterTemplate and specified on the cluster-create command, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create k8s-cluster-template \
                           --image fedora-atomic-latest \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 5 \
                           --network-driver flannel \
                           --coe kubernetes

magnum cluster-create k8s-cluster \
                      --cluster-template k8s-cluster-template \
                      --master-count 3 \
                      --node-count 8</pre></div><p>Following are further details relevant to a Kubernetes cluster:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.37.7.1"><span class="term ">Number of masters (master-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as master in the cluster.  Having more than one will provide high
                        availability.  The masters will be in a load balancer pool and the
                        virtual IP address (VIP) of the load balancer will serve as the
                        Kubernetes API endpoint.  For external access, a floating IP
                        associated with this VIP is available and this is the endpoint
                        shown for Kubernetes in the ‘cluster-show’ command.</p></dd><dt id="id-1.7.37.7.2"><span class="term ">Number of nodes (node-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as node in the cluster to host the users’ pods.  The nodes are registered
                        in Kubernetes using the Nova instance name.</p></dd><dt id="id-1.7.37.7.3"><span class="term ">Network driver (network-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the network driver.
                        The supported and default network driver is ‘flannel’, an overlay
                        network providing a flat network for all pods.</p></dd><dt id="id-1.7.37.7.4"><span class="term ">Volume driver (volume-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the volume driver.  The supported
                        volume driver is ‘cinder’, allowing Cinder volumes to be mounted in
                        containers for use as persistent storage.  Data written to these volumes
                        will persist after the container exits and can be accessed again from other
                        containers, while data written to the union file system hosting the container
                        will be deleted.</p></dd><dt id="id-1.7.37.7.5"><span class="term ">Storage driver (docker-storage-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the Docker storage driver.  The
                        supported storage drivers are ‘devicemapper’ and ‘overlay’, with
                        ‘devicemapper’ being the default.</p></dd><dt id="id-1.7.37.7.6"><span class="term ">Image (image)</span></dt><dd><p>Specified in the ClusterTemplate to indicate the image to boot the servers.
                        The image binary is loaded in Glance with the attribute
                        ‘os_distro = fedora-atomic’.
                        Current supported images are Fedora Atomic (download from <a class="link" href="https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images" target="_blank">Fedora</a> )
                        and CoreOS (download from <a class="link" href="http://beta.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2" target="_blank">CoreOS</a> )</p></dd><dt id="id-1.7.37.7.7"><span class="term ">TLS (tls-disabled)</span></dt><dd><p>Transport Layer Security is enabled by default, so you need a key and
                        signed certificate to access the Kubernetes API and CLI.  Magnum
                        handles its own key and certificate when interfacing with the
                        Kubernetes cluster.  In development mode, TLS can be disabled.  Refer to
                        the ‘Transport Layer Security’_ section for more details.</p></dd><dt id="id-1.7.37.7.8"><span class="term ">What runs on the servers</span></dt><dd><p>The servers for Kubernetes master host containers in the ‘kube-system’
                        name space to run the Kubernetes proxy, scheduler and controller manager.
                        The masters will not host users’ pods.  Kubernetes API server, docker
                        daemon, etcd and flannel run as systemd services.  The servers for
                        Kubernetes node also host a container in the ‘kube-system’ name space
                        to run the Kubernetes proxy, while Kubernetes kubelet, docker daemon
                        and flannel run as systemd services.</p></dd><dt id="id-1.7.37.7.9"><span class="term ">Log into the servers</span></dt><dd><p>You can log into the master servers using the login ‘fedora’ and the
                        keypair specified in the ClusterTemplate.</p></dd></dl></div><p>In addition to the common attributes in the ClusterTemplate, you can specify
            the following attributes that are specific to Kubernetes by using the
            labels attribute.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.37.9.1"><span class="term "></span></dt><dd><p>This label corresponds to Kubernetes parameter for the API server ‘–admission-control’.
                        For more details, refer to the <a class="link" href="https://kubernetes.io/docs/admin/admission-controllers//" target="_blank">Admission Controllers</a>.
                        The default value corresponds to the one recommended in this doc
                        for our current Kubernetes version.</p></dd><dt id="id-1.7.37.9.2"><span class="term "></span></dt><dd><p>This label sets the size of a volume holding the etcd storage data.
                        The default value is 0, meaning the etcd data is not persisted (no volume).</p></dd><dt id="id-1.7.37.9.3"><span class="term "></span></dt><dd><p>This label allows users to select <a class="link" href="https://hub.docker.com/r/openstackmagnum/kubernetes-apiserver/tags/" target="_blank">a specific Kubernetes release,
                            based on its container tag</a>.
                        If unset, the current Magnum version’s default Kubernetes release is
                        installed.</p></dd><dt id="id-1.7.37.9.4"><span class="term "></span></dt><dd><p>This label triggers the deployment of the kubernetes dashboard.
                        The default value is 1, meaning it will be enabled.</p></dd></dl></div><div class="sect2" id="id-1.7.37.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.36.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">External load balancer for services</span> <a title="Permalink" class="permalink" href="#id-1.7.37.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#kubernetes</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>All Kubernetes pods and services created in the cluster are assigned IP
                addresses on a private container network so they can access each other
                and the external internet.  However, these IP addresses are not
                accessible from an external network.</p><p>To publish a service endpoint externally so that the service can be
                accessed from the external network, Kubernetes provides the external
                load balancer feature.  This is done by simply specifying in the
                service manifest the attribute “type: LoadBalancer”.  Magnum enables
                and configures the Kubernetes plugin for OpenStack so that it can
                interface with Neutron and manage the necessary networking resources.</p><p>When the service is created, Kubernetes will add an external load
                balancer in front of the service so that the service will have an
                external IP address in addition to the internal IP address on the
                container network.  The service endpoint can then be accessed with
                this external IP address.  Kubernetes handles all the life cycle
                operations when pods are modified behind the service and when the
                service is deleted.</p><p>Refer to the document <a class="link" href="https://github.com/openstack/magnum/blob/master/doc/source/dev/kubernetes-load-balancer.rst" target="_blank">Kubernetes external load balancer</a>
                for more details.</p></div></div><div class="sect1" id="id-1.7.38"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.37 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swarm</span> <a title="Permalink" class="permalink" href="#id-1.7.38">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#swarm</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A Swarm cluster is a pool of servers running Docker daemon that is
            managed as a single Docker host.  One or more Swarm managers accepts
            the standard Docker API and manage this pool of servers.
            Magnum deploys a Swarm cluster using parameters defined in
            the ClusterTemplate and specified on the ‘cluster-create’ command, for
            example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create swarm-cluster-template \
                           --image fedora-atomic-latest \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 5 \
                           --coe swarm

magnum cluster-create swarm-cluster \
                  --cluster-template swarm-cluster-template \
                  --master-count 3 \
                  --node-count 8</pre></div><p>Following are further details relevant to Swarm:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.38.5.1"><span class="term ">What runs on the servers</span></dt><dd><p>There are two types of servers in the Swarm cluster: managers and nodes.
                        The Docker daemon runs on all servers.  On the servers for manager,
                        the Swarm manager is run as a Docker container on port 2376 and this
                        is initiated by the systemd service swarm-manager.  Etcd is also run
                        on the manager servers for discovery of the node servers in the cluster.
                        On the servers for node, the Swarm agent is run as a Docker
                        container on port 2375 and this is initiated by the systemd service
                        swarm-agent.  On start up, the agents will register themselves in
                        etcd and the managers will discover the new node to manage.</p></dd><dt id="id-1.7.38.5.2"><span class="term ">Number of managers (master-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as managers in the cluster.  Having more than one will provide high
                        availability.  The managers will be in a load balancer pool and the
                        load balancer virtual IP address (VIP) will serve as the Swarm API
                        endpoint.  A floating IP associated with the load balancer VIP will
                        serve as the external Swarm API endpoint.  The managers accept
                        the standard Docker API and perform the corresponding operation on the
                        servers in the pool.  For instance, when a new container is created,
                        the managers will select one of the servers based on some strategy
                        and schedule the containers there.</p></dd><dt id="id-1.7.38.5.3"><span class="term ">Number of nodes (node-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers will
                        run as nodes in the cluster to host your Docker containers.  These servers
                        will register themselves in etcd for discovery by the managers, and
                        interact with the managers.  Docker daemon is run locally to host
                        containers from users.</p></dd><dt id="id-1.7.38.5.4"><span class="term ">Network driver (network-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the network driver.  The supported
                        drivers are ‘docker’ and ‘flannel’, with ‘docker’ as the default.
                        With the ‘docker’ driver, containers are connected to the ‘docker0’
                        bridge on each node and are assigned local IP address.  With the
                        ‘flannel’ driver, containers are connected to a flat overlay network
                        and are assigned IP address by Flannel.</p></dd><dt id="id-1.7.38.5.5"><span class="term ">Volume driver (volume-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the volume driver to provide
                        persistent storage for containers.  The supported volume driver is
                        ‘rexray’.  The default is no volume driver.  When ‘rexray’ or other
                        volume driver is deployed, you can use the Docker ‘volume’ command to
                        create, mount, unmount, delete volumes in containers.  Cinder block
                        storage is used as the backend to support this feature.</p></dd><dt id="id-1.7.38.5.6"><span class="term ">Storage driver (docker-storage-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the Docker storage driver.  The
                        supported storage driver are ‘devicemapper’ and ‘overlay’, with
                        ‘devicemapper’ being the default.</p></dd><dt id="id-1.7.38.5.7"><span class="term ">Image (image)</span></dt><dd><p>Specified in the ClusterTemplate to indicate the image to boot the servers
                        for the Swarm manager and node.
                        The image binary is loaded in Glance with the attribute
                        ‘os_distro = fedora-atomic’.
                        Current supported image is Fedora Atomic (download from <a class="link" href="https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images" target="_blank">Fedora</a> )</p></dd><dt id="id-1.7.38.5.8"><span class="term ">TLS (tls-disabled)</span></dt><dd><p>Transport Layer Security is enabled by default to secure the Swarm API for
                        access by both the users and Magnum.  You will need a key and a
                        signed certificate to access the Swarm API and CLI.  Magnum
                        handles its own key and certificate when interfacing with the
                        Swarm cluster.  In development mode, TLS can be disabled.  Refer to
                        the ‘Transport Layer Security’_ section for details on how to create your
                        key and have Magnum sign your certificate.</p></dd><dt id="id-1.7.38.5.9"><span class="term ">Log into the servers</span></dt><dd><p>You can log into the manager and node servers with the account ‘fedora’ and
                        the keypair specified in the ClusterTemplate.</p></dd></dl></div><p>In addition to the common attributes in the ClusterTemplate, you can specify
            the following attributes that are specific to Swarm by using the
            labels attribute.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.38.7.1"><span class="term "></span></dt><dd><p>This label corresponds to Swarm parameter for master ‘–strategy’.
                        For more details, refer to the <a class="link" href="https://docs.docker.com/swarm/scheduler/strategy/" target="_blank">Swarm Strategy</a>.
                        Valid values for this label are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>spread</p></li><li class="listitem "><p>binpack</p></li><li class="listitem "><p>random</p></li></ul></div></dd></dl></div></div><div class="sect1" id="id-1.7.39"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.38 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Mesos</span> <a title="Permalink" class="permalink" href="#id-1.7.39">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#mesos</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>A Mesos cluster consists of a pool of servers running as Mesos slaves,
            managed by a set of servers running as Mesos masters.  Mesos manages
            the resources from the slaves but does not itself deploy containers.
            Instead, one of more Mesos frameworks running on the Mesos cluster would
            accept user requests on their own endpoint, using their particular
            API.  These frameworks would then negotiate the resources with Mesos
            and the containers are deployed on the servers where the resources are
            offered.</p><p>Magnum deploys a Mesos cluster using parameters defined in the ClusterTemplate
            and specified on the ‘cluster-create’ command, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create mesos-cluster-template \
                       --image ubuntu-mesos \
                       --keypair testkey \
                       --external-network public \
                       --dns-nameserver 8.8.8.8 \
                       --flavor m1.small \
                       --coe mesos

magnum cluster-create mesos-cluster \
                  --cluster-template mesos-cluster-template \
                  --master-count 3 \
                  --node-count 8</pre></div><p>Following are further details relevant to Mesos:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.39.6.1"><span class="term ">What runs on the servers</span></dt><dd><p>There are two types of servers in the Mesos cluster: masters and slaves.
                        The Docker daemon runs on all servers.  On the servers for master,
                        the Mesos master is run as a process on port 5050 and this is
                        initiated by the upstart service ‘mesos-master’.  Zookeeper is also
                        run on the master servers, initiated by the upstart service
                        ‘zookeeper’.  Zookeeper is used by the master servers for electing
                        the leader among the masters, and by the slave servers and
                        frameworks to determine the current leader.  The framework Marathon
                        is run as a process on port 8080 on the master servers, initiated by
                        the upstart service ‘marathon’.  On the servers for slave, the Mesos
                        slave is run as a process initiated by the upstart service
                        ‘mesos-slave’.</p></dd><dt id="id-1.7.39.6.2"><span class="term ">Number of master (master-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers
                        will run as masters in the cluster.  Having more than one will provide
                        high availability.  If the load balancer option is specified, the
                        masters will be in a load balancer pool and the load balancer
                        virtual IP address (VIP) will serve as the Mesos API endpoint.  A
                        floating IP associated with the load balancer VIP will serve as the
                        external Mesos API endpoint.</p></dd><dt id="id-1.7.39.6.3"><span class="term ">Number of agents (node-count)</span></dt><dd><p>Specified in the cluster-create command to indicate how many servers
                        will run as Mesos slave in the cluster.  Docker daemon is run locally to
                        host containers from users.  The slaves report their available
                        resources to the master and accept request from the master to deploy
                        tasks from the frameworks.  In this case, the tasks will be to
                        run Docker containers.</p></dd><dt id="id-1.7.39.6.4"><span class="term ">Network driver (network-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the network driver.  Currently
                        ‘docker’ is the only supported driver: containers are connected to
                        the ‘docker0’ bridge on each node and are assigned local IP address.</p></dd><dt id="id-1.7.39.6.5"><span class="term ">Volume driver (volume-driver)</span></dt><dd><p>Specified in the ClusterTemplate to select the volume driver to provide
                        persistent storage for containers.  The supported volume driver is
                        ‘rexray’.  The default is no volume driver.  When ‘rexray’ or other
                        volume driver is deployed, you can use the Docker ‘volume’ command to
                        create, mount, unmount, delete volumes in containers.  Cinder block
                        storage is used as the backend to support this feature.</p></dd><dt id="id-1.7.39.6.6"><span class="term ">Storage driver (docker-storage-driver)</span></dt><dd><p>This is currently not supported for Mesos.</p></dd></dl></div><p>Image (image)</p><p>Specified in the ClusterTemplate to indicate the image to boot the servers
                for the Mesos master and slave.  The image binary is loaded in
                Glance with the attribute ‘os_distro = ubuntu’.  You can download
                the <a class="link" href="https://fedorapeople.org/groups/magnum/ubuntu-mesos-latest.qcow2" target="_blank">ready-built
		image</a>.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.39.9.1"><span class="term ">TLS (tls-disabled)</span></dt><dd><p>Transport Layer Security is currently not implemented yet for Mesos.</p></dd><dt id="id-1.7.39.9.2"><span class="term ">Log into the servers</span></dt><dd><p>You can log into the manager and node servers with the account
                        ‘ubuntu’ and the keypair specified in the ClusterTemplate.</p></dd></dl></div><p>In addition to the common attributes in the baymodel, you can specify
            the following attributes that are specific to Mesos by using the
            labels attribute.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.39.11.1"><span class="term "></span></dt><dd><p>When the volume driver ‘rexray’ is used, you can mount a data volume
                        backed by Cinder to a host to be accessed by a container.  In this
                        case, the label ‘rexray_preempt’ can optionally be set to True or
                        False to enable any host to take control of the volume regardless of
                        whether other hosts are using the volume.  This will in effect
                        unmount the volume from the current host and remount it on the new
                        host.  If this label is set to false, then rexray will ensure data
                        safety for locking the volume before remounting.  The default value
                        is False.</p></dd><dt id="id-1.7.39.11.2"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter for slave
                        ‘–isolation’.  The isolators are needed to provide proper isolation
                        according to the runtime configurations specified in the container
                        image.  For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a>
                        and the <a class="link" href="http://mesos.apache.org/documentation/latest/container-image/" target="_blank">Mesos container image support</a>.
                        Valid values for this label are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>filesystem/posix</p></li><li class="listitem "><p>filesystem/linux</p></li><li class="listitem "><p>filesystem/shared</p></li><li class="listitem "><p>posix/cpu</p></li><li class="listitem "><p>posix/mem</p></li><li class="listitem "><p>posix/disk</p></li><li class="listitem "><p>cgroups/cpu</p></li><li class="listitem "><p>cgroups/mem</p></li><li class="listitem "><p>docker/runtime</p></li><li class="listitem "><p>namespaces/pid</p></li></ul></div></dd><dt id="id-1.7.39.11.3"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter for agent
                        ‘–image_providers’, which tells Mesos containerizer what
                        types of container images are allowed.
                        For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a> and
                        the <a class="link" href="http://mesos.apache.org/documentation/latest/container-image/" target="_blank">Mesos container image support</a>.
                        Valid values are:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>appc</p></li><li class="listitem "><p>docker</p></li><li class="listitem "><p>appc,docker</p></li></ul></div></dd><dt id="id-1.7.39.11.4"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter ‘–work_dir’ for slave.
                        For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a>.
                        Valid value is a directory path to use as the work directory for
                        the framework, for example:</p><div class="verbatim-wrap"><pre class="screen">mesos_slave_work_dir=/tmp/mesos</pre></div></dd><dt id="id-1.7.39.11.5"><span class="term "></span></dt><dd><p>This label corresponds to the Mesos parameter for slave
                        ‘–executor_environment_variables’, which passes additional
                        environment variables to the executor and subsequent tasks.
                        For more details, refer to the <a class="link" href="http://mesos.apache.org/documentation/latest/configuration/" target="_blank">Mesos configuration</a>.
                        Valid value is the name of a JSON file, for example:</p><div class="verbatim-wrap"><pre class="screen">mesos_slave_executor_env_variables=/home/ubuntu/test.json</pre></div><p>The JSON file should contain environment variables, for example:</p><div class="verbatim-wrap"><pre class="screen">{
   "PATH": "/bin:/usr/bin",
   "LD_LIBRARY_PATH": "/usr/local/lib"
}</pre></div><p>By default the executor will inherit the slave’s environment
                        variables.</p></dd></dl></div><div class="sect2" id="id-1.7.39.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.38.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Building Mesos image</span> <a title="Permalink" class="permalink" href="#id-1.7.39.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#mesos</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The boot image for Mesos cluster is an Ubuntu 14.04 base image with the
                following middleware pre-installed:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
                <code class="literal">docker</code>
              </p></li><li class="listitem "><p>
                <code class="literal">zookeeper</code>
              </p></li><li class="listitem "><p>
                <code class="literal">mesos</code>
              </p></li><li class="listitem "><p>
                <code class="literal">marathon</code>
              </p></li></ul></div><p>The cluster driver provides two ways to create this image, as follows.</p><div class="sect3" id="id-1.7.39.12.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.38.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Diskimage-builder</span> <a title="Permalink" class="permalink" href="#id-1.7.39.12.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#mesos</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To run the <a class="link" href="http://docs.openstack.org/developer/diskimage-builder" target="_blank">diskimage-builder</a> tool
                    manually, use the provided <a class="link" href="http://git.openstack.org/cgit/openstack/magnum/tree/magnum/drivers/mesos_ubuntu_v1/image/mesos/" target="_blank">elements</a>.
                    Following are the typical steps to use the diskimage-builder tool on
                    an Ubuntu server:</p><div class="verbatim-wrap"><pre class="screen">$ sudo apt-get update
$ sudo apt-get install git qemu-utils python-pip
$ sudo pip install diskimage-builder

$ git clone https://git.openstack.org/openstack/magnum
$ git clone https://git.openstack.org/openstack/dib-utils.git
$ git clone https://git.openstack.org/openstack/tripleo-image-elements.git
$ git clone https://git.openstack.org/openstack/heat-templates.git
$ export PATH="${PWD}/dib-utils/bin:$PATH"
$ export ELEMENTS_PATH=tripleo-image-elements/elements:heat-templates/hot/software-config/elements:magnum/magnum/drivers/mesos_ubuntu_v1/image/mesos
$ export DIB_RELEASE=trusty

$ disk-image-create ubuntu vm docker mesos \
    os-collect-config os-refresh-config os-apply-config \
    heat-config heat-config-script \
    -o ubuntu-mesos.qcow2</pre></div></div><div class="sect3" id="id-1.7.39.12.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.38.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Dockerfile</span> <a title="Permalink" class="permalink" href="#id-1.7.39.12.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#mesos</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To build the image as above but within a Docker container, use the
                    provided <a class="link" href="http://git.openstack.org/cgit/openstack/magnum/tree/magnum/drivers/mesos_ubuntu_v1/image/Dockerfile" target="_blank">Dockerfile</a>.
                    The output image will be saved as ‘/tmp/ubuntu-mesos.qcow2’.
                    Following are the typical steps to run a Docker container to build the image:</p><div class="verbatim-wrap"><pre class="screen">$ git clone https://git.openstack.org/openstack/magnum
$ cd magnum/magnum/drivers/mesos_ubuntu_v1/image
$ sudo docker build -t magnum/mesos-builder .
$ sudo docker run -v /tmp:/output --rm -ti --privileged magnum/mesos-builder
...
Image file /output/ubuntu-mesos.qcow2 created...</pre></div></div></div><div class="sect2" id="id-1.7.39.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.38.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Marathon</span> <a title="Permalink" class="permalink" href="#id-1.7.39.13">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#mesos</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Marathon is a Mesos framework for long running applications.  Docker
                containers can be deployed via Marathon’s REST API.  To get the
                endpoint for Marathon, run the cluster-show command and look for the
                property ‘api_address’.  Marathon’s endpoint is port 8080 on this IP
                address, so the web console can be accessed at:</p><div class="verbatim-wrap"><pre class="screen">http://&lt;api_address&gt;:8080/</pre></div><p>Refer to Marathon documentation for details on running applications.
                For example, you can ‘post’ a JSON app description to
                <code class="literal">http://&lt;api_address&gt;:8080/apps</code> to deploy a Docker container:</p><div class="verbatim-wrap"><pre class="screen">$ cat &gt; app.json &lt;&lt; END
{
  "container": {
    "type": "DOCKER",
    "docker": {
      "image": "libmesos/ubuntu"
    }
  },
  "id": "ubuntu",
  "instances": 1,
  "cpus": 0.5,
  "mem": 512,
  "uris": [],
  "cmd": "while sleep 10; do date -u +%T; done"
}
END
$ API_ADDRESS=$(magnum cluster-show mesos-cluster | awk '/ api_address /{print $4}')
$ curl -X POST -H "Content-Type: application/json" \
    http://${API_ADDRESS}:8080/v2/apps -d@app.json</pre></div></div></div><div class="sect1" id="id-1.7.40"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.39 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Transport Layer Security</span> <a title="Permalink" class="permalink" href="#id-1.7.40">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum uses TLS to secure communication between a cluster’s services and
            the outside world.  TLS is a complex subject, and many guides on it
            exist already.  This guide will not attempt to fully describe TLS, but
            instead will only cover the necessary steps to get a client set up to
            talk to a cluster with TLS. A more in-depth guide on TLS can be found in
            the <a class="link" href="https://www.feistyduck.com/books/openssl-cookbook/" target="_blank">OpenSSL Cookbook</a> by Ivan Ristić.</p><p>TLS is employed at 3 points in a cluster:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>By Magnum to communicate with the cluster API endpoint</p></li><li class="step "><p>By the cluster worker nodes to communicate with the master nodes</p></li><li class="step "><p>By the end-user when they use the native client libraries to
                    interact with the cluster.  This applies to both a CLI or a program
                    that uses a client for the particular cluster.  Each client needs a
                    valid certificate to authenticate and communicate with a cluster.</p></li></ol></div></div><p>The first two cases are implemented internally by Magnum and are not
            exposed to the users, while the last case involves the users and is
            described in more details below.</p><div class="sect2" id="id-1.7.40.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.39.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying a secure cluster</span> <a title="Permalink" class="permalink" href="#id-1.7.40.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Current TLS support is summarized below:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="12" class="c1" /><col width="13" class="c2" /></colgroup><thead><tr><th>
                    <p>COE</p>
                  </th><th>
                    <p>TLS support</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Kubernetes</p>
                  </td><td>
                    <p>yes</p>
                  </td></tr><tr><td>
                    <p>Swarm</p>
                  </td><td>
                    <p>yes</p>
                  </td></tr><tr><td>
                    <p>Mesos</p>
                  </td><td>
                    <p>no</p>
                  </td></tr></tbody></table></div><p>For cluster type with TLS support, e.g. Kubernetes and Swarm, TLS is
                enabled by default.  To disable TLS in Magnum, you can specify the
                parameter ‘–tls-disabled’ in the ClusterTemplate.  Please note it is not
                recommended to disable TLS due to security reasons.</p><p>In the following example, Kubernetes is used to illustrate a secure
                cluster, but the steps are similar for other cluster types that have TLS
                support.</p><p>First, create a ClusterTemplate; by default TLS is enabled in
                Magnum, therefore it does not need to be specified via a parameter:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create secure-kubernetes \
                           --keypair default \
                           --external-network public \
                           --image fedora-atomic-latest \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 3 \
                           --coe kubernetes \
                           --network-driver flannel

+-----------------------+--------------------------------------+
| Property              | Value                                |
+-----------------------+--------------------------------------+
| insecure_registry     | None                                 |
| http_proxy            | None                                 |
| updated_at            | None                                 |
| master_flavor_id      | None                                 |
| uuid                  | 5519b24a-621c-413c-832f-c30424528b31 |
| no_proxy              | None                                 |
| https_proxy           | None                                 |
| tls_disabled          | False                                |
| keypair_id            | time4funkey                          |
| public                | False                                |
| labels                | {}                                   |
| docker_volume_size    | 5                                    |
| server_type           | vm                                   |
| external_network_id   | public                               |
| cluster_distro        | fedora-atomic                        |
| image_id              | fedora-atomic-latest                 |
| volume_driver         | None                                 |
| registry_enabled      | False                                |
| docker_storage_driver | devicemapper                         |
| apiserver_port        | None                                 |
| name                  | secure-kubernetes                    |
| created_at            | 2016-07-25T23:09:50+00:00            |
| network_driver        | flannel                              |
| fixed_network         | None                                 |
| coe                   | kubernetes                           |
| flavor_id             | m1.small                             |
| dns_nameserver        | 8.8.8.8                              |
+-----------------------+--------------------------------------+</pre></div><p>Now create a cluster. Use the ClusterTemplate name as a template for cluster
                creation:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create secure-k8s-cluster \
                      --cluster-template secure-kubernetes \
                      --node-count 1

+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_IN_PROGRESS                                         |
| uuid               | 3968ffd5-678d-4555-9737-35f191340fda                       |
| stack_id           | c96b66dd-2109-4ae2-b510-b3428f1e8761                       |
| status_reason      | None                                                       |
| created_at         | 2016-07-25T23:14:06+00:00                                  |
| updated_at         | None                                                       |
| create_timeout     | 0                                                          |
| api_address        | None                                                       |
| coe_version        | -                                                          |
| cluster_template_id| 5519b24a-621c-413c-832f-c30424528b31                       |
| master_addresses   | None                                                       |
| node_count         | 1                                                          |
| node_addresses     | None                                                       |
| master_count       | 1                                                          |
| container_version  | -                                                          |
| discovery_url      | https://discovery.etcd.io/ba52a8178e7364d43a323ee4387cf28e |
| name               | secure-k8s-cluster                                          |
+--------------------+------------------------------------------------------------+</pre></div><p>Now run cluster-show command to get the details of the cluster and verify that
                the api_address is ‘https’:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-show secure-k8scluster
+--------------------+------------------------------------------------------------+
| Property           | Value                                                      |
+--------------------+------------------------------------------------------------+
| status             | CREATE_COMPLETE                                            |
| uuid               | 04952c60-a338-437f-a7e7-d016d1d00e65                       |
| stack_id           | b7bf72ce-b08e-4768-8201-e63a99346898                       |
| status_reason      | Stack CREATE completed successfully                        |
| created_at         | 2016-07-25T23:14:06+00:00                                  |
| updated_at         | 2016-07-25T23:14:10+00:00                                  |
| create_timeout     | 60                                                         |
| coe_version        | v1.2.0                                                     |
| api_address        | https://192.168.19.86:6443                                 |
| cluster_template_id| da2825a0-6d09-4208-b39e-b2db666f1118                       |
| master_addresses   | ['192.168.19.87']                                          |
| node_count         | 1                                                          |
| node_addresses     | ['192.168.19.88']                                          |
| master_count       | 1                                                          |
| container_version  | 1.9.1                                                      |
| discovery_url      | https://discovery.etcd.io/3b7fb09733429d16679484673ba3bfd5 |
| name               | secure-k8s-cluster                                          |
+--------------------+------------------------------------------------------------+</pre></div><p>You can see the api_address contains https in the URL, showing that
                the Kubernetes services are configured securely with SSL certificates
                and now any communication to kube-apiserver will be over https.</p></div><div class="sect2" id="id-1.7.40.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.39.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Interfacing with a secure cluster</span> <a title="Permalink" class="permalink" href="#id-1.7.40.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>To communicate with the API endpoint of a secure cluster, you will need so
                supply 3 SSL artifacts:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Your client key</p></li><li class="step "><p>A certificate for your client key that has been signed by a
                        Certificate Authority (CA)</p></li><li class="step "><p>The certificate of the CA</p></li></ol></div></div><p>There are two ways to obtain these 3 artifacts.</p><div class="sect3" id="id-1.7.40.7.5"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.39.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Automated</span> <a title="Permalink" class="permalink" href="#id-1.7.40.7.5">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum provides the command ‘cluster-config’ to help the user in setting
                    up the environment and artifacts for TLS, for example:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-config swarm-cluster --dir myclusterconfig</pre></div><p>This will display the necessary environment variables, which you
                    can add to your environment:</p><div class="verbatim-wrap"><pre class="screen">export DOCKER_HOST=tcp://172.24.4.5:2376
export DOCKER_CERT_PATH=myclusterconfig
export DOCKER_TLS_VERIFY=True</pre></div><p>And the artifacts are placed in the directory specified:</p><div class="verbatim-wrap"><pre class="screen">ca.pem
cert.pem
key.pem</pre></div><p>You can now use the native client to interact with the COE.
                    The variables and artifacts are unique to the cluster.</p><p>The parameters for ‘bay-config’ are as follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.40.7.5.10.1"><span class="term ">–dir &lt;dirname&gt;</span></dt><dd><p>Directory to save the certificate and config files.</p></dd></dl></div><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.40.7.5.11.1"><span class="term ">
                  <code class="option">--force</code>
                </span></dt><dd><p>Overwrite existing files in the directory specified.</p></dd></dl></div></div><div class="sect3" id="id-1.7.40.7.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.39.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manual</span> <a title="Permalink" class="permalink" href="#id-1.7.40.7.6">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>You can create the key and certificates manually using the following steps.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.40.7.6.3.1"><span class="term ">Client Key</span></dt><dd><p>Your personal private key is essentially a cryptographically generated
                                string of bytes. It should be protected in the same manner as a
                                password. To generate an RSA key, you can use the ‘genrsa’ command of
                                the ‘openssl’ tool:</p><div class="verbatim-wrap"><pre class="screen">openssl genrsa -out key.pem 4096</pre></div><p>This command generates a 4096 byte RSA key at key.pem.</p></dd><dt id="id-1.7.40.7.6.3.2"><span class="term ">Signed Certificate</span></dt><dd><p>To authenticate your key, you need to have it signed by a CA.  First
                                generate the Certificate Signing Request (CSR).  The CSR will be
                                used by Magnum to generate a signed certificate that you will use to
                                communicate with the cluster.  To generate a CSR, openssl requires a
                                config file that specifies a few values.  Using the example template
                                below, you can fill in the ‘CN’ value with your name and save it as
                                client.conf:</p><div class="verbatim-wrap"><pre class="screen">$ cat &gt; client.conf &lt;&lt; END
[req]
distinguished_name = req_distinguished_name
req_extensions     = req_ext
prompt = no
[req_distinguished_name]
CN = Your Name
[req_ext]
extendedKeyUsage = clientAuth
END</pre></div><p>Once you have client.conf, you can run the openssl ‘req’ command to
                                generate the CSR:</p><div class="verbatim-wrap"><pre class="screen">openssl req -new -days 365 \
    -config client.conf \
    -key key.pem \
    -out client.csr</pre></div><p>Now that you have your client CSR, you can use the Magnum CLI to
                                send it off to Magnum to get it signed:</p><div class="verbatim-wrap"><pre class="screen">magnum ca-sign --cluster secure-k8s-cluster --csr client.csr &gt; cert.pem</pre></div></dd><dt id="id-1.7.40.7.6.3.3"><span class="term ">Certificate Authority</span></dt><dd><p>The final artifact you need to retrieve is the CA certificate for
                                the cluster. This is used by your native client to ensure you are only
                                communicating with hosts that Magnum set up:</p><div class="verbatim-wrap"><pre class="screen">magnum ca-show --cluster secure-k8s-cluster &gt; ca.pem</pre></div></dd><dt id="id-1.7.40.7.6.3.4"><span class="term ">Rotate Certificate</span></dt><dd><p>To rotate the CA certificate for a cluster and invalidate all user
                                certificates, you can use the following command:</p><div class="verbatim-wrap"><pre class="screen">magnum ca-rotate --cluster secure-k8s-cluster</pre></div></dd></dl></div></div></div><div class="sect2" id="id-1.7.40.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.39.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">User Examples</span> <a title="Permalink" class="permalink" href="#id-1.7.40.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Here are some examples for using the CLI on a secure Kubernetes and
                Swarm cluster.  You can perform all the TLS set up automatically by:</p><div class="verbatim-wrap"><pre class="screen">eval $(magnum cluster-config &lt;cluster-name&gt;)</pre></div><p>Or you can perform the manual steps as described above and specify
                the TLS options on the CLI.  The SSL artifacts are assumed to be
                saved in local files as follows:</p><div class="verbatim-wrap"><pre class="screen">- key.pem: your SSL key
- cert.pem: signed certificate
- ca.pem: certificate for cluster CA</pre></div><p>For Kubernetes, you need to get ‘kubectl’, a kubernetes CLI tool, to
                communicate with the cluster:</p><div class="verbatim-wrap"><pre class="screen">curl -O https://storage.googleapis.com/kubernetes-release/release/v1.2.0/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv kubectl /usr/local/bin/kubectl</pre></div><p>Now let’s run some ‘kubectl’ commands to check the secure communication.
                If you used ‘cluster-config’, then you can simply run the ‘kubectl’ command
                without having to specify the TLS options since they have been defined
                in the environment:</p><div class="verbatim-wrap"><pre class="screen">kubectl version
Client Version: version.Info{Major:"1", Minor:"0", GitVersion:"v1.2.0", GitCommit:"cffae0523cfa80ddf917aba69f08508b91f603d5", GitTreeState:"clean"}
Server Version: version.Info{Major:"1", Minor:"0", GitVersion:"v1.2.0", GitCommit:"cffae0523cfa80ddf917aba69f08508b91f603d5", GitTreeState:"clean"}</pre></div><p>You can specify the TLS options manually as follows:</p><div class="verbatim-wrap"><pre class="screen">KUBERNETES_URL=$(magnum cluster-show secure-k8s-cluster |
                 awk '/ api_address /{print $4}')
kubectl version --certificate-authority=ca.pem \
                --client-key=key.pem \
                --client-certificate=cert.pem -s $KUBERNETES_URL

kubectl create -f redis-master.yaml --certificate-authority=ca.pem \
                                    --client-key=key.pem \
                                    --client-certificate=cert.pem -s $KUBERNETES_URL

pods/test2

kubectl get pods --certificate-authority=ca.pem \
                 --client-key=key.pem \
                 --client-certificate=cert.pem -s $KUBERNETES_URL
NAME           READY     STATUS    RESTARTS   AGE
redis-master   2/2       Running   0          1m</pre></div><p>Beside using the environment variables, you can also configure ‘kubectl’
                to remember the TLS options:</p><div class="verbatim-wrap"><pre class="screen">kubectl config set-cluster secure-k8s-cluster --server=${KUBERNETES_URL} \
    --certificate-authority=${PWD}/ca.pem
kubectl config set-credentials client --certificate-authority=${PWD}/ca.pem \
    --client-key=${PWD}/key.pem --client-certificate=${PWD}/cert.pem
kubectl config set-context secure-k8scluster --cluster=secure-k8scluster --user=client
kubectl config use-context secure-k8scluster</pre></div><p>Then you can use ‘kubectl’ commands without the certificates:</p><div class="verbatim-wrap"><pre class="screen">kubectl get pods
NAME           READY     STATUS    RESTARTS   AGE
redis-master   2/2       Running   0          1m</pre></div><p>Access to Kubernetes User Interface:</p><div class="verbatim-wrap"><pre class="screen">curl -L ${KUBERNETES_URL}/ui --cacert ca.pem --key key.pem \
    --cert cert.pem</pre></div><p>You may also set up ‘kubectl’ proxy which will use your client
                certificates to allow you to browse to a local address to use the UI
                without installing a certificate in your browser:</p><div class="verbatim-wrap"><pre class="screen">kubectl proxy --api-prefix=/ --certificate-authority=ca.pem --client-key=key.pem \
              --client-certificate=cert.pem -s $KUBERNETES_URL</pre></div><p>You can then open <a class="link" href="http://localhost:8001/ui" target="_blank">http://localhost:8001/ui</a> in your browser.</p><p>The examples for Docker are similar.  With ‘cluster-config’ set up,
                you can just run docker commands without TLS options.  To specify the
                TLS options manually:</p><div class="verbatim-wrap"><pre class="screen">docker -H tcp://192.168.19.86:2376 --tlsverify \
       --tlscacert ca.pem \
       --tlskey key.pem \
       --tlscert cert.pem \
       info</pre></div></div><div class="sect2" id="id-1.7.40.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.39.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storing the certificates</span> <a title="Permalink" class="permalink" href="#id-1.7.40.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#transport-layer-security</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum generates and maintains a certificate for each cluster so that it
                can also communicate securely with the cluster.  As a result, it is
                necessary to store the certificates in a secure manner.  Magnum
                provides the following methods for storing the certificates and this
                is configured in /etc/magnum/magnum.conf in the section [certificates]
                with the parameter ‘cert_manager_type’.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Barbican:
                        Barbican is a service in OpenStack for storing secrets.  It is used
                        by Magnum to store the certificates when cert_manager_type is
                        configured as:</p><div class="verbatim-wrap"><pre class="screen">cert_manager_type = barbican</pre></div><p>This is the recommended configuration for a production environment.
                        Magnum will interface with Barbican to store and retrieve
                        certificates, delegating the task of securing the certificates to
                        Barbican.</p></li><li class="step "><p>Magnum database:
                        In some cases, a user may want an alternative to storing the
                        certificates that does not require Barbican.  This can be a
                        development environment, or a private cloud that has been secured
                        by other means.  Magnum can store the certificates in its own
                        database; this is done with the configuration:</p><div class="verbatim-wrap"><pre class="screen">cert_manager_type = x509keypair</pre></div><p>This storage mode is only as secure as the controller server that
                        hosts the database for the OpenStack services.</p></li><li class="step "><p>Local store:
                        As another alternative that does not require Barbican, Magnum can
                        simply store the certificates on the local host filesystem where the
                        conductor is running, using the configuration:</p><div class="verbatim-wrap"><pre class="screen">cert_manager_type = local</pre></div><p>Note that this mode is only supported when there is a single Magnum
                        conductor running since the certificates are stored locally.  The
                        ‘local’ mode is not recommended for a production environment.</p></li></ol></div></div><p>For the nodes, the certificates for communicating with the masters are
                stored locally and the nodes are assumed to be secured.</p></div></div><div class="sect1" id="id-1.7.41"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.40 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking</span> <a title="Permalink" class="permalink" href="#id-1.7.41">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#networking</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>There are two components that make up the networking in a cluster.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>The Neutron infrastructure for the cluster: this includes the
                    private network, subnet, ports, routers, load balancers, etc.</p></li><li class="step "><p>The networking model presented to the containers: this is what the
                    containers see in communicating with each other and to the external
                    world. Typically this consists of a driver deployed on each node.</p></li></ol></div></div><p>The two components are deployed and managed separately.  The Neutron
            infrastructure is the integration with OpenStack; therefore, it
            is stable and more or less similar across different COE
            types.  The networking model, on the other hand, is specific to the
            COE type and is still under active development in the various
            COE communities, for example,
            <a class="link" href="https://github.com/docker/libnetwork" target="_blank">Docker libnetwork</a> and
            <a class="link" href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/design/networking.md" target="_blank">Kubernetes Container Networking</a>.
            As a result, the implementation for the networking models is evolving and
            new models are likely to be introduced in the future.</p><p>For the Neutron infrastructure, the following configuration can
            be set in the ClusterTemplate:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.41.6.1"><span class="term ">external-network</span></dt><dd><p>The external Neutron network ID to connect to this cluster. This
                        is used to connect the cluster to the external internet, allowing
                        the nodes in the cluster to access external URL for discovery, image
                        download, etc.  If not specified, the default value is “public” and this
                        is valid for a typical devstack.</p></dd><dt id="id-1.7.41.6.2"><span class="term ">fixed-network</span></dt><dd><p>The Neutron network to use as the private network for the cluster nodes.
                        If not specified, a new Neutron private network will be created.</p></dd><dt id="id-1.7.41.6.3"><span class="term ">dns-nameserver</span></dt><dd><p>The DNS nameserver to use for this cluster.  This is an IP address for
                        the server and it is used to configure the Neutron subnet of the
                        cluster (dns_nameservers).  If not specified, the default DNS is
                        8.8.8.8, the publicly available DNS.</p></dd><dt id="id-1.7.41.6.4"><span class="term ">http-proxy, https-proxy, no-proxy</span></dt><dd><p>The proxy for the nodes in the cluster, to be used when the cluster is
                        behind a firewall and containers cannot access URL’s on the external
                        internet directly.  For the parameter http-proxy and https-proxy, the
                        value to provide is a URL and it will be set in the environment
                        variable HTTP_PROXY and HTTPS_PROXY respectively in the nodes.  For
                        the parameter no-proxy, the value to provide is an IP or list of IP’s
                        separated by comma.  Likewise, the value will be set in the
                        environment variable NO_PROXY in the nodes.</p></dd></dl></div><p>For the networking model to the container, the following configuration
            can be set in the ClusterTemplate:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.41.8.1"><span class="term ">network-driver</span></dt><dd><p>The network driver name for instantiating container networks.
                        Currently, the following network drivers are supported:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="8" class="c1" /><col width="13" class="c2" /><col width="11" class="c3" /><col width="13" class="c4" /></colgroup><thead><tr><th>
                        <p>Driver</p>
                      </th><th>
                        <p>Kubernetes</p>
                      </th><th>
                        <p>Swarm</p>
                      </th><th>
                        <p>Mesos</p>
                      </th></tr></thead><tbody><tr><td>
                        <p>Flannel</p>
                      </td><td>
                        <p>supported</p>
                      </td><td>
                        <p>supported</p>
                      </td><td>
                        <p>unsupported</p>
                      </td></tr><tr><td>
                        <p>Docker</p>
                      </td><td>
                        <p>unsupported</p>
                      </td><td>
                        <p>supported</p>
                      </td><td>
                        <p>supported</p>
                      </td></tr></tbody></table></div><p>If not specified, the default driver is Flannel for Kubernetes, and
                        Docker for Swarm and Mesos.</p></dd></dl></div><p>Particular network driver may require its own set of parameters for
            configuration, and these parameters are specified through the labels
            in the ClusterTemplate.  Labels are arbitrary key=value pairs.</p><p>When Flannel is specified as the network driver, the following
            optional labels can be added:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.41.11.1"><span class="term "></span></dt><dd><p>IPv4 network in CIDR format to use for the entire Flannel network.
                        If not specified, the default is 10.100.0.0/16.</p></dd><dt id="id-1.7.41.11.2"><span class="term "></span></dt><dd><p>The size of the subnet allocated to each host. If not specified, the
                        default is 24.</p></dd><dt id="id-1.7.41.11.3"><span class="term "></span></dt><dd><p>The type of backend for Flannel.  Possible values are <span class="emphasis"><em>udp, vxlan,
                            host-gw</em></span>.  If not specified, the default is <span class="emphasis"><em>udp</em></span>.  Selecting the
                        best backend depends on your networking.  Generally, <span class="emphasis"><em>udp</em></span> is
                        the most generally supported backend since there is little
                        requirement on the network, but it typically offers the lowest
                        performance.  The <span class="emphasis"><em>vxlan</em></span> backend performs better, but requires
                        vxlan support in the kernel so the image used to provision the
                        nodes needs to include this support.  The <span class="emphasis"><em>host-gw</em></span> backend offers
                        the best performance since it does not actually encapsulate
                        messages, but it requires all the nodes to be on the same L2
                        network.  The private Neutron network that Magnum creates does
                        meet this requirement;  therefore if the parameter <span class="emphasis"><em>fixed_network</em></span>
                        is not specified in the ClusterTemplate, <span class="emphasis"><em>host-gw</em></span> is the best choice for
                        the Flannel backend.</p></dd></dl></div></div><div class="sect1" id="id-1.7.42"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.41 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">High Availability</span> <a title="Permalink" class="permalink" href="#id-1.7.42">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#high-availability</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
          <span class="emphasis"><em>To be filled in</em></span>
        </p></div><div class="sect1" id="id-1.7.43"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.42 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Scaling</span> <a title="Permalink" class="permalink" href="#id-1.7.43">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#scaling</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="sect2" id="id-1.7.43.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.42.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Performance tuning for periodic task</span> <a title="Permalink" class="permalink" href="#id-1.7.43.2">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#scaling</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum’s periodic task performs a <code class="literal">stack-get</code> operation on the Heat stack
                underlying each of its clusters. If you have a large amount of clusters this
                can create considerable load on the Heat API. To reduce that load you can
                configure Magnum to perform one global <code class="literal">stack-list</code> per periodic task instead
                of one per cluster. This is disabled by default, both from the Heat and Magnum
                side since it causes a security issue, though: any user in any tenant holding
                the <code class="literal">admin</code> role can perform a global <code class="literal">stack-list</code> operation if Heat is
                configured to allow it for Magnum. If you want to enable it nonetheless,
                proceed as follows:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Set <code class="literal">periodic_global_stack_list</code> in magnum.conf to <code class="literal">True</code>
                        (<code class="literal">False</code> by default).</p></li><li class="step "><p>Update heat policy to allow magnum list stacks. To this end, edit your heat
                        policy file, usually etc/heat/policy.json``:</p><div class="verbatim-wrap highlight ini"><pre class="screen">...
stacks:global_index: "rule:context_is_admin",</pre></div><p>Now restart heat.</p></li></ol></div></div></div><div class="sect2" id="id-1.7.43.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.42.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Containers and nodes</span> <a title="Permalink" class="permalink" href="#id-1.7.43.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#scaling</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Scaling containers and nodes refers to increasing or decreasing
                allocated system resources.  Scaling is a broad topic and involves
                many dimensions.  In the context of Magnum in this guide, we consider
                the following issues:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Scaling containers and scaling cluster nodes (infrastructure)</p></li><li class="listitem "><p>Manual and automatic scaling</p></li></ul></div><p>Since this is an active area of development, a complete solution
                covering all issues does not exist yet, but partial solutions are
                emerging.</p><p>Scaling containers involves managing the number of instances of the
                container by replicating or deleting instances.  This can be used to
                respond to change in the workload being supported by the application;
                in this case, it is typically driven by certain metrics relevant to the
                application such as response time, etc.  Other use cases include
                rolling upgrade, where a new version of a service can gradually be
                scaled up while the older version is gradually scaled down.  Scaling
                containers is supported at the COE level and is specific to each COE
                as well as the version of the COE.  You will need to refer to the
                documentation for the proper COE version for full details, but
                following are some pointers for reference.</p><p>For Kubernetes, pods are scaled manually by setting the count in the
                replication controller.  Kubernetes version 1.3 and later also
                supports <a class="link" href="http://blog.kubernetes.io/2016/07/autoscaling-in-kubernetes.html" target="_blank">autoscaling</a>.
                For Docker, the tool ‘Docker Compose’ provides the command
                <a class="link" href="https://docs.docker.com/compose/reference/scale/" target="_blank">docker-compose scale</a> which lets you
                manually set the number of instances of a container.  For Swarm
                version 1.12 and later, services can also be scaled manually through
                the command <a class="link" href="https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/" target="_blank">docker service scale</a>.
                Automatic scaling for Swarm is not yet available.  Mesos manages the
                resources and does not support scaling directly; instead, this is
                provided by frameworks running within Mesos.  With the Marathon
                framework currently supported in the Mesos cluster, you can use the
                <a class="link" href="https://mesosphere.github.io/marathon/docs/application-basics.html" target="_blank">scale operation</a>
                on the Marathon UI or through a REST API call to manually set the
                attribute ‘instance’ for a container.</p><p>Scaling the cluster nodes involves managing the number of nodes in the
                cluster by adding more nodes or removing nodes.  There is no direct
                correlation between the number of nodes and the number of containers
                that can be hosted since the resources consumed (memory, CPU, etc)
                depend on the containers.  However, if a certain resource is exhausted
                in the cluster, adding more nodes would add more resources for hosting
                more containers.  As part of the infrastructure management, Magnum
                supports manual scaling through the attribute ‘node_count’ in the
                cluster, so you can scale the cluster simply by changing this
                attribute:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-update mycluster replace node_count=2</pre></div><p>Adding nodes to a cluster is straightforward: Magnum deploys
                additional VMs or baremetal servers through the heat templates and
                invokes the COE-specific mechanism for registering the new nodes to
                update the available resources in the cluster.  Afterward, it is up to
                the COE or user to re-balance the workload by launching new container
                instances or re-launching dead instances on the new nodes.</p><p>Removing nodes from a cluster requires some more care to ensure
                continuous operation of the containers since the nodes being removed
                may be actively hosting some containers.  Magnum performs a simple
                heuristic that is specific to the COE to find the best node candidates
                for removal, as follows:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.43.3.12.1"><span class="term ">Kubernetes</span></dt><dd><p>Magnum scans the pods in the namespace ‘Default’ to determine the
                            nodes that are <span class="emphasis"><em>not</em></span> hosting any (empty nodes).  If the number of
                            nodes to be removed is equal or less than the number of these empty
                            nodes, these nodes will be removed from the cluster.  If the number
                            of nodes to be removed is larger than the number of empty nodes, a
                            warning message will be sent to the Magnum log and the empty nodes
                            along with additional nodes will be removed from the cluster.  The
                            additional nodes are selected randomly and the pods running on them
                            will be deleted without warning.  For this reason, a good practice
                            is to manage the pods through the replication controller so that the
                            deleted pods will be relaunched elsewhere in the cluster.  Note also
                            that even when only the empty nodes are removed, there is no
                            guarantee that no pod will be deleted because there is no locking to
                            ensure that Kubernetes will not launch new pods on these nodes after
                            Magnum has scanned the pods.</p></dd><dt id="id-1.7.43.3.12.2"><span class="term ">Swarm</span></dt><dd><p>No node selection heuristic is currently supported.  If you decrease
                            the node_count, a node will be chosen by magnum without
                            consideration of what containers are running on the selected node.</p></dd><dt id="id-1.7.43.3.12.3"><span class="term ">Mesos</span></dt><dd><p>Magnum scans the running tasks on Marathon server to determine the
                            nodes on which there is <span class="emphasis"><em>no</em></span> task running (empty nodes). If the
                            number of nodes to be removed is equal or less than the number of
                            these empty nodes, these nodes will be removed from the cluster.
                            If the number of nodes to be removed is larger than the number of
                            empty nodes, a warning message will be sent to the Magnum log and
                            the empty nodes along with additional nodes will be removed from the
                            cluster. The additional nodes are selected randomly and the containers
                            running on them will be deleted without warning. Note that even when
                            only the empty nodes are removed, there is no guarantee that no
                            container will be deleted because there is no locking to ensure that
                            Mesos will not launch new containers on these nodes after Magnum
                            has scanned the tasks.</p></dd></dl></div><p>Currently, scaling containers and scaling cluster nodes are handled
                separately, but in many use cases, there are interactions between the
                two operations.  For instance, scaling up the containers may exhaust
                the available resources in the cluster, thereby requiring scaling up
                the cluster nodes as well.  Many complex issues are involved in
                managing this interaction.  A presentation at the OpenStack Tokyo
                Summit 2015 covered some of these issues along with some early
                proposals, <a class="link" href="https://www.openstack.org/summit/tokyo-2015/videos/presentation/exploring-magnum-and-senlin-integration-for-autoscaling-containers" target="_blank">Exploring Magnum and Senlin integration for autoscaling
                    containers</a>.
                This remains an active area of discussion and research.</p></div></div><div class="sect1" id="id-1.7.44"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.43 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Storage</span> <a title="Permalink" class="permalink" href="#id-1.7.44">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#storage</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Currently Cinder provides the block storage to the containers, and the
            storage is made available in two ways: as ephemeral storage and as
            persistent storage.</p><div class="sect2" id="id-1.7.44.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.43.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ephemeral storage</span> <a title="Permalink" class="permalink" href="#id-1.7.44.3">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#storage</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The filesystem for the container consists of multiple layers from the
                image and a top layer that holds the modification made by the
                container.  This top layer requires storage space and the storage is
                configured in the Docker daemon through a number of storage options.
                When the container is removed, the storage allocated to the particular
                container is also deleted.</p><p>Magnum can manage the containers’ filesystem in two ways, storing them
                on the local disk of the compute instances or in a separate Cinder block
                volume for each node in the cluster, mounts it to the node and
                configures it to be used as ephemeral storage.  Users can specify the
                size of the Cinder volume with the ClusterTemplate attribute
                ‘docker-volume-size’. Currently the block size is fixed at cluster
                creation time, but future lifecycle operations may allow modifying the
                block size during the life of the cluster.</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.44.3.4.1"><span class="term "></span></dt><dd><p>For drivers that support additional volumes for container storage, a
                            label named ‘docker_volume_type’ is exposed so that users can select
                            different cinder volume types for their volumes. The default volume
                            <span class="emphasis"><em>must</em></span> be set in ‘default_docker_volume_type’ in the ‘cinder’ section
                            of magnum.conf, an obvious value is the default volume type set in
                            cinder.conf of your cinder deployment . Please note, that
                            docker_volume_type refers to a cinder volume type and it is unrelated
                            to docker or kubernetes volumes.</p></dd></dl></div><p>Both local disk and the Cinder block storage can be used with a number
                of Docker storage drivers available.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>‘devicemapper’: When used with a dedicated Cinder volume it is
                        configured using direct-lvm and offers very good performance. If it’s
                        used with the compute instance’s local disk uses a loopback device
                        offering poor performance and it’s not recommended for production
                        environments. Using the ‘devicemapper’ driver does allow the use of
                        SELinux.</p></li><li class="listitem "><p>‘overlay’ When used with a dedicated Cinder volume offers as good
                        or better performance than devicemapper. If used on the local disk of
                        the compute instance (especially with high IOPS drives) you can get
                        significant performance gains. However, for kernel versions less than
                        4.9, SELinux must be disabled inside the containers resulting in worse
                        container isolation, although it still runs in enforcing mode on the
                        cluster compute instances.</p></li></ul></div></div><div class="sect2" id="id-1.7.44.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.43.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Persistent storage</span> <a title="Permalink" class="permalink" href="#id-1.7.44.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#storage</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In some use cases, data read/written by a container needs to persist
                so that it can be accessed later.  To persist the data, a Cinder
                volume with a filesystem on it can be mounted on a host and be made
                available to the container, then be unmounted when the container exits.</p><p>Docker provides the ‘volume’ feature for this purpose: the user
                invokes the ‘volume create’ command, specifying a particular volume
                driver to perform the actual work.  Then this volume can be mounted
                when a container is created.  A number of third-party volume drivers
                support OpenStack Cinder as the backend, for example Rexray and
                Flocker.  Magnum currently supports Rexray as the volume driver for
                Swarm and Mesos.  Other drivers are being considered.</p><p>Kubernetes allows a previously created Cinder block to be mounted to
                a pod and this is done by specifying the block ID in the pod YAML file.
                When the pod is scheduled on a node, Kubernetes will interface with
                Cinder to request the volume to be mounted on this node, then
                Kubernetes will launch the Docker container with the proper options to
                make the filesystem on the Cinder volume accessible to the container
                in the pod.  When the pod exits, Kubernetes will again send a request
                to Cinder to unmount the volume’s filesystem, making it available to be
                mounted on other nodes.</p><p>Magnum supports these features to use Cinder as persistent storage
                using the ClusterTemplate attribute ‘volume-driver’ and the support matrix
                for the COE types is summarized as follows:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="8" class="c1" /><col width="13" class="c2" /><col width="13" class="c3" /><col width="13" class="c4" /></colgroup><thead><tr><th>
                    <p>Driver</p>
                  </th><th>
                    <p>Kubernetes</p>
                  </th><th>
                    <p>Swarm</p>
                  </th><th>
                    <p>Mesos</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>cinder</p>
                  </td><td>
                    <p>supported</p>
                  </td><td>
                    <p>unsupported</p>
                  </td><td>
                    <p>unsupported</p>
                  </td></tr><tr><td>
                    <p>rexray</p>
                  </td><td>
                    <p>unsupported</p>
                  </td><td>
                    <p>supported</p>
                  </td><td>
                    <p>supported</p>
                  </td></tr></tbody></table></div><p>Following are some examples for using Cinder as persistent storage.</p><div class="sect3" id="id-1.7.44.4.8"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.43.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Cinder in Kubernetes</span> <a title="Permalink" class="permalink" href="#id-1.7.44.4.8">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#storage</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p><span class="bold"><strong>NOTE:</strong></span> This feature requires Kubernetes version 1.5.0 or above.
                    The public Fedora image from Atomic currently meets this requirement.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the ClusterTemplate.</p><p>Specify ‘cinder’ as the volume-driver for Kubernetes:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create k8s-cluster-template \
                           --image fedora-23-atomic-7 \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --flavor m1.small \
                           --docker-volume-size 5 \
                           --network-driver flannel \
                           --coe kubernetes \
                           --volume-driver cinder</pre></div></li><li class="step "><p>Create the cluster:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create k8s-cluster \
                      --cluster-template k8s-cluster-template \
                      --node-count 1</pre></div></li></ol></div></div><p>Kubernetes is now ready to use Cinder for persistent storage.
                    Following is an example illustrating how Cinder is used in a pod.</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the cinder volume:</p><div class="verbatim-wrap"><pre class="screen">cinder create --display-name=test-repo 1

XML:ID=$(cinder create --display-name=test-repo 1 | awk -F'|' '$2~/^[[:space:]]*id/ {print $3}')</pre></div><p>The command will generate the volume with a ID. The volume ID will be
                            specified in Step 2.</p></li><li class="step "><p>Create a pod in this cluster and mount this cinder volume to the pod.
                            Create a file (e.g nginx-cinder.yaml) describing the pod:</p><div class="verbatim-wrap"><pre class="screen">cat &gt; nginx-cinder.yaml &lt;&lt; END
apiVersion: v1
kind: Pod
metadata:
  name: aws-web
spec:
  containers:
    - name: web
      image: nginx
      ports:
        - name: web
          containerPort: 80
          hostPort: 8081
          protocol: TCP
      volumeMounts:
        - name: html-volume
          mountPath: "/usr/share/nginx/html"
  volumes:
    - name: html-volume
      cinder:
        # Enter the volume ID below
        volumeID: $ID
        fsType: ext4
END</pre></div></li></ol></div></div><p><span class="bold"><strong>NOTE:</strong></span> The Cinder volume ID needs to be configured in the YAML file
                    so the existing Cinder volume can be mounted in a pod by specifying
                    the volume ID in the pod manifest as follows:</p><div class="verbatim-wrap"><pre class="screen">volumes:
- name: html-volume
  cinder:
    volumeID: $ID
    fsType: ext4</pre></div><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>Create the pod by the normal Kubernetes interface:</p><div class="verbatim-wrap"><pre class="screen">kubectl create -f nginx-cinder.yaml</pre></div></li></ul></div></div><p>You can start a shell in the container to check that the mountPath exists,
                    and on an OpenStack client you can run the command ‘cinder list’ to verify
                    that the cinder volume status is ‘in-use’.</p></div><div class="sect3" id="id-1.7.44.4.9"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.43.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Cinder in Swarm</span> <a title="Permalink" class="permalink" href="#id-1.7.44.4.9">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#storage</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
              <span class="emphasis"><em>To be filled in</em></span>
            </p></div><div class="sect3" id="id-1.7.44.4.10"><div class="titlepage"><div><div><h4 class="title"><span class="number">5.43.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Cinder in Mesos</span> <a title="Permalink" class="permalink" href="#id-1.7.44.4.10">#</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#storage</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create the ClusterTemplate.</p><p>Specify ‘rexray’ as the volume-driver for Mesos.  As an option, you
                            can specify in a label the attributes ‘rexray_preempt’ to enable
                            any host to take control of a volume regardless if other
                            hosts are using the volume. If this is set to false, the driver
                            will ensure data safety by locking the volume:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-template-create mesos-cluster-template \
                           --image ubuntu-mesos \
                           --keypair testkey \
                           --external-network public \
                           --dns-nameserver 8.8.8.8 \
                           --master-flavor m1.magnum \
                           --docker-volume-size 4 \
                           --tls-disabled \
                           --flavor m1.magnum \
                           --coe mesos \
                           --volume-driver rexray \
                           --labels rexray-preempt=true</pre></div></li><li class="step "><p>Create the Mesos cluster:</p><div class="verbatim-wrap"><pre class="screen">magnum cluster-create mesos-cluster \
                      --cluster-template mesos-cluster-template \
                      --node-count 1</pre></div></li><li class="step "><p>Create the cinder volume and configure this cluster:</p><div class="verbatim-wrap"><pre class="screen">cinder create --display-name=redisdata 1</pre></div><p>Create the following file</p><div class="verbatim-wrap"><pre class="screen">cat &gt; mesos.json &lt;&lt; END
{
  "id": "redis",
  "container": {
    "docker": {
    "image": "redis",
    "network": "BRIDGE",
    "portMappings": [
      { "containerPort": 80, "hostPort": 0, "protocol": "tcp"}
    ],
    "parameters": [
       { "key": "volume-driver", "value": "rexray" },
       { "key": "volume", "value": "redisdata:/data" }
    ]
    }
 },
 "cpus": 0.2,
 "mem": 32.0,
 "instances": 1
}
END</pre></div></li></ol></div></div><p><span class="bold"><strong>NOTE:</strong></span> When the Mesos cluster is created using this ClusterTemplate, the
                    Mesos cluster will be configured so that a filesystem on an existing cinder
                    volume can be mounted in a container by configuring the parameters to mount
                    the cinder volume in the JSON file</p><div class="verbatim-wrap"><pre class="screen">"parameters": [
   { "key": "volume-driver", "value": "rexray" },
   { "key": "volume", "value": "redisdata:/data" }
]</pre></div><div class="procedure "><div class="procedure-contents"><ul class="procedure"><li class="step "><p>Create the container using Marathon REST API</p><div class="verbatim-wrap"><pre class="screen">MASTER_IP=$(magnum cluster-show mesos-cluster | awk '/ api_address /{print $4}')
curl -X POST -H "Content-Type: application/json" \
http://${MASTER_IP}:8080/v2/apps -d@mesos.json</pre></div></li></ul></div></div><p>You can log into the container to check that the mountPath exists, and
                    you can run the command ‘cinder list’ to verify that your cinder
                    volume status is ‘in-use’.</p></div></div></div><div class="sect1" id="id-1.7.45"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.44 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Image Management</span> <a title="Permalink" class="permalink" href="#id-1.7.45">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#image-management</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>When a COE is deployed, an image from Glance is used to boot the nodes
            in the cluster and then the software will be configured and started on
            the nodes to bring up the full cluster.  An image is based on a
            particular distro such as Fedora, Ubuntu, etc, and is prebuilt with
            the software specific to the COE such as Kubernetes, Swarm, Mesos.
            The image is tightly coupled with the following in Magnum:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Heat templates to orchestrate the configuration.</p></li><li class="step "><p>Template definition to map ClusterTemplate parameters to Heat
                    template parameters.</p></li><li class="step "><p>Set of scripts to configure software.</p></li></ol></div></div><p>Collectively, they constitute the driver for a particular COE and a
            particular distro; therefore, developing a new image needs to be done
            in conjunction with developing these other components.  Image can be
            built by various methods such as diskimagebuilder, or in some case, a
            distro image can be used directly.  A number of drivers and the
            associated images is supported in Magnum as reference implementation.
            In this section, we focus mainly on the supported images.</p><p>All images must include support for cloud-init and the heat software
            configuration utility:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>os-collect-config</p></li><li class="listitem "><p>os-refresh-config</p></li><li class="listitem "><p>os-apply-config</p></li><li class="listitem "><p>heat-config</p></li><li class="listitem "><p>heat-config-script</p></li></ul></div><p>Additional software are described as follows.</p><div class="sect2" id="id-1.7.45.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.44.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes on Fedora Atomic</span> <a title="Permalink" class="permalink" href="#id-1.7.45.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#image-management</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image can be downloaded from the <a class="link" href="https://alt.fedoraproject.org/pub/alt/atomic/stable/Cloud-Images/x86_64/Images/" target="_blank">public Atomic site</a>
                or can be built locally using diskimagebuilder.  Details can be found in the
                <a class="link" href="https://github.com/openstack/magnum/tree/master/magnum/elements/fedora-atomic" target="_blank">fedora-atomic element</a>
                The image currently has the following OS/software:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="11" class="c2" /></colgroup><thead><tr><th>
                    <p>OS/software</p>
                  </th><th>
                    <p>version</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Fedora</p>
                  </td><td>
                    <p>26</p>
                  </td></tr><tr><td>
                    <p>Docker</p>
                  </td><td>
                    <p>1.13.1</p>
                  </td></tr><tr><td>
                    <p>Kubernetes</p>
                  </td><td>
                    <p>1.7.4</p>
                  </td></tr><tr><td>
                    <p>etcd</p>
                  </td><td>
                    <p>3.1.3</p>
                  </td></tr><tr><td>
                    <p>Flannel</p>
                  </td><td>
                    <p>0.7.0</p>
                  </td></tr></tbody></table></div><p>The following software are managed as systemd services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kube-apiserver</p></li><li class="listitem "><p>kubelet</p></li><li class="listitem "><p>etcd</p></li><li class="listitem "><p>flannel (if specified as network driver)</p></li><li class="listitem "><p>docker</p></li></ul></div><p>The following software are managed as Docker containers:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kube-controller-manager</p></li><li class="listitem "><p>kube-scheduler</p></li><li class="listitem "><p>kube-proxy</p></li></ul></div><p>The login for this image is <span class="emphasis"><em>fedora</em></span>.</p></div><div class="sect2" id="id-1.7.45.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.44.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes on CoreOS</span> <a title="Permalink" class="permalink" href="#id-1.7.45.9">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#image-management</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>CoreOS publishes a <a class="link" href="http://beta.release.core-os.net/amd64-usr/current/coreos_production_openstack_image.img.bz2" target="_blank">stock image</a>
                that is being used to deploy Kubernetes.
                This image has the following OS/software:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="11" class="c2" /></colgroup><thead><tr><th>
                    <p>OS/software</p>
                  </th><th>
                    <p>version</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>CoreOS</p>
                  </td><td>
                    <p>4.3.6</p>
                  </td></tr><tr><td>
                    <p>Docker</p>
                  </td><td>
                    <p>1.9.1</p>
                  </td></tr><tr><td>
                    <p>Kubernetes</p>
                  </td><td>
                    <p>1.0.6</p>
                  </td></tr><tr><td>
                    <p>etcd</p>
                  </td><td>
                    <p>2.2.3</p>
                  </td></tr><tr><td>
                    <p>Flannel</p>
                  </td><td>
                    <p>0.5.5</p>
                  </td></tr></tbody></table></div><p>The following software are managed as systemd services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kubelet</p></li><li class="listitem "><p>flannel (if specified as network driver)</p></li><li class="listitem "><p>docker</p></li><li class="listitem "><p>etcd</p></li></ul></div><p>The following software are managed as Docker containers:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>kube-apiserver</p></li><li class="listitem "><p>kube-controller-manager</p></li><li class="listitem "><p>kube-scheduler</p></li><li class="listitem "><p>kube-proxy</p></li></ul></div><p>The login for this image is <span class="emphasis"><em>core</em></span>.</p></div><div class="sect2" id="id-1.7.45.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.44.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes on Ironic</span> <a title="Permalink" class="permalink" href="#id-1.7.45.10">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#image-management</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image is built manually using diskimagebuilder.  The scripts and
                instructions are included in <a class="link" href="https://github.com/openstack/magnum/tree/master/magnum/templates/kubernetes/elements" target="_blank">Magnum code repo</a>.
                Currently Ironic is not fully supported yet, therefore more details will be
                provided when this driver has been fully tested.</p></div><div class="sect2" id="id-1.7.45.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.44.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Swarm on Fedora Atomic</span> <a title="Permalink" class="permalink" href="#id-1.7.45.11">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#image-management</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image is the same as the image for Kubernetes on Fedora
	  Atomic described above.  The login for this image is <span class="emphasis"><em>fedora</em></span>.</p></div><div class="sect2" id="id-1.7.45.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.44.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Mesos on Ubuntu</span> <a title="Permalink" class="permalink" href="#id-1.7.45.12">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#image-management</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This image is built manually using diskimagebuilder.
                The Fedora site hosts the current image <a class="link" href="https://fedorapeople.org/groups/magnum/ubuntu-mesos-latest.qcow2" target="_blank">ubuntu-mesos-latest.qcow2</a>.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="13" class="c1" /><col width="11" class="c2" /></colgroup><thead><tr><th>
                    <p>OS/software</p>
                  </th><th>
                    <p>version</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>Ubuntu</p>
                  </td><td>
                    <p>14.04</p>
                  </td></tr><tr><td>
                    <p>Docker</p>
                  </td><td>
                    <p>1.8.1</p>
                  </td></tr><tr><td>
                    <p>Mesos</p>
                  </td><td>
                    <p>0.25.0</p>
                  </td></tr><tr><td>
                    <p>Marathon</p>
                  </td><td>
                    <p>0.11.1</p>
                  </td></tr></tbody></table></div></div></div><div class="sect1" id="id-1.7.46"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.45 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Notification</span> <a title="Permalink" class="permalink" href="#id-1.7.46">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#notification</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum provides notifications about usage data so that 3rd party applications
            can use the data for auditing, billing, monitoring, or quota purposes. This
            document describes the current inclusions and exclusions for Magnum
            notifications.</p><p>Magnum uses Cloud Auditing Data Federation (<a class="link" href="http://www.dmtf.org/standards/cadf" target="_blank">CADF</a>) Notification as its
            notification format for better support of auditing, details about CADF are
            documented below.</p><div class="sect2" id="id-1.7.46.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.45.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Auditing with CADF</span> <a title="Permalink" class="permalink" href="#id-1.7.46.4">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#notification</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Magnum uses the <a class="link" href="http://docs.openstack.org/developer/pycadf" target="_blank">PyCADF</a> library to emit CADF notifications, these events
                adhere to the DMTF <a class="link" href="http://www.dmtf.org/standards/cadf" target="_blank">CADF</a> specification. This standard provides auditing
                capabilities for compliance with security, operational, and business processes
                and supports normalized and categorized event data for federation and
                aggregation.</p><p>Below table describes the event model components and semantics for
                each component:</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="17" class="c1" /><col width="58" class="c2" /></colgroup><thead><tr><th>
                    <p>model component</p>
                  </th><th>
                    <p>CADF Definition</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>OBSERVER</p>
                  </td><td>
                    <p>The RESOURCE that generates the CADF Event Record based
                                    on its observation (directly or indirectly) of the
                                    Actual Event.</p>
                  </td></tr><tr><td>
                    <p>INITIATOR</p>
                  </td><td>
                    <p>The RESOURCE that initiated, originated, or instigated
                                    the event’s ACTION, according to the OBSERVER.</p>
                  </td></tr><tr><td>
                    <p>ACTION</p>
                  </td><td>
                    <p>The operation or activity the INITIATOR has performed,
                                    has attempted to perform or has pending against the
                                    event’s TARGET, according to the OBSERVER.</p>
                  </td></tr><tr><td>
                    <p>TARGET</p>
                  </td><td>
                    <p>The RESOURCE against which the ACTION of a CADF Event
                                    Record was performed, attempted, or is pending,
                                    according to the OBSERVER.</p>
                  </td></tr><tr><td>
                    <p>OUTCOME</p>
                  </td><td>
                    <p>The result or status of the ACTION against the TARGET,
                                    according to the OBSERVER.</p>
                  </td></tr></tbody></table></div><p>The <code class="literal">payload</code> portion of a CADF Notification is a CADF <code class="literal">event</code>, which
                is represented as a JSON dictionary. For example:</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "typeURI": "http://schemas.dmtf.org/cloud/audit/1.0/event",
    "initiator": {
        "typeURI": "service/security/account/user",
        "host": {
            "agent": "curl/7.22.0(x86_64-pc-linux-gnu)",
            "address": "127.0.0.1"
        },
        "id": "&lt;initiator_id&gt;"
    },
    "target": {
        "typeURI": "&lt;target_uri&gt;",
        "id": "openstack:1c2fc591-facb-4479-a327-520dade1ea15"
    },
    "observer": {
        "typeURI": "service/security",
        "id": "openstack:3d4a50a9-2b59-438b-bf19-c231f9c7625a"
    },
    "eventType": "activity",
    "eventTime": "2014-02-14T01:20:47.932842+00:00",
    "action": "&lt;action&gt;",
    "outcome": "success",
    "id": "openstack:f5352d7b-bee6-4c22-8213-450e7b646e9f",
}</pre></div><p>Where the following are defined:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">&lt;initiator_id&gt;</code>: ID of the user that performed the operation</p></li><li class="listitem "><p><code class="literal">&lt;target_uri&gt;</code>: CADF specific target URI, (i.e.:  data/security/project)</p></li><li class="listitem "><p><code class="literal">&lt;action&gt;</code>: The action being performed, typically:
                        <code class="literal">&lt;operation&gt;</code>. <code class="literal">&lt;resource_type&gt;</code></p></li></ul></div><p>Additionally there may be extra keys present depending on the operation being
                performed, these will be discussed below.</p><p>Note, the <code class="literal">eventType</code> property of the CADF payload is different from the
                <code class="literal">event_type</code> property of a notifications. The former (<code class="literal">eventType</code>) is a
                CADF keyword which designates the type of event that is being measured, this
                can be: <code class="literal">activity</code>, <code class="literal">monitor</code> or <code class="literal">control</code>. Whereas the latter
                (<code class="literal">event_type</code>) is described in previous sections as:
                <code class="literal">magnum.&lt;resource_type&gt;.&lt;operation&gt;</code></p></div><div class="sect2" id="id-1.7.46.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.45.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supported Events</span> <a title="Permalink" class="permalink" href="#id-1.7.46.5">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#notification</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following table displays the corresponding relationship between resource
                types and operations. The bay type is deprecated and will be removed in a
                future version. Cluster is the new equivalent term.</p><div class="informaltable"><table class="informaltable" border="1"><colgroup><col width="15" class="c1" /><col width="28" class="c2" /><col width="25" class="c3" /></colgroup><thead><tr><th>
                    <p>resource type</p>
                  </th><th>
                    <p>supported operations</p>
                  </th><th>
                    <p>typeURI</p>
                  </th></tr></thead><tbody><tr><td>
                    <p>bay</p>
                  </td><td>
                    <p>create, update, delete</p>
                  </td><td>
                    <p>service/magnum/bay</p>
                  </td></tr><tr><td>
                    <p>cluster</p>
                  </td><td>
                    <p>create, update, delete</p>
                  </td><td>
                    <p>service/magnum/cluster</p>
                  </td></tr></tbody></table></div></div><div class="sect2" id="id-1.7.46.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.45.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Example Notification - Cluster Create</span> <a title="Permalink" class="permalink" href="#id-1.7.46.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#notification</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The following is an example of a notification that is sent when a cluster is
                created. This example can be applied for any <code class="literal">create</code>, <code class="literal">update</code> or
                <code class="literal">delete</code> event that is seen in the table above. The <code class="literal">&lt;action&gt;</code> and
                <code class="literal">typeURI</code> fields will be change.</p><div class="verbatim-wrap highlight javascript"><pre class="screen">{
    "event_type": "magnum.cluster.created",
    "message_id": "0156ee79-b35f-4cef-ac37-d4a85f231c69",
    "payload": {
        "typeURI": "http://schemas.dmtf.org/cloud/audit/1.0/event",
        "initiator": {
            "typeURI": "service/security/account/user",
            "id": "c9f76d3c31e142af9291de2935bde98a",
            "user_id": "0156ee79-b35f-4cef-ac37-d4a85f231c69",
            "project_id": "3d4a50a9-2b59-438b-bf19-c231f9c7625a"
        },
        "target": {
            "typeURI": "service/magnum/cluster",
            "id": "openstack:1c2fc591-facb-4479-a327-520dade1ea15"
        },
        "observer": {
            "typeURI": "service/magnum/cluster",
            "id": "openstack:3d4a50a9-2b59-438b-bf19-c231f9c7625a"
        },
        "eventType": "activity",
        "eventTime": "2015-05-20T01:20:47.932842+00:00",
        "action": "create",
        "outcome": "success",
        "id": "openstack:f5352d7b-bee6-4c22-8213-450e7b646e9f",
        "resource_info": "671da331c47d4e29bb6ea1d270154ec3"
    }
    "priority": "INFO",
    "publisher_id": "magnum.host1234",
    "timestamp": "2016-05-20 15:03:45.960280"
}</pre></div></div></div><div class="sect1" id="id-1.7.47"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.46 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Container Monitoring</span> <a title="Permalink" class="permalink" href="#id-1.7.47">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#container-monitoring</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>The offered monitoring stack relies on the following set of containers and
            services:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>cAdvisor</p></li><li class="listitem "><p>Node Exporter</p></li><li class="listitem "><p>Prometheus</p></li><li class="listitem "><p>Grafana</p></li></ul></div><p>To setup this monitoring stack, users are given two configurable labels in
            the Magnum cluster template’s definition:</p><div class="variablelist "><dl class="variablelist"><dt id="id-1.7.47.5.1"><span class="term "></span></dt><dd><p>This label accepts a boolean value. If <span class="emphasis"><em>True</em></span>, the monitoring stack will be
                        setup. By default <span class="emphasis"><em>prometheus_monitoring = False</em></span>.</p></dd><dt id="id-1.7.47.5.2"><span class="term "></span></dt><dd><p>This label lets users create their own <span class="emphasis"><em>admin</em></span> user password for the Grafana
                        interface. It expects a string value. By default it is set to <span class="emphasis"><em>admin</em></span>.</p></dd></dl></div><div class="sect2" id="id-1.7.47.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.46.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Container Monitoring in Kubernetes</span> <a title="Permalink" class="permalink" href="#id-1.7.47.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#container-monitoring</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>By default, all Kubernetes clusters already contain <span class="emphasis"><em>cAdvisor</em></span> integrated
                with the <span class="emphasis"><em>Kubelet</em></span> binary. Its container monitoring data can be accessed on
                a node level basis through <span class="emphasis"><em>http://NODE_IP:4194</em></span>.</p><p>Node Exporter is part of the above mentioned monitoring stack as it can be
                used to export machine metrics. Such functionality also work on a node level
                which means that when <code class="literal">prometheus-monitoring</code> is <span class="emphasis"><em>True</em></span>, the Kubernetes nodes
                will be populated with an additional manifest under
                <span class="emphasis"><em>/etc/kubernetes/manifests</em></span>. Node Exporter is then automatically picked up
                and launched as a regular Kubernetes POD.</p><p>To aggregate and complement all the existing monitoring metrics and add a
                built-in visualization layer, Prometheus is used. It is launched by the
                Kubernetes master node(s) as a <span class="emphasis"><em>Service</em></span> within a <span class="emphasis"><em>Deployment</em></span> with one
                replica and it relies on a <span class="emphasis"><em>ConfigMap</em></span> where the Prometheus configuration
                (prometheus.yml) is defined. This configuration uses Prometheus native
                support for service discovery in Kubernetes clusters,
                <span class="emphasis"><em>kubernetes_sd_configs</em></span>. The respective manifests can be found in
                <span class="emphasis"><em>/srv/kubernetes/monitoring/</em></span> on the master nodes and once the service is
                up and running, Prometheus UI can be accessed through port 9090.</p><p>Finally, for custom plotting and enhanced metric aggregation and
                visualization, Prometheus can be integrated with Grafana as it provides
                native compliance for Prometheus data sources. Also Grafana is deployed as
                a <span class="emphasis"><em>Service</em></span> within a <span class="emphasis"><em>Deployment</em></span> with one replica. The default user is
                <span class="emphasis"><em>admin</em></span> and the password is setup according to <code class="literal">grafana-admin-passwd</code>.
                There is also a default Grafana dashboard provided with this installation,
                from the official <a class="link" href="https://grafana.net/dashboards" target="_blank">Grafana dashboards’ repository</a>. The Prometheus data
                source is automatically added to Grafana once it is up and running, pointing
                to <span class="emphasis"><em>http://prometheus:9090</em></span> through <span class="emphasis"><em>Proxy</em></span>. The respective manifests can
                also be found in <span class="emphasis"><em>/srv/kubernetes/monitoring/</em></span> on the master nodes and once
                the service is running, the Grafana dashboards can be accessed through port
                3000.</p><p>For both Prometheus and Grafana, there is an assigned <span class="emphasis"><em>systemd</em></span> service
                called <span class="emphasis"><em>kube-enable-monitoring</em></span>.</p></div></div><div class="sect1" id="id-1.7.48"><div class="titlepage"><div><div><h2 class="title"><span class="number">5.47 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Kubernetes External Load Balancer</span> <a title="Permalink" class="permalink" href="#id-1.7.48">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#id7</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>In a Kubernetes cluster, all masters and minions are connected to a private
            Neutron subnet, which in turn is connected by a router to the public network.
            This allows the nodes to access each other and the external internet.</p><p>All Kubernetes pods and services created in the cluster are connected to a
            private container network which by default is Flannel, an overlay network that
            runs on top of the Neutron private subnet.  The pods and services are assigned
            IP addresses from this container network and they can access each other and
            the external internet.  However, these IP addresses are not accessible from an
            external network.</p><p>To publish a service endpoint externally so that the service can be accessed
            from the external network, Kubernetes provides the external load balancer
            feature.  This is done by simply specifying the attribute “type: LoadBalancer”
            in the service manifest.  When the service is created, Kubernetes will add an
            external load balancer in front of the service so that the service will have
            an external IP address in addition to the internal IP address on the container
            network.  The service endpoint can then be accessed with this external IP
            address.  Refer to the <a class="link" href="https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer" target="_blank">Kubernetes service document</a> for more details.</p><p>A Kubernetes cluster deployed by Magnum will have all the necessary
            configuration required for the external load balancer.  This document describes
            how to use this feature.</p><div class="sect2" id="id-1.7.48.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.47.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Steps for the cluster administrator</span> <a title="Permalink" class="permalink" href="#id-1.7.48.6">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#id7</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Because the Kubernetes master needs to interface with OpenStack to create and
                manage the Neutron load balancer, we need to provide a credential for
                Kubernetes to use.</p><p>In the current implementation, the cluster administrator needs to manually
                perform this step.  We are looking into several ways to let Magnum automate
                this step in a secure manner.  This means that after the Kubernetes cluster is
                initially deployed, the load balancer support is disabled.  If the
                administrator does not want to enable this feature, no further action is
                required.  All the services will be created normally; services that specify the
                load balancer will also be created successfully, but a load balancer will not
                be created.</p><p>Note that different versions of Kubernetes require different versions of
                Neutron LBaaS plugin running on the OpenStack instance:</p><div class="verbatim-wrap"><pre class="screen">============================  ==============================
Kubernetes Version on Master  Neutron LBaaS Version Required
============================  ==============================
1.2                           LBaaS v1
1.3 or later                  LBaaS v2
============================  ==============================</pre></div><p>Before enabling the Kubernetes load balancer feature, confirm that the
                OpenStack instance is running the required version of Neutron LBaaS plugin.
                To determine if your OpenStack instance is running LBaaS v1, try running
                the following command from your OpenStack control node:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-pool-list</pre></div><p>Or look for the following configuration in neutron.conf or
                neutron_lbaas.conf:</p><div class="verbatim-wrap"><pre class="screen">service_provider = LOADBALANCER:Haproxy:neutron_lbaas.services.loadbalancer.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default</pre></div><p>To determine if your OpenStack instance is running LBaaS v2, try running
                the following command from your OpenStack control node:</p><div class="verbatim-wrap"><pre class="screen">neutron lbaas-pool-list</pre></div><p>Or look for the following configuration in neutron.conf or
                neutron_lbaas.conf:</p><div class="verbatim-wrap"><pre class="screen">service_plugins = neutron.plugins.services.agent_loadbalancer.plugin.LoadBalancerPluginv2</pre></div><p>To configure LBaaS v1 or v2, refer to the Neutron documentation.</p><p>Before deleting the Kubernetes cluster, make sure to
                delete all the services that created load balancers. Because the Neutron
                objects created by Kubernetes are not managed by Heat, they will not be
                deleted by Heat and this will cause the cluster-delete operation to fail. If
                this occurs, delete the neutron objects manually (lb-pool, lb-vip, lb-member,
                lb-healthmonitor) and then run cluster-delete again.</p></div><div class="sect2" id="id-1.7.48.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.47.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Steps for the users</span> <a title="Permalink" class="permalink" href="#id-1.7.48.7">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#id7</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>This feature requires the OpenStack cloud provider to be enabled.
                To do so, enable the cinder support (–volume-driver cinder).</p><p>For the user, publishing the service endpoint externally involves the following
                2 steps:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Specify “type: LoadBalancer” in the service manifest</p></li><li class="step "><p>After the service is created, associate a floating IP with the VIP of the
                        load balancer pool.</p></li></ol></div></div><p>The following example illustrates how to create an external endpoint for
                a pod running nginx.</p><p>Create a file (e.g nginx.yaml) describing a pod running nginx:</p><div class="verbatim-wrap"><pre class="screen">apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
   app: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80</pre></div><p>Create a file (e.g nginx-service.yaml) describing a service for the nginx pod:</p><div class="verbatim-wrap"><pre class="screen">apiVersion: v1
kind: Service
metadata:
  name: nginxservice
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
  selector:
    app: nginx
  type: LoadBalancer</pre></div><p>Please refer to the <a class="link" href="https://docs.openstack.org/developer/magnum/userguide.html" target="_blank">quickstart</a> guide on how to connect to Kubernetes running on the launched
                cluster. Assuming a Kubernetes cluster named k8sclusterv1 has been created,
                deploy the pod and service using following commands:</p><div class="verbatim-wrap"><pre class="screen">kubectl create -f nginx.yaml

kubectl create -f nginx-service.yaml</pre></div><p>For more details on verifying the load balancer in OpenStack, refer to the
                following section on how it works.</p><p>Next, associate a floating IP to the load balancer.  This can be done easily
                on Horizon by navigating to:</p><div class="verbatim-wrap"><pre class="screen">Compute -&gt; Access &amp; Security -&gt; Floating IPs</pre></div><p>Click on “Allocate IP To Project” and then on “Associate” for the new floating
                IP.</p><p>Alternatively, associating a floating IP can be done on the command line by
                allocating a floating IP, finding the port of the VIP, and associating the
                floating IP to the port.
                The commands shown below are for illustration purpose and assume
                that there is only one service with load balancer running in the cluster and
                no other load balancers exist except for those created for the cluster.</p><p>First create a floating IP on the public network:</p><div class="verbatim-wrap"><pre class="screen">neutron floatingip-create public

Created a new floatingip:

+---------------------+--------------------------------------+
| Field               | Value                                |
+---------------------+--------------------------------------+
| fixed_ip_address    |                                      |
| floating_ip_address | 172.24.4.78                          |
| floating_network_id | 4808eacb-e1a0-40aa-97b6-ecb745af2a4d |
| id                  | b170eb7a-41d0-4c00-9207-18ad1c30fecf |
| port_id             |                                      |
| router_id           |                                      |
| status              | DOWN                                 |
| tenant_id           | 012722667dc64de6bf161556f49b8a62     |
+---------------------+--------------------------------------+</pre></div><p>Note the floating IP 172.24.4.78 that has been allocated.  The ID for this
                floating IP is shown above, but it can also be queried by:</p><div class="verbatim-wrap"><pre class="screen">FLOATING_XML:ID=$(neutron floatingip-list | grep "172.24.4.78" | awk '{print $2}')</pre></div><p>Next find the VIP for the load balancer:</p><div class="verbatim-wrap"><pre class="screen">VIP_XML:ID=$(neutron lb-vip-list | grep TCP | grep -v pool | awk '{print $2}')</pre></div><p>Find the port for this VIP:</p><div class="verbatim-wrap"><pre class="screen">PORT_XML:ID=$(neutron lb-vip-show $VIP_ID | grep port_id | awk '{print $4}')</pre></div><p>Finally associate the floating IP with the port of the VIP:</p><div class="verbatim-wrap"><pre class="screen">neutron floatingip-associate $FLOATING_ID $PORT_ID</pre></div><p>The endpoint for nginx can now be accessed on a browser at this floating IP:</p><div class="verbatim-wrap"><pre class="screen">http://172.24.4.78:80</pre></div><p>Alternatively, you can check for the nginx ‘welcome’ message by:</p><div class="verbatim-wrap"><pre class="screen">curl http://172.24.4.78:80</pre></div><p>NOTE: it is not necessary to indicate port :80 here but it is shown to
                correlate with the port that was specified in the service manifest.</p></div><div class="sect2" id="id-1.7.48.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">5.47.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How it works</span> <a title="Permalink" class="permalink" href="#id-1.7.48.8">#</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user/index#id7</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>Kubernetes is designed to work with different Clouds such as Google Compute
                Engine (GCE), Amazon Web Services (AWS), and OpenStack;  therefore, different
                load balancers need to be created on the particular Cloud for the services.
                This is done through a plugin for each Cloud and the OpenStack plugin was
                developed by Angus Lees:</p><div class="verbatim-wrap"><pre class="screen">https://github.com/kubernetes/kubernetes/blob/release-1.0/pkg/cloudprovider/openstack/openstack.go</pre></div><p>When the Kubernetes components kube-apiserver and kube-controller-manager start
                up, they will use the credential provided to authenticate a client
                to interface with OpenStack.</p><p>When a service with load balancer is created, the plugin code will interface
                with Neutron in this sequence:</p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>Create lb-pool for the Kubernetes service</p></li><li class="step "><p>Create lb-member for the minions</p></li><li class="step "><p>Create lb-healthmonitor</p></li><li class="step "><p>Create lb-vip on the private network of the Kubernetes cluster</p></li></ol></div></div><p>These Neutron objects can be verified as follows.  For the load balancer pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-pool-list
+--------------------------------------+--------------------------------------------------+----------+-------------+----------+----------------+--------+
| id                                   | name                                             | provider | lb_method   | protocol | admin_state_up | status |
+--------------------------------------+--------------------------------------------------+----------+-------------+----------+----------------+--------+
| 241357b3-2a8f-442e-b534-bde7cd6ba7e4 | a1f03e40f634011e59c9efa163eae8ab                 | haproxy  | ROUND_ROBIN | TCP      | True           | ACTIVE |
| 82b39251-1455-4eb6-a81e-802b54c2df29 | k8sclusterv1-iypacicrskib-api_pool-fydshw7uvr7h  | haproxy  | ROUND_ROBIN | HTTP     | True           | ACTIVE |
| e59ea983-c6e8-4cec-975d-89ade6b59e50 | k8sclusterv1-iypacicrskib-etcd_pool-qbpo43ew2m3x | haproxy  | ROUND_ROBIN | HTTP     | True           | ACTIVE |
+--------------------------------------+--------------------------------------------------+----------+-------------+----------+----------------+--------+</pre></div><p>Note that 2 load balancers already exist to implement high availability for the
                cluster (api and ectd). The new load balancer for the Kubernetes service uses
                the TCP protocol and has a name assigned by Kubernetes.</p><p>For the members of the pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-member-list
+--------------------------------------+----------+---------------+--------+----------------+--------+
| id                                   | address  | protocol_port | weight | admin_state_up | status |
+--------------------------------------+----------+---------------+--------+----------------+--------+
| 9ab7dcd7-6e10-4d9f-ba66-861f4d4d627c | 10.0.0.5 |          8080 |      1 | True           | ACTIVE |
| b179c1ad-456d-44b2-bf83-9cdc127c2b27 | 10.0.0.5 |          2379 |      1 | True           | ACTIVE |
| f222b60e-e4a9-4767-bc44-ffa66ec22afe | 10.0.0.6 |         31157 |      1 | True           | ACTIVE |
+--------------------------------------+----------+---------------+--------+----------------+--------+</pre></div><p>Again, 2 members already exist for high availability and they serve the master
                node at 10.0.0.5. The new member serves the minion at 10.0.0.6, which hosts the
                Kubernetes service.</p><p>For the monitor of the pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-healthmonitor-list
+--------------------------------------+------+----------------+
| id                                   | type | admin_state_up |
+--------------------------------------+------+----------------+
| 381d3d35-7912-40da-9dc9-b2322d5dda47 | TCP  | True           |
| 67f2ae8f-ffc6-4f86-ba5f-1a135f4af85c | TCP  | True           |
| d55ff0f3-9149-44e7-9b52-2e055c27d1d3 | TCP  | True           |
+--------------------------------------+------+----------------+</pre></div><p>For the VIP of the pool:</p><div class="verbatim-wrap"><pre class="screen">neutron lb-vip-list
+--------------------------------------+----------------------------------+----------+----------+----------------+--------+
| id                                   | name                             | address  | protocol | admin_state_up | status |
+--------------------------------------+----------------------------------+----------+----------+----------------+--------+
| 9ae2ebfb-b409-4167-9583-4a3588d2ff42 | api_pool.vip                     | 10.0.0.3 | HTTP     | True           | ACTIVE |
| c318aec6-8b7b-485c-a419-1285a7561152 | a1f03e40f634011e59c9efa163eae8ab | 10.0.0.7 | TCP      | True           | ACTIVE |
| fc62cf40-46ad-47bd-aa1e-48339b95b011 | etcd_pool.vip                    | 10.0.0.4 | HTTP     | True           | ACTIVE |
+--------------------------------------+----------------------------------+----------+----------+----------------+--------+</pre></div><p>Note that the VIP is created on the private network of the cluster;  therefore
                it has an internal IP address of 10.0.0.7.  This address is also associated as
                the “external address” of the Kubernetes service.  You can verify this in
                Kubernetes by running following command:</p><div class="verbatim-wrap"><pre class="screen">kubectl get services
NAME           LABELS                                    SELECTOR    IP(S)            PORT(S)
kubernetes     component=apiserver,provider=kubernetes   &lt;none&gt;      10.254.0.1       443/TCP
nginxservice   app=nginx                                 app=nginx   10.254.122.191   80/TCP
                                                                     10.0.0.7</pre></div><p>On GCE, the networking implementation gives the load balancer an external
                address automatically. On OpenStack, we need to take the additional step of
                associating a floating IP to the load balancer.</p></div></div></div><div class="chapter " id="nova-user-guide"><div class="titlepage"><div><div><h1 class="title"><span class="number">6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Nova User Guide</span> <a title="Permalink" class="permalink" href="#nova-user-guide">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-nova.xml</li><li><span class="ds-label">ID: </span>nova-user-guide</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="#tools-for-using-nova"><span class="number">6.1 </span><span class="name">Tools for using Nova</span></a></span></dt><dt><span class="section"><a href="#writing-to-the-api"><span class="number">6.2 </span><span class="name">Writing to the API</span></a></span></dt></dl></div></div><p>As an end user of nova, you'll use nova to create and manage servers with
                either tools or the API directly.</p><div class="sect1" id="tools-for-using-nova"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Tools for using Nova</span> <a title="Permalink" class="permalink" href="#tools-for-using-nova">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-nova.xml</li><li><span class="ds-label">ID: </span>tools-for-using-nova</li></ul></div></div></div></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><a class="link" href="https://docs.openstack.org/horizon/pike/user/launch-instances.html" target="_blank">Horizon</a>: The
                            official web UI for the OpenStack Project.</p></li><li class="listitem "><p><a class="link" href="https://docs.openstack.org/python-openstackclient/pike/" target="_blank">OpenStack Client</a>: The official
                            CLI for OpenStack Projects. You should use this as your CLI for most OpenStack operations,
                            as it includes commands for most of the projects in OpenStack.</p></li><li class="listitem "><p><a class="link" href="https://docs.openstack.org/python-novaclient/pike/user/shell.html" target="_blank">Nova Client</a>: For
                            some very advanced features (or administrative commands) of nova you may need
                            to use nova client. It is still supported, but we recommend the <code class="literal">openstack</code> CLI.</p></li></ul></div></div><div class="sect1" id="writing-to-the-api"><div class="titlepage"><div><div><h2 class="title"><span class="number">6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Writing to the API</span> <a title="Permalink" class="permalink" href="#writing-to-the-api">#</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>user-nova.xml</li><li><span class="ds-label">ID: </span>writing-to-the-api</li></ul></div></div></div></div><p>All end user (and some administrative) features of nova are exposed via a REST
                    API, which can be used to build more complicated logic or automation with
                    nova. This can be consumed directly, or via various SDKs. The following
                    resources will help you get started with consuming the API directly.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><a class="link" href="https://developer.openstack.org/api-guide/compute/" target="_blank">Compute API Guide:</a>: The
                            concept guide for the API. This helps lay out the concepts behind the API to
                            make consuming the API reference easier.</p></li><li class="listitem "><p><a class="link" href="http://developer.openstack.org/api-ref/compute/" target="_blank">Compute API Reference</a>:
                            The complete reference for the API, including all methods, request, and
                            response parameters and their meaning.</p></li><li class="listitem "><p>The compute API evolves over time through <a class="link" href="https://developer.openstack.org/api-guide/compute/microversions.html" target="_blank">Microversions</a>. This
                provides the history of all those changes. Consider it a "what's new" in the
                compute API.</p></li><li class="listitem "><p><a class="link" href="https://docs.openstack.org/nova/pike/user/block-device-mapping.html" target="_blank">Block Device Mapping</a>:
                One of the trickier parts to understand is the Block Device Mapping parameters used to connect
                specific block devices to computes. This deserves its own deep dive.</p></li><li class="listitem "><p><a class="link" href="https://docs.openstack.org/nova/pike/user/config-drive.html" target="_blank">Store metadata on a configuration drive</a>:
                Provide information to the guest instance when it is created.</p></li></ul></div></div></div><div xml:lang="en" class="glossary" lang="en"><div class="titlepage"><div><div><h1 class="title"><span class="number"> </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Glossary</span> <a title="Permalink" class="permalink" href="#id-1.9">#</a></h1><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>openstack_glossary.xml</li><li><span class="ds-label">ID: </span>book-upstream-user</li></ul></div></div></div></div><div class="line"></div><p>This glossary offers a list of terms and definitions to define a
vocabulary for OpenStack-related concepts.</p><p>To add to OpenStack glossary, clone the <a class="link" href="https://git.openstack.org/cgit/openstack/openstack-manuals" target="_blank">openstack/openstack-manuals
repository</a> and
update the source file <code class="literal">doc/common/glossary.rst</code> through the
OpenStack contribution process.</p><div class="glossdiv" id="id-1.9.5"><h3 class="title">0-9</h3><dl><dt id="id-1.9.5.3"><span><span class="glossterm">6to4</span> <a title="Permalink" class="permalink" href="#id-1.9.5.3">#</a></span></dt><dd class="glossdef"><p>A mechanism that allows IPv6 packets to be transmitted
over an IPv4 network, providing a strategy for migrating to
IPv6.</p></dd></dl></div><div class="glossdiv" id="id-1.9.6"><h3 class="title">A</h3><dl><dt id="id-1.9.6.3"><span><span class="glossterm">absolute limit</span> <a title="Permalink" class="permalink" href="#id-1.9.6.3">#</a></span></dt><dd class="glossdef"><p>Impassable limits for guest VMs. Settings include total RAM
size, maximum number of vCPUs, and maximum disk size.</p></dd><dt id="id-1.9.6.4"><span><span class="glossterm">access control list (ACL)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.4">#</a></span></dt><dd class="glossdef"><p>A list of permissions attached to an object. An ACL specifies
which users or system processes have access to objects. It also
defines which operations can be performed on specified objects. Each
entry in a typical ACL specifies a subject and an operation. For
instance, the ACL entry <code class="literal">(Alice, delete)</code> for a file gives
Alice permission to delete the file.</p></dd><dt id="id-1.9.6.5"><span><span class="glossterm">access key</span> <a title="Permalink" class="permalink" href="#id-1.9.6.5">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Amazon EC2 access key. See EC2 access
key.</p></dd><dt id="id-1.9.6.6"><span><span class="glossterm">account</span> <a title="Permalink" class="permalink" href="#id-1.9.6.6">#</a></span></dt><dd class="glossdef"><p>The Object Storage context of an account. Do not confuse with a
user account from an authentication service, such as Active Directory,
/etc/passwd, OpenLDAP, OpenStack Identity, and so on.</p></dd><dt id="id-1.9.6.7"><span><span class="glossterm">account auditor</span> <a title="Permalink" class="permalink" href="#id-1.9.6.7">#</a></span></dt><dd class="glossdef"><p>Checks for missing replicas and incorrect or corrupted objects
in a specified Object Storage account by running queries against the
back-end SQLite database.</p></dd><dt id="id-1.9.6.8"><span><span class="glossterm">account database</span> <a title="Permalink" class="permalink" href="#id-1.9.6.8">#</a></span></dt><dd class="glossdef"><p>A SQLite database that contains Object Storage accounts and
related metadata and that the accounts server accesses.</p></dd><dt id="id-1.9.6.9"><span><span class="glossterm">account reaper</span> <a title="Permalink" class="permalink" href="#id-1.9.6.9">#</a></span></dt><dd class="glossdef"><p>An Object Storage worker that scans for and deletes account
databases and that the account server has marked for deletion.</p></dd><dt id="id-1.9.6.10"><span><span class="glossterm">account server</span> <a title="Permalink" class="permalink" href="#id-1.9.6.10">#</a></span></dt><dd class="glossdef"><p>Lists containers in Object Storage and stores container
information in the account database.</p></dd><dt id="id-1.9.6.11"><span><span class="glossterm">account service</span> <a title="Permalink" class="permalink" href="#id-1.9.6.11">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that provides account services such
as list, create, modify, and audit. Do not confuse with OpenStack
Identity service, OpenLDAP, or similar user-account services.</p></dd><dt id="id-1.9.6.12"><span><span class="glossterm">accounting</span> <a title="Permalink" class="permalink" href="#id-1.9.6.12">#</a></span></dt><dd class="glossdef"><p>The Compute service provides accounting information through the
event notification and system usage data facilities.</p></dd><dt id="id-1.9.6.13"><span><span class="glossterm">Active Directory</span> <a title="Permalink" class="permalink" href="#id-1.9.6.13">#</a></span></dt><dd class="glossdef"><p>Authentication and identity service by Microsoft, based on LDAP.
Supported in OpenStack.</p></dd><dt id="id-1.9.6.14"><span><span class="glossterm">active/active configuration</span> <a title="Permalink" class="permalink" href="#id-1.9.6.14">#</a></span></dt><dd class="glossdef"><p>In a high-availability setup with an active/active
configuration, several systems share the load together and if one
fails, the load is distributed to the remaining systems.</p></dd><dt id="id-1.9.6.15"><span><span class="glossterm">active/passive configuration</span> <a title="Permalink" class="permalink" href="#id-1.9.6.15">#</a></span></dt><dd class="glossdef"><p>In a high-availability setup with an active/passive
configuration, systems are set up to bring additional resources online
to replace those that have failed.</p></dd><dt id="id-1.9.6.16"><span><span class="glossterm">address pool</span> <a title="Permalink" class="permalink" href="#id-1.9.6.16">#</a></span></dt><dd class="glossdef"><p>A group of fixed and/or floating IP addresses that are assigned
to a project and can be used by or assigned to the VM instances in a
project.</p></dd><dt id="id-1.9.6.17"><span><span class="glossterm">Address Resolution Protocol (ARP)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.17">#</a></span></dt><dd class="glossdef"><p>The protocol by which layer-3 IP addresses are resolved into
layer-2 link local addresses.</p></dd><dt id="id-1.9.6.18"><span><span class="glossterm">admin API</span> <a title="Permalink" class="permalink" href="#id-1.9.6.18">#</a></span></dt><dd class="glossdef"><p>A subset of API calls that are accessible to authorized
administrators and are generally not accessible to end users or the
public Internet. They can exist as a separate service (keystone) or
can be a subset of another API (nova).</p></dd><dt id="id-1.9.6.19"><span><span class="glossterm">admin server</span> <a title="Permalink" class="permalink" href="#id-1.9.6.19">#</a></span></dt><dd class="glossdef"><p>In the context of the Identity service, the worker process that
provides access to the admin API.</p></dd><dt id="id-1.9.6.20"><span><span class="glossterm">administrator</span> <a title="Permalink" class="permalink" href="#id-1.9.6.20">#</a></span></dt><dd class="glossdef"><p>The person responsible for installing, configuring,
and managing an OpenStack cloud.</p></dd><dt id="id-1.9.6.21"><span><span class="glossterm">Advanced Message Queuing Protocol (AMQP)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.21">#</a></span></dt><dd class="glossdef"><p>The open standard messaging protocol used by OpenStack
components for intra-service communications, provided by RabbitMQ,
Qpid, or ZeroMQ.</p></dd><dt id="id-1.9.6.22"><span><span class="glossterm">Advanced RISC Machine (ARM)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.22">#</a></span></dt><dd class="glossdef"><p>Lower power consumption CPU often found in mobile and embedded
devices. Supported by OpenStack.</p></dd><dt id="id-1.9.6.23"><span><span class="glossterm">alert</span> <a title="Permalink" class="permalink" href="#id-1.9.6.23">#</a></span></dt><dd class="glossdef"><p>The Compute service can send alerts through its notification
system, which includes a facility to create custom notification
drivers. Alerts can be sent to and displayed on the dashboard.</p></dd><dt id="id-1.9.6.24"><span><span class="glossterm">allocate</span> <a title="Permalink" class="permalink" href="#id-1.9.6.24">#</a></span></dt><dd class="glossdef"><p>The process of taking a floating IP address from the address
pool so it can be associated with a fixed IP on a guest VM
instance.</p></dd><dt id="id-1.9.6.25"><span><span class="glossterm">Amazon Kernel Image (AKI)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.25">#</a></span></dt><dd class="glossdef"><p>Both a VM container format and disk format. Supported by Image
service.</p></dd><dt id="id-1.9.6.26"><span><span class="glossterm">Amazon Machine Image (AMI)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.26">#</a></span></dt><dd class="glossdef"><p>Both a VM container format and disk format. Supported by Image
service.</p></dd><dt id="id-1.9.6.27"><span><span class="glossterm">Amazon Ramdisk Image (ARI)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.27">#</a></span></dt><dd class="glossdef"><p>Both a VM container format and disk format. Supported by Image
service.</p></dd><dt id="id-1.9.6.28"><span><span class="glossterm">Anvil</span> <a title="Permalink" class="permalink" href="#id-1.9.6.28">#</a></span></dt><dd class="glossdef"><p>A project that ports the shell script-based project named
DevStack to Python.</p></dd><dt id="id-1.9.6.29"><span><span class="glossterm">aodh</span> <a title="Permalink" class="permalink" href="#id-1.9.6.29">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; provides alarming functionality.</p></dd><dt id="id-1.9.6.30"><span><span class="glossterm">Apache</span> <a title="Permalink" class="permalink" href="#id-1.9.6.30">#</a></span></dt><dd class="glossdef"><p>The Apache Software Foundation supports the Apache community of
open-source software projects. These projects provide software
products for the public good.</p></dd><dt id="id-1.9.6.31"><span><span class="glossterm">Apache License 2.0</span> <a title="Permalink" class="permalink" href="#id-1.9.6.31">#</a></span></dt><dd class="glossdef"><p>All OpenStack core projects are provided under the terms of the
Apache License 2.0 license.</p></dd><dt id="id-1.9.6.32"><span><span class="glossterm">Apache Web Server</span> <a title="Permalink" class="permalink" href="#id-1.9.6.32">#</a></span></dt><dd class="glossdef"><p>The most common web server software currently used on the
Internet.</p></dd><dt id="id-1.9.6.33"><span><span class="glossterm">API endpoint</span> <a title="Permalink" class="permalink" href="#id-1.9.6.33">#</a></span></dt><dd class="glossdef"><p>The daemon, worker, or service that a client communicates with
to access an API. API endpoints can provide any number of services,
such as authentication, sales data, performance meters, Compute VM
commands, census data, and so on.</p></dd><dt id="id-1.9.6.34"><span><span class="glossterm">API extension</span> <a title="Permalink" class="permalink" href="#id-1.9.6.34">#</a></span></dt><dd class="glossdef"><p>Custom modules that extend some OpenStack core APIs.</p></dd><dt id="id-1.9.6.35"><span><span class="glossterm">API extension plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.6.35">#</a></span></dt><dd class="glossdef"><p>Alternative term for a Networking plug-in or Networking API
extension.</p></dd><dt id="id-1.9.6.36"><span><span class="glossterm">API key</span> <a title="Permalink" class="permalink" href="#id-1.9.6.36">#</a></span></dt><dd class="glossdef"><p>Alternative term for an API token.</p></dd><dt id="id-1.9.6.37"><span><span class="glossterm">API server</span> <a title="Permalink" class="permalink" href="#id-1.9.6.37">#</a></span></dt><dd class="glossdef"><p>Any node running a daemon or worker that provides an API
endpoint.</p></dd><dt id="id-1.9.6.38"><span><span class="glossterm">API token</span> <a title="Permalink" class="permalink" href="#id-1.9.6.38">#</a></span></dt><dd class="glossdef"><p>Passed to API requests and used by OpenStack to verify that the
client is authorized to run the requested operation.</p></dd><dt id="id-1.9.6.39"><span><span class="glossterm">API version</span> <a title="Permalink" class="permalink" href="#id-1.9.6.39">#</a></span></dt><dd class="glossdef"><p>In OpenStack, the API version for a project is part of the URL.
For example, <code class="literal">example.com/nova/v1/foobar</code>.</p></dd><dt id="id-1.9.6.40"><span><span class="glossterm">applet</span> <a title="Permalink" class="permalink" href="#id-1.9.6.40">#</a></span></dt><dd class="glossdef"><p>A Java program that can be embedded into a web page.</p></dd><dt id="term-application-catalog-service-murano"><span><span class="glossterm">Application Catalog service (murano)</span> <a title="Permalink" class="permalink" href="#term-application-catalog-service-murano">#</a></span></dt><dd class="glossdef"><p>The project that provides an application catalog service so that users
can compose and deploy composite environments on an application
abstraction level while managing the application lifecycle.</p></dd><dt id="term-application-programming-interface-api"><span><span class="glossterm">Application Programming Interface (API)</span> <a title="Permalink" class="permalink" href="#term-application-programming-interface-api">#</a></span></dt><dd class="glossdef"><p>A collection of specifications used to access a service,
application, or program. Includes service calls, required parameters
for each call, and the expected return values.</p></dd><dt id="id-1.9.6.43"><span><span class="glossterm">application server</span> <a title="Permalink" class="permalink" href="#id-1.9.6.43">#</a></span></dt><dd class="glossdef"><p>A piece of software that makes available another piece of
software over a network.</p></dd><dt id="id-1.9.6.44"><span><span class="glossterm">Application Service Provider (ASP)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.44">#</a></span></dt><dd class="glossdef"><p>Companies that rent specialized applications that help
businesses and organizations provide additional services
with lower cost.</p></dd><dt id="id-1.9.6.45"><span><span class="glossterm">arptables</span> <a title="Permalink" class="permalink" href="#id-1.9.6.45">#</a></span></dt><dd class="glossdef"><p>Tool used for maintaining Address Resolution Protocol packet
filter rules in the Linux kernel firewall modules. Used along with
iptables, ebtables, and ip6tables in Compute to provide firewall
services for VMs.</p></dd><dt id="id-1.9.6.46"><span><span class="glossterm">associate</span> <a title="Permalink" class="permalink" href="#id-1.9.6.46">#</a></span></dt><dd class="glossdef"><p>The process associating a Compute floating IP address with a
fixed IP address.</p></dd><dt id="id-1.9.6.47"><span><span class="glossterm">Asynchronous JavaScript and XML (AJAX)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.47">#</a></span></dt><dd class="glossdef"><p>A group of interrelated web development techniques used on the
client-side to create asynchronous web applications. Used extensively
in horizon.</p></dd><dt id="id-1.9.6.48"><span><span class="glossterm">ATA over Ethernet (AoE)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.48">#</a></span></dt><dd class="glossdef"><p>A disk storage protocol tunneled within Ethernet.</p></dd><dt id="id-1.9.6.49"><span><span class="glossterm">attach</span> <a title="Permalink" class="permalink" href="#id-1.9.6.49">#</a></span></dt><dd class="glossdef"><p>The process of connecting a VIF or vNIC to a L2 network in
Networking. In the context of Compute, this process connects a storage
volume to an instance.</p></dd><dt id="id-1.9.6.50"><span><span class="glossterm">attachment (network)</span> <a title="Permalink" class="permalink" href="#id-1.9.6.50">#</a></span></dt><dd class="glossdef"><p>Association of an interface ID to a logical port. Plugs an
interface into a port.</p></dd><dt id="id-1.9.6.51"><span><span class="glossterm">auditing</span> <a title="Permalink" class="permalink" href="#id-1.9.6.51">#</a></span></dt><dd class="glossdef"><p>Provided in Compute through the system usage data
facility.</p></dd><dt id="id-1.9.6.52"><span><span class="glossterm">auditor</span> <a title="Permalink" class="permalink" href="#id-1.9.6.52">#</a></span></dt><dd class="glossdef"><p>A worker process that verifies the integrity of Object Storage
objects, containers, and accounts. Auditors is the collective term for
the Object Storage account auditor, container auditor, and object
auditor.</p></dd><dt id="id-1.9.6.53"><span><span class="glossterm">Austin</span> <a title="Permalink" class="permalink" href="#id-1.9.6.53">#</a></span></dt><dd class="glossdef"><p>The code name for the initial release of
OpenStack. The first design summit took place in
Austin, Texas, US.</p></dd><dt id="id-1.9.6.54"><span><span class="glossterm">auth node</span> <a title="Permalink" class="permalink" href="#id-1.9.6.54">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Object Storage authorization
node.</p></dd><dt id="id-1.9.6.55"><span><span class="glossterm">authentication</span> <a title="Permalink" class="permalink" href="#id-1.9.6.55">#</a></span></dt><dd class="glossdef"><p>The process that confirms that the user, process, or client is
really who they say they are through private key, secret token,
password, fingerprint, or similar method.</p></dd><dt id="id-1.9.6.56"><span><span class="glossterm">authentication token</span> <a title="Permalink" class="permalink" href="#id-1.9.6.56">#</a></span></dt><dd class="glossdef"><p>A string of text provided to the client after authentication.
Must be provided by the user or process in subsequent requests to the
API endpoint.</p></dd><dt id="id-1.9.6.57"><span><span class="glossterm">AuthN</span> <a title="Permalink" class="permalink" href="#id-1.9.6.57">#</a></span></dt><dd class="glossdef"><p>The Identity service component that provides authentication
services.</p></dd><dt id="id-1.9.6.58"><span><span class="glossterm">authorization</span> <a title="Permalink" class="permalink" href="#id-1.9.6.58">#</a></span></dt><dd class="glossdef"><p>The act of verifying that a user, process, or client is
authorized to perform an action.</p></dd><dt id="id-1.9.6.59"><span><span class="glossterm">authorization node</span> <a title="Permalink" class="permalink" href="#id-1.9.6.59">#</a></span></dt><dd class="glossdef"><p>An Object Storage node that provides authorization
services.</p></dd><dt id="id-1.9.6.60"><span><span class="glossterm">AuthZ</span> <a title="Permalink" class="permalink" href="#id-1.9.6.60">#</a></span></dt><dd class="glossdef"><p>The Identity component that provides high-level
authorization services.</p></dd><dt id="id-1.9.6.61"><span><span class="glossterm">Auto ACK</span> <a title="Permalink" class="permalink" href="#id-1.9.6.61">#</a></span></dt><dd class="glossdef"><p>Configuration setting within RabbitMQ that enables or disables
message acknowledgment. Enabled by default.</p></dd><dt id="id-1.9.6.62"><span><span class="glossterm">auto declare</span> <a title="Permalink" class="permalink" href="#id-1.9.6.62">#</a></span></dt><dd class="glossdef"><p>A Compute RabbitMQ setting that determines whether a message
exchange is automatically created when the program starts.</p></dd><dt id="id-1.9.6.63"><span><span class="glossterm">availability zone</span> <a title="Permalink" class="permalink" href="#id-1.9.6.63">#</a></span></dt><dd class="glossdef"><p>An Amazon EC2 concept of an isolated area that is used for fault
tolerance. Do not confuse with an OpenStack Compute zone or
cell.</p></dd><dt id="id-1.9.6.64"><span><span class="glossterm">AWS CloudFormation template</span> <a title="Permalink" class="permalink" href="#id-1.9.6.64">#</a></span></dt><dd class="glossdef"><p>AWS CloudFormation allows Amazon Web Services (AWS) users to create and manage a
collection of related resources. The Orchestration service
supports a CloudFormation-compatible format (CFN).</p></dd></dl></div><div class="glossdiv" id="id-1.9.7"><h3 class="title">B</h3><dl><dt id="id-1.9.7.3"><span><span class="glossterm">back end</span> <a title="Permalink" class="permalink" href="#id-1.9.7.3">#</a></span></dt><dd class="glossdef"><p>Interactions and processes that are obfuscated from the user,
such as Compute volume mount, data transmission to an iSCSI target by
a daemon, or Object Storage object integrity checks.</p></dd><dt id="id-1.9.7.4"><span><span class="glossterm">back-end catalog</span> <a title="Permalink" class="permalink" href="#id-1.9.7.4">#</a></span></dt><dd class="glossdef"><p>The storage method used by the Identity service catalog service
to store and retrieve information about API endpoints that are
available to the client. Examples include an SQL database, LDAP
database, or KVS back end.</p></dd><dt id="id-1.9.7.5"><span><span class="glossterm">back-end store</span> <a title="Permalink" class="permalink" href="#id-1.9.7.5">#</a></span></dt><dd class="glossdef"><p>The persistent data store used to save and retrieve information
for a service, such as lists of Object Storage objects, current state
of guest VMs, lists of user names, and so on. Also, the method that the
Image service uses to get and store VM images. Options include Object
Storage, locally mounted file system, RADOS block devices, VMware
datastore, and HTTP.</p></dd><dt id="term-backup-restore-and-disaster-recovery-service-freezer"><span><span class="glossterm">Backup, Restore, and Disaster Recovery service (freezer)</span> <a title="Permalink" class="permalink" href="#term-backup-restore-and-disaster-recovery-service-freezer">#</a></span></dt><dd class="glossdef"><p>The project that provides integrated tooling for backing up, restoring,
and recovering file systems, instances, or database backups.</p></dd><dt id="id-1.9.7.7"><span><span class="glossterm">bandwidth</span> <a title="Permalink" class="permalink" href="#id-1.9.7.7">#</a></span></dt><dd class="glossdef"><p>The amount of available data used by communication resources,
such as the Internet. Represents the amount of data that is used to
download things or the amount of data available to download.</p></dd><dt id="id-1.9.7.8"><span><span class="glossterm">barbican</span> <a title="Permalink" class="permalink" href="#id-1.9.7.8">#</a></span></dt><dd class="glossdef"><p>Code name of the <a class="xref" href="#term-key-manager-service-barbican" title="Key Manager service (barbican)">Key Manager service (barbican)</a>.</p></dd><dt id="id-1.9.7.9"><span><span class="glossterm">bare</span> <a title="Permalink" class="permalink" href="#id-1.9.7.9">#</a></span></dt><dd class="glossdef"><p>An Image service container format that indicates that no
container exists for the VM image.</p></dd><dt id="term-bare-metal-service-ironic"><span><span class="glossterm">Bare Metal service (ironic)</span> <a title="Permalink" class="permalink" href="#term-bare-metal-service-ironic">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provides a service and associated libraries
capable of managing and provisioning physical machines in a
security-aware and fault-tolerant manner.</p></dd><dt id="id-1.9.7.11"><span><span class="glossterm">base image</span> <a title="Permalink" class="permalink" href="#id-1.9.7.11">#</a></span></dt><dd class="glossdef"><p>An OpenStack-provided image.</p></dd><dt id="id-1.9.7.12"><span><span class="glossterm">Bell-LaPadula model</span> <a title="Permalink" class="permalink" href="#id-1.9.7.12">#</a></span></dt><dd class="glossdef"><p>A security model that focuses on data confidentiality
and controlled access to classified information.
This model divides the entities into subjects and objects.
The clearance of a subject is compared to the classification of the
object to determine if the subject is authorized for the specific access mode.
The clearance or classification scheme is expressed in terms of a lattice.</p></dd><dt id="term-benchmark-service-rally"><span><span class="glossterm">Benchmark service (rally)</span> <a title="Permalink" class="permalink" href="#term-benchmark-service-rally">#</a></span></dt><dd class="glossdef"><p>OpenStack project that provides a framework for
performance analysis and benchmarking of individual
OpenStack components as well as full production OpenStack
cloud deployments.</p></dd><dt id="id-1.9.7.14"><span><span class="glossterm">Bexar</span> <a title="Permalink" class="permalink" href="#id-1.9.7.14">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to
OpenStack that came out in February of 2011. It
included only Compute (nova) and Object Storage (swift).
Bexar is the code name for the second release of
OpenStack. The design summit took place in
San Antonio, Texas, US, which is the county seat for Bexar county.</p></dd><dt id="id-1.9.7.15"><span><span class="glossterm">binary</span> <a title="Permalink" class="permalink" href="#id-1.9.7.15">#</a></span></dt><dd class="glossdef"><p>Information that consists solely of ones and zeroes, which is
the language of computers.</p></dd><dt id="id-1.9.7.16"><span><span class="glossterm">bit</span> <a title="Permalink" class="permalink" href="#id-1.9.7.16">#</a></span></dt><dd class="glossdef"><p>A bit is a single digit number that is in base of 2 (either a
zero or one). Bandwidth usage is measured in bits per second.</p></dd><dt id="id-1.9.7.17"><span><span class="glossterm">bits per second (BPS)</span> <a title="Permalink" class="permalink" href="#id-1.9.7.17">#</a></span></dt><dd class="glossdef"><p>The universal measurement of how quickly data is transferred
from place to place.</p></dd><dt id="id-1.9.7.18"><span><span class="glossterm">block device</span> <a title="Permalink" class="permalink" href="#id-1.9.7.18">#</a></span></dt><dd class="glossdef"><p>A device that moves data in the form of blocks. These device
nodes interface the devices, such as hard disks, CD-ROM drives, flash
drives, and other addressable regions of memory.</p></dd><dt id="id-1.9.7.19"><span><span class="glossterm">block migration</span> <a title="Permalink" class="permalink" href="#id-1.9.7.19">#</a></span></dt><dd class="glossdef"><p>A method of VM live migration used by KVM to evacuate instances
from one host to another with very little downtime during a
user-initiated switchover. Does not require shared storage. Supported
by Compute.</p></dd><dt id="id-1.9.7.20"><span><span class="glossterm">Block Storage API</span> <a title="Permalink" class="permalink" href="#id-1.9.7.20">#</a></span></dt><dd class="glossdef"><p>An API on a separate endpoint for attaching,
detaching, and creating block storage for compute
VMs.</p></dd><dt id="term-block-storage-service-cinder"><span><span class="glossterm">Block Storage service (cinder)</span> <a title="Permalink" class="permalink" href="#term-block-storage-service-cinder">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that implement services and libraries to provide
on-demand, self-service access to Block Storage resources via abstraction
and automation on top of other block storage devices.</p></dd><dt id="id-1.9.7.22"><span><span class="glossterm">BMC (Baseboard Management Controller)</span> <a title="Permalink" class="permalink" href="#id-1.9.7.22">#</a></span></dt><dd class="glossdef"><p>The intelligence in the IPMI architecture, which is a specialized
micro-controller that is embedded on the motherboard of a computer
and acts as a server. Manages the interface between system management
software and platform hardware.</p></dd><dt id="id-1.9.7.23"><span><span class="glossterm">bootable disk image</span> <a title="Permalink" class="permalink" href="#id-1.9.7.23">#</a></span></dt><dd class="glossdef"><p>A type of VM image that exists as a single, bootable
file.</p></dd><dt id="id-1.9.7.24"><span><span class="glossterm">Bootstrap Protocol (BOOTP)</span> <a title="Permalink" class="permalink" href="#id-1.9.7.24">#</a></span></dt><dd class="glossdef"><p>A network protocol used by a network client to obtain an IP
address from a configuration server. Provided in Compute through the
dnsmasq daemon when using either the FlatDHCP manager or VLAN manager
network manager.</p></dd><dt id="id-1.9.7.25"><span><span class="glossterm">Border Gateway Protocol (BGP)</span> <a title="Permalink" class="permalink" href="#id-1.9.7.25">#</a></span></dt><dd class="glossdef"><p>The Border Gateway Protocol is a dynamic routing protocol
that connects autonomous systems.  Considered the
backbone of the Internet, this protocol connects disparate
networks to form a larger network.</p></dd><dt id="id-1.9.7.26"><span><span class="glossterm">browser</span> <a title="Permalink" class="permalink" href="#id-1.9.7.26">#</a></span></dt><dd class="glossdef"><p>Any client software that enables a computer or device to access
the Internet.</p></dd><dt id="id-1.9.7.27"><span><span class="glossterm">builder file</span> <a title="Permalink" class="permalink" href="#id-1.9.7.27">#</a></span></dt><dd class="glossdef"><p>Contains configuration information that Object Storage uses to
reconfigure a ring or to re-create it from scratch after a serious
failure.</p></dd><dt id="id-1.9.7.28"><span><span class="glossterm">bursting</span> <a title="Permalink" class="permalink" href="#id-1.9.7.28">#</a></span></dt><dd class="glossdef"><p>The practice of utilizing a secondary environment to
elastically build instances on-demand when the primary
environment is resource constrained.</p></dd><dt id="id-1.9.7.29"><span><span class="glossterm">button class</span> <a title="Permalink" class="permalink" href="#id-1.9.7.29">#</a></span></dt><dd class="glossdef"><p>A group of related button types within horizon. Buttons to
start, stop, and suspend VMs are in one class. Buttons to associate
and disassociate floating IP addresses are in another class, and so
on.</p></dd><dt id="id-1.9.7.30"><span><span class="glossterm">byte</span> <a title="Permalink" class="permalink" href="#id-1.9.7.30">#</a></span></dt><dd class="glossdef"><p>Set of bits that make up a single character; there are usually 8
bits to a byte.</p></dd></dl></div><div class="glossdiv" id="id-1.9.8"><h3 class="title">C</h3><dl><dt id="id-1.9.8.3"><span><span class="glossterm">cache pruner</span> <a title="Permalink" class="permalink" href="#id-1.9.8.3">#</a></span></dt><dd class="glossdef"><p>A program that keeps the Image service VM image cache at or
below its configured maximum size.</p></dd><dt id="id-1.9.8.4"><span><span class="glossterm">Cactus</span> <a title="Permalink" class="permalink" href="#id-1.9.8.4">#</a></span></dt><dd class="glossdef"><p>An OpenStack grouped release of projects that came out in the
spring of 2011. It included Compute (nova), Object Storage (swift),
and the Image service (glance).
Cactus is a city in Texas, US and is the code name for
the third release of OpenStack. When OpenStack releases went
from three to six months long, the code name of the release
changed to match a geography nearest the previous
summit.</p></dd><dt id="id-1.9.8.5"><span><span class="glossterm">CALL</span> <a title="Permalink" class="permalink" href="#id-1.9.8.5">#</a></span></dt><dd class="glossdef"><p>One of the RPC primitives used by the OpenStack message queue
software. Sends a message and waits for a response.</p></dd><dt id="id-1.9.8.6"><span><span class="glossterm">capability</span> <a title="Permalink" class="permalink" href="#id-1.9.8.6">#</a></span></dt><dd class="glossdef"><p>Defines resources for a cell, including CPU, storage, and
networking. Can apply to the specific services within a cell or a
whole cell.</p></dd><dt id="id-1.9.8.7"><span><span class="glossterm">capacity cache</span> <a title="Permalink" class="permalink" href="#id-1.9.8.7">#</a></span></dt><dd class="glossdef"><p>A Compute back-end database table that contains the current
workload, amount of free RAM, and number of VMs running on each host.
Used to determine on which host a VM starts.</p></dd><dt id="id-1.9.8.8"><span><span class="glossterm">capacity updater</span> <a title="Permalink" class="permalink" href="#id-1.9.8.8">#</a></span></dt><dd class="glossdef"><p>A notification driver that monitors VM instances and updates the
capacity cache as needed.</p></dd><dt id="id-1.9.8.9"><span><span class="glossterm">CAST</span> <a title="Permalink" class="permalink" href="#id-1.9.8.9">#</a></span></dt><dd class="glossdef"><p>One of the RPC primitives used by the OpenStack message queue
software. Sends a message and does not wait for a response.</p></dd><dt id="id-1.9.8.10"><span><span class="glossterm">catalog</span> <a title="Permalink" class="permalink" href="#id-1.9.8.10">#</a></span></dt><dd class="glossdef"><p>A list of API endpoints that are available to a user after
authentication with the Identity service.</p></dd><dt id="id-1.9.8.11"><span><span class="glossterm">catalog service</span> <a title="Permalink" class="permalink" href="#id-1.9.8.11">#</a></span></dt><dd class="glossdef"><p>An Identity service that lists API endpoints that are available
to a user after authentication with the Identity service.</p></dd><dt id="id-1.9.8.12"><span><span class="glossterm">ceilometer</span> <a title="Permalink" class="permalink" href="#id-1.9.8.12">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; gathers and stores metrics from other
OpenStack services.</p></dd><dt id="id-1.9.8.13"><span><span class="glossterm">cell</span> <a title="Permalink" class="permalink" href="#id-1.9.8.13">#</a></span></dt><dd class="glossdef"><p>Provides logical partitioning of Compute resources in a child
and parent relationship. Requests are passed from parent cells to
child cells if the parent cannot provide the requested
resource.</p></dd><dt id="id-1.9.8.14"><span><span class="glossterm">cell forwarding</span> <a title="Permalink" class="permalink" href="#id-1.9.8.14">#</a></span></dt><dd class="glossdef"><p>A Compute option that enables parent cells to pass resource
requests to child cells if the parent cannot provide the requested
resource.</p></dd><dt id="id-1.9.8.15"><span><span class="glossterm">cell manager</span> <a title="Permalink" class="permalink" href="#id-1.9.8.15">#</a></span></dt><dd class="glossdef"><p>The Compute component that contains a list of the current
capabilities of each host within the cell and routes requests as
appropriate.</p></dd><dt id="id-1.9.8.16"><span><span class="glossterm">CentOS</span> <a title="Permalink" class="permalink" href="#id-1.9.8.16">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.9.8.17"><span><span class="glossterm">Ceph</span> <a title="Permalink" class="permalink" href="#id-1.9.8.17">#</a></span></dt><dd class="glossdef"><p>Massively scalable distributed storage system that consists of
an object store, block store, and POSIX-compatible distributed file
system. Compatible with OpenStack.</p></dd><dt id="id-1.9.8.18"><span><span class="glossterm">CephFS</span> <a title="Permalink" class="permalink" href="#id-1.9.8.18">#</a></span></dt><dd class="glossdef"><p>The POSIX-compliant file system provided by Ceph.</p></dd><dt id="term-certificate-authority-ca"><span><span class="glossterm">certificate authority (CA)</span> <a title="Permalink" class="permalink" href="#term-certificate-authority-ca">#</a></span></dt><dd class="glossdef"><p>In cryptography, an entity that issues digital certificates. The digital
certificate certifies the ownership of a public key by the named
subject of the certificate. This enables others (relying parties) to
rely upon signatures or assertions made by the private key that
corresponds to the certified public key. In this model of trust
relationships, a CA is a trusted third party for both the subject
(owner) of the certificate and the party relying upon the certificate.
CAs are characteristic of many public key infrastructure (PKI)
schemes.
In OpenStack, a simple certificate authority is provided by Compute for
cloudpipe VPNs and VM image decryption.</p></dd><dt id="id-1.9.8.20"><span><span class="glossterm">Challenge-Handshake Authentication Protocol (CHAP)</span> <a title="Permalink" class="permalink" href="#id-1.9.8.20">#</a></span></dt><dd class="glossdef"><p>An iSCSI authentication method supported by Compute.</p></dd><dt id="id-1.9.8.21"><span><span class="glossterm">chance scheduler</span> <a title="Permalink" class="permalink" href="#id-1.9.8.21">#</a></span></dt><dd class="glossdef"><p>A scheduling method used by Compute that randomly chooses an
available host from the pool.</p></dd><dt id="id-1.9.8.22"><span><span class="glossterm">changes since</span> <a title="Permalink" class="permalink" href="#id-1.9.8.22">#</a></span></dt><dd class="glossdef"><p>A Compute API parameter that downloads changes to the requested
item since your last request, instead of downloading a new, fresh set
of data and comparing it against the old data.</p></dd><dt id="id-1.9.8.23"><span><span class="glossterm">Chef</span> <a title="Permalink" class="permalink" href="#id-1.9.8.23">#</a></span></dt><dd class="glossdef"><p>An operating system configuration management tool supporting
OpenStack deployments.</p></dd><dt id="id-1.9.8.24"><span><span class="glossterm">child cell</span> <a title="Permalink" class="permalink" href="#id-1.9.8.24">#</a></span></dt><dd class="glossdef"><p>If a requested resource such as CPU time, disk storage, or
memory is not available in the parent cell, the request is forwarded
to its associated child cells. If the child cell can fulfill the
request, it does. Otherwise, it attempts to pass the request to any of
its children.</p></dd><dt id="id-1.9.8.25"><span><span class="glossterm">cinder</span> <a title="Permalink" class="permalink" href="#id-1.9.8.25">#</a></span></dt><dd class="glossdef"><p>Codename for <a class="xref" href="#term-block-storage-service-cinder" title="Block Storage service (cinder)">Block Storage service (cinder)</a>.</p></dd><dt id="id-1.9.8.26"><span><span class="glossterm">CirrOS</span> <a title="Permalink" class="permalink" href="#id-1.9.8.26">#</a></span></dt><dd class="glossdef"><p>A minimal Linux distribution designed for use as a test
image on clouds such as OpenStack.</p></dd><dt id="id-1.9.8.27"><span><span class="glossterm">Cisco neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.8.27">#</a></span></dt><dd class="glossdef"><p>A Networking plug-in for Cisco devices and technologies,
including UCS and Nexus.</p></dd><dt id="id-1.9.8.28"><span><span class="glossterm">cloud architect</span> <a title="Permalink" class="permalink" href="#id-1.9.8.28">#</a></span></dt><dd class="glossdef"><p>A person who plans, designs, and oversees the creation of
clouds.</p></dd><dt id="id-1.9.8.29"><span><span class="glossterm">Cloud Auditing Data Federation (CADF)</span> <a title="Permalink" class="permalink" href="#id-1.9.8.29">#</a></span></dt><dd class="glossdef"><p>Cloud Auditing Data Federation (CADF) is a
specification for audit event data. CADF is
supported by OpenStack Identity.</p></dd><dt id="id-1.9.8.30"><span><span class="glossterm">cloud computing</span> <a title="Permalink" class="permalink" href="#id-1.9.8.30">#</a></span></dt><dd class="glossdef"><p>A model that enables access to a shared pool of configurable
computing resources, such as networks, servers, storage, applications,
and services, that can be rapidly provisioned and released with
minimal management effort or service provider interaction.</p></dd><dt id="term-cloud-controller"><span><span class="glossterm">cloud controller</span> <a title="Permalink" class="permalink" href="#term-cloud-controller">#</a></span></dt><dd class="glossdef"><p>Collection of Compute components that represent the global state
of the cloud; talks to services, such as Identity authentication,
Object Storage, and node/storage workers through a
queue.</p></dd><dt id="id-1.9.8.32"><span><span class="glossterm">cloud controller node</span> <a title="Permalink" class="permalink" href="#id-1.9.8.32">#</a></span></dt><dd class="glossdef"><p>A node that runs network, volume, API, scheduler, and image
services. Each service may be broken out into separate nodes for
scalability or availability.</p></dd><dt id="id-1.9.8.33"><span><span class="glossterm">Cloud Data Management Interface (CDMI)</span> <a title="Permalink" class="permalink" href="#id-1.9.8.33">#</a></span></dt><dd class="glossdef"><p>SINA standard that defines a RESTful API for managing objects in
the cloud, currently unsupported in OpenStack.</p></dd><dt id="id-1.9.8.34"><span><span class="glossterm">Cloud Infrastructure Management Interface (CIMI)</span> <a title="Permalink" class="permalink" href="#id-1.9.8.34">#</a></span></dt><dd class="glossdef"><p>An in-progress specification for cloud management. Currently
unsupported in OpenStack.</p></dd><dt id="id-1.9.8.35"><span><span class="glossterm">cloud-init</span> <a title="Permalink" class="permalink" href="#id-1.9.8.35">#</a></span></dt><dd class="glossdef"><p>A package commonly installed in VM images that performs
initialization of an instance after boot using information that it
retrieves from the metadata service, such as the SSH public key and
user data.</p></dd><dt id="id-1.9.8.36"><span><span class="glossterm">cloudadmin</span> <a title="Permalink" class="permalink" href="#id-1.9.8.36">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system. Grants
complete system access.</p></dd><dt id="id-1.9.8.37"><span><span class="glossterm">Cloudbase-Init</span> <a title="Permalink" class="permalink" href="#id-1.9.8.37">#</a></span></dt><dd class="glossdef"><p>A Windows project providing guest initialization features,
similar to cloud-init.</p></dd><dt id="id-1.9.8.38"><span><span class="glossterm">cloudpipe</span> <a title="Permalink" class="permalink" href="#id-1.9.8.38">#</a></span></dt><dd class="glossdef"><p>A compute service that creates VPNs on a per-project
basis.</p></dd><dt id="id-1.9.8.39"><span><span class="glossterm">cloudpipe image</span> <a title="Permalink" class="permalink" href="#id-1.9.8.39">#</a></span></dt><dd class="glossdef"><p>A pre-made VM image that serves as a cloudpipe server.
Essentially, OpenVPN running on Linux.</p></dd><dt id="term-clustering-service-senlin"><span><span class="glossterm">Clustering service (senlin)</span> <a title="Permalink" class="permalink" href="#term-clustering-service-senlin">#</a></span></dt><dd class="glossdef"><p>The project that implements clustering services and libraries
for the management of groups of homogeneous objects exposed
by other OpenStack services.</p></dd><dt id="id-1.9.8.41"><span><span class="glossterm">command filter</span> <a title="Permalink" class="permalink" href="#id-1.9.8.41">#</a></span></dt><dd class="glossdef"><p>Lists allowed commands within the Compute rootwrap
facility.</p></dd><dt id="id-1.9.8.42"><span><span class="glossterm">Common Internet File System (CIFS)</span> <a title="Permalink" class="permalink" href="#id-1.9.8.42">#</a></span></dt><dd class="glossdef"><p>A file sharing protocol. It is a public or open variation of the
original Server Message Block (SMB) protocol developed and used by
Microsoft. Like the SMB protocol, CIFS runs at a higher level and uses
the TCP/IP protocol.</p></dd><dt id="term-common-libraries-oslo"><span><span class="glossterm">Common Libraries (oslo)</span> <a title="Permalink" class="permalink" href="#term-common-libraries-oslo">#</a></span></dt><dd class="glossdef"><p>The project that produces a set of python libraries containing code
shared by OpenStack projects. The APIs provided by these libraries
should be high quality, stable, consistent, documented and generally
applicable.</p></dd><dt id="id-1.9.8.44"><span><span class="glossterm">community project</span> <a title="Permalink" class="permalink" href="#id-1.9.8.44">#</a></span></dt><dd class="glossdef"><p>A project that is not officially endorsed by the OpenStack
Foundation. If the project is successful enough, it might be elevated
to an incubated project and then to a core project, or it might be
merged with the main code trunk.</p></dd><dt id="id-1.9.8.45"><span><span class="glossterm">compression</span> <a title="Permalink" class="permalink" href="#id-1.9.8.45">#</a></span></dt><dd class="glossdef"><p>Reducing the size of files by special encoding, the file can be
decompressed again to its original content. OpenStack supports
compression at the Linux file system level but does not support
compression for things such as Object Storage objects or Image service
VM images.</p></dd><dt id="term-compute-api-nova-api"><span><span class="glossterm">Compute API (Nova API)</span> <a title="Permalink" class="permalink" href="#term-compute-api-nova-api">#</a></span></dt><dd class="glossdef"><p>The nova-api daemon provides access to nova services. Can communicate with
other APIs, such as the Amazon EC2 API.</p></dd><dt id="id-1.9.8.47"><span><span class="glossterm">compute controller</span> <a title="Permalink" class="permalink" href="#id-1.9.8.47">#</a></span></dt><dd class="glossdef"><p>The Compute component that chooses suitable hosts on which to
start VM instances.</p></dd><dt id="id-1.9.8.48"><span><span class="glossterm">compute host</span> <a title="Permalink" class="permalink" href="#id-1.9.8.48">#</a></span></dt><dd class="glossdef"><p>Physical host dedicated to running compute nodes.</p></dd><dt id="id-1.9.8.49"><span><span class="glossterm">compute node</span> <a title="Permalink" class="permalink" href="#id-1.9.8.49">#</a></span></dt><dd class="glossdef"><p>A node that runs the nova-compute daemon that manages VM
instances that provide a wide
range of services, such as web applications and analytics.</p></dd><dt id="term-compute-service-nova"><span><span class="glossterm">Compute service (nova)</span> <a title="Permalink" class="permalink" href="#term-compute-service-nova">#</a></span></dt><dd class="glossdef"><p>The OpenStack core project that implements services and associated
libraries to provide massively-scalable, on-demand, self-service
access to compute resources, including bare metal, virtual machines,
and containers.</p></dd><dt id="id-1.9.8.51"><span><span class="glossterm">compute worker</span> <a title="Permalink" class="permalink" href="#id-1.9.8.51">#</a></span></dt><dd class="glossdef"><p>The Compute component that runs on each compute node and manages
the VM instance lifecycle, including run, reboot, terminate,
attach/detach volumes, and so on. Provided by the nova-compute daemon.</p></dd><dt id="id-1.9.8.52"><span><span class="glossterm">concatenated object</span> <a title="Permalink" class="permalink" href="#id-1.9.8.52">#</a></span></dt><dd class="glossdef"><p>A set of segment objects that Object Storage combines and sends
to the client.</p></dd><dt id="id-1.9.8.53"><span><span class="glossterm">conductor</span> <a title="Permalink" class="permalink" href="#id-1.9.8.53">#</a></span></dt><dd class="glossdef"><p>In Compute, conductor is the process that proxies database
requests from the compute process. Using conductor improves security
because compute nodes do not need direct access to the
database.</p></dd><dt id="id-1.9.8.54"><span><span class="glossterm">congress</span> <a title="Permalink" class="permalink" href="#id-1.9.8.54">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-governance-service-congress" title="Governance service (congress)">Governance service (congress)</a>.</p></dd><dt id="id-1.9.8.55"><span><span class="glossterm">consistency window</span> <a title="Permalink" class="permalink" href="#id-1.9.8.55">#</a></span></dt><dd class="glossdef"><p>The amount of time it takes for a new Object Storage object to
become accessible to all clients.</p></dd><dt id="id-1.9.8.56"><span><span class="glossterm">console log</span> <a title="Permalink" class="permalink" href="#id-1.9.8.56">#</a></span></dt><dd class="glossdef"><p>Contains the output from a Linux VM console in Compute.</p></dd><dt id="id-1.9.8.57"><span><span class="glossterm">container</span> <a title="Permalink" class="permalink" href="#id-1.9.8.57">#</a></span></dt><dd class="glossdef"><p>Organizes and stores objects in Object Storage. Similar to the
concept of a Linux directory but cannot be nested. Alternative term
for an Image service container format.</p></dd><dt id="id-1.9.8.58"><span><span class="glossterm">container auditor</span> <a title="Permalink" class="permalink" href="#id-1.9.8.58">#</a></span></dt><dd class="glossdef"><p>Checks for missing replicas or incorrect objects in specified
Object Storage containers through queries to the SQLite back-end
database.</p></dd><dt id="id-1.9.8.59"><span><span class="glossterm">container database</span> <a title="Permalink" class="permalink" href="#id-1.9.8.59">#</a></span></dt><dd class="glossdef"><p>A SQLite database that stores Object Storage containers and
container metadata. The container server accesses this
database.</p></dd><dt id="id-1.9.8.60"><span><span class="glossterm">container format</span> <a title="Permalink" class="permalink" href="#id-1.9.8.60">#</a></span></dt><dd class="glossdef"><p>A wrapper used by the Image service that contains a VM image and
its associated metadata, such as machine state, OS disk size, and so
on.</p></dd><dt id="term-container-infrastructure-management-service-magnum"><span><span class="glossterm">Container Infrastructure Management service (magnum)</span> <a title="Permalink" class="permalink" href="#term-container-infrastructure-management-service-magnum">#</a></span></dt><dd class="glossdef"><p>The project which provides a set of services for provisioning, scaling,
and managing container orchestration engines.</p></dd><dt id="id-1.9.8.62"><span><span class="glossterm">container server</span> <a title="Permalink" class="permalink" href="#id-1.9.8.62">#</a></span></dt><dd class="glossdef"><p>An Object Storage server that manages containers.</p></dd><dt id="id-1.9.8.63"><span><span class="glossterm">container service</span> <a title="Permalink" class="permalink" href="#id-1.9.8.63">#</a></span></dt><dd class="glossdef"><p>The Object Storage component that provides container services,
such as create, delete, list, and so on.</p></dd><dt id="id-1.9.8.64"><span><span class="glossterm">content delivery network (CDN)</span> <a title="Permalink" class="permalink" href="#id-1.9.8.64">#</a></span></dt><dd class="glossdef"><p>A content delivery network is a specialized network that is
used to distribute content to clients, typically located
close to the client for increased performance.</p></dd><dt id="id-1.9.8.65"><span><span class="glossterm">controller node</span> <a title="Permalink" class="permalink" href="#id-1.9.8.65">#</a></span></dt><dd class="glossdef"><p>Alternative term for a cloud controller node.</p></dd><dt id="id-1.9.8.66"><span><span class="glossterm">core API</span> <a title="Permalink" class="permalink" href="#id-1.9.8.66">#</a></span></dt><dd class="glossdef"><p>Depending on context, the core API is either the OpenStack API
or the main API of a specific core project, such as Compute,
Networking, Image service, and so on.</p></dd><dt id="id-1.9.8.67"><span><span class="glossterm">core service</span> <a title="Permalink" class="permalink" href="#id-1.9.8.67">#</a></span></dt><dd class="glossdef"><p>An official OpenStack service defined as core by
DefCore Committee. Currently, consists of
Block Storage service (cinder), Compute service (nova),
Identity service (keystone), Image service (glance),
Networking service (neutron), and Object Storage service (swift).</p></dd><dt id="id-1.9.8.68"><span><span class="glossterm">cost</span> <a title="Permalink" class="permalink" href="#id-1.9.8.68">#</a></span></dt><dd class="glossdef"><p>Under the Compute distributed scheduler, this is calculated by
looking at the capabilities of each host relative to the flavor of the
VM instance being requested.</p></dd><dt id="id-1.9.8.69"><span><span class="glossterm">credentials</span> <a title="Permalink" class="permalink" href="#id-1.9.8.69">#</a></span></dt><dd class="glossdef"><p>Data that is only known to or accessible by a user and
used to verify that the user is who he says he is.
Credentials are presented to the server during
authentication. Examples include a password, secret key,
digital certificate, and fingerprint.</p></dd><dt id="term-cross-origin-resource-sharing-cors"><span><span class="glossterm">Cross-Origin Resource Sharing (CORS)</span> <a title="Permalink" class="permalink" href="#term-cross-origin-resource-sharing-cors">#</a></span></dt><dd class="glossdef"><p>A mechanism that allows many resources (for example,
fonts, JavaScript) on a web page to be requested from
another domain outside the domain from which the resource
originated. In particular, JavaScript's AJAX calls can use
the XMLHttpRequest mechanism.</p></dd><dt id="id-1.9.8.71"><span><span class="glossterm">Crowbar</span> <a title="Permalink" class="permalink" href="#id-1.9.8.71">#</a></span></dt><dd class="glossdef"><p>An open source community project by Dell that aims to provide
all necessary services to quickly deploy clouds.</p></dd><dt id="id-1.9.8.72"><span><span class="glossterm">current workload</span> <a title="Permalink" class="permalink" href="#id-1.9.8.72">#</a></span></dt><dd class="glossdef"><p>An element of the Compute capacity cache that is calculated
based on the number of build, snapshot, migrate, and resize operations
currently in progress on a given host.</p></dd><dt id="id-1.9.8.73"><span><span class="glossterm">customer</span> <a title="Permalink" class="permalink" href="#id-1.9.8.73">#</a></span></dt><dd class="glossdef"><p>Alternative term for project.</p></dd><dt id="id-1.9.8.74"><span><span class="glossterm">customization module</span> <a title="Permalink" class="permalink" href="#id-1.9.8.74">#</a></span></dt><dd class="glossdef"><p>A user-created Python module that is loaded by horizon to change
the look and feel of the dashboard.</p></dd></dl></div><div class="glossdiv" id="id-1.9.9"><h3 class="title">D</h3><dl><dt id="id-1.9.9.3"><span><span class="glossterm">daemon</span> <a title="Permalink" class="permalink" href="#id-1.9.9.3">#</a></span></dt><dd class="glossdef"><p>A process that runs in the background and waits for requests.
May or may not listen on a TCP or UDP port. Do not confuse with a
worker.</p></dd><dt id="term-dashboard-horizon"><span><span class="glossterm">Dashboard (horizon)</span> <a title="Permalink" class="permalink" href="#term-dashboard-horizon">#</a></span></dt><dd class="glossdef"><p>OpenStack project which provides an extensible, unified, web-based
user interface for all OpenStack services.</p></dd><dt id="id-1.9.9.5"><span><span class="glossterm">data encryption</span> <a title="Permalink" class="permalink" href="#id-1.9.9.5">#</a></span></dt><dd class="glossdef"><p>Both Image service and Compute support encrypted virtual machine
(VM) images (but not instances). In-transit data encryption is
supported in OpenStack using technologies such as HTTPS, SSL, TLS, and
SSH. Object Storage does not support object encryption at the
application level but may support storage that uses disk encryption.</p></dd><dt id="id-1.9.9.6"><span><span class="glossterm">Data loss prevention (DLP) software</span> <a title="Permalink" class="permalink" href="#id-1.9.9.6">#</a></span></dt><dd class="glossdef"><p>Software programs used to protect sensitive information
and prevent it from leaking outside a network boundary
through the detection and denying of the data transportation.</p></dd><dt id="term-data-processing-service-sahara"><span><span class="glossterm">Data Processing service (sahara)</span> <a title="Permalink" class="permalink" href="#term-data-processing-service-sahara">#</a></span></dt><dd class="glossdef"><p>OpenStack project that provides a scalable
data-processing stack and associated management
interfaces.</p></dd><dt id="term-data-store"><span><span class="glossterm">data store</span> <a title="Permalink" class="permalink" href="#term-data-store">#</a></span></dt><dd class="glossdef"><p>A database engine supported by the Database service.</p></dd><dt id="id-1.9.9.9"><span><span class="glossterm">database ID</span> <a title="Permalink" class="permalink" href="#id-1.9.9.9">#</a></span></dt><dd class="glossdef"><p>A unique ID given to each replica of an Object Storage
database.</p></dd><dt id="id-1.9.9.10"><span><span class="glossterm">database replicator</span> <a title="Permalink" class="permalink" href="#id-1.9.9.10">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that copies changes in the account,
container, and object databases to other nodes.</p></dd><dt id="term-database-service-trove"><span><span class="glossterm">Database service (trove)</span> <a title="Permalink" class="permalink" href="#term-database-service-trove">#</a></span></dt><dd class="glossdef"><p>An integrated project that provides scalable and reliable
Cloud Database-as-a-Service functionality for both
relational and non-relational database engines.</p></dd><dt id="id-1.9.9.12"><span><span class="glossterm">deallocate</span> <a title="Permalink" class="permalink" href="#id-1.9.9.12">#</a></span></dt><dd class="glossdef"><p>The process of removing the association between a floating IP
address and a fixed IP address. Once this association is removed, the
floating IP returns to the address pool.</p></dd><dt id="id-1.9.9.13"><span><span class="glossterm">Debian</span> <a title="Permalink" class="permalink" href="#id-1.9.9.13">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.9.9.14"><span><span class="glossterm">deduplication</span> <a title="Permalink" class="permalink" href="#id-1.9.9.14">#</a></span></dt><dd class="glossdef"><p>The process of finding duplicate data at the disk block, file,
and/or object level to minimize storage use—currently unsupported
within OpenStack.</p></dd><dt id="id-1.9.9.15"><span><span class="glossterm">default panel</span> <a title="Permalink" class="permalink" href="#id-1.9.9.15">#</a></span></dt><dd class="glossdef"><p>The default panel that is displayed when a user accesses the
dashboard.</p></dd><dt id="id-1.9.9.16"><span><span class="glossterm">default project</span> <a title="Permalink" class="permalink" href="#id-1.9.9.16">#</a></span></dt><dd class="glossdef"><p>New users are assigned to this project if no project is specified
when a user is created.</p></dd><dt id="id-1.9.9.17"><span><span class="glossterm">default token</span> <a title="Permalink" class="permalink" href="#id-1.9.9.17">#</a></span></dt><dd class="glossdef"><p>An Identity service token that is not associated with a specific
project and is exchanged for a scoped token.</p></dd><dt id="id-1.9.9.18"><span><span class="glossterm">delayed delete</span> <a title="Permalink" class="permalink" href="#id-1.9.9.18">#</a></span></dt><dd class="glossdef"><p>An option within Image service so that an image is deleted after
a predefined number of seconds instead of immediately.</p></dd><dt id="id-1.9.9.19"><span><span class="glossterm">delivery mode</span> <a title="Permalink" class="permalink" href="#id-1.9.9.19">#</a></span></dt><dd class="glossdef"><p>Setting for the Compute RabbitMQ message delivery mode; can be
set to either transient or persistent.</p></dd><dt id="id-1.9.9.20"><span><span class="glossterm">denial of service (DoS)</span> <a title="Permalink" class="permalink" href="#id-1.9.9.20">#</a></span></dt><dd class="glossdef"><p>Denial of service (DoS) is a short form for
denial-of-service attack. This is a malicious attempt to
prevent legitimate users from using a service.</p></dd><dt id="id-1.9.9.21"><span><span class="glossterm">deprecated auth</span> <a title="Permalink" class="permalink" href="#id-1.9.9.21">#</a></span></dt><dd class="glossdef"><p>An option within Compute that enables administrators to create
and manage users through the <code class="literal">nova-manage</code> command as
opposed to using the Identity service.</p></dd><dt id="id-1.9.9.22"><span><span class="glossterm">designate</span> <a title="Permalink" class="permalink" href="#id-1.9.9.22">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-dns-service-designate" title="DNS service (designate)">DNS service (designate)</a>.</p></dd><dt id="id-1.9.9.23"><span><span class="glossterm">Desktop-as-a-Service</span> <a title="Permalink" class="permalink" href="#id-1.9.9.23">#</a></span></dt><dd class="glossdef"><p>A platform that provides a suite of desktop environments
that users access to receive a desktop experience from
any location. This may provide general use, development, or
even homogeneous testing environments.</p></dd><dt id="id-1.9.9.24"><span><span class="glossterm">developer</span> <a title="Permalink" class="permalink" href="#id-1.9.9.24">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system and the
default role assigned to a new user.</p></dd><dt id="id-1.9.9.25"><span><span class="glossterm">device ID</span> <a title="Permalink" class="permalink" href="#id-1.9.9.25">#</a></span></dt><dd class="glossdef"><p>Maps Object Storage partitions to physical storage
devices.</p></dd><dt id="id-1.9.9.26"><span><span class="glossterm">device weight</span> <a title="Permalink" class="permalink" href="#id-1.9.9.26">#</a></span></dt><dd class="glossdef"><p>Distributes partitions proportionately across Object Storage
devices based on the storage capacity of each device.</p></dd><dt id="id-1.9.9.27"><span><span class="glossterm">DevStack</span> <a title="Permalink" class="permalink" href="#id-1.9.9.27">#</a></span></dt><dd class="glossdef"><p>Community project that uses shell scripts to quickly build
complete OpenStack development environments.</p></dd><dt id="id-1.9.9.28"><span><span class="glossterm">DHCP agent</span> <a title="Permalink" class="permalink" href="#id-1.9.9.28">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides DHCP services
for virtual networks.</p></dd><dt id="id-1.9.9.29"><span><span class="glossterm">Diablo</span> <a title="Permalink" class="permalink" href="#id-1.9.9.29">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to OpenStack that came out
in the fall of 2011, the fourth release of OpenStack. It included
Compute (nova 2011.3), Object Storage (swift 1.4.3), and the Image
service (glance).
Diablo is the code name for the fourth release of
OpenStack. The design summit took place in
the Bay Area near Santa Clara,
California, US and Diablo is a nearby city.</p></dd><dt id="id-1.9.9.30"><span><span class="glossterm">direct consumer</span> <a title="Permalink" class="permalink" href="#id-1.9.9.30">#</a></span></dt><dd class="glossdef"><p>An element of the Compute RabbitMQ that comes to life when a RPC
call is executed. It connects to a direct exchange through a unique
exclusive queue, sends the message, and terminates.</p></dd><dt id="id-1.9.9.31"><span><span class="glossterm">direct exchange</span> <a title="Permalink" class="permalink" href="#id-1.9.9.31">#</a></span></dt><dd class="glossdef"><p>A routing table that is created within the Compute RabbitMQ
during RPC calls; one is created for each RPC call that is
invoked.</p></dd><dt id="id-1.9.9.32"><span><span class="glossterm">direct publisher</span> <a title="Permalink" class="permalink" href="#id-1.9.9.32">#</a></span></dt><dd class="glossdef"><p>Element of RabbitMQ that provides a response to an incoming MQ
message.</p></dd><dt id="id-1.9.9.33"><span><span class="glossterm">disassociate</span> <a title="Permalink" class="permalink" href="#id-1.9.9.33">#</a></span></dt><dd class="glossdef"><p>The process of removing the association between a floating IP
address and fixed IP and thus returning the floating IP address to the
address pool.</p></dd><dt id="id-1.9.9.34"><span><span class="glossterm">Discretionary Access Control (DAC)</span> <a title="Permalink" class="permalink" href="#id-1.9.9.34">#</a></span></dt><dd class="glossdef"><p>Governs the ability of subjects to access objects, while enabling
users to make policy decisions and assign security attributes.
The traditional UNIX system of users, groups, and read-write-execute
permissions is an example of DAC.</p></dd><dt id="id-1.9.9.35"><span><span class="glossterm">disk encryption</span> <a title="Permalink" class="permalink" href="#id-1.9.9.35">#</a></span></dt><dd class="glossdef"><p>The ability to encrypt data at the file system, disk partition,
or whole-disk level. Supported within Compute VMs.</p></dd><dt id="id-1.9.9.36"><span><span class="glossterm">disk format</span> <a title="Permalink" class="permalink" href="#id-1.9.9.36">#</a></span></dt><dd class="glossdef"><p>The underlying format that a disk image for a VM is stored as
within the Image service back-end store. For example, AMI, ISO, QCOW2,
VMDK, and so on.</p></dd><dt id="id-1.9.9.37"><span><span class="glossterm">dispersion</span> <a title="Permalink" class="permalink" href="#id-1.9.9.37">#</a></span></dt><dd class="glossdef"><p>In Object Storage, tools to test and ensure dispersion of
objects and containers to ensure fault tolerance.</p></dd><dt id="id-1.9.9.38"><span><span class="glossterm">distributed virtual router (DVR)</span> <a title="Permalink" class="permalink" href="#id-1.9.9.38">#</a></span></dt><dd class="glossdef"><p>Mechanism for highly available multi-host routing when using
OpenStack Networking (neutron).</p></dd><dt id="id-1.9.9.39"><span><span class="glossterm">Django</span> <a title="Permalink" class="permalink" href="#id-1.9.9.39">#</a></span></dt><dd class="glossdef"><p>A web framework used extensively in horizon.</p></dd><dt id="id-1.9.9.40"><span><span class="glossterm">DNS record</span> <a title="Permalink" class="permalink" href="#id-1.9.9.40">#</a></span></dt><dd class="glossdef"><p>A record that specifies information about a particular domain
and belongs to the domain.</p></dd><dt id="term-dns-service-designate"><span><span class="glossterm">DNS service (designate)</span> <a title="Permalink" class="permalink" href="#term-dns-service-designate">#</a></span></dt><dd class="glossdef"><p>OpenStack project that provides scalable, on demand, self
service access to authoritative DNS services, in a
technology-agnostic manner.</p></dd><dt id="id-1.9.9.42"><span><span class="glossterm">dnsmasq</span> <a title="Permalink" class="permalink" href="#id-1.9.9.42">#</a></span></dt><dd class="glossdef"><p>Daemon that provides DNS, DHCP, BOOTP, and TFTP services for
virtual networks.</p></dd><dt id="id-1.9.9.43"><span><span class="glossterm">domain</span> <a title="Permalink" class="permalink" href="#id-1.9.9.43">#</a></span></dt><dd class="glossdef"><p>An Identity API v3 entity. Represents a collection of
projects, groups and users that defines administrative boundaries for
managing OpenStack Identity entities.
On the Internet, separates a website from other sites. Often,
the domain name has two or more parts that are separated by dots.
For example, yahoo.com, usa.gov, harvard.edu, or
mail.yahoo.com.
Also, a domain is an entity or container of all DNS-related
information containing one or more records.</p></dd><dt id="id-1.9.9.44"><span><span class="glossterm">Domain Name System (DNS)</span> <a title="Permalink" class="permalink" href="#id-1.9.9.44">#</a></span></dt><dd class="glossdef"><p>A system by which Internet domain name-to-address and
address-to-name resolutions are determined.
DNS helps navigate the Internet by translating the IP address
into an address that is easier to remember. For example, translating
111.111.111.1 into www.yahoo.com.
All domains and their components, such as mail servers, utilize
DNS to resolve to the appropriate locations. DNS servers are usually
set up in a master-slave relationship such that failure of the master
invokes the slave. DNS servers might also be clustered or replicated
such that changes made to one DNS server are automatically propagated
to other active servers.
In Compute, the support that enables associating DNS entries
with floating IP addresses, nodes, or cells so that hostnames are
consistent across reboots.</p></dd><dt id="id-1.9.9.45"><span><span class="glossterm">download</span> <a title="Permalink" class="permalink" href="#id-1.9.9.45">#</a></span></dt><dd class="glossdef"><p>The transfer of data, usually in the form of files, from one
computer to another.</p></dd><dt id="id-1.9.9.46"><span><span class="glossterm">durable exchange</span> <a title="Permalink" class="permalink" href="#id-1.9.9.46">#</a></span></dt><dd class="glossdef"><p>The Compute RabbitMQ message exchange that remains active when
the server restarts.</p></dd><dt id="id-1.9.9.47"><span><span class="glossterm">durable queue</span> <a title="Permalink" class="permalink" href="#id-1.9.9.47">#</a></span></dt><dd class="glossdef"><p>A Compute RabbitMQ message queue that remains active when the
server restarts.</p></dd><dt id="id-1.9.9.48"><span><span class="glossterm">Dynamic Host Configuration Protocol (DHCP)</span> <a title="Permalink" class="permalink" href="#id-1.9.9.48">#</a></span></dt><dd class="glossdef"><p>A network protocol that configures devices that are connected to a
network so that they can communicate on that network by using the
Internet Protocol (IP). The protocol is implemented in a client-server
model where DHCP clients request configuration data, such as an IP
address, a default route, and one or more DNS server addresses from a
DHCP server.
A method to automatically configure networking for a host at
boot time. Provided by both Networking and Compute.</p></dd><dt id="id-1.9.9.49"><span><span class="glossterm">Dynamic HyperText Markup Language (DHTML)</span> <a title="Permalink" class="permalink" href="#id-1.9.9.49">#</a></span></dt><dd class="glossdef"><p>Pages that use HTML, JavaScript, and Cascading Style Sheets to
enable users to interact with a web page or show simple
animation.</p></dd></dl></div><div class="glossdiv" id="id-1.9.10"><h3 class="title">E</h3><dl><dt id="id-1.9.10.3"><span><span class="glossterm">east-west traffic</span> <a title="Permalink" class="permalink" href="#id-1.9.10.3">#</a></span></dt><dd class="glossdef"><p>Network traffic between servers in the same cloud or data center.
See also north-south traffic.</p></dd><dt id="id-1.9.10.4"><span><span class="glossterm">EBS boot volume</span> <a title="Permalink" class="permalink" href="#id-1.9.10.4">#</a></span></dt><dd class="glossdef"><p>An Amazon EBS storage volume that contains a bootable VM image,
currently unsupported in OpenStack.</p></dd><dt id="id-1.9.10.5"><span><span class="glossterm">ebtables</span> <a title="Permalink" class="permalink" href="#id-1.9.10.5">#</a></span></dt><dd class="glossdef"><p>Filtering tool for a Linux bridging firewall, enabling
filtering of network traffic passing through a Linux bridge.
Used in Compute along with arptables, iptables, and ip6tables
to ensure isolation of network communications.</p></dd><dt id="id-1.9.10.6"><span><span class="glossterm">EC2</span> <a title="Permalink" class="permalink" href="#id-1.9.10.6">#</a></span></dt><dd class="glossdef"><p>The Amazon commercial compute product, similar to
Compute.</p></dd><dt id="id-1.9.10.7"><span><span class="glossterm">EC2 access key</span> <a title="Permalink" class="permalink" href="#id-1.9.10.7">#</a></span></dt><dd class="glossdef"><p>Used along with an EC2 secret key to access the Compute EC2
API.</p></dd><dt id="id-1.9.10.8"><span><span class="glossterm">EC2 API</span> <a title="Permalink" class="permalink" href="#id-1.9.10.8">#</a></span></dt><dd class="glossdef"><p>OpenStack supports accessing the Amazon EC2 API through
Compute.</p></dd><dt id="id-1.9.10.9"><span><span class="glossterm">EC2 Compatibility API</span> <a title="Permalink" class="permalink" href="#id-1.9.10.9">#</a></span></dt><dd class="glossdef"><p>A Compute component that enables OpenStack to communicate with
Amazon EC2.</p></dd><dt id="id-1.9.10.10"><span><span class="glossterm">EC2 secret key</span> <a title="Permalink" class="permalink" href="#id-1.9.10.10">#</a></span></dt><dd class="glossdef"><p>Used along with an EC2 access key when communicating with the
Compute EC2 API; used to digitally sign each request.</p></dd><dt id="id-1.9.10.11"><span><span class="glossterm">Elastic Block Storage (EBS)</span> <a title="Permalink" class="permalink" href="#id-1.9.10.11">#</a></span></dt><dd class="glossdef"><p>The Amazon commercial block storage product.</p></dd><dt id="id-1.9.10.12"><span><span class="glossterm">encapsulation</span> <a title="Permalink" class="permalink" href="#id-1.9.10.12">#</a></span></dt><dd class="glossdef"><p>The practice of placing one packet type within another for
the purposes of abstracting or securing data. Examples
include GRE, MPLS, or IPsec.</p></dd><dt id="id-1.9.10.13"><span><span class="glossterm">encryption</span> <a title="Permalink" class="permalink" href="#id-1.9.10.13">#</a></span></dt><dd class="glossdef"><p>OpenStack supports encryption technologies such as HTTPS, SSH,
SSL, TLS, digital certificates, and data encryption.</p></dd><dt id="id-1.9.10.14"><span><span class="glossterm">endpoint</span> <a title="Permalink" class="permalink" href="#id-1.9.10.14">#</a></span></dt><dd class="glossdef"><p>See API endpoint.</p></dd><dt id="id-1.9.10.15"><span><span class="glossterm">endpoint registry</span> <a title="Permalink" class="permalink" href="#id-1.9.10.15">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Identity service catalog.</p></dd><dt id="id-1.9.10.16"><span><span class="glossterm">endpoint template</span> <a title="Permalink" class="permalink" href="#id-1.9.10.16">#</a></span></dt><dd class="glossdef"><p>A list of URL and port number endpoints that indicate where a
service, such as Object Storage, Compute, Identity, and so on, can be
accessed.</p></dd><dt id="id-1.9.10.17"><span><span class="glossterm">entity</span> <a title="Permalink" class="permalink" href="#id-1.9.10.17">#</a></span></dt><dd class="glossdef"><p>Any piece of hardware or software that wants to connect to the
network services provided by Networking, the network connectivity
service. An entity can make use of Networking by implementing a
VIF.</p></dd><dt id="id-1.9.10.18"><span><span class="glossterm">ephemeral image</span> <a title="Permalink" class="permalink" href="#id-1.9.10.18">#</a></span></dt><dd class="glossdef"><p>A VM image that does not save changes made to its volumes and
reverts them to their original state after the instance is
terminated.</p></dd><dt id="id-1.9.10.19"><span><span class="glossterm">ephemeral volume</span> <a title="Permalink" class="permalink" href="#id-1.9.10.19">#</a></span></dt><dd class="glossdef"><p>Volume that does not save the changes made to it and reverts to
its original state when the current user relinquishes control.</p></dd><dt id="id-1.9.10.20"><span><span class="glossterm">Essex</span> <a title="Permalink" class="permalink" href="#id-1.9.10.20">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to OpenStack that came out
in April 2012, the fifth release of OpenStack. It included Compute
(nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity
(keystone), and Dashboard (horizon).
Essex is the code name for the fifth release of
OpenStack. The design summit took place in
Boston, Massachusetts, US and Essex is a nearby city.</p></dd><dt id="id-1.9.10.21"><span><span class="glossterm">ESXi</span> <a title="Permalink" class="permalink" href="#id-1.9.10.21">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.9.10.22"><span><span class="glossterm">ETag</span> <a title="Permalink" class="permalink" href="#id-1.9.10.22">#</a></span></dt><dd class="glossdef"><p>MD5 hash of an object within Object Storage, used to ensure data
integrity.</p></dd><dt id="id-1.9.10.23"><span><span class="glossterm">euca2ools</span> <a title="Permalink" class="permalink" href="#id-1.9.10.23">#</a></span></dt><dd class="glossdef"><p>A collection of command-line tools for administering VMs; most
are compatible with OpenStack.</p></dd><dt id="id-1.9.10.24"><span><span class="glossterm">Eucalyptus Kernel Image (EKI)</span> <a title="Permalink" class="permalink" href="#id-1.9.10.24">#</a></span></dt><dd class="glossdef"><p>Used along with an ERI to create an EMI.</p></dd><dt id="id-1.9.10.25"><span><span class="glossterm">Eucalyptus Machine Image (EMI)</span> <a title="Permalink" class="permalink" href="#id-1.9.10.25">#</a></span></dt><dd class="glossdef"><p>VM image container format supported by Image service.</p></dd><dt id="id-1.9.10.26"><span><span class="glossterm">Eucalyptus Ramdisk Image (ERI)</span> <a title="Permalink" class="permalink" href="#id-1.9.10.26">#</a></span></dt><dd class="glossdef"><p>Used along with an EKI to create an EMI.</p></dd><dt id="id-1.9.10.27"><span><span class="glossterm">evacuate</span> <a title="Permalink" class="permalink" href="#id-1.9.10.27">#</a></span></dt><dd class="glossdef"><p>The process of migrating one or all virtual machine (VM)
instances from one host to another, compatible with both shared
storage live migration and block migration.</p></dd><dt id="id-1.9.10.28"><span><span class="glossterm">exchange</span> <a title="Permalink" class="permalink" href="#id-1.9.10.28">#</a></span></dt><dd class="glossdef"><p>Alternative term for a RabbitMQ message exchange.</p></dd><dt id="id-1.9.10.29"><span><span class="glossterm">exchange type</span> <a title="Permalink" class="permalink" href="#id-1.9.10.29">#</a></span></dt><dd class="glossdef"><p>A routing algorithm in the Compute RabbitMQ.</p></dd><dt id="id-1.9.10.30"><span><span class="glossterm">exclusive queue</span> <a title="Permalink" class="permalink" href="#id-1.9.10.30">#</a></span></dt><dd class="glossdef"><p>Connected to by a direct consumer in RabbitMQ—Compute, the
message can be consumed only by the current connection.</p></dd><dt id="id-1.9.10.31"><span><span class="glossterm">extended attributes (xattr)</span> <a title="Permalink" class="permalink" href="#id-1.9.10.31">#</a></span></dt><dd class="glossdef"><p>File system option that enables storage of additional
information beyond owner, group, permissions, modification time, and
so on. The underlying Object Storage file system must support extended
attributes.</p></dd><dt id="id-1.9.10.32"><span><span class="glossterm">extension</span> <a title="Permalink" class="permalink" href="#id-1.9.10.32">#</a></span></dt><dd class="glossdef"><p>Alternative term for an API extension or plug-in. In the context
of Identity service, this is a call that is specific to the
implementation, such as adding support for OpenID.</p></dd><dt id="id-1.9.10.33"><span><span class="glossterm">external network</span> <a title="Permalink" class="permalink" href="#id-1.9.10.33">#</a></span></dt><dd class="glossdef"><p>A network segment typically used for instance Internet
access.</p></dd><dt id="id-1.9.10.34"><span><span class="glossterm">extra specs</span> <a title="Permalink" class="permalink" href="#id-1.9.10.34">#</a></span></dt><dd class="glossdef"><p>Specifies additional requirements when Compute determines where
to start a new instance. Examples include a minimum amount of network
bandwidth or a GPU.</p></dd></dl></div><div class="glossdiv" id="id-1.9.11"><h3 class="title">F</h3><dl><dt id="id-1.9.11.3"><span><span class="glossterm">FakeLDAP</span> <a title="Permalink" class="permalink" href="#id-1.9.11.3">#</a></span></dt><dd class="glossdef"><p>An easy method to create a local LDAP directory for testing
Identity and Compute. Requires Redis.</p></dd><dt id="id-1.9.11.4"><span><span class="glossterm">fan-out exchange</span> <a title="Permalink" class="permalink" href="#id-1.9.11.4">#</a></span></dt><dd class="glossdef"><p>Within RabbitMQ and Compute, it is the messaging interface that
is used by the scheduler service to receive capability messages from
the compute, volume, and network nodes.</p></dd><dt id="id-1.9.11.5"><span><span class="glossterm">federated identity</span> <a title="Permalink" class="permalink" href="#id-1.9.11.5">#</a></span></dt><dd class="glossdef"><p>A method to establish trusts between identity providers and the
OpenStack cloud.</p></dd><dt id="id-1.9.11.6"><span><span class="glossterm">Fedora</span> <a title="Permalink" class="permalink" href="#id-1.9.11.6">#</a></span></dt><dd class="glossdef"><p>A Linux distribution compatible with OpenStack.</p></dd><dt id="id-1.9.11.7"><span><span class="glossterm">Fibre Channel</span> <a title="Permalink" class="permalink" href="#id-1.9.11.7">#</a></span></dt><dd class="glossdef"><p>Storage protocol similar in concept to TCP/IP; encapsulates SCSI
commands and data.</p></dd><dt id="id-1.9.11.8"><span><span class="glossterm">Fibre Channel over Ethernet (FCoE)</span> <a title="Permalink" class="permalink" href="#id-1.9.11.8">#</a></span></dt><dd class="glossdef"><p>The fibre channel protocol tunneled within Ethernet.</p></dd><dt id="id-1.9.11.9"><span><span class="glossterm">fill-first scheduler</span> <a title="Permalink" class="permalink" href="#id-1.9.11.9">#</a></span></dt><dd class="glossdef"><p>The Compute scheduling method that attempts to fill a host with
VMs rather than starting new VMs on a variety of hosts.</p></dd><dt id="id-1.9.11.10"><span><span class="glossterm">filter</span> <a title="Permalink" class="permalink" href="#id-1.9.11.10">#</a></span></dt><dd class="glossdef"><p>The step in the Compute scheduling process when hosts that
cannot run VMs are eliminated and not chosen.</p></dd><dt id="id-1.9.11.11"><span><span class="glossterm">firewall</span> <a title="Permalink" class="permalink" href="#id-1.9.11.11">#</a></span></dt><dd class="glossdef"><p>Used to restrict communications between hosts and/or nodes,
implemented in Compute using iptables, arptables, ip6tables, and
ebtables.</p></dd><dt id="id-1.9.11.12"><span><span class="glossterm">FireWall-as-a-Service (FWaaS)</span> <a title="Permalink" class="permalink" href="#id-1.9.11.12">#</a></span></dt><dd class="glossdef"><p>A Networking extension that provides perimeter firewall
functionality.</p></dd><dt id="id-1.9.11.13"><span><span class="glossterm">fixed IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.11.13">#</a></span></dt><dd class="glossdef"><p>An IP address that is associated with the same instance each
time that instance boots, is generally not accessible to end users or
the public Internet, and is used for management of the
instance.</p></dd><dt id="id-1.9.11.14"><span><span class="glossterm">Flat Manager</span> <a title="Permalink" class="permalink" href="#id-1.9.11.14">#</a></span></dt><dd class="glossdef"><p>The Compute component that gives IP addresses to authorized
nodes and assumes DHCP, DNS, and routing configuration and services
are provided by something else.</p></dd><dt id="id-1.9.11.15"><span><span class="glossterm">flat mode injection</span> <a title="Permalink" class="permalink" href="#id-1.9.11.15">#</a></span></dt><dd class="glossdef"><p>A Compute networking method where the OS network configuration
information is injected into the VM image before the instance
starts.</p></dd><dt id="id-1.9.11.16"><span><span class="glossterm">flat network</span> <a title="Permalink" class="permalink" href="#id-1.9.11.16">#</a></span></dt><dd class="glossdef"><p>Virtual network type that uses neither VLANs nor tunnels to
segregate project traffic. Each flat network typically requires
a separate underlying physical interface defined by bridge
mappings. However, a flat network can contain multiple
subnets.</p></dd><dt id="id-1.9.11.17"><span><span class="glossterm">FlatDHCP Manager</span> <a title="Permalink" class="permalink" href="#id-1.9.11.17">#</a></span></dt><dd class="glossdef"><p>The Compute component that provides dnsmasq (DHCP, DNS, BOOTP,
TFTP) and radvd (routing) services.</p></dd><dt id="id-1.9.11.18"><span><span class="glossterm">flavor</span> <a title="Permalink" class="permalink" href="#id-1.9.11.18">#</a></span></dt><dd class="glossdef"><p>Alternative term for a VM instance type.</p></dd><dt id="id-1.9.11.19"><span><span class="glossterm">flavor ID</span> <a title="Permalink" class="permalink" href="#id-1.9.11.19">#</a></span></dt><dd class="glossdef"><p>UUID for each Compute or Image service VM flavor or instance
type.</p></dd><dt id="id-1.9.11.20"><span><span class="glossterm">floating IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.11.20">#</a></span></dt><dd class="glossdef"><p>An IP address that a project can associate with a VM so that the
instance has the same public IP address each time that it boots. You
create a pool of floating IP addresses and assign them to instances as
they are launched to maintain a consistent IP address for maintaining
DNS assignment.</p></dd><dt id="id-1.9.11.21"><span><span class="glossterm">Folsom</span> <a title="Permalink" class="permalink" href="#id-1.9.11.21">#</a></span></dt><dd class="glossdef"><p>A grouped release of projects related to OpenStack that came out
in the fall of 2012, the sixth release of OpenStack. It includes
Compute (nova), Object Storage (swift), Identity (keystone),
Networking (neutron), Image service (glance), and Volumes or Block
Storage (cinder).
Folsom is the code name for the sixth release of
OpenStack. The design summit took place in
San Francisco, California, US and Folsom is a nearby city.</p></dd><dt id="id-1.9.11.22"><span><span class="glossterm">FormPost</span> <a title="Permalink" class="permalink" href="#id-1.9.11.22">#</a></span></dt><dd class="glossdef"><p>Object Storage middleware that uploads (posts) an image through
a form on a web page.</p></dd><dt id="id-1.9.11.23"><span><span class="glossterm">freezer</span> <a title="Permalink" class="permalink" href="#id-1.9.11.23">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-backup-restore-and-disaster-recovery-service-freezer" title="Backup, Restore, and Disaster Recovery service (freezer)">Backup, Restore, and Disaster Recovery service (freezer)</a>.</p></dd><dt id="id-1.9.11.24"><span><span class="glossterm">front end</span> <a title="Permalink" class="permalink" href="#id-1.9.11.24">#</a></span></dt><dd class="glossdef"><p>The point where a user interacts with a service; can be an API
endpoint, the dashboard, or a command-line tool.</p></dd></dl></div><div class="glossdiv" id="id-1.9.12"><h3 class="title">G</h3><dl><dt id="id-1.9.12.3"><span><span class="glossterm">gateway</span> <a title="Permalink" class="permalink" href="#id-1.9.12.3">#</a></span></dt><dd class="glossdef"><p>An IP address, typically assigned to a router, that
passes network traffic between different networks.</p></dd><dt id="id-1.9.12.4"><span><span class="glossterm">generic receive offload (GRO)</span> <a title="Permalink" class="permalink" href="#id-1.9.12.4">#</a></span></dt><dd class="glossdef"><p>Feature of certain network interface drivers that
combines many smaller received packets into a large packet
before delivery to the kernel IP stack.</p></dd><dt id="id-1.9.12.5"><span><span class="glossterm">generic routing encapsulation (GRE)</span> <a title="Permalink" class="permalink" href="#id-1.9.12.5">#</a></span></dt><dd class="glossdef"><p>Protocol that encapsulates a wide variety of network
layer protocols inside virtual point-to-point links.</p></dd><dt id="id-1.9.12.6"><span><span class="glossterm">glance</span> <a title="Permalink" class="permalink" href="#id-1.9.12.6">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-image-service-glance" title="Image service (glance)">Image service (glance)</a>.</p></dd><dt id="id-1.9.12.7"><span><span class="glossterm">glance API server</span> <a title="Permalink" class="permalink" href="#id-1.9.12.7">#</a></span></dt><dd class="glossdef"><p>Alternative name for the <a class="xref" href="#term-image-api" title="Image API">Image API</a>.</p></dd><dt id="id-1.9.12.8"><span><span class="glossterm">glance registry</span> <a title="Permalink" class="permalink" href="#id-1.9.12.8">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Image service <a class="xref" href="#term-image-registry" title="image registry">image registry</a>.</p></dd><dt id="id-1.9.12.9"><span><span class="glossterm">global endpoint template</span> <a title="Permalink" class="permalink" href="#id-1.9.12.9">#</a></span></dt><dd class="glossdef"><p>The Identity service endpoint template that contains services
available to all projects.</p></dd><dt id="id-1.9.12.10"><span><span class="glossterm">GlusterFS</span> <a title="Permalink" class="permalink" href="#id-1.9.12.10">#</a></span></dt><dd class="glossdef"><p>A file system designed to aggregate NAS hosts, compatible with
OpenStack.</p></dd><dt id="id-1.9.12.11"><span><span class="glossterm">gnocchi</span> <a title="Permalink" class="permalink" href="#id-1.9.12.11">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; provides an indexer and time-series
database.</p></dd><dt id="id-1.9.12.12"><span><span class="glossterm">golden image</span> <a title="Permalink" class="permalink" href="#id-1.9.12.12">#</a></span></dt><dd class="glossdef"><p>A method of operating system installation where a finalized disk
image is created and then used by all nodes without
modification.</p></dd><dt id="term-governance-service-congress"><span><span class="glossterm">Governance service (congress)</span> <a title="Permalink" class="permalink" href="#term-governance-service-congress">#</a></span></dt><dd class="glossdef"><p>The project that provides Governance-as-a-Service across
any collection of cloud services in order to monitor,
enforce, and audit policy over dynamic infrastructure.</p></dd><dt id="id-1.9.12.14"><span><span class="glossterm">Graphic Interchange Format (GIF)</span> <a title="Permalink" class="permalink" href="#id-1.9.12.14">#</a></span></dt><dd class="glossdef"><p>A type of image file that is commonly used for animated images
on web pages.</p></dd><dt id="id-1.9.12.15"><span><span class="glossterm">Graphics Processing Unit (GPU)</span> <a title="Permalink" class="permalink" href="#id-1.9.12.15">#</a></span></dt><dd class="glossdef"><p>Choosing a host based on the existence of a GPU is currently
unsupported in OpenStack.</p></dd><dt id="id-1.9.12.16"><span><span class="glossterm">Green Threads</span> <a title="Permalink" class="permalink" href="#id-1.9.12.16">#</a></span></dt><dd class="glossdef"><p>The cooperative threading model used by Python; reduces race
conditions and only context switches when specific library calls are
made. Each OpenStack service is its own thread.</p></dd><dt id="id-1.9.12.17"><span><span class="glossterm">Grizzly</span> <a title="Permalink" class="permalink" href="#id-1.9.12.17">#</a></span></dt><dd class="glossdef"><p>The code name for the seventh release of
OpenStack. The design summit took place in
San Diego, California, US and Grizzly is an element of the state flag of
California.</p></dd><dt id="id-1.9.12.18"><span><span class="glossterm">Group</span> <a title="Permalink" class="permalink" href="#id-1.9.12.18">#</a></span></dt><dd class="glossdef"><p>An Identity v3 API entity. Represents a collection of users that is
owned by a specific domain.</p></dd><dt id="id-1.9.12.19"><span><span class="glossterm">guest OS</span> <a title="Permalink" class="permalink" href="#id-1.9.12.19">#</a></span></dt><dd class="glossdef"><p>An operating system instance running under the control of a
hypervisor.</p></dd></dl></div><div class="glossdiv" id="id-1.9.13"><h3 class="title">H</h3><dl><dt id="id-1.9.13.3"><span><span class="glossterm">Hadoop</span> <a title="Permalink" class="permalink" href="#id-1.9.13.3">#</a></span></dt><dd class="glossdef"><p>Apache Hadoop is an open source software framework that supports
data-intensive distributed applications.</p></dd><dt id="id-1.9.13.4"><span><span class="glossterm">Hadoop Distributed File System (HDFS)</span> <a title="Permalink" class="permalink" href="#id-1.9.13.4">#</a></span></dt><dd class="glossdef"><p>A distributed, highly fault-tolerant file system designed to run
on low-cost commodity hardware.</p></dd><dt id="id-1.9.13.5"><span><span class="glossterm">handover</span> <a title="Permalink" class="permalink" href="#id-1.9.13.5">#</a></span></dt><dd class="glossdef"><p>An object state in Object Storage where a new replica of the
object is automatically created due to a drive failure.</p></dd><dt id="term-haproxy"><span><span class="glossterm">HAProxy</span> <a title="Permalink" class="permalink" href="#term-haproxy">#</a></span></dt><dd class="glossdef"><p>Provides a high availability load balancer and proxy server for
TCP and HTTP-based applications that spreads requests across
multiple servers.</p></dd><dt id="id-1.9.13.7"><span><span class="glossterm">hard reboot</span> <a title="Permalink" class="permalink" href="#id-1.9.13.7">#</a></span></dt><dd class="glossdef"><p>A type of reboot where a physical or virtual power button is
pressed as opposed to a graceful, proper shutdown of the operating
system.</p></dd><dt id="id-1.9.13.8"><span><span class="glossterm">Havana</span> <a title="Permalink" class="permalink" href="#id-1.9.13.8">#</a></span></dt><dd class="glossdef"><p>The code name for the eighth release of OpenStack. The
design summit took place in Portland, Oregon, US and Havana is
an unincorporated community in Oregon.</p></dd><dt id="id-1.9.13.9"><span><span class="glossterm">health monitor</span> <a title="Permalink" class="permalink" href="#id-1.9.13.9">#</a></span></dt><dd class="glossdef"><p>Determines whether back-end members of a VIP pool can
process a request. A pool can have several health monitors
associated with it. When a pool has several monitors
associated with it, all monitors check each member of the
pool. All monitors must declare a member to be healthy for
it to stay active.</p></dd><dt id="id-1.9.13.10"><span><span class="glossterm">heat</span> <a title="Permalink" class="permalink" href="#id-1.9.13.10">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-orchestration-service-heat" title="Orchestration service (heat)">Orchestration service (heat)</a>.</p></dd><dt id="id-1.9.13.11"><span><span class="glossterm">Heat Orchestration Template (HOT)</span> <a title="Permalink" class="permalink" href="#id-1.9.13.11">#</a></span></dt><dd class="glossdef"><p>Heat input in the format native to OpenStack.</p></dd><dt id="id-1.9.13.12"><span><span class="glossterm">high availability (HA)</span> <a title="Permalink" class="permalink" href="#id-1.9.13.12">#</a></span></dt><dd class="glossdef"><p>A high availability system design approach and associated
service implementation ensures that a prearranged level of
operational performance will be met during a contractual
measurement period. High availability systems seek to
minimize system downtime and data loss.</p></dd><dt id="id-1.9.13.13"><span><span class="glossterm">horizon</span> <a title="Permalink" class="permalink" href="#id-1.9.13.13">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-dashboard-horizon" title="Dashboard (horizon)">Dashboard (horizon)</a>.</p></dd><dt id="id-1.9.13.14"><span><span class="glossterm">horizon plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.13.14">#</a></span></dt><dd class="glossdef"><p>A plug-in for the OpenStack Dashboard (horizon).</p></dd><dt id="id-1.9.13.15"><span><span class="glossterm">host</span> <a title="Permalink" class="permalink" href="#id-1.9.13.15">#</a></span></dt><dd class="glossdef"><p>A physical computer, not a VM instance (node).</p></dd><dt id="id-1.9.13.16"><span><span class="glossterm">host aggregate</span> <a title="Permalink" class="permalink" href="#id-1.9.13.16">#</a></span></dt><dd class="glossdef"><p>A method to further subdivide availability zones into hypervisor
pools, a collection of common hosts.</p></dd><dt id="id-1.9.13.17"><span><span class="glossterm">Host Bus Adapter (HBA)</span> <a title="Permalink" class="permalink" href="#id-1.9.13.17">#</a></span></dt><dd class="glossdef"><p>Device plugged into a PCI slot, such as a fibre channel or
network card.</p></dd><dt id="id-1.9.13.18"><span><span class="glossterm">hybrid cloud</span> <a title="Permalink" class="permalink" href="#id-1.9.13.18">#</a></span></dt><dd class="glossdef"><p>A hybrid cloud is a composition of two or more clouds
(private, community or public) that remain distinct entities
but are bound together, offering the benefits of multiple
deployment models.  Hybrid cloud can also mean the ability
to connect colocation, managed and/or dedicated services
with cloud resources.</p></dd><dt id="id-1.9.13.19"><span><span class="glossterm">hyperlink</span> <a title="Permalink" class="permalink" href="#id-1.9.13.19">#</a></span></dt><dd class="glossdef"><p>Any kind of text that contains a link to some other site,
commonly found in documents where clicking on a word or words opens up
a different website.</p></dd><dt id="id-1.9.13.20"><span><span class="glossterm">Hypertext Transfer Protocol (HTTP)</span> <a title="Permalink" class="permalink" href="#id-1.9.13.20">#</a></span></dt><dd class="glossdef"><p>An application protocol for distributed, collaborative,
hypermedia information systems. It is the foundation of data
communication for the World Wide Web. Hypertext is structured
text that uses logical links (hyperlinks) between nodes containing
text. HTTP is the protocol to exchange or transfer hypertext.</p></dd><dt id="id-1.9.13.21"><span><span class="glossterm">Hypertext Transfer Protocol Secure (HTTPS)</span> <a title="Permalink" class="permalink" href="#id-1.9.13.21">#</a></span></dt><dd class="glossdef"><p>An encrypted communications protocol for secure communication
over a computer network, with especially wide deployment on the
Internet. Technically, it is not a protocol in and of itself;
rather, it is the result of simply layering the Hypertext Transfer
Protocol (HTTP) on top of the TLS or SSL protocol, thus adding the
security capabilities of TLS or SSL to standard HTTP communications.
Most OpenStack API endpoints and many inter-component communications
support HTTPS communication.</p></dd><dt id="id-1.9.13.22"><span><span class="glossterm">hypervisor</span> <a title="Permalink" class="permalink" href="#id-1.9.13.22">#</a></span></dt><dd class="glossdef"><p>Software that arbitrates and controls VM access to the actual
underlying hardware.</p></dd><dt id="id-1.9.13.23"><span><span class="glossterm">hypervisor pool</span> <a title="Permalink" class="permalink" href="#id-1.9.13.23">#</a></span></dt><dd class="glossdef"><p>A collection of hypervisors grouped together through host
aggregates.</p></dd></dl></div><div class="glossdiv" id="id-1.9.14"><h3 class="title">I</h3><dl><dt id="id-1.9.14.3"><span><span class="glossterm">Icehouse</span> <a title="Permalink" class="permalink" href="#id-1.9.14.3">#</a></span></dt><dd class="glossdef"><p>The code name for the ninth release of OpenStack. The
design summit took place in Hong Kong and Ice House is a
street in that city.</p></dd><dt id="id-1.9.14.4"><span><span class="glossterm">ID number</span> <a title="Permalink" class="permalink" href="#id-1.9.14.4">#</a></span></dt><dd class="glossdef"><p>Unique numeric ID associated with each user in Identity,
conceptually similar to a Linux or LDAP UID.</p></dd><dt id="id-1.9.14.5"><span><span class="glossterm">Identity API</span> <a title="Permalink" class="permalink" href="#id-1.9.14.5">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Identity service API.</p></dd><dt id="id-1.9.14.6"><span><span class="glossterm">Identity back end</span> <a title="Permalink" class="permalink" href="#id-1.9.14.6">#</a></span></dt><dd class="glossdef"><p>The source used by Identity service to retrieve user
information; an OpenLDAP server, for example.</p></dd><dt id="id-1.9.14.7"><span><span class="glossterm">identity provider</span> <a title="Permalink" class="permalink" href="#id-1.9.14.7">#</a></span></dt><dd class="glossdef"><p>A directory service, which allows users to login with a user
name and password. It is a typical source of authentication
tokens.</p></dd><dt id="term-identity-service-keystone"><span><span class="glossterm">Identity service (keystone)</span> <a title="Permalink" class="permalink" href="#term-identity-service-keystone">#</a></span></dt><dd class="glossdef"><p>The project that facilitates API client authentication, service
discovery, distributed multi-tenant authorization, and auditing.
It provides a central directory of users mapped to the OpenStack
services they can access. It also registers endpoints for OpenStack
services and acts as a common authentication system.</p></dd><dt id="id-1.9.14.9"><span><span class="glossterm">Identity service API</span> <a title="Permalink" class="permalink" href="#id-1.9.14.9">#</a></span></dt><dd class="glossdef"><p>The API used to access the OpenStack Identity service provided
through keystone.</p></dd><dt id="id-1.9.14.10"><span><span class="glossterm">image</span> <a title="Permalink" class="permalink" href="#id-1.9.14.10">#</a></span></dt><dd class="glossdef"><p>A collection of files for a specific operating system (OS) that
you use to create or rebuild a server. OpenStack provides pre-built
images. You can also create custom images, or snapshots, from servers
that you have launched. Custom images can be used for data backups or
as "gold" images for additional servers.</p></dd><dt id="term-image-api"><span><span class="glossterm">Image API</span> <a title="Permalink" class="permalink" href="#term-image-api">#</a></span></dt><dd class="glossdef"><p>The Image service API endpoint for management of VM
images.
Processes client requests for VMs, updates Image service
metadata on the registry server, and communicates with the store
adapter to upload VM images from the back-end store.</p></dd><dt id="id-1.9.14.12"><span><span class="glossterm">image cache</span> <a title="Permalink" class="permalink" href="#id-1.9.14.12">#</a></span></dt><dd class="glossdef"><p>Used by Image service to obtain images on the local host rather
than re-downloading them from the image server each time one is
requested.</p></dd><dt id="id-1.9.14.13"><span><span class="glossterm">image ID</span> <a title="Permalink" class="permalink" href="#id-1.9.14.13">#</a></span></dt><dd class="glossdef"><p>Combination of a URI and UUID used to access Image service VM
images through the image API.</p></dd><dt id="id-1.9.14.14"><span><span class="glossterm">image membership</span> <a title="Permalink" class="permalink" href="#id-1.9.14.14">#</a></span></dt><dd class="glossdef"><p>A list of projects that can access a given VM image within Image
service.</p></dd><dt id="id-1.9.14.15"><span><span class="glossterm">image owner</span> <a title="Permalink" class="permalink" href="#id-1.9.14.15">#</a></span></dt><dd class="glossdef"><p>The project who owns an Image service virtual machine
image.</p></dd><dt id="term-image-registry"><span><span class="glossterm">image registry</span> <a title="Permalink" class="permalink" href="#term-image-registry">#</a></span></dt><dd class="glossdef"><p>A list of VM images that are available through Image
service.</p></dd><dt id="term-image-service-glance"><span><span class="glossterm">Image service (glance)</span> <a title="Permalink" class="permalink" href="#term-image-service-glance">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provide services and associated libraries
to store, browse, share, distribute and manage bootable disk images,
other data closely associated with initializing compute resources,
and metadata definitions.</p></dd><dt id="id-1.9.14.18"><span><span class="glossterm">image status</span> <a title="Permalink" class="permalink" href="#id-1.9.14.18">#</a></span></dt><dd class="glossdef"><p>The current status of a VM image in Image service, not to be
confused with the status of a running instance.</p></dd><dt id="id-1.9.14.19"><span><span class="glossterm">image store</span> <a title="Permalink" class="permalink" href="#id-1.9.14.19">#</a></span></dt><dd class="glossdef"><p>The back-end store used by Image service to store VM images,
options include Object Storage, locally mounted file system,
RADOS block devices, VMware datastore, or HTTP.</p></dd><dt id="id-1.9.14.20"><span><span class="glossterm">image UUID</span> <a title="Permalink" class="permalink" href="#id-1.9.14.20">#</a></span></dt><dd class="glossdef"><p>UUID used by Image service to uniquely identify each VM
image.</p></dd><dt id="id-1.9.14.21"><span><span class="glossterm">incubated project</span> <a title="Permalink" class="permalink" href="#id-1.9.14.21">#</a></span></dt><dd class="glossdef"><p>A community project may be elevated to this status and is then
promoted to a core project.</p></dd><dt id="term-infrastructure-optimization-service-watcher"><span><span class="glossterm">Infrastructure Optimization service (watcher)</span> <a title="Permalink" class="permalink" href="#term-infrastructure-optimization-service-watcher">#</a></span></dt><dd class="glossdef"><p>OpenStack project that aims to provide a flexible and scalable resource
optimization service for multi-tenant OpenStack-based clouds.</p></dd><dt id="term-infrastructure-as-a-service-iaas"><span><span class="glossterm">Infrastructure-as-a-Service (IaaS)</span> <a title="Permalink" class="permalink" href="#term-infrastructure-as-a-service-iaas">#</a></span></dt><dd class="glossdef"><p>IaaS is a provisioning model in which an organization outsources
physical components of a data center, such as storage, hardware,
servers, and networking components. A service provider owns the
equipment and is responsible for housing, operating and maintaining
it. The client typically pays on a per-use basis.
IaaS is a model for providing cloud services.</p></dd><dt id="id-1.9.14.24"><span><span class="glossterm">ingress filtering</span> <a title="Permalink" class="permalink" href="#id-1.9.14.24">#</a></span></dt><dd class="glossdef"><p>The process of filtering incoming network traffic. Supported by
Compute.</p></dd><dt id="id-1.9.14.25"><span><span class="glossterm">INI format</span> <a title="Permalink" class="permalink" href="#id-1.9.14.25">#</a></span></dt><dd class="glossdef"><p>The OpenStack configuration files use an INI format to
describe options and their values. It consists of sections
and key value pairs.</p></dd><dt id="id-1.9.14.26"><span><span class="glossterm">injection</span> <a title="Permalink" class="permalink" href="#id-1.9.14.26">#</a></span></dt><dd class="glossdef"><p>The process of putting a file into a virtual machine image
before the instance is started.</p></dd><dt id="term-input-output-operations-per-second-iops"><span><span class="glossterm">Input/Output Operations Per Second (IOPS)</span> <a title="Permalink" class="permalink" href="#term-input-output-operations-per-second-iops">#</a></span></dt><dd class="glossdef"><p>IOPS are a common performance measurement used to benchmark computer
storage devices like hard disk drives, solid state drives, and
storage area networks.</p></dd><dt id="id-1.9.14.28"><span><span class="glossterm">instance</span> <a title="Permalink" class="permalink" href="#id-1.9.14.28">#</a></span></dt><dd class="glossdef"><p>A running VM, or a VM in a known state such as suspended, that
can be used like a hardware server.</p></dd><dt id="id-1.9.14.29"><span><span class="glossterm">instance ID</span> <a title="Permalink" class="permalink" href="#id-1.9.14.29">#</a></span></dt><dd class="glossdef"><p>Alternative term for instance UUID.</p></dd><dt id="id-1.9.14.30"><span><span class="glossterm">instance state</span> <a title="Permalink" class="permalink" href="#id-1.9.14.30">#</a></span></dt><dd class="glossdef"><p>The current state of a guest VM image.</p></dd><dt id="id-1.9.14.31"><span><span class="glossterm">instance tunnels network</span> <a title="Permalink" class="permalink" href="#id-1.9.14.31">#</a></span></dt><dd class="glossdef"><p>A network segment used for instance traffic tunnels
between compute nodes and the network node.</p></dd><dt id="id-1.9.14.32"><span><span class="glossterm">instance type</span> <a title="Permalink" class="permalink" href="#id-1.9.14.32">#</a></span></dt><dd class="glossdef"><p>Describes the parameters of the various virtual machine images
that are available to users; includes parameters such as CPU, storage,
and memory. Alternative term for flavor.</p></dd><dt id="id-1.9.14.33"><span><span class="glossterm">instance type ID</span> <a title="Permalink" class="permalink" href="#id-1.9.14.33">#</a></span></dt><dd class="glossdef"><p>Alternative term for a flavor ID.</p></dd><dt id="id-1.9.14.34"><span><span class="glossterm">instance UUID</span> <a title="Permalink" class="permalink" href="#id-1.9.14.34">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each guest VM instance.</p></dd><dt id="id-1.9.14.35"><span><span class="glossterm">Intelligent Platform Management Interface (IPMI)</span> <a title="Permalink" class="permalink" href="#id-1.9.14.35">#</a></span></dt><dd class="glossdef"><p>IPMI is a standardized computer system interface used by system
administrators for out-of-band management of computer systems and
monitoring of their operation. In layman's terms, it is a way to
manage a computer using a direct network connection, whether it is
turned on or not; connecting to the hardware rather than an operating
system or login shell.</p></dd><dt id="id-1.9.14.36"><span><span class="glossterm">interface</span> <a title="Permalink" class="permalink" href="#id-1.9.14.36">#</a></span></dt><dd class="glossdef"><p>A physical or virtual device that provides connectivity
to another device or medium.</p></dd><dt id="id-1.9.14.37"><span><span class="glossterm">interface ID</span> <a title="Permalink" class="permalink" href="#id-1.9.14.37">#</a></span></dt><dd class="glossdef"><p>Unique ID for a Networking VIF or vNIC in the form of a
UUID.</p></dd><dt id="id-1.9.14.38"><span><span class="glossterm">Internet Control Message Protocol (ICMP)</span> <a title="Permalink" class="permalink" href="#id-1.9.14.38">#</a></span></dt><dd class="glossdef"><p>A network protocol used by network devices for control messages.
For example, <code class="command">ping</code> uses ICMP to test
connectivity.</p></dd><dt id="id-1.9.14.39"><span><span class="glossterm">Internet protocol (IP)</span> <a title="Permalink" class="permalink" href="#id-1.9.14.39">#</a></span></dt><dd class="glossdef"><p>Principal communications protocol in the internet protocol
suite for relaying datagrams across network boundaries.</p></dd><dt id="id-1.9.14.40"><span><span class="glossterm">Internet Service Provider (ISP)</span> <a title="Permalink" class="permalink" href="#id-1.9.14.40">#</a></span></dt><dd class="glossdef"><p>Any business that provides Internet access to individuals or
businesses.</p></dd><dt id="id-1.9.14.41"><span><span class="glossterm">Internet Small Computer System Interface (iSCSI)</span> <a title="Permalink" class="permalink" href="#id-1.9.14.41">#</a></span></dt><dd class="glossdef"><p>Storage protocol that encapsulates SCSI frames for transport
over IP networks.
Supported by Compute, Object Storage, and Image service.</p></dd><dt id="id-1.9.14.42"><span><span class="glossterm">IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.14.42">#</a></span></dt><dd class="glossdef"><p>Number that is unique to every computer system on the Internet.
Two versions of the Internet Protocol (IP) are in use for addresses:
IPv4 and IPv6.</p></dd><dt id="id-1.9.14.43"><span><span class="glossterm">IP Address Management (IPAM)</span> <a title="Permalink" class="permalink" href="#id-1.9.14.43">#</a></span></dt><dd class="glossdef"><p>The process of automating IP address allocation, deallocation,
and management. Currently provided by Compute, melange, and
Networking.</p></dd><dt id="id-1.9.14.44"><span><span class="glossterm">ip6tables</span> <a title="Permalink" class="permalink" href="#id-1.9.14.44">#</a></span></dt><dd class="glossdef"><p>Tool used to set up, maintain, and inspect the tables of IPv6
packet filter rules in the Linux kernel. In OpenStack Compute,
ip6tables is used along with arptables, ebtables, and iptables to
create firewalls for both nodes and VMs.</p></dd><dt id="id-1.9.14.45"><span><span class="glossterm">ipset</span> <a title="Permalink" class="permalink" href="#id-1.9.14.45">#</a></span></dt><dd class="glossdef"><p>Extension to iptables that allows creation of firewall rules
that match entire "sets" of IP addresses simultaneously. These
sets reside in indexed data structures to increase efficiency,
particularly on systems with a large quantity of rules.</p></dd><dt id="id-1.9.14.46"><span><span class="glossterm">iptables</span> <a title="Permalink" class="permalink" href="#id-1.9.14.46">#</a></span></dt><dd class="glossdef"><p>Used along with arptables and ebtables, iptables create
firewalls in Compute. iptables are the tables provided by the Linux
kernel firewall (implemented as different Netfilter modules) and the
chains and rules it stores. Different kernel modules and programs are
currently used for different protocols: iptables applies to IPv4,
ip6tables to IPv6, arptables to ARP, and ebtables to Ethernet frames.
Requires root privilege to manipulate.</p></dd><dt id="id-1.9.14.47"><span><span class="glossterm">ironic</span> <a title="Permalink" class="permalink" href="#id-1.9.14.47">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-bare-metal-service-ironic" title="Bare Metal service (ironic)">Bare Metal service (ironic)</a>.</p></dd><dt id="term-iscsi-qualified-name-iqn"><span><span class="glossterm">iSCSI Qualified Name (IQN)</span> <a title="Permalink" class="permalink" href="#term-iscsi-qualified-name-iqn">#</a></span></dt><dd class="glossdef"><p>IQN is the format most commonly used for iSCSI names, which uniquely
identify nodes in an iSCSI network.
All IQNs follow the pattern iqn.yyyy-mm.domain:identifier, where
'yyyy-mm' is the year and month in which the domain was registered,
'domain' is the reversed domain name of the issuing organization, and
'identifier' is an optional string which makes each IQN under the same
domain unique. For example, 'iqn.2015-10.org.openstack.408ae959bce1'.</p></dd><dt id="id-1.9.14.49"><span><span class="glossterm">ISO9660</span> <a title="Permalink" class="permalink" href="#id-1.9.14.49">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.9.14.50"><span><span class="glossterm">itsec</span> <a title="Permalink" class="permalink" href="#id-1.9.14.50">#</a></span></dt><dd class="glossdef"><p>A default role in the Compute RBAC system that can quarantine an
instance in any project.</p></dd></dl></div><div class="glossdiv" id="id-1.9.15"><h3 class="title">J</h3><dl><dt id="id-1.9.15.3"><span><span class="glossterm">Java</span> <a title="Permalink" class="permalink" href="#id-1.9.15.3">#</a></span></dt><dd class="glossdef"><p>A programming language that is used to create systems that
involve more than one computer by way of a network.</p></dd><dt id="id-1.9.15.4"><span><span class="glossterm">JavaScript</span> <a title="Permalink" class="permalink" href="#id-1.9.15.4">#</a></span></dt><dd class="glossdef"><p>A scripting language that is used to build web pages.</p></dd><dt id="id-1.9.15.5"><span><span class="glossterm">JavaScript Object Notation (JSON)</span> <a title="Permalink" class="permalink" href="#id-1.9.15.5">#</a></span></dt><dd class="glossdef"><p>One of the supported response formats in OpenStack.</p></dd><dt id="id-1.9.15.6"><span><span class="glossterm">Jenkins</span> <a title="Permalink" class="permalink" href="#id-1.9.15.6">#</a></span></dt><dd class="glossdef"><p>Tool used to run jobs automatically for OpenStack
development.</p></dd><dt id="id-1.9.15.7"><span><span class="glossterm">jumbo frame</span> <a title="Permalink" class="permalink" href="#id-1.9.15.7">#</a></span></dt><dd class="glossdef"><p>Feature in modern Ethernet networks that supports frames up to
approximately 9000 bytes.</p></dd><dt id="id-1.9.15.8"><span><span class="glossterm">Juno</span> <a title="Permalink" class="permalink" href="#id-1.9.15.8">#</a></span></dt><dd class="glossdef"><p>The code name for the tenth release of OpenStack. The
design summit took place in Atlanta, Georgia, US and Juno is
an unincorporated community in Georgia.</p></dd></dl></div><div class="glossdiv" id="id-1.9.16"><h3 class="title">K</h3><dl><dt id="id-1.9.16.3"><span><span class="glossterm">Kerberos</span> <a title="Permalink" class="permalink" href="#id-1.9.16.3">#</a></span></dt><dd class="glossdef"><p>A network authentication protocol which works on the basis of
tickets. Kerberos allows nodes communication over a non-secure
network, and allows nodes to prove their identity to one another in a
secure manner.</p></dd><dt id="id-1.9.16.4"><span><span class="glossterm">kernel-based VM (KVM)</span> <a title="Permalink" class="permalink" href="#id-1.9.16.4">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor. KVM is a full
virtualization solution for Linux on x86 hardware containing
virtualization extensions (Intel VT or AMD-V), ARM, IBM
Power, and IBM zSeries. It consists of a loadable kernel
module, that provides the core virtualization infrastructure
and a processor specific module.</p></dd><dt id="term-key-manager-service-barbican"><span><span class="glossterm">Key Manager service (barbican)</span> <a title="Permalink" class="permalink" href="#term-key-manager-service-barbican">#</a></span></dt><dd class="glossdef"><p>The project that produces a secret storage and
generation system capable of providing key management for
services wishing to enable encryption features.</p></dd><dt id="id-1.9.16.6"><span><span class="glossterm">keystone</span> <a title="Permalink" class="permalink" href="#id-1.9.16.6">#</a></span></dt><dd class="glossdef"><p>Codename of the <a class="xref" href="#term-identity-service-keystone" title="Identity service (keystone)">Identity service (keystone)</a>.</p></dd><dt id="id-1.9.16.7"><span><span class="glossterm">Kickstart</span> <a title="Permalink" class="permalink" href="#id-1.9.16.7">#</a></span></dt><dd class="glossdef"><p>A tool to automate system configuration and installation on Red
Hat, Fedora, and CentOS-based Linux distributions.</p></dd><dt id="id-1.9.16.8"><span><span class="glossterm">Kilo</span> <a title="Permalink" class="permalink" href="#id-1.9.16.8">#</a></span></dt><dd class="glossdef"><p>The code name for the eleventh release of OpenStack. The
design summit took place in Paris, France. Due to delays in the name
selection, the release was known only as K. Because <code class="literal">k</code> is the
unit symbol for kilo and the reference artifact is stored near Paris
in the Pavillon de Breteuil in Sèvres, the community chose Kilo as
the release name.</p></dd></dl></div><div class="glossdiv" id="id-1.9.17"><h3 class="title">L</h3><dl><dt id="id-1.9.17.3"><span><span class="glossterm">large object</span> <a title="Permalink" class="permalink" href="#id-1.9.17.3">#</a></span></dt><dd class="glossdef"><p>An object within Object Storage that is larger than 5 GB.</p></dd><dt id="id-1.9.17.4"><span><span class="glossterm">Launchpad</span> <a title="Permalink" class="permalink" href="#id-1.9.17.4">#</a></span></dt><dd class="glossdef"><p>The collaboration site for OpenStack.</p></dd><dt id="id-1.9.17.5"><span><span class="glossterm">Layer-2 (L2) agent</span> <a title="Permalink" class="permalink" href="#id-1.9.17.5">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides layer-2
connectivity for virtual networks.</p></dd><dt id="id-1.9.17.6"><span><span class="glossterm">Layer-2 network</span> <a title="Permalink" class="permalink" href="#id-1.9.17.6">#</a></span></dt><dd class="glossdef"><p>Term used in the OSI network architecture for the data link
layer. The data link layer is responsible for media access
control, flow control and detecting and possibly correcting
errors that may occur in the physical layer.</p></dd><dt id="id-1.9.17.7"><span><span class="glossterm">Layer-3 (L3) agent</span> <a title="Permalink" class="permalink" href="#id-1.9.17.7">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides layer-3
(routing) services for virtual networks.</p></dd><dt id="id-1.9.17.8"><span><span class="glossterm">Layer-3 network</span> <a title="Permalink" class="permalink" href="#id-1.9.17.8">#</a></span></dt><dd class="glossdef"><p>Term used in the OSI network architecture for the network
layer. The network layer is responsible for packet
forwarding including routing from one node to another.</p></dd><dt id="id-1.9.17.9"><span><span class="glossterm">Liberty</span> <a title="Permalink" class="permalink" href="#id-1.9.17.9">#</a></span></dt><dd class="glossdef"><p>The code name for the twelfth release of OpenStack. The
design summit took place in Vancouver, Canada and Liberty is
the name of a village in the Canadian province of
Saskatchewan.</p></dd><dt id="id-1.9.17.10"><span><span class="glossterm">libvirt</span> <a title="Permalink" class="permalink" href="#id-1.9.17.10">#</a></span></dt><dd class="glossdef"><p>Virtualization API library used by OpenStack to interact with
many of its supported hypervisors.</p></dd><dt id="id-1.9.17.11"><span><span class="glossterm">Lightweight Directory Access Protocol (LDAP)</span> <a title="Permalink" class="permalink" href="#id-1.9.17.11">#</a></span></dt><dd class="glossdef"><p>An application protocol for accessing and maintaining distributed
directory information services over an IP network.</p></dd><dt id="id-1.9.17.12"><span><span class="glossterm">Linux bridge</span> <a title="Permalink" class="permalink" href="#id-1.9.17.12">#</a></span></dt><dd class="glossdef"><p>Software that enables multiple VMs to share a single physical
NIC within Compute.</p></dd><dt id="id-1.9.17.13"><span><span class="glossterm">Linux Bridge neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.17.13">#</a></span></dt><dd class="glossdef"><p>Enables a Linux bridge to understand a Networking port,
interface attachment, and other abstractions.</p></dd><dt id="id-1.9.17.14"><span><span class="glossterm">Linux containers (LXC)</span> <a title="Permalink" class="permalink" href="#id-1.9.17.14">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.9.17.15"><span><span class="glossterm">live migration</span> <a title="Permalink" class="permalink" href="#id-1.9.17.15">#</a></span></dt><dd class="glossdef"><p>The ability within Compute to move running virtual machine
instances from one host to another with only a small service
interruption during switchover.</p></dd><dt id="id-1.9.17.16"><span><span class="glossterm">load balancer</span> <a title="Permalink" class="permalink" href="#id-1.9.17.16">#</a></span></dt><dd class="glossdef"><p>A load balancer is a logical device that belongs to a cloud
account. It is used to distribute workloads between multiple back-end
systems or services, based on the criteria defined as part of its
configuration.</p></dd><dt id="id-1.9.17.17"><span><span class="glossterm">load balancing</span> <a title="Permalink" class="permalink" href="#id-1.9.17.17">#</a></span></dt><dd class="glossdef"><p>The process of spreading client requests between two or more
nodes to improve performance and availability.</p></dd><dt id="id-1.9.17.18"><span><span class="glossterm">Load-Balancer-as-a-Service (LBaaS)</span> <a title="Permalink" class="permalink" href="#id-1.9.17.18">#</a></span></dt><dd class="glossdef"><p>Enables Networking to distribute incoming requests evenly
between designated instances.</p></dd><dt id="term-load-balancing-service-octavia"><span><span class="glossterm">Load-balancing service (octavia)</span> <a title="Permalink" class="permalink" href="#term-load-balancing-service-octavia">#</a></span></dt><dd class="glossdef"><p>The project that aims to rovide scalable, on demand, self service
access to load-balancer services, in technology-agnostic manner.</p></dd><dt id="term-logical-volume-manager-lvm"><span><span class="glossterm">Logical Volume Manager (LVM)</span> <a title="Permalink" class="permalink" href="#term-logical-volume-manager-lvm">#</a></span></dt><dd class="glossdef"><p>Provides a method of allocating space on mass-storage
devices that is more flexible than conventional partitioning
schemes.</p></dd></dl></div><div class="glossdiv" id="id-1.9.18"><h3 class="title">M</h3><dl><dt id="id-1.9.18.3"><span><span class="glossterm">magnum</span> <a title="Permalink" class="permalink" href="#id-1.9.18.3">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-container-infrastructure-management-service-magnum" title="Container Infrastructure Management service (magnum)">Container Infrastructure Management service (magnum)</a>.</p></dd><dt id="id-1.9.18.4"><span><span class="glossterm">management API</span> <a title="Permalink" class="permalink" href="#id-1.9.18.4">#</a></span></dt><dd class="glossdef"><p>Alternative term for an admin API.</p></dd><dt id="id-1.9.18.5"><span><span class="glossterm">management network</span> <a title="Permalink" class="permalink" href="#id-1.9.18.5">#</a></span></dt><dd class="glossdef"><p>A network segment used for administration, not accessible to the
public Internet.</p></dd><dt id="id-1.9.18.6"><span><span class="glossterm">manager</span> <a title="Permalink" class="permalink" href="#id-1.9.18.6">#</a></span></dt><dd class="glossdef"><p>Logical groupings of related code, such as the Block Storage
volume manager or network manager.</p></dd><dt id="id-1.9.18.7"><span><span class="glossterm">manifest</span> <a title="Permalink" class="permalink" href="#id-1.9.18.7">#</a></span></dt><dd class="glossdef"><p>Used to track segments of a large object within Object
Storage.</p></dd><dt id="id-1.9.18.8"><span><span class="glossterm">manifest object</span> <a title="Permalink" class="permalink" href="#id-1.9.18.8">#</a></span></dt><dd class="glossdef"><p>A special Object Storage object that contains the manifest for a
large object.</p></dd><dt id="id-1.9.18.9"><span><span class="glossterm">manila</span> <a title="Permalink" class="permalink" href="#id-1.9.18.9">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-shared-file-systems-service-manila" title="Shared File Systems service (manila)">Shared File Systems service (manila)</a>.</p></dd><dt id="id-1.9.18.10"><span><span class="glossterm">manila-share</span> <a title="Permalink" class="permalink" href="#id-1.9.18.10">#</a></span></dt><dd class="glossdef"><p>Responsible for managing Shared File System Service devices, specifically
the back-end devices.</p></dd><dt id="id-1.9.18.11"><span><span class="glossterm">maximum transmission unit (MTU)</span> <a title="Permalink" class="permalink" href="#id-1.9.18.11">#</a></span></dt><dd class="glossdef"><p>Maximum frame or packet size for a particular network
medium. Typically 1500 bytes for Ethernet networks.</p></dd><dt id="id-1.9.18.12"><span><span class="glossterm">mechanism driver</span> <a title="Permalink" class="permalink" href="#id-1.9.18.12">#</a></span></dt><dd class="glossdef"><p>A driver for the Modular Layer 2 (ML2) neutron plug-in that
provides layer-2 connectivity for virtual instances. A
single OpenStack installation can use multiple mechanism
drivers.</p></dd><dt id="id-1.9.18.13"><span><span class="glossterm">melange</span> <a title="Permalink" class="permalink" href="#id-1.9.18.13">#</a></span></dt><dd class="glossdef"><p>Project name for OpenStack Network Information Service. To be
merged with Networking.</p></dd><dt id="id-1.9.18.14"><span><span class="glossterm">membership</span> <a title="Permalink" class="permalink" href="#id-1.9.18.14">#</a></span></dt><dd class="glossdef"><p>The association between an Image service VM image and a project.
Enables images to be shared with specified projects.</p></dd><dt id="id-1.9.18.15"><span><span class="glossterm">membership list</span> <a title="Permalink" class="permalink" href="#id-1.9.18.15">#</a></span></dt><dd class="glossdef"><p>A list of projects that can access a given VM image within Image
service.</p></dd><dt id="id-1.9.18.16"><span><span class="glossterm">memcached</span> <a title="Permalink" class="permalink" href="#id-1.9.18.16">#</a></span></dt><dd class="glossdef"><p>A distributed memory object caching system that is used by
Object Storage for caching.</p></dd><dt id="id-1.9.18.17"><span><span class="glossterm">memory overcommit</span> <a title="Permalink" class="permalink" href="#id-1.9.18.17">#</a></span></dt><dd class="glossdef"><p>The ability to start new VM instances based on the actual memory
usage of a host, as opposed to basing the decision on the amount of
RAM each running instance thinks it has available. Also known as RAM
overcommit.</p></dd><dt id="id-1.9.18.18"><span><span class="glossterm">message broker</span> <a title="Permalink" class="permalink" href="#id-1.9.18.18">#</a></span></dt><dd class="glossdef"><p>The software package used to provide AMQP messaging capabilities
within Compute. Default package is RabbitMQ.</p></dd><dt id="id-1.9.18.19"><span><span class="glossterm">message bus</span> <a title="Permalink" class="permalink" href="#id-1.9.18.19">#</a></span></dt><dd class="glossdef"><p>The main virtual communication line used by all AMQP messages
for inter-cloud communications within Compute.</p></dd><dt id="id-1.9.18.20"><span><span class="glossterm">message queue</span> <a title="Permalink" class="permalink" href="#id-1.9.18.20">#</a></span></dt><dd class="glossdef"><p>Passes requests from clients to the appropriate workers and
returns the output to the client after the job completes.</p></dd><dt id="term-message-service-zaqar"><span><span class="glossterm">Message service (zaqar)</span> <a title="Permalink" class="permalink" href="#term-message-service-zaqar">#</a></span></dt><dd class="glossdef"><p>The project that provides a messaging service that affords a
variety of distributed application patterns in an efficient,
scalable and highly available manner, and to create and maintain
associated Python libraries and documentation.</p></dd><dt id="id-1.9.18.22"><span><span class="glossterm">Meta-Data Server (MDS)</span> <a title="Permalink" class="permalink" href="#id-1.9.18.22">#</a></span></dt><dd class="glossdef"><p>Stores CephFS metadata.</p></dd><dt id="id-1.9.18.23"><span><span class="glossterm">Metadata agent</span> <a title="Permalink" class="permalink" href="#id-1.9.18.23">#</a></span></dt><dd class="glossdef"><p>OpenStack Networking agent that provides metadata
services for instances.</p></dd><dt id="id-1.9.18.24"><span><span class="glossterm">migration</span> <a title="Permalink" class="permalink" href="#id-1.9.18.24">#</a></span></dt><dd class="glossdef"><p>The process of moving a VM instance from one host to
another.</p></dd><dt id="id-1.9.18.25"><span><span class="glossterm">mistral</span> <a title="Permalink" class="permalink" href="#id-1.9.18.25">#</a></span></dt><dd class="glossdef"><p>Code name for <a class="xref" href="#term-workflow-service-mistral" title="Workflow service (mistral)">Workflow service (mistral)</a>.</p></dd><dt id="id-1.9.18.26"><span><span class="glossterm">Mitaka</span> <a title="Permalink" class="permalink" href="#id-1.9.18.26">#</a></span></dt><dd class="glossdef"><p>The code name for the thirteenth release of OpenStack.
The design summit took place in Tokyo, Japan. Mitaka
is a city in Tokyo.</p></dd><dt id="id-1.9.18.27"><span><span class="glossterm">Modular Layer 2 (ML2) neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.18.27">#</a></span></dt><dd class="glossdef"><p>Can concurrently use multiple layer-2 networking technologies,
such as 802.1Q and VXLAN, in Networking.</p></dd><dt id="id-1.9.18.28"><span><span class="glossterm">monasca</span> <a title="Permalink" class="permalink" href="#id-1.9.18.28">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-monitoring-monasca" title="Monitoring (monasca)">Monitoring (monasca)</a>.</p></dd><dt id="id-1.9.18.29"><span><span class="glossterm">Monitor (LBaaS)</span> <a title="Permalink" class="permalink" href="#id-1.9.18.29">#</a></span></dt><dd class="glossdef"><p>LBaaS feature that provides availability monitoring using the
<code class="literal">ping</code> command, TCP, and HTTP/HTTPS GET.</p></dd><dt id="id-1.9.18.30"><span><span class="glossterm">Monitor (Mon)</span> <a title="Permalink" class="permalink" href="#id-1.9.18.30">#</a></span></dt><dd class="glossdef"><p>A Ceph component that communicates with external clients, checks
data state and consistency, and performs quorum functions.</p></dd><dt id="term-monitoring-monasca"><span><span class="glossterm">Monitoring (monasca)</span> <a title="Permalink" class="permalink" href="#term-monitoring-monasca">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provides a multi-tenant, highly scalable,
performant, fault-tolerant monitoring-as-a-service solution for metrics,
complex event processing and logging. To build an extensible platform for
advanced monitoring services that can be used by both operators and
tenants to gain operational insight and visibility, ensuring availability
and stability.</p></dd><dt id="id-1.9.18.32"><span><span class="glossterm">multi-factor authentication</span> <a title="Permalink" class="permalink" href="#id-1.9.18.32">#</a></span></dt><dd class="glossdef"><p>Authentication method that uses two or more credentials, such as
a password and a private key. Currently not supported in
Identity.</p></dd><dt id="id-1.9.18.33"><span><span class="glossterm">multi-host</span> <a title="Permalink" class="permalink" href="#id-1.9.18.33">#</a></span></dt><dd class="glossdef"><p>High-availability mode for legacy (nova) networking.
Each compute node handles NAT and DHCP and acts as a gateway
for all of the VMs on it. A networking failure on one compute
node doesn't affect VMs on other compute nodes.</p></dd><dt id="id-1.9.18.34"><span><span class="glossterm">multinic</span> <a title="Permalink" class="permalink" href="#id-1.9.18.34">#</a></span></dt><dd class="glossdef"><p>Facility in Compute that allows each virtual machine instance to
have more than one VIF connected to it.</p></dd><dt id="id-1.9.18.35"><span><span class="glossterm">murano</span> <a title="Permalink" class="permalink" href="#id-1.9.18.35">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-application-catalog-service-murano" title="Application Catalog service (murano)">Application Catalog service (murano)</a>.</p></dd></dl></div><div class="glossdiv" id="id-1.9.19"><h3 class="title">N</h3><dl><dt id="id-1.9.19.3"><span><span class="glossterm">Nebula</span> <a title="Permalink" class="permalink" href="#id-1.9.19.3">#</a></span></dt><dd class="glossdef"><p>Released as open source by NASA in 2010 and is the basis for
Compute.</p></dd><dt id="id-1.9.19.4"><span><span class="glossterm">netadmin</span> <a title="Permalink" class="permalink" href="#id-1.9.19.4">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system. Enables the
user to allocate publicly accessible IP addresses to instances and
change firewall rules.</p></dd><dt id="id-1.9.19.5"><span><span class="glossterm">NetApp volume driver</span> <a title="Permalink" class="permalink" href="#id-1.9.19.5">#</a></span></dt><dd class="glossdef"><p>Enables Compute to communicate with NetApp storage devices
through the NetApp OnCommand
Provisioning Manager.</p></dd><dt id="id-1.9.19.6"><span><span class="glossterm">network</span> <a title="Permalink" class="permalink" href="#id-1.9.19.6">#</a></span></dt><dd class="glossdef"><p>A virtual network that provides connectivity between entities.
For example, a collection of virtual ports that share network
connectivity. In Networking terminology, a network is always a layer-2
network.</p></dd><dt id="id-1.9.19.7"><span><span class="glossterm">Network Address Translation (NAT)</span> <a title="Permalink" class="permalink" href="#id-1.9.19.7">#</a></span></dt><dd class="glossdef"><p>Process of modifying IP address information while in transit.
Supported by Compute and Networking.</p></dd><dt id="id-1.9.19.8"><span><span class="glossterm">network controller</span> <a title="Permalink" class="permalink" href="#id-1.9.19.8">#</a></span></dt><dd class="glossdef"><p>A Compute daemon that orchestrates the network configuration of
nodes, including IP addresses, VLANs, and bridging. Also manages
routing for both public and private networks.</p></dd><dt id="id-1.9.19.9"><span><span class="glossterm">Network File System (NFS)</span> <a title="Permalink" class="permalink" href="#id-1.9.19.9">#</a></span></dt><dd class="glossdef"><p>A method for making file systems available over the network.
Supported by OpenStack.</p></dd><dt id="id-1.9.19.10"><span><span class="glossterm">network ID</span> <a title="Permalink" class="permalink" href="#id-1.9.19.10">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each network segment within Networking.
Same as network UUID.</p></dd><dt id="id-1.9.19.11"><span><span class="glossterm">network manager</span> <a title="Permalink" class="permalink" href="#id-1.9.19.11">#</a></span></dt><dd class="glossdef"><p>The Compute component that manages various network components,
such as firewall rules, IP address allocation, and so on.</p></dd><dt id="id-1.9.19.12"><span><span class="glossterm">network namespace</span> <a title="Permalink" class="permalink" href="#id-1.9.19.12">#</a></span></dt><dd class="glossdef"><p>Linux kernel feature that provides independent virtual
networking instances on a single host with separate routing
tables and interfaces. Similar to virtual routing and forwarding
(VRF) services on physical network equipment.</p></dd><dt id="id-1.9.19.13"><span><span class="glossterm">network node</span> <a title="Permalink" class="permalink" href="#id-1.9.19.13">#</a></span></dt><dd class="glossdef"><p>Any compute node that runs the network worker daemon.</p></dd><dt id="id-1.9.19.14"><span><span class="glossterm">network segment</span> <a title="Permalink" class="permalink" href="#id-1.9.19.14">#</a></span></dt><dd class="glossdef"><p>Represents a virtual, isolated OSI layer-2 subnet in
Networking.</p></dd><dt id="id-1.9.19.15"><span><span class="glossterm">Network Service Header (NSH)</span> <a title="Permalink" class="permalink" href="#id-1.9.19.15">#</a></span></dt><dd class="glossdef"><p>Provides a mechanism for metadata exchange along the
instantiated service path.</p></dd><dt id="id-1.9.19.16"><span><span class="glossterm">Network Time Protocol (NTP)</span> <a title="Permalink" class="permalink" href="#id-1.9.19.16">#</a></span></dt><dd class="glossdef"><p>Method of keeping a clock for a host or node correct via
communication with a trusted, accurate time source.</p></dd><dt id="id-1.9.19.17"><span><span class="glossterm">network UUID</span> <a title="Permalink" class="permalink" href="#id-1.9.19.17">#</a></span></dt><dd class="glossdef"><p>Unique ID for a Networking network segment.</p></dd><dt id="id-1.9.19.18"><span><span class="glossterm">network worker</span> <a title="Permalink" class="permalink" href="#id-1.9.19.18">#</a></span></dt><dd class="glossdef"><p>The <code class="literal">nova-network</code> worker daemon; provides
services such as giving an IP address to a booting nova
instance.</p></dd><dt id="term-networking-api-neutron-api"><span><span class="glossterm">Networking API (Neutron API)</span> <a title="Permalink" class="permalink" href="#term-networking-api-neutron-api">#</a></span></dt><dd class="glossdef"><p>API used to access OpenStack Networking. Provides an extensible
architecture to enable custom plug-in creation.</p></dd><dt id="term-networking-service-neutron"><span><span class="glossterm">Networking service (neutron)</span> <a title="Permalink" class="permalink" href="#term-networking-service-neutron">#</a></span></dt><dd class="glossdef"><p>The OpenStack project which implements services and associated
libraries to provide on-demand, scalable, and technology-agnostic
network abstraction.</p></dd><dt id="id-1.9.19.21"><span><span class="glossterm">neutron</span> <a title="Permalink" class="permalink" href="#id-1.9.19.21">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-networking-service-neutron" title="Networking service (neutron)">Networking service (neutron)</a>.</p></dd><dt id="id-1.9.19.22"><span><span class="glossterm">neutron API</span> <a title="Permalink" class="permalink" href="#id-1.9.19.22">#</a></span></dt><dd class="glossdef"><p>An alternative name for <a class="xref" href="#term-networking-api-neutron-api" title="Networking API (Neutron API)">Networking API (Neutron API)</a>.</p></dd><dt id="id-1.9.19.23"><span><span class="glossterm">neutron manager</span> <a title="Permalink" class="permalink" href="#id-1.9.19.23">#</a></span></dt><dd class="glossdef"><p>Enables Compute and Networking integration, which enables
Networking to perform network management for guest VMs.</p></dd><dt id="id-1.9.19.24"><span><span class="glossterm">neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.19.24">#</a></span></dt><dd class="glossdef"><p>Interface within Networking that enables organizations to create
custom plug-ins for advanced features, such as QoS, ACLs, or
IDS.</p></dd><dt id="id-1.9.19.25"><span><span class="glossterm">Newton</span> <a title="Permalink" class="permalink" href="#id-1.9.19.25">#</a></span></dt><dd class="glossdef"><p>The code name for the fourteenth release of OpenStack. The
design summit took place in Austin, Texas, US. The
release is named after "Newton House" which is located at
1013 E. Ninth St., Austin, TX. which is listed on the
National Register of Historic Places.</p></dd><dt id="id-1.9.19.26"><span><span class="glossterm">Nexenta volume driver</span> <a title="Permalink" class="permalink" href="#id-1.9.19.26">#</a></span></dt><dd class="glossdef"><p>Provides support for NexentaStor devices in Compute.</p></dd><dt id="term-nfv-orchestration-service-tacker"><span><span class="glossterm">NFV Orchestration Service (tacker)</span> <a title="Permalink" class="permalink" href="#term-nfv-orchestration-service-tacker">#</a></span></dt><dd class="glossdef"><p>OpenStack service that aims to implement Network Function Virtualization
(NFV) Orchestration services and libraries for end-to-end life-cycle
management of Network Services and Virtual Network Functions (VNFs).</p></dd><dt id="id-1.9.19.28"><span><span class="glossterm">Nginx</span> <a title="Permalink" class="permalink" href="#id-1.9.19.28">#</a></span></dt><dd class="glossdef"><p>An HTTP and reverse proxy server, a mail proxy server, and a generic
TCP/UDP proxy server.</p></dd><dt id="id-1.9.19.29"><span><span class="glossterm">No ACK</span> <a title="Permalink" class="permalink" href="#id-1.9.19.29">#</a></span></dt><dd class="glossdef"><p>Disables server-side message acknowledgment in the Compute
RabbitMQ. Increases performance but decreases reliability.</p></dd><dt id="id-1.9.19.30"><span><span class="glossterm">node</span> <a title="Permalink" class="permalink" href="#id-1.9.19.30">#</a></span></dt><dd class="glossdef"><p>A VM instance that runs on a host.</p></dd><dt id="id-1.9.19.31"><span><span class="glossterm">non-durable exchange</span> <a title="Permalink" class="permalink" href="#id-1.9.19.31">#</a></span></dt><dd class="glossdef"><p>Message exchange that is cleared when the service restarts. Its
data is not written to persistent storage.</p></dd><dt id="id-1.9.19.32"><span><span class="glossterm">non-durable queue</span> <a title="Permalink" class="permalink" href="#id-1.9.19.32">#</a></span></dt><dd class="glossdef"><p>Message queue that is cleared when the service restarts. Its
data is not written to persistent storage.</p></dd><dt id="id-1.9.19.33"><span><span class="glossterm">non-persistent volume</span> <a title="Permalink" class="permalink" href="#id-1.9.19.33">#</a></span></dt><dd class="glossdef"><p>Alternative term for an ephemeral volume.</p></dd><dt id="id-1.9.19.34"><span><span class="glossterm">north-south traffic</span> <a title="Permalink" class="permalink" href="#id-1.9.19.34">#</a></span></dt><dd class="glossdef"><p>Network traffic between a user or client (north) and a
server (south), or traffic into the cloud (south) and
out of the cloud (north). See also east-west traffic.</p></dd><dt id="id-1.9.19.35"><span><span class="glossterm">nova</span> <a title="Permalink" class="permalink" href="#id-1.9.19.35">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-compute-service-nova" title="Compute service (nova)">Compute service (nova)</a>.</p></dd><dt id="id-1.9.19.36"><span><span class="glossterm">Nova API</span> <a title="Permalink" class="permalink" href="#id-1.9.19.36">#</a></span></dt><dd class="glossdef"><p>Alternative term for the <a class="xref" href="#term-compute-api-nova-api" title="Compute API (Nova API)">Compute API (Nova API)</a>.</p></dd><dt id="id-1.9.19.37"><span><span class="glossterm">nova-network</span> <a title="Permalink" class="permalink" href="#id-1.9.19.37">#</a></span></dt><dd class="glossdef"><p>A Compute component that manages IP address allocation,
firewalls, and other network-related tasks. This is the legacy
networking option and an alternative to Networking.</p></dd></dl></div><div class="glossdiv" id="id-1.9.20"><h3 class="title">O</h3><dl><dt id="id-1.9.20.3"><span><span class="glossterm">object</span> <a title="Permalink" class="permalink" href="#id-1.9.20.3">#</a></span></dt><dd class="glossdef"><p>A BLOB of data held by Object Storage; can be in any
format.</p></dd><dt id="id-1.9.20.4"><span><span class="glossterm">object auditor</span> <a title="Permalink" class="permalink" href="#id-1.9.20.4">#</a></span></dt><dd class="glossdef"><p>Opens all objects for an object server and verifies the MD5
hash, size, and metadata for each object.</p></dd><dt id="id-1.9.20.5"><span><span class="glossterm">object expiration</span> <a title="Permalink" class="permalink" href="#id-1.9.20.5">#</a></span></dt><dd class="glossdef"><p>A configurable option within Object Storage to automatically
delete objects after a specified amount of time has passed or a
certain date is reached.</p></dd><dt id="id-1.9.20.6"><span><span class="glossterm">object hash</span> <a title="Permalink" class="permalink" href="#id-1.9.20.6">#</a></span></dt><dd class="glossdef"><p>Unique ID for an Object Storage object.</p></dd><dt id="id-1.9.20.7"><span><span class="glossterm">object path hash</span> <a title="Permalink" class="permalink" href="#id-1.9.20.7">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage to determine the location of an object in
the ring. Maps objects to partitions.</p></dd><dt id="id-1.9.20.8"><span><span class="glossterm">object replicator</span> <a title="Permalink" class="permalink" href="#id-1.9.20.8">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that copies an object to remote
partitions for fault tolerance.</p></dd><dt id="id-1.9.20.9"><span><span class="glossterm">object server</span> <a title="Permalink" class="permalink" href="#id-1.9.20.9">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that is responsible for managing
objects.</p></dd><dt id="id-1.9.20.10"><span><span class="glossterm">Object Storage API</span> <a title="Permalink" class="permalink" href="#id-1.9.20.10">#</a></span></dt><dd class="glossdef"><p>API used to access OpenStack <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a>.</p></dd><dt id="id-1.9.20.11"><span><span class="glossterm">Object Storage Device (OSD)</span> <a title="Permalink" class="permalink" href="#id-1.9.20.11">#</a></span></dt><dd class="glossdef"><p>The Ceph storage daemon.</p></dd><dt id="term-object-storage-service-swift"><span><span class="glossterm">Object Storage service (swift)</span> <a title="Permalink" class="permalink" href="#term-object-storage-service-swift">#</a></span></dt><dd class="glossdef"><p>The OpenStack core project that provides eventually consistent
and redundant storage and retrieval of fixed digital content.</p></dd><dt id="id-1.9.20.13"><span><span class="glossterm">object versioning</span> <a title="Permalink" class="permalink" href="#id-1.9.20.13">#</a></span></dt><dd class="glossdef"><p>Allows a user to set a flag on an <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a> container so that all objects within the container are
versioned.</p></dd><dt id="id-1.9.20.14"><span><span class="glossterm">Ocata</span> <a title="Permalink" class="permalink" href="#id-1.9.20.14">#</a></span></dt><dd class="glossdef"><p>The code name for the fifteenth release of OpenStack. The
design summit will take place in Barcelona, Spain. Ocata is
a beach north of Barcelona.</p></dd><dt id="term-octavia"><span><span class="glossterm">Octavia</span> <a title="Permalink" class="permalink" href="#term-octavia">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-load-balancing-service-octavia" title="Load-balancing service (octavia)">Load-balancing service (octavia)</a>.</p></dd><dt id="id-1.9.20.16"><span><span class="glossterm">Oldie</span> <a title="Permalink" class="permalink" href="#id-1.9.20.16">#</a></span></dt><dd class="glossdef"><p>Term for an <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a>
process that runs for a long time.  Can indicate a hung process.</p></dd><dt id="id-1.9.20.17"><span><span class="glossterm">Open Cloud Computing Interface (OCCI)</span> <a title="Permalink" class="permalink" href="#id-1.9.20.17">#</a></span></dt><dd class="glossdef"><p>A standardized interface for managing compute, data, and network
resources, currently unsupported in OpenStack.</p></dd><dt id="id-1.9.20.18"><span><span class="glossterm">Open Virtualization Format (OVF)</span> <a title="Permalink" class="permalink" href="#id-1.9.20.18">#</a></span></dt><dd class="glossdef"><p>Standard for packaging VM images. Supported in OpenStack.</p></dd><dt id="id-1.9.20.19"><span><span class="glossterm">Open vSwitch</span> <a title="Permalink" class="permalink" href="#id-1.9.20.19">#</a></span></dt><dd class="glossdef"><p>Open vSwitch is a production quality, multilayer virtual
switch licensed under the open source Apache 2.0 license. It
is designed to enable massive network automation through
programmatic extension, while still supporting standard
management interfaces and protocols (for example NetFlow,
sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag).</p></dd><dt id="id-1.9.20.20"><span><span class="glossterm">Open vSwitch (OVS) agent</span> <a title="Permalink" class="permalink" href="#id-1.9.20.20">#</a></span></dt><dd class="glossdef"><p>Provides an interface to the underlying Open vSwitch service for
the Networking plug-in.</p></dd><dt id="id-1.9.20.21"><span><span class="glossterm">Open vSwitch neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.20.21">#</a></span></dt><dd class="glossdef"><p>Provides support for Open vSwitch in Networking.</p></dd><dt id="id-1.9.20.22"><span><span class="glossterm">OpenLDAP</span> <a title="Permalink" class="permalink" href="#id-1.9.20.22">#</a></span></dt><dd class="glossdef"><p>An open source LDAP server. Supported by both Compute and
Identity.</p></dd><dt id="id-1.9.20.23"><span><span class="glossterm">OpenStack</span> <a title="Permalink" class="permalink" href="#id-1.9.20.23">#</a></span></dt><dd class="glossdef"><p>OpenStack is a cloud operating system that controls large pools
of compute, storage, and networking resources throughout a data
center, all managed through a dashboard that gives administrators
control while empowering their users to provision resources through a
web interface. OpenStack is an open source project licensed under the
Apache License 2.0.</p></dd><dt id="id-1.9.20.24"><span><span class="glossterm">OpenStack code name</span> <a title="Permalink" class="permalink" href="#id-1.9.20.24">#</a></span></dt><dd class="glossdef"><p>Each OpenStack release has a code name. Code names ascend in
alphabetical order: Austin, Bexar, Cactus, Diablo, Essex,
Folsom, Grizzly, Havana, Icehouse, Juno, Kilo, Liberty,
Mitaka, Newton, Ocata, Pike, and Queens.
Code names are cities or counties near where the
corresponding OpenStack design summit took place. An
exception, called the Waldon exception, is granted to
elements of the state flag that sound especially cool. Code
names are chosen by popular vote.</p></dd><dt id="id-1.9.20.25"><span><span class="glossterm">openSUSE</span> <a title="Permalink" class="permalink" href="#id-1.9.20.25">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.9.20.26"><span><span class="glossterm">operator</span> <a title="Permalink" class="permalink" href="#id-1.9.20.26">#</a></span></dt><dd class="glossdef"><p>The person responsible for planning and maintaining an OpenStack
installation.</p></dd><dt id="id-1.9.20.27"><span><span class="glossterm">optional service</span> <a title="Permalink" class="permalink" href="#id-1.9.20.27">#</a></span></dt><dd class="glossdef"><p>An official OpenStack service defined as optional by
DefCore Committee. Currently, consists of
Dashboard (horizon), Telemetry service (Telemetry),
Orchestration service (heat), Database service (trove),
Bare Metal service (ironic), and so on.</p></dd><dt id="term-orchestration-service-heat"><span><span class="glossterm">Orchestration service (heat)</span> <a title="Permalink" class="permalink" href="#term-orchestration-service-heat">#</a></span></dt><dd class="glossdef"><p>The OpenStack service which orchestrates composite cloud
applications using a declarative template format through
an OpenStack-native REST API.</p></dd><dt id="id-1.9.20.29"><span><span class="glossterm">orphan</span> <a title="Permalink" class="permalink" href="#id-1.9.20.29">#</a></span></dt><dd class="glossdef"><p>In the context of Object Storage, this is a process that is not
terminated after an upgrade, restart, or reload of the service.</p></dd><dt id="id-1.9.20.30"><span><span class="glossterm">Oslo</span> <a title="Permalink" class="permalink" href="#id-1.9.20.30">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-common-libraries-oslo" title="Common Libraries (oslo)">Common Libraries (oslo)</a>.</p></dd></dl></div><div class="glossdiv" id="id-1.9.21"><h3 class="title">P</h3><dl><dt id="id-1.9.21.3"><span><span class="glossterm">panko</span> <a title="Permalink" class="permalink" href="#id-1.9.21.3">#</a></span></dt><dd class="glossdef"><p>Part of the OpenStack <a class="xref" href="#term-telemetry-service-telemetry" title="Telemetry service (telemetry)">Telemetry service (telemetry)</a>; provides event storage.</p></dd><dt id="id-1.9.21.4"><span><span class="glossterm">parent cell</span> <a title="Permalink" class="permalink" href="#id-1.9.21.4">#</a></span></dt><dd class="glossdef"><p>If a requested resource, such as CPU time, disk storage, or
memory, is not available in the parent cell, the request is forwarded
to associated child cells.</p></dd><dt id="id-1.9.21.5"><span><span class="glossterm">partition</span> <a title="Permalink" class="permalink" href="#id-1.9.21.5">#</a></span></dt><dd class="glossdef"><p>A unit of storage within Object Storage used to store objects.
It exists on top of devices and is replicated for fault
tolerance.</p></dd><dt id="id-1.9.21.6"><span><span class="glossterm">partition index</span> <a title="Permalink" class="permalink" href="#id-1.9.21.6">#</a></span></dt><dd class="glossdef"><p>Contains the locations of all Object Storage partitions within
the ring.</p></dd><dt id="id-1.9.21.7"><span><span class="glossterm">partition shift value</span> <a title="Permalink" class="permalink" href="#id-1.9.21.7">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage to determine which partition data should
reside on.</p></dd><dt id="id-1.9.21.8"><span><span class="glossterm">path MTU discovery (PMTUD)</span> <a title="Permalink" class="permalink" href="#id-1.9.21.8">#</a></span></dt><dd class="glossdef"><p>Mechanism in IP networks to detect end-to-end MTU and adjust
packet size accordingly.</p></dd><dt id="id-1.9.21.9"><span><span class="glossterm">pause</span> <a title="Permalink" class="permalink" href="#id-1.9.21.9">#</a></span></dt><dd class="glossdef"><p>A VM state where no changes occur (no changes in memory, network
communications stop, etc); the VM is frozen but not shut down.</p></dd><dt id="id-1.9.21.10"><span><span class="glossterm">PCI passthrough</span> <a title="Permalink" class="permalink" href="#id-1.9.21.10">#</a></span></dt><dd class="glossdef"><p>Gives guest VMs exclusive access to a PCI device. Currently
supported in OpenStack Havana and later releases.</p></dd><dt id="id-1.9.21.11"><span><span class="glossterm">persistent message</span> <a title="Permalink" class="permalink" href="#id-1.9.21.11">#</a></span></dt><dd class="glossdef"><p>A message that is stored both in memory and on disk. The message
is not lost after a failure or restart.</p></dd><dt id="id-1.9.21.12"><span><span class="glossterm">persistent volume</span> <a title="Permalink" class="permalink" href="#id-1.9.21.12">#</a></span></dt><dd class="glossdef"><p>Changes to these types of disk volumes are saved.</p></dd><dt id="id-1.9.21.13"><span><span class="glossterm">personality file</span> <a title="Permalink" class="permalink" href="#id-1.9.21.13">#</a></span></dt><dd class="glossdef"><p>A file used to customize a Compute instance. It can be used to
inject SSH keys or a specific network configuration.</p></dd><dt id="id-1.9.21.14"><span><span class="glossterm">Pike</span> <a title="Permalink" class="permalink" href="#id-1.9.21.14">#</a></span></dt><dd class="glossdef"><p>The code name for the sixteenth release of OpenStack. The design
summit will take place in Boston, Massachusetts, US. The release
is named after the Massachusetts Turnpike, abbreviated commonly
as the Mass Pike, which is the eastermost stretch of
Interstate 90.</p></dd><dt id="id-1.9.21.15"><span><span class="glossterm">Platform-as-a-Service (PaaS)</span> <a title="Permalink" class="permalink" href="#id-1.9.21.15">#</a></span></dt><dd class="glossdef"><p>Provides to the consumer the ability to deploy applications
through a programming language or tools supported by the cloud
platform provider. An example of Platform-as-a-Service is an
Eclipse/Java programming platform provided with no downloads
required.</p></dd><dt id="id-1.9.21.16"><span><span class="glossterm">plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.21.16">#</a></span></dt><dd class="glossdef"><p>Software component providing the actual implementation for
Networking APIs, or for Compute APIs, depending on the context.</p></dd><dt id="id-1.9.21.17"><span><span class="glossterm">policy service</span> <a title="Permalink" class="permalink" href="#id-1.9.21.17">#</a></span></dt><dd class="glossdef"><p>Component of Identity that provides a rule-management
interface and a rule-based authorization engine.</p></dd><dt id="id-1.9.21.18"><span><span class="glossterm">policy-based routing (PBR)</span> <a title="Permalink" class="permalink" href="#id-1.9.21.18">#</a></span></dt><dd class="glossdef"><p>Provides a mechanism to implement packet forwarding and routing
according to the policies defined by the network administrator.</p></dd><dt id="id-1.9.21.19"><span><span class="glossterm">pool</span> <a title="Permalink" class="permalink" href="#id-1.9.21.19">#</a></span></dt><dd class="glossdef"><p>A logical set of devices, such as web servers, that you
group together to receive and process traffic. The load
balancing function chooses which member of the pool handles
the new requests or connections received on the VIP
address. Each VIP has one pool.</p></dd><dt id="id-1.9.21.20"><span><span class="glossterm">pool member</span> <a title="Permalink" class="permalink" href="#id-1.9.21.20">#</a></span></dt><dd class="glossdef"><p>An application that runs on the back-end server in a
load-balancing system.</p></dd><dt id="id-1.9.21.21"><span><span class="glossterm">port</span> <a title="Permalink" class="permalink" href="#id-1.9.21.21">#</a></span></dt><dd class="glossdef"><p>A virtual network port within Networking; VIFs / vNICs are
connected to a port.</p></dd><dt id="id-1.9.21.22"><span><span class="glossterm">port UUID</span> <a title="Permalink" class="permalink" href="#id-1.9.21.22">#</a></span></dt><dd class="glossdef"><p>Unique ID for a Networking port.</p></dd><dt id="id-1.9.21.23"><span><span class="glossterm">preseed</span> <a title="Permalink" class="permalink" href="#id-1.9.21.23">#</a></span></dt><dd class="glossdef"><p>A tool to automate system configuration and installation on
Debian-based Linux distributions.</p></dd><dt id="id-1.9.21.24"><span><span class="glossterm">private image</span> <a title="Permalink" class="permalink" href="#id-1.9.21.24">#</a></span></dt><dd class="glossdef"><p>An Image service VM image that is only available to specified
projects.</p></dd><dt id="id-1.9.21.25"><span><span class="glossterm">private IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.21.25">#</a></span></dt><dd class="glossdef"><p>An IP address used for management and administration, not
available to the public Internet.</p></dd><dt id="id-1.9.21.26"><span><span class="glossterm">private network</span> <a title="Permalink" class="permalink" href="#id-1.9.21.26">#</a></span></dt><dd class="glossdef"><p>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. A private network interface can be a flat or VLAN network
interface. A flat network interface is controlled by the
flat_interface with flat managers. A VLAN network interface is
controlled by the <code class="literal">vlan_interface</code> option with VLAN
managers.</p></dd><dt id="id-1.9.21.27"><span><span class="glossterm">project</span> <a title="Permalink" class="permalink" href="#id-1.9.21.27">#</a></span></dt><dd class="glossdef"><p>Projects represent the base unit of “ownership” in OpenStack,
in that all resources in OpenStack should be owned by a specific project.
In OpenStack Identity, a project must be owned by a specific domain.</p></dd><dt id="term-project-id"><span><span class="glossterm">project ID</span> <a title="Permalink" class="permalink" href="#term-project-id">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each project by the Identity service.</p></dd><dt id="id-1.9.21.29"><span><span class="glossterm">project VPN</span> <a title="Permalink" class="permalink" href="#id-1.9.21.29">#</a></span></dt><dd class="glossdef"><p>Alternative term for a cloudpipe.</p></dd><dt id="id-1.9.21.30"><span><span class="glossterm">promiscuous mode</span> <a title="Permalink" class="permalink" href="#id-1.9.21.30">#</a></span></dt><dd class="glossdef"><p>Causes the network interface to pass all traffic it
receives to the host rather than passing only the frames
addressed to it.</p></dd><dt id="id-1.9.21.31"><span><span class="glossterm">protected property</span> <a title="Permalink" class="permalink" href="#id-1.9.21.31">#</a></span></dt><dd class="glossdef"><p>Generally, extra properties on an Image service image to
which only cloud administrators have access. Limits which user
roles can perform CRUD operations on that property. The cloud
administrator can configure any image property as
protected.</p></dd><dt id="id-1.9.21.32"><span><span class="glossterm">provider</span> <a title="Permalink" class="permalink" href="#id-1.9.21.32">#</a></span></dt><dd class="glossdef"><p>An administrator who has access to all hosts and
instances.</p></dd><dt id="id-1.9.21.33"><span><span class="glossterm">proxy node</span> <a title="Permalink" class="permalink" href="#id-1.9.21.33">#</a></span></dt><dd class="glossdef"><p>A node that provides the Object Storage proxy service.</p></dd><dt id="id-1.9.21.34"><span><span class="glossterm">proxy server</span> <a title="Permalink" class="permalink" href="#id-1.9.21.34">#</a></span></dt><dd class="glossdef"><p>Users of Object Storage interact with the service through the
proxy server, which in turn looks up the location of the requested
data within the ring and returns the results to the user.</p></dd><dt id="id-1.9.21.35"><span><span class="glossterm">public API</span> <a title="Permalink" class="permalink" href="#id-1.9.21.35">#</a></span></dt><dd class="glossdef"><p>An API endpoint used for both service-to-service communication
and end-user interactions.</p></dd><dt id="id-1.9.21.36"><span><span class="glossterm">public image</span> <a title="Permalink" class="permalink" href="#id-1.9.21.36">#</a></span></dt><dd class="glossdef"><p>An Image service VM image that is available to all
projects.</p></dd><dt id="id-1.9.21.37"><span><span class="glossterm">public IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.21.37">#</a></span></dt><dd class="glossdef"><p>An IP address that is accessible to end-users.</p></dd><dt id="id-1.9.21.38"><span><span class="glossterm">public key authentication</span> <a title="Permalink" class="permalink" href="#id-1.9.21.38">#</a></span></dt><dd class="glossdef"><p>Authentication method that uses keys rather than
passwords.</p></dd><dt id="id-1.9.21.39"><span><span class="glossterm">public network</span> <a title="Permalink" class="permalink" href="#id-1.9.21.39">#</a></span></dt><dd class="glossdef"><p>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. The public network interface is controlled by the
<code class="literal">public_interface</code> option.</p></dd><dt id="id-1.9.21.40"><span><span class="glossterm">Puppet</span> <a title="Permalink" class="permalink" href="#id-1.9.21.40">#</a></span></dt><dd class="glossdef"><p>An operating system configuration-management tool supported by
OpenStack.</p></dd><dt id="id-1.9.21.41"><span><span class="glossterm">Python</span> <a title="Permalink" class="permalink" href="#id-1.9.21.41">#</a></span></dt><dd class="glossdef"><p>Programming language used extensively in OpenStack.</p></dd></dl></div><div class="glossdiv" id="id-1.9.22"><h3 class="title">Q</h3><dl><dt id="id-1.9.22.3"><span><span class="glossterm">QEMU Copy On Write 2 (QCOW2)</span> <a title="Permalink" class="permalink" href="#id-1.9.22.3">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.9.22.4"><span><span class="glossterm">Qpid</span> <a title="Permalink" class="permalink" href="#id-1.9.22.4">#</a></span></dt><dd class="glossdef"><p>Message queue software supported by OpenStack; an alternative to
RabbitMQ.</p></dd><dt id="term-quality-of-service-qos"><span><span class="glossterm">Quality of Service (QoS)</span> <a title="Permalink" class="permalink" href="#term-quality-of-service-qos">#</a></span></dt><dd class="glossdef"><p>The ability to guarantee certain network or storage requirements to
satisfy a Service Level Agreement (SLA) between an application provider
and end users.
Typically includes performance requirements like networking bandwidth,
latency, jitter correction, and reliability as well as storage
performance in Input/Output Operations Per Second (IOPS), throttling
agreements, and performance expectations at peak load.</p></dd><dt id="id-1.9.22.6"><span><span class="glossterm">quarantine</span> <a title="Permalink" class="permalink" href="#id-1.9.22.6">#</a></span></dt><dd class="glossdef"><p>If Object Storage finds objects, containers, or accounts that
are corrupt, they are placed in this state, are not replicated, cannot
be read by clients, and a correct copy is re-replicated.</p></dd><dt id="id-1.9.22.7"><span><span class="glossterm">Queens</span> <a title="Permalink" class="permalink" href="#id-1.9.22.7">#</a></span></dt><dd class="glossdef"><p>The code name for the seventeenth release of OpenStack. The
design summit will take place in Sydney, Australia. The release
is named after the Queens Pound river in the South Coast region
of New South Wales.</p></dd><dt id="id-1.9.22.8"><span><span class="glossterm">Quick EMUlator (QEMU)</span> <a title="Permalink" class="permalink" href="#id-1.9.22.8">#</a></span></dt><dd class="glossdef"><p>QEMU is a generic and open source machine emulator and
virtualizer.
One of the hypervisors supported by OpenStack, generally used
for development purposes.</p></dd><dt id="id-1.9.22.9"><span><span class="glossterm">quota</span> <a title="Permalink" class="permalink" href="#id-1.9.22.9">#</a></span></dt><dd class="glossdef"><p>In Compute and Block Storage, the ability to set resource limits
on a per-project basis.</p></dd></dl></div><div class="glossdiv" id="id-1.9.23"><h3 class="title">R</h3><dl><dt id="id-1.9.23.3"><span><span class="glossterm">RabbitMQ</span> <a title="Permalink" class="permalink" href="#id-1.9.23.3">#</a></span></dt><dd class="glossdef"><p>The default message queue software used by OpenStack.</p></dd><dt id="id-1.9.23.4"><span><span class="glossterm">Rackspace Cloud Files</span> <a title="Permalink" class="permalink" href="#id-1.9.23.4">#</a></span></dt><dd class="glossdef"><p>Released as open source by Rackspace in 2010; the basis for
Object Storage.</p></dd><dt id="id-1.9.23.5"><span><span class="glossterm">RADOS Block Device (RBD)</span> <a title="Permalink" class="permalink" href="#id-1.9.23.5">#</a></span></dt><dd class="glossdef"><p>Ceph component that enables a Linux block device to be striped
over multiple distributed data stores.</p></dd><dt id="id-1.9.23.6"><span><span class="glossterm">radvd</span> <a title="Permalink" class="permalink" href="#id-1.9.23.6">#</a></span></dt><dd class="glossdef"><p>The router advertisement daemon, used by the Compute VLAN
manager and FlatDHCP manager to provide routing services for VM
instances.</p></dd><dt id="id-1.9.23.7"><span><span class="glossterm">rally</span> <a title="Permalink" class="permalink" href="#id-1.9.23.7">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-benchmark-service-rally" title="Benchmark service (rally)">Benchmark service (rally)</a>.</p></dd><dt id="id-1.9.23.8"><span><span class="glossterm">RAM filter</span> <a title="Permalink" class="permalink" href="#id-1.9.23.8">#</a></span></dt><dd class="glossdef"><p>The Compute setting that enables or disables RAM
overcommitment.</p></dd><dt id="id-1.9.23.9"><span><span class="glossterm">RAM overcommit</span> <a title="Permalink" class="permalink" href="#id-1.9.23.9">#</a></span></dt><dd class="glossdef"><p>The ability to start new VM instances based on the actual memory
usage of a host, as opposed to basing the decision on the amount of
RAM each running instance thinks it has available. Also known as
memory overcommit.</p></dd><dt id="id-1.9.23.10"><span><span class="glossterm">rate limit</span> <a title="Permalink" class="permalink" href="#id-1.9.23.10">#</a></span></dt><dd class="glossdef"><p>Configurable option within Object Storage to limit database
writes on a per-account and/or per-container basis.</p></dd><dt id="id-1.9.23.11"><span><span class="glossterm">raw</span> <a title="Permalink" class="permalink" href="#id-1.9.23.11">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image service; an
unstructured disk image.</p></dd><dt id="id-1.9.23.12"><span><span class="glossterm">rebalance</span> <a title="Permalink" class="permalink" href="#id-1.9.23.12">#</a></span></dt><dd class="glossdef"><p>The process of distributing Object Storage partitions across all
drives in the ring; used during initial ring creation and after ring
reconfiguration.</p></dd><dt id="id-1.9.23.13"><span><span class="glossterm">reboot</span> <a title="Permalink" class="permalink" href="#id-1.9.23.13">#</a></span></dt><dd class="glossdef"><p>Either a soft or hard reboot of a server. With a soft reboot,
the operating system is signaled to restart, which enables a graceful
shutdown of all processes. A hard reboot is the equivalent of power
cycling the server. The virtualization platform should ensure that the
reboot action has completed successfully, even in cases in which the
underlying domain/VM is paused or halted/stopped.</p></dd><dt id="id-1.9.23.14"><span><span class="glossterm">rebuild</span> <a title="Permalink" class="permalink" href="#id-1.9.23.14">#</a></span></dt><dd class="glossdef"><p>Removes all data on the server and replaces it with the
specified image. Server ID and IP addresses remain the same.</p></dd><dt id="id-1.9.23.15"><span><span class="glossterm">Recon</span> <a title="Permalink" class="permalink" href="#id-1.9.23.15">#</a></span></dt><dd class="glossdef"><p>An Object Storage component that collects meters.</p></dd><dt id="id-1.9.23.16"><span><span class="glossterm">record</span> <a title="Permalink" class="permalink" href="#id-1.9.23.16">#</a></span></dt><dd class="glossdef"><p>Belongs to a particular domain and is used to specify
information about the domain.
There are several types of DNS records. Each record type contains
particular information used to describe the purpose of that record.
Examples include mail exchange (MX) records, which specify the mail
server for a particular domain; and name server (NS) records, which
specify the authoritative name servers for a domain.</p></dd><dt id="id-1.9.23.17"><span><span class="glossterm">record ID</span> <a title="Permalink" class="permalink" href="#id-1.9.23.17">#</a></span></dt><dd class="glossdef"><p>A number within a database that is incremented each time a
change is made. Used by Object Storage when replicating.</p></dd><dt id="id-1.9.23.18"><span><span class="glossterm">Red Hat Enterprise Linux (RHEL)</span> <a title="Permalink" class="permalink" href="#id-1.9.23.18">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.9.23.19"><span><span class="glossterm">reference architecture</span> <a title="Permalink" class="permalink" href="#id-1.9.23.19">#</a></span></dt><dd class="glossdef"><p>A recommended architecture for an OpenStack cloud.</p></dd><dt id="id-1.9.23.20"><span><span class="glossterm">region</span> <a title="Permalink" class="permalink" href="#id-1.9.23.20">#</a></span></dt><dd class="glossdef"><p>A discrete OpenStack environment with dedicated API endpoints
that typically shares only the Identity (keystone) with other
regions.</p></dd><dt id="id-1.9.23.21"><span><span class="glossterm">registry</span> <a title="Permalink" class="permalink" href="#id-1.9.23.21">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Image service registry.</p></dd><dt id="id-1.9.23.22"><span><span class="glossterm">registry server</span> <a title="Permalink" class="permalink" href="#id-1.9.23.22">#</a></span></dt><dd class="glossdef"><p>An Image service that provides VM image metadata information to
clients.</p></dd><dt id="id-1.9.23.23"><span><span class="glossterm">Reliable, Autonomic Distributed Object Store</span> <a title="Permalink" class="permalink" href="#id-1.9.23.23">#</a></span></dt><dd class="glossdef"><p>(RADOS)</p><p>A collection of components that provides object storage within
Ceph. Similar to OpenStack Object Storage.</p></dd><dt id="term-remote-procedure-call-rpc"><span><span class="glossterm">Remote Procedure Call (RPC)</span> <a title="Permalink" class="permalink" href="#term-remote-procedure-call-rpc">#</a></span></dt><dd class="glossdef"><p>The method used by the Compute RabbitMQ for intra-service
communications.</p></dd><dt id="id-1.9.23.25"><span><span class="glossterm">replica</span> <a title="Permalink" class="permalink" href="#id-1.9.23.25">#</a></span></dt><dd class="glossdef"><p>Provides data redundancy and fault tolerance by creating copies
of Object Storage objects, accounts, and containers so that they are
not lost when the underlying storage fails.</p></dd><dt id="id-1.9.23.26"><span><span class="glossterm">replica count</span> <a title="Permalink" class="permalink" href="#id-1.9.23.26">#</a></span></dt><dd class="glossdef"><p>The number of replicas of the data in an Object Storage
ring.</p></dd><dt id="id-1.9.23.27"><span><span class="glossterm">replication</span> <a title="Permalink" class="permalink" href="#id-1.9.23.27">#</a></span></dt><dd class="glossdef"><p>The process of copying data to a separate physical device for
fault tolerance and performance.</p></dd><dt id="id-1.9.23.28"><span><span class="glossterm">replicator</span> <a title="Permalink" class="permalink" href="#id-1.9.23.28">#</a></span></dt><dd class="glossdef"><p>The Object Storage back-end process that creates and manages
object replicas.</p></dd><dt id="id-1.9.23.29"><span><span class="glossterm">request ID</span> <a title="Permalink" class="permalink" href="#id-1.9.23.29">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each request sent to Compute.</p></dd><dt id="id-1.9.23.30"><span><span class="glossterm">rescue image</span> <a title="Permalink" class="permalink" href="#id-1.9.23.30">#</a></span></dt><dd class="glossdef"><p>A special type of VM image that is booted when an instance is
placed into rescue mode. Allows an administrator to mount the file
systems for an instance to correct the problem.</p></dd><dt id="id-1.9.23.31"><span><span class="glossterm">resize</span> <a title="Permalink" class="permalink" href="#id-1.9.23.31">#</a></span></dt><dd class="glossdef"><p>Converts an existing server to a different flavor, which scales
the server up or down. The original server is saved to enable rollback
if a problem occurs. All resizes must be tested and explicitly
confirmed, at which time the original server is removed.</p></dd><dt id="id-1.9.23.32"><span><span class="glossterm">RESTful</span> <a title="Permalink" class="permalink" href="#id-1.9.23.32">#</a></span></dt><dd class="glossdef"><p>A kind of web service API that uses REST, or Representational
State Transfer. REST is the style of architecture for hypermedia
systems that is used for the World Wide Web.</p></dd><dt id="id-1.9.23.33"><span><span class="glossterm">ring</span> <a title="Permalink" class="permalink" href="#id-1.9.23.33">#</a></span></dt><dd class="glossdef"><p>An entity that maps Object Storage data to partitions. A
separate ring exists for each service, such as account, object, and
container.</p></dd><dt id="id-1.9.23.34"><span><span class="glossterm">ring builder</span> <a title="Permalink" class="permalink" href="#id-1.9.23.34">#</a></span></dt><dd class="glossdef"><p>Builds and manages rings within Object Storage, assigns
partitions to devices, and pushes the configuration to other storage
nodes.</p></dd><dt id="id-1.9.23.35"><span><span class="glossterm">role</span> <a title="Permalink" class="permalink" href="#id-1.9.23.35">#</a></span></dt><dd class="glossdef"><p>A personality that a user assumes to perform a specific set of
operations. A role includes a set of rights and privileges. A user
assuming that role inherits those rights and privileges.</p></dd><dt id="id-1.9.23.36"><span><span class="glossterm">Role Based Access Control (RBAC)</span> <a title="Permalink" class="permalink" href="#id-1.9.23.36">#</a></span></dt><dd class="glossdef"><p>Provides a predefined list of actions that the user can perform,
such as start or stop VMs, reset passwords, and so on. Supported in
both Identity and Compute and can be configured using the dashboard.</p></dd><dt id="id-1.9.23.37"><span><span class="glossterm">role ID</span> <a title="Permalink" class="permalink" href="#id-1.9.23.37">#</a></span></dt><dd class="glossdef"><p>Alphanumeric ID assigned to each Identity service role.</p></dd><dt id="term-root-cause-analysis-rca-service-vitrage"><span><span class="glossterm">Root Cause Analysis (RCA) service (Vitrage)</span> <a title="Permalink" class="permalink" href="#term-root-cause-analysis-rca-service-vitrage">#</a></span></dt><dd class="glossdef"><p>OpenStack project that aims to organize, analyze and visualize OpenStack
alarms and events, yield insights regarding the root cause of problems
and deduce their existence before they are directly detected.</p></dd><dt id="id-1.9.23.39"><span><span class="glossterm">rootwrap</span> <a title="Permalink" class="permalink" href="#id-1.9.23.39">#</a></span></dt><dd class="glossdef"><p>A feature of Compute that allows the unprivileged "nova" user to
run a specified list of commands as the Linux root user.</p></dd><dt id="id-1.9.23.40"><span><span class="glossterm">round-robin scheduler</span> <a title="Permalink" class="permalink" href="#id-1.9.23.40">#</a></span></dt><dd class="glossdef"><p>Type of Compute scheduler that evenly distributes instances
among available hosts.</p></dd><dt id="id-1.9.23.41"><span><span class="glossterm">router</span> <a title="Permalink" class="permalink" href="#id-1.9.23.41">#</a></span></dt><dd class="glossdef"><p>A physical or virtual network device that passes network
traffic between different networks.</p></dd><dt id="id-1.9.23.42"><span><span class="glossterm">routing key</span> <a title="Permalink" class="permalink" href="#id-1.9.23.42">#</a></span></dt><dd class="glossdef"><p>The Compute direct exchanges, fanout exchanges, and topic
exchanges use this key to determine how to process a message;
processing varies depending on exchange type.</p></dd><dt id="id-1.9.23.43"><span><span class="glossterm">RPC driver</span> <a title="Permalink" class="permalink" href="#id-1.9.23.43">#</a></span></dt><dd class="glossdef"><p>Modular system that allows the underlying message queue software
of Compute to be changed. For example, from RabbitMQ to ZeroMQ or
Qpid.</p></dd><dt id="id-1.9.23.44"><span><span class="glossterm">rsync</span> <a title="Permalink" class="permalink" href="#id-1.9.23.44">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage to push object replicas.</p></dd><dt id="id-1.9.23.45"><span><span class="glossterm">RXTX cap</span> <a title="Permalink" class="permalink" href="#id-1.9.23.45">#</a></span></dt><dd class="glossdef"><p>Absolute limit on the amount of network traffic a Compute VM
instance can send and receive.</p></dd><dt id="id-1.9.23.46"><span><span class="glossterm">RXTX quota</span> <a title="Permalink" class="permalink" href="#id-1.9.23.46">#</a></span></dt><dd class="glossdef"><p>Soft limit on the amount of network traffic a Compute VM
instance can send and receive.</p></dd></dl></div><div class="glossdiv" id="id-1.9.24"><h3 class="title">S</h3><dl><dt id="id-1.9.24.3"><span><span class="glossterm">sahara</span> <a title="Permalink" class="permalink" href="#id-1.9.24.3">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-data-processing-service-sahara" title="Data Processing service (sahara)">Data Processing service (sahara)</a>.</p></dd><dt id="id-1.9.24.4"><span><span class="glossterm">SAML assertion</span> <a title="Permalink" class="permalink" href="#id-1.9.24.4">#</a></span></dt><dd class="glossdef"><p>Contains information about a user as provided by the identity
provider. It is an indication that a user has been authenticated.</p></dd><dt id="id-1.9.24.5"><span><span class="glossterm">scheduler manager</span> <a title="Permalink" class="permalink" href="#id-1.9.24.5">#</a></span></dt><dd class="glossdef"><p>A Compute component that determines where VM instances should
start. Uses modular design to support a variety of scheduler
types.</p></dd><dt id="id-1.9.24.6"><span><span class="glossterm">scoped token</span> <a title="Permalink" class="permalink" href="#id-1.9.24.6">#</a></span></dt><dd class="glossdef"><p>An Identity service API access token that is associated with a
specific project.</p></dd><dt id="id-1.9.24.7"><span><span class="glossterm">scrubber</span> <a title="Permalink" class="permalink" href="#id-1.9.24.7">#</a></span></dt><dd class="glossdef"><p>Checks for and deletes unused VMs; the component of Image
service that implements delayed delete.</p></dd><dt id="id-1.9.24.8"><span><span class="glossterm">secret key</span> <a title="Permalink" class="permalink" href="#id-1.9.24.8">#</a></span></dt><dd class="glossdef"><p>String of text known only by the user; used along with an access
key to make requests to the Compute API.</p></dd><dt id="id-1.9.24.9"><span><span class="glossterm">secure boot</span> <a title="Permalink" class="permalink" href="#id-1.9.24.9">#</a></span></dt><dd class="glossdef"><p>Process whereby the system firmware validates the authenticity of
the code involved in the boot process.</p></dd><dt id="id-1.9.24.10"><span><span class="glossterm">secure shell (SSH)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.10">#</a></span></dt><dd class="glossdef"><p>Open source tool used to access remote hosts through an
encrypted communications channel, SSH key injection is supported by
Compute.</p></dd><dt id="id-1.9.24.11"><span><span class="glossterm">security group</span> <a title="Permalink" class="permalink" href="#id-1.9.24.11">#</a></span></dt><dd class="glossdef"><p>A set of network traffic filtering rules that are applied to a
Compute instance.</p></dd><dt id="id-1.9.24.12"><span><span class="glossterm">segmented object</span> <a title="Permalink" class="permalink" href="#id-1.9.24.12">#</a></span></dt><dd class="glossdef"><p>An Object Storage large object that has been broken up into
pieces. The re-assembled object is called a concatenated
object.</p></dd><dt id="id-1.9.24.13"><span><span class="glossterm">self-service</span> <a title="Permalink" class="permalink" href="#id-1.9.24.13">#</a></span></dt><dd class="glossdef"><p>For IaaS, ability for a regular (non-privileged) account to
manage a virtual infrastructure component such as networks without
involving an administrator.</p></dd><dt id="id-1.9.24.14"><span><span class="glossterm">SELinux</span> <a title="Permalink" class="permalink" href="#id-1.9.24.14">#</a></span></dt><dd class="glossdef"><p>Linux kernel security module that provides the mechanism for
supporting access control policies.</p></dd><dt id="id-1.9.24.15"><span><span class="glossterm">senlin</span> <a title="Permalink" class="permalink" href="#id-1.9.24.15">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-clustering-service-senlin" title="Clustering service (senlin)">Clustering service (senlin)</a>.</p></dd><dt id="id-1.9.24.16"><span><span class="glossterm">server</span> <a title="Permalink" class="permalink" href="#id-1.9.24.16">#</a></span></dt><dd class="glossdef"><p>Computer that provides explicit services to the client software
running on that system, often managing a variety of computer
operations.
A server is a VM instance in the Compute system. Flavor and
image are requisite elements when creating a server.</p></dd><dt id="id-1.9.24.17"><span><span class="glossterm">server image</span> <a title="Permalink" class="permalink" href="#id-1.9.24.17">#</a></span></dt><dd class="glossdef"><p>Alternative term for a VM image.</p></dd><dt id="id-1.9.24.18"><span><span class="glossterm">server UUID</span> <a title="Permalink" class="permalink" href="#id-1.9.24.18">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each guest VM instance.</p></dd><dt id="term-service"><span><span class="glossterm">service</span> <a title="Permalink" class="permalink" href="#term-service">#</a></span></dt><dd class="glossdef"><p>An OpenStack service, such as Compute, Object Storage, or Image
service. Provides one or more endpoints through which users can access
resources and perform operations.</p></dd><dt id="id-1.9.24.20"><span><span class="glossterm">service catalog</span> <a title="Permalink" class="permalink" href="#id-1.9.24.20">#</a></span></dt><dd class="glossdef"><p>Alternative term for the Identity service catalog.</p></dd><dt id="id-1.9.24.21"><span><span class="glossterm">Service Function Chain (SFC)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.21">#</a></span></dt><dd class="glossdef"><p>For a given service, SFC is the abstracted view of the required
service functions and the order in which they are to be applied.</p></dd><dt id="id-1.9.24.22"><span><span class="glossterm">service ID</span> <a title="Permalink" class="permalink" href="#id-1.9.24.22">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each service that is available in the
Identity service catalog.</p></dd><dt id="id-1.9.24.23"><span><span class="glossterm">Service Level Agreement (SLA)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.23">#</a></span></dt><dd class="glossdef"><p>Contractual obligations that ensure the availability of a
service.</p></dd><dt id="id-1.9.24.24"><span><span class="glossterm">service project</span> <a title="Permalink" class="permalink" href="#id-1.9.24.24">#</a></span></dt><dd class="glossdef"><p>Special project that contains all services that are listed in the
catalog.</p></dd><dt id="id-1.9.24.25"><span><span class="glossterm">service provider</span> <a title="Permalink" class="permalink" href="#id-1.9.24.25">#</a></span></dt><dd class="glossdef"><p>A system that provides services to other system entities. In
case of federated identity, OpenStack Identity is the service
provider.</p></dd><dt id="id-1.9.24.26"><span><span class="glossterm">service registration</span> <a title="Permalink" class="permalink" href="#id-1.9.24.26">#</a></span></dt><dd class="glossdef"><p>An Identity service feature that enables services, such as
Compute, to automatically register with the catalog.</p></dd><dt id="id-1.9.24.27"><span><span class="glossterm">service token</span> <a title="Permalink" class="permalink" href="#id-1.9.24.27">#</a></span></dt><dd class="glossdef"><p>An administrator-defined token used by Compute to communicate
securely with the Identity service.</p></dd><dt id="id-1.9.24.28"><span><span class="glossterm">session back end</span> <a title="Permalink" class="permalink" href="#id-1.9.24.28">#</a></span></dt><dd class="glossdef"><p>The method of storage used by horizon to track client sessions,
such as local memory, cookies, a database, or memcached.</p></dd><dt id="id-1.9.24.29"><span><span class="glossterm">session persistence</span> <a title="Permalink" class="permalink" href="#id-1.9.24.29">#</a></span></dt><dd class="glossdef"><p>A feature of the load-balancing service. It attempts to force
subsequent connections to a service to be redirected to the same node
as long as it is online.</p></dd><dt id="id-1.9.24.30"><span><span class="glossterm">session storage</span> <a title="Permalink" class="permalink" href="#id-1.9.24.30">#</a></span></dt><dd class="glossdef"><p>A horizon component that stores and tracks client session
information. Implemented through the Django sessions framework.</p></dd><dt id="id-1.9.24.31"><span><span class="glossterm">share</span> <a title="Permalink" class="permalink" href="#id-1.9.24.31">#</a></span></dt><dd class="glossdef"><p>A remote, mountable file system in the context of the <a class="xref" href="#term-shared-file-systems-service-manila" title="Shared File Systems service (manila)">Shared File Systems service (manila)</a>. You can
mount a share to, and access a share from, several hosts by several
users at a time.</p></dd><dt id="id-1.9.24.32"><span><span class="glossterm">share network</span> <a title="Permalink" class="permalink" href="#id-1.9.24.32">#</a></span></dt><dd class="glossdef"><p>An entity in the context of the <a class="xref" href="#term-shared-file-systems-service-manila" title="Shared File Systems service (manila)">Shared File Systems service (manila)</a> that encapsulates
interaction with the Networking service. If the driver you selected
runs in the mode requiring such kind of interaction, you need to
specify the share network to create a share.</p></dd><dt id="id-1.9.24.33"><span><span class="glossterm">Shared File Systems API</span> <a title="Permalink" class="permalink" href="#id-1.9.24.33">#</a></span></dt><dd class="glossdef"><p>A Shared File Systems service that provides a stable RESTful API.
The service authenticates and routes requests throughout the Shared
File Systems service. There is python-manilaclient to interact with
the API.</p></dd><dt id="term-shared-file-systems-service-manila"><span><span class="glossterm">Shared File Systems service (manila)</span> <a title="Permalink" class="permalink" href="#term-shared-file-systems-service-manila">#</a></span></dt><dd class="glossdef"><p>The service that provides a set of services for
management of shared file systems in a multi-tenant cloud
environment, similar to how OpenStack provides block-based storage
management through the OpenStack <a class="xref" href="#term-block-storage-service-cinder" title="Block Storage service (cinder)">Block Storage service (cinder)</a> project.
With the Shared File Systems service, you can create a remote file
system and mount the file system on your instances. You can also
read and write data from your instances to and from your file system.</p></dd><dt id="id-1.9.24.35"><span><span class="glossterm">shared IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.24.35">#</a></span></dt><dd class="glossdef"><p>An IP address that can be assigned to a VM instance within the
shared IP group. Public IP addresses can be shared across multiple
servers for use in various high-availability scenarios. When an IP
address is shared to another server, the cloud network restrictions
are modified to enable each server to listen to and respond on that IP
address. You can optionally specify that the target server network
configuration be modified. Shared IP addresses can be used with many
standard heartbeat facilities, such as keepalive, that monitor for
failure and manage IP failover.</p></dd><dt id="id-1.9.24.36"><span><span class="glossterm">shared IP group</span> <a title="Permalink" class="permalink" href="#id-1.9.24.36">#</a></span></dt><dd class="glossdef"><p>A collection of servers that can share IPs with other members of
the group. Any server in a group can share one or more public IPs with
any other server in the group. With the exception of the first server
in a shared IP group, servers must be launched into shared IP groups.
A server may be a member of only one shared IP group.</p></dd><dt id="id-1.9.24.37"><span><span class="glossterm">shared storage</span> <a title="Permalink" class="permalink" href="#id-1.9.24.37">#</a></span></dt><dd class="glossdef"><p>Block storage that is simultaneously accessible by multiple
clients, for example, NFS.</p></dd><dt id="id-1.9.24.38"><span><span class="glossterm">Sheepdog</span> <a title="Permalink" class="permalink" href="#id-1.9.24.38">#</a></span></dt><dd class="glossdef"><p>Distributed block storage system for QEMU, supported by
OpenStack.</p></dd><dt id="id-1.9.24.39"><span><span class="glossterm">Simple Cloud Identity Management (SCIM)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.39">#</a></span></dt><dd class="glossdef"><p>Specification for managing identity in the cloud, currently
unsupported by OpenStack.</p></dd><dt id="id-1.9.24.40"><span><span class="glossterm">Simple Protocol for Independent Computing Environments (SPICE)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.40">#</a></span></dt><dd class="glossdef"><p>SPICE provides remote desktop access to guest virtual machines. It
is an alternative to VNC. SPICE is supported by OpenStack.</p></dd><dt id="id-1.9.24.41"><span><span class="glossterm">Single-root I/O Virtualization (SR-IOV)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.41">#</a></span></dt><dd class="glossdef"><p>A specification that, when implemented by a physical PCIe
device, enables it to appear as multiple separate PCIe devices. This
enables multiple virtualized guests to share direct access to the
physical device, offering improved performance over an equivalent
virtual device. Currently supported in OpenStack Havana and later
releases.</p></dd><dt id="id-1.9.24.42"><span><span class="glossterm">SmokeStack</span> <a title="Permalink" class="permalink" href="#id-1.9.24.42">#</a></span></dt><dd class="glossdef"><p>Runs automated tests against the core OpenStack API; written in
Rails.</p></dd><dt id="id-1.9.24.43"><span><span class="glossterm">snapshot</span> <a title="Permalink" class="permalink" href="#id-1.9.24.43">#</a></span></dt><dd class="glossdef"><p>A point-in-time copy of an OpenStack storage volume or image.
Use storage volume snapshots to back up volumes. Use image snapshots
to back up data, or as "gold" images for additional servers.</p></dd><dt id="id-1.9.24.44"><span><span class="glossterm">soft reboot</span> <a title="Permalink" class="permalink" href="#id-1.9.24.44">#</a></span></dt><dd class="glossdef"><p>A controlled reboot where a VM instance is properly restarted
through operating system commands.</p></dd><dt id="term-software-development-lifecycle-automation-service-solum"><span><span class="glossterm">Software Development Lifecycle Automation service (solum)</span> <a title="Permalink" class="permalink" href="#term-software-development-lifecycle-automation-service-solum">#</a></span></dt><dd class="glossdef"><p>OpenStack project that aims to make cloud services easier to
consume and integrate with application development process
by automating the source-to-image process, and simplifying
app-centric deployment.</p></dd><dt id="id-1.9.24.46"><span><span class="glossterm">Software-defined networking (SDN)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.46">#</a></span></dt><dd class="glossdef"><p>Provides an approach for network administrators to manage computer
network services through abstraction of lower-level functionality.</p></dd><dt id="id-1.9.24.47"><span><span class="glossterm">SolidFire Volume Driver</span> <a title="Permalink" class="permalink" href="#id-1.9.24.47">#</a></span></dt><dd class="glossdef"><p>The Block Storage driver for the SolidFire iSCSI storage
appliance.</p></dd><dt id="id-1.9.24.48"><span><span class="glossterm">solum</span> <a title="Permalink" class="permalink" href="#id-1.9.24.48">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-software-development-lifecycle-automation-service-solum" title="Software Development Lifecycle Automation service (solum)">Software Development Lifecycle Automation service (solum)</a>.</p></dd><dt id="id-1.9.24.49"><span><span class="glossterm">spread-first scheduler</span> <a title="Permalink" class="permalink" href="#id-1.9.24.49">#</a></span></dt><dd class="glossdef"><p>The Compute VM scheduling algorithm that attempts to start a new
VM on the host with the least amount of load.</p></dd><dt id="id-1.9.24.50"><span><span class="glossterm">SQLAlchemy</span> <a title="Permalink" class="permalink" href="#id-1.9.24.50">#</a></span></dt><dd class="glossdef"><p>An open source SQL toolkit for Python, used in OpenStack.</p></dd><dt id="id-1.9.24.51"><span><span class="glossterm">SQLite</span> <a title="Permalink" class="permalink" href="#id-1.9.24.51">#</a></span></dt><dd class="glossdef"><p>A lightweight SQL database, used as the default persistent
storage method in many OpenStack services.</p></dd><dt id="id-1.9.24.52"><span><span class="glossterm">stack</span> <a title="Permalink" class="permalink" href="#id-1.9.24.52">#</a></span></dt><dd class="glossdef"><p>A set of OpenStack resources created and managed by the
Orchestration service according to a given template (either an
AWS CloudFormation template or a Heat Orchestration
Template (HOT)).</p></dd><dt id="id-1.9.24.53"><span><span class="glossterm">StackTach</span> <a title="Permalink" class="permalink" href="#id-1.9.24.53">#</a></span></dt><dd class="glossdef"><p>Community project that captures Compute AMQP communications;
useful for debugging.</p></dd><dt id="id-1.9.24.54"><span><span class="glossterm">static IP address</span> <a title="Permalink" class="permalink" href="#id-1.9.24.54">#</a></span></dt><dd class="glossdef"><p>Alternative term for a fixed IP address.</p></dd><dt id="id-1.9.24.55"><span><span class="glossterm">StaticWeb</span> <a title="Permalink" class="permalink" href="#id-1.9.24.55">#</a></span></dt><dd class="glossdef"><p>WSGI middleware component of Object Storage that serves
container data as a static web page.</p></dd><dt id="id-1.9.24.56"><span><span class="glossterm">storage back end</span> <a title="Permalink" class="permalink" href="#id-1.9.24.56">#</a></span></dt><dd class="glossdef"><p>The method that a service uses for persistent storage, such as
iSCSI, NFS, or local disk.</p></dd><dt id="id-1.9.24.57"><span><span class="glossterm">storage manager</span> <a title="Permalink" class="permalink" href="#id-1.9.24.57">#</a></span></dt><dd class="glossdef"><p>A XenAPI component that provides a pluggable interface to
support a wide variety of persistent storage back ends.</p></dd><dt id="id-1.9.24.58"><span><span class="glossterm">storage manager back end</span> <a title="Permalink" class="permalink" href="#id-1.9.24.58">#</a></span></dt><dd class="glossdef"><p>A persistent storage method supported by XenAPI, such as iSCSI
or NFS.</p></dd><dt id="id-1.9.24.59"><span><span class="glossterm">storage node</span> <a title="Permalink" class="permalink" href="#id-1.9.24.59">#</a></span></dt><dd class="glossdef"><p>An Object Storage node that provides container services, account
services, and object services; controls the account databases,
container databases, and object storage.</p></dd><dt id="id-1.9.24.60"><span><span class="glossterm">storage services</span> <a title="Permalink" class="permalink" href="#id-1.9.24.60">#</a></span></dt><dd class="glossdef"><p>Collective name for the Object Storage object services,
container services, and account services.</p></dd><dt id="term-strategy"><span><span class="glossterm">strategy</span> <a title="Permalink" class="permalink" href="#term-strategy">#</a></span></dt><dd class="glossdef"><p>Specifies the authentication source used by Image service or
Identity. In the Database service, it refers to the extensions
implemented for a data store.</p></dd><dt id="id-1.9.24.62"><span><span class="glossterm">subdomain</span> <a title="Permalink" class="permalink" href="#id-1.9.24.62">#</a></span></dt><dd class="glossdef"><p>A domain within a parent domain. Subdomains cannot be
registered. Subdomains enable you to delegate domains. Subdomains can
themselves have subdomains, so third-level, fourth-level, fifth-level,
and deeper levels of nesting are possible.</p></dd><dt id="id-1.9.24.63"><span><span class="glossterm">subnet</span> <a title="Permalink" class="permalink" href="#id-1.9.24.63">#</a></span></dt><dd class="glossdef"><p>Logical subdivision of an IP network.</p></dd><dt id="id-1.9.24.64"><span><span class="glossterm">SUSE Linux Enterprise Server (SLES)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.64">#</a></span></dt><dd class="glossdef"><p>A Linux distribution that is compatible with OpenStack.</p></dd><dt id="id-1.9.24.65"><span><span class="glossterm">suspend</span> <a title="Permalink" class="permalink" href="#id-1.9.24.65">#</a></span></dt><dd class="glossdef"><p>Alternative term for a paused VM instance.</p></dd><dt id="id-1.9.24.66"><span><span class="glossterm">swap</span> <a title="Permalink" class="permalink" href="#id-1.9.24.66">#</a></span></dt><dd class="glossdef"><p>Disk-based virtual memory used by operating systems to provide
more memory than is actually available on the system.</p></dd><dt id="id-1.9.24.67"><span><span class="glossterm">swauth</span> <a title="Permalink" class="permalink" href="#id-1.9.24.67">#</a></span></dt><dd class="glossdef"><p>An authentication and authorization service for Object Storage,
implemented through WSGI middleware; uses Object Storage itself as the
persistent backing store.</p></dd><dt id="id-1.9.24.68"><span><span class="glossterm">swift</span> <a title="Permalink" class="permalink" href="#id-1.9.24.68">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-object-storage-service-swift" title="Object Storage service (swift)">Object Storage service (swift)</a>.</p></dd><dt id="id-1.9.24.69"><span><span class="glossterm">swift All in One (SAIO)</span> <a title="Permalink" class="permalink" href="#id-1.9.24.69">#</a></span></dt><dd class="glossdef"><p>Creates a full Object Storage development environment within a
single VM.</p></dd><dt id="id-1.9.24.70"><span><span class="glossterm">swift middleware</span> <a title="Permalink" class="permalink" href="#id-1.9.24.70">#</a></span></dt><dd class="glossdef"><p>Collective term for Object Storage components that provide
additional functionality.</p></dd><dt id="id-1.9.24.71"><span><span class="glossterm">swift proxy server</span> <a title="Permalink" class="permalink" href="#id-1.9.24.71">#</a></span></dt><dd class="glossdef"><p>Acts as the gatekeeper to Object Storage and is responsible for
authenticating the user.</p></dd><dt id="id-1.9.24.72"><span><span class="glossterm">swift storage node</span> <a title="Permalink" class="permalink" href="#id-1.9.24.72">#</a></span></dt><dd class="glossdef"><p>A node that runs Object Storage account, container, and object
services.</p></dd><dt id="id-1.9.24.73"><span><span class="glossterm">sync point</span> <a title="Permalink" class="permalink" href="#id-1.9.24.73">#</a></span></dt><dd class="glossdef"><p>Point in time since the last container and accounts database
sync among nodes within Object Storage.</p></dd><dt id="id-1.9.24.74"><span><span class="glossterm">sysadmin</span> <a title="Permalink" class="permalink" href="#id-1.9.24.74">#</a></span></dt><dd class="glossdef"><p>One of the default roles in the Compute RBAC system. Enables a
user to add other users to a project, interact with VM images that are
associated with the project, and start and stop VM instances.</p></dd><dt id="id-1.9.24.75"><span><span class="glossterm">system usage</span> <a title="Permalink" class="permalink" href="#id-1.9.24.75">#</a></span></dt><dd class="glossdef"><p>A Compute component that, along with the notification system,
collects meters and usage information. This information can be used
for billing.</p></dd></dl></div><div class="glossdiv" id="id-1.9.25"><h3 class="title">T</h3><dl><dt id="id-1.9.25.3"><span><span class="glossterm">tacker</span> <a title="Permalink" class="permalink" href="#id-1.9.25.3">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-nfv-orchestration-service-tacker" title="NFV Orchestration Service (tacker)">NFV Orchestration Service (tacker)</a></p></dd><dt id="term-telemetry-service-telemetry"><span><span class="glossterm">Telemetry service (telemetry)</span> <a title="Permalink" class="permalink" href="#term-telemetry-service-telemetry">#</a></span></dt><dd class="glossdef"><p>The OpenStack project which collects measurements of the utilization
of the physical and virtual resources comprising deployed clouds,
persists this data for subsequent retrieval and analysis, and triggers
actions when defined criteria are met.</p></dd><dt id="id-1.9.25.5"><span><span class="glossterm">TempAuth</span> <a title="Permalink" class="permalink" href="#id-1.9.25.5">#</a></span></dt><dd class="glossdef"><p>An authentication facility within Object Storage that enables
Object Storage itself to perform authentication and authorization.
Frequently used in testing and development.</p></dd><dt id="id-1.9.25.6"><span><span class="glossterm">Tempest</span> <a title="Permalink" class="permalink" href="#id-1.9.25.6">#</a></span></dt><dd class="glossdef"><p>Automated software test suite designed to run against the trunk
of the OpenStack core project.</p></dd><dt id="id-1.9.25.7"><span><span class="glossterm">TempURL</span> <a title="Permalink" class="permalink" href="#id-1.9.25.7">#</a></span></dt><dd class="glossdef"><p>An Object Storage middleware component that enables creation of
URLs for temporary object access.</p></dd><dt id="id-1.9.25.8"><span><span class="glossterm">tenant</span> <a title="Permalink" class="permalink" href="#id-1.9.25.8">#</a></span></dt><dd class="glossdef"><p>A group of users; used to isolate access to Compute resources.
An alternative term for a project.</p></dd><dt id="id-1.9.25.9"><span><span class="glossterm">Tenant API</span> <a title="Permalink" class="permalink" href="#id-1.9.25.9">#</a></span></dt><dd class="glossdef"><p>An API that is accessible to projects.</p></dd><dt id="id-1.9.25.10"><span><span class="glossterm">tenant endpoint</span> <a title="Permalink" class="permalink" href="#id-1.9.25.10">#</a></span></dt><dd class="glossdef"><p>An Identity service API endpoint that is associated with one or
more projects.</p></dd><dt id="id-1.9.25.11"><span><span class="glossterm">tenant ID</span> <a title="Permalink" class="permalink" href="#id-1.9.25.11">#</a></span></dt><dd class="glossdef"><p>An alternative term for <a class="xref" href="#term-project-id" title="project ID">project ID</a>.</p></dd><dt id="id-1.9.25.12"><span><span class="glossterm">token</span> <a title="Permalink" class="permalink" href="#id-1.9.25.12">#</a></span></dt><dd class="glossdef"><p>An alpha-numeric string of text used to access OpenStack APIs
and resources.</p></dd><dt id="id-1.9.25.13"><span><span class="glossterm">token services</span> <a title="Permalink" class="permalink" href="#id-1.9.25.13">#</a></span></dt><dd class="glossdef"><p>An Identity service component that manages and validates tokens
after a user or project has been authenticated.</p></dd><dt id="id-1.9.25.14"><span><span class="glossterm">tombstone</span> <a title="Permalink" class="permalink" href="#id-1.9.25.14">#</a></span></dt><dd class="glossdef"><p>Used to mark Object Storage objects that have been
deleted; ensures that the object is not updated on another node after
it has been deleted.</p></dd><dt id="id-1.9.25.15"><span><span class="glossterm">topic publisher</span> <a title="Permalink" class="permalink" href="#id-1.9.25.15">#</a></span></dt><dd class="glossdef"><p>A process that is created when a RPC call is executed; used to
push the message to the topic exchange.</p></dd><dt id="id-1.9.25.16"><span><span class="glossterm">Torpedo</span> <a title="Permalink" class="permalink" href="#id-1.9.25.16">#</a></span></dt><dd class="glossdef"><p>Community project used to run automated tests against the
OpenStack API.</p></dd><dt id="id-1.9.25.17"><span><span class="glossterm">transaction ID</span> <a title="Permalink" class="permalink" href="#id-1.9.25.17">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each Object Storage request; used for
debugging and tracing.</p></dd><dt id="id-1.9.25.18"><span><span class="glossterm">transient</span> <a title="Permalink" class="permalink" href="#id-1.9.25.18">#</a></span></dt><dd class="glossdef"><p>Alternative term for non-durable.</p></dd><dt id="id-1.9.25.19"><span><span class="glossterm">transient exchange</span> <a title="Permalink" class="permalink" href="#id-1.9.25.19">#</a></span></dt><dd class="glossdef"><p>Alternative term for a non-durable exchange.</p></dd><dt id="id-1.9.25.20"><span><span class="glossterm">transient message</span> <a title="Permalink" class="permalink" href="#id-1.9.25.20">#</a></span></dt><dd class="glossdef"><p>A message that is stored in memory and is lost after the server
is restarted.</p></dd><dt id="id-1.9.25.21"><span><span class="glossterm">transient queue</span> <a title="Permalink" class="permalink" href="#id-1.9.25.21">#</a></span></dt><dd class="glossdef"><p>Alternative term for a non-durable queue.</p></dd><dt id="id-1.9.25.22"><span><span class="glossterm">TripleO</span> <a title="Permalink" class="permalink" href="#id-1.9.25.22">#</a></span></dt><dd class="glossdef"><p>OpenStack-on-OpenStack program. The code name for the
OpenStack Deployment program.</p></dd><dt id="id-1.9.25.23"><span><span class="glossterm">trove</span> <a title="Permalink" class="permalink" href="#id-1.9.25.23">#</a></span></dt><dd class="glossdef"><p>Codename for OpenStack <a class="xref" href="#term-database-service-trove" title="Database service (trove)">Database service (trove)</a>.</p></dd><dt id="id-1.9.25.24"><span><span class="glossterm">trusted platform module (TPM)</span> <a title="Permalink" class="permalink" href="#id-1.9.25.24">#</a></span></dt><dd class="glossdef"><p>Specialized microprocessor for incorporating cryptographic keys
into devices for authenticating and securing a hardware platform.</p></dd></dl></div><div class="glossdiv" id="id-1.9.26"><h3 class="title">U</h3><dl><dt id="id-1.9.26.3"><span><span class="glossterm">Ubuntu</span> <a title="Permalink" class="permalink" href="#id-1.9.26.3">#</a></span></dt><dd class="glossdef"><p>A Debian-based Linux distribution.</p></dd><dt id="id-1.9.26.4"><span><span class="glossterm">unscoped token</span> <a title="Permalink" class="permalink" href="#id-1.9.26.4">#</a></span></dt><dd class="glossdef"><p>Alternative term for an Identity service default token.</p></dd><dt id="id-1.9.26.5"><span><span class="glossterm">updater</span> <a title="Permalink" class="permalink" href="#id-1.9.26.5">#</a></span></dt><dd class="glossdef"><p>Collective term for a group of Object Storage components that
processes queued and failed updates for containers and objects.</p></dd><dt id="id-1.9.26.6"><span><span class="glossterm">user</span> <a title="Permalink" class="permalink" href="#id-1.9.26.6">#</a></span></dt><dd class="glossdef"><p>In OpenStack Identity,  entities represent individual API
consumers and are owned by a specific domain. In OpenStack Compute,
a user can be associated with roles, projects, or both.</p></dd><dt id="id-1.9.26.7"><span><span class="glossterm">user data</span> <a title="Permalink" class="permalink" href="#id-1.9.26.7">#</a></span></dt><dd class="glossdef"><p>A blob of data that the user can specify when they launch
an instance. The instance can access this data through the
metadata service or config drive.
Commonly used to pass a shell script that the instance runs on boot.</p></dd><dt id="id-1.9.26.8"><span><span class="glossterm">User Mode Linux (UML)</span> <a title="Permalink" class="permalink" href="#id-1.9.26.8">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd></dl></div><div class="glossdiv" id="id-1.9.27"><h3 class="title">V</h3><dl><dt id="id-1.9.27.3"><span><span class="glossterm">VIF UUID</span> <a title="Permalink" class="permalink" href="#id-1.9.27.3">#</a></span></dt><dd class="glossdef"><p>Unique ID assigned to each Networking VIF.</p></dd><dt id="id-1.9.27.4"><span><span class="glossterm">Virtual Central Processing Unit (vCPU)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.4">#</a></span></dt><dd class="glossdef"><p>Subdivides physical CPUs. Instances can then use those
divisions.</p></dd><dt id="id-1.9.27.5"><span><span class="glossterm">Virtual Disk Image (VDI)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.5">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.9.27.6"><span><span class="glossterm">Virtual Extensible LAN (VXLAN)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.6">#</a></span></dt><dd class="glossdef"><p>A network virtualization technology that attempts to reduce the
scalability problems associated with large cloud computing
deployments. It uses a VLAN-like encapsulation technique to
encapsulate Ethernet frames within UDP packets.</p></dd><dt id="id-1.9.27.7"><span><span class="glossterm">Virtual Hard Disk (VHD)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.7">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.9.27.8"><span><span class="glossterm">virtual IP address (VIP)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.8">#</a></span></dt><dd class="glossdef"><p>An Internet Protocol (IP) address configured on the load
balancer for use by clients connecting to a service that is load
balanced. Incoming connections are distributed to back-end nodes based
on the configuration of the load balancer.</p></dd><dt id="id-1.9.27.9"><span><span class="glossterm">virtual machine (VM)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.9">#</a></span></dt><dd class="glossdef"><p>An operating system instance that runs on top of a hypervisor.
Multiple VMs can run at the same time on the same physical
host.</p></dd><dt id="id-1.9.27.10"><span><span class="glossterm">virtual network</span> <a title="Permalink" class="permalink" href="#id-1.9.27.10">#</a></span></dt><dd class="glossdef"><p>An L2 network segment within Networking.</p></dd><dt id="id-1.9.27.11"><span><span class="glossterm">Virtual Network Computing (VNC)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.11">#</a></span></dt><dd class="glossdef"><p>Open source GUI and CLI tools used for remote console access to
VMs. Supported by Compute.</p></dd><dt id="id-1.9.27.12"><span><span class="glossterm">Virtual Network InterFace (VIF)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.12">#</a></span></dt><dd class="glossdef"><p>An interface that is plugged into a port in a Networking
network. Typically a virtual network interface belonging to a
VM.</p></dd><dt id="id-1.9.27.13"><span><span class="glossterm">virtual networking</span> <a title="Permalink" class="permalink" href="#id-1.9.27.13">#</a></span></dt><dd class="glossdef"><p>A generic term for virtualization of network functions
such as switching, routing, load balancing, and security using
a combination of VMs and overlays on physical network
infrastructure.</p></dd><dt id="id-1.9.27.14"><span><span class="glossterm">virtual port</span> <a title="Permalink" class="permalink" href="#id-1.9.27.14">#</a></span></dt><dd class="glossdef"><p>Attachment point where a virtual interface connects to a virtual
network.</p></dd><dt id="id-1.9.27.15"><span><span class="glossterm">virtual private network (VPN)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.15">#</a></span></dt><dd class="glossdef"><p>Provided by Compute in the form of cloudpipes, specialized
instances that are used to create VPNs on a per-project basis.</p></dd><dt id="id-1.9.27.16"><span><span class="glossterm">virtual server</span> <a title="Permalink" class="permalink" href="#id-1.9.27.16">#</a></span></dt><dd class="glossdef"><p>Alternative term for a VM or guest.</p></dd><dt id="id-1.9.27.17"><span><span class="glossterm">virtual switch (vSwitch)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.17">#</a></span></dt><dd class="glossdef"><p>Software that runs on a host or node and provides the features
and functions of a hardware-based network switch.</p></dd><dt id="id-1.9.27.18"><span><span class="glossterm">virtual VLAN</span> <a title="Permalink" class="permalink" href="#id-1.9.27.18">#</a></span></dt><dd class="glossdef"><p>Alternative term for a virtual network.</p></dd><dt id="id-1.9.27.19"><span><span class="glossterm">VirtualBox</span> <a title="Permalink" class="permalink" href="#id-1.9.27.19">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.9.27.20"><span><span class="glossterm">Vitrage</span> <a title="Permalink" class="permalink" href="#id-1.9.27.20">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-root-cause-analysis-rca-service-vitrage" title="Root Cause Analysis (RCA) service (Vitrage)">Root Cause Analysis (RCA) service (Vitrage)</a>.</p></dd><dt id="id-1.9.27.21"><span><span class="glossterm">VLAN manager</span> <a title="Permalink" class="permalink" href="#id-1.9.27.21">#</a></span></dt><dd class="glossdef"><p>A Compute component that provides dnsmasq and radvd and sets up
forwarding to and from cloudpipe instances.</p></dd><dt id="id-1.9.27.22"><span><span class="glossterm">VLAN network</span> <a title="Permalink" class="permalink" href="#id-1.9.27.22">#</a></span></dt><dd class="glossdef"><p>The Network Controller provides virtual networks to enable
compute servers to interact with each other and with the public
network. All machines must have a public and private network
interface. A VLAN network is a private network interface, which is
controlled by the <code class="literal">vlan_interface</code> option with VLAN
managers.</p></dd><dt id="id-1.9.27.23"><span><span class="glossterm">VM disk (VMDK)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.23">#</a></span></dt><dd class="glossdef"><p>One of the VM image disk formats supported by Image
service.</p></dd><dt id="id-1.9.27.24"><span><span class="glossterm">VM image</span> <a title="Permalink" class="permalink" href="#id-1.9.27.24">#</a></span></dt><dd class="glossdef"><p>Alternative term for an image.</p></dd><dt id="id-1.9.27.25"><span><span class="glossterm">VM Remote Control (VMRC)</span> <a title="Permalink" class="permalink" href="#id-1.9.27.25">#</a></span></dt><dd class="glossdef"><p>Method to access VM instance consoles using a web browser.
Supported by Compute.</p></dd><dt id="id-1.9.27.26"><span><span class="glossterm">VMware API</span> <a title="Permalink" class="permalink" href="#id-1.9.27.26">#</a></span></dt><dd class="glossdef"><p>Supports interaction with VMware products in Compute.</p></dd><dt id="id-1.9.27.27"><span><span class="glossterm">VMware NSX Neutron plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.27.27">#</a></span></dt><dd class="glossdef"><p>Provides support for VMware NSX in Neutron.</p></dd><dt id="id-1.9.27.28"><span><span class="glossterm">VNC proxy</span> <a title="Permalink" class="permalink" href="#id-1.9.27.28">#</a></span></dt><dd class="glossdef"><p>A Compute component that provides users access to the consoles
of their VM instances through VNC or VMRC.</p></dd><dt id="id-1.9.27.29"><span><span class="glossterm">volume</span> <a title="Permalink" class="permalink" href="#id-1.9.27.29">#</a></span></dt><dd class="glossdef"><p>Disk-based data storage generally represented as an iSCSI target
with a file system that supports extended attributes; can be
persistent or ephemeral.</p></dd><dt id="id-1.9.27.30"><span><span class="glossterm">Volume API</span> <a title="Permalink" class="permalink" href="#id-1.9.27.30">#</a></span></dt><dd class="glossdef"><p>Alternative name for the Block Storage API.</p></dd><dt id="id-1.9.27.31"><span><span class="glossterm">volume controller</span> <a title="Permalink" class="permalink" href="#id-1.9.27.31">#</a></span></dt><dd class="glossdef"><p>A Block Storage component that oversees and coordinates storage
volume actions.</p></dd><dt id="id-1.9.27.32"><span><span class="glossterm">volume driver</span> <a title="Permalink" class="permalink" href="#id-1.9.27.32">#</a></span></dt><dd class="glossdef"><p>Alternative term for a volume plug-in.</p></dd><dt id="id-1.9.27.33"><span><span class="glossterm">volume ID</span> <a title="Permalink" class="permalink" href="#id-1.9.27.33">#</a></span></dt><dd class="glossdef"><p>Unique ID applied to each storage volume under the Block Storage
control.</p></dd><dt id="id-1.9.27.34"><span><span class="glossterm">volume manager</span> <a title="Permalink" class="permalink" href="#id-1.9.27.34">#</a></span></dt><dd class="glossdef"><p>A Block Storage component that creates, attaches, and detaches
persistent storage volumes.</p></dd><dt id="id-1.9.27.35"><span><span class="glossterm">volume node</span> <a title="Permalink" class="permalink" href="#id-1.9.27.35">#</a></span></dt><dd class="glossdef"><p>A Block Storage node that runs the cinder-volume daemon.</p></dd><dt id="id-1.9.27.36"><span><span class="glossterm">volume plug-in</span> <a title="Permalink" class="permalink" href="#id-1.9.27.36">#</a></span></dt><dd class="glossdef"><p>Provides support for new and specialized types of back-end
storage for the Block Storage volume manager.</p></dd><dt id="id-1.9.27.37"><span><span class="glossterm">volume worker</span> <a title="Permalink" class="permalink" href="#id-1.9.27.37">#</a></span></dt><dd class="glossdef"><p>A cinder component that interacts with back-end storage to manage
the creation and deletion of volumes and the creation of compute
volumes, provided by the cinder-volume daemon.</p></dd><dt id="id-1.9.27.38"><span><span class="glossterm">vSphere</span> <a title="Permalink" class="permalink" href="#id-1.9.27.38">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd></dl></div><div class="glossdiv" id="id-1.9.28"><h3 class="title">W</h3><dl><dt id="id-1.9.28.3"><span><span class="glossterm">Watcher</span> <a title="Permalink" class="permalink" href="#id-1.9.28.3">#</a></span></dt><dd class="glossdef"><p>Code name for the <a class="xref" href="#term-infrastructure-optimization-service-watcher" title="Infrastructure Optimization service (watcher)">Infrastructure Optimization service (watcher)</a>.</p></dd><dt id="id-1.9.28.4"><span><span class="glossterm">weight</span> <a title="Permalink" class="permalink" href="#id-1.9.28.4">#</a></span></dt><dd class="glossdef"><p>Used by Object Storage devices to determine which storage
devices are suitable for the job. Devices are weighted by size.</p></dd><dt id="id-1.9.28.5"><span><span class="glossterm">weighted cost</span> <a title="Permalink" class="permalink" href="#id-1.9.28.5">#</a></span></dt><dd class="glossdef"><p>The sum of each cost used when deciding where to start a new VM
instance in Compute.</p></dd><dt id="id-1.9.28.6"><span><span class="glossterm">weighting</span> <a title="Permalink" class="permalink" href="#id-1.9.28.6">#</a></span></dt><dd class="glossdef"><p>A Compute process that determines the suitability of the VM
instances for a job for a particular host. For example, not enough RAM
on the host, too many CPUs on the host, and so on.</p></dd><dt id="id-1.9.28.7"><span><span class="glossterm">worker</span> <a title="Permalink" class="permalink" href="#id-1.9.28.7">#</a></span></dt><dd class="glossdef"><p>A daemon that listens to a queue and carries out tasks in
response to messages. For example, the cinder-volume worker manages volume
creation and deletion on storage arrays.</p></dd><dt id="term-workflow-service-mistral"><span><span class="glossterm">Workflow service (mistral)</span> <a title="Permalink" class="permalink" href="#term-workflow-service-mistral">#</a></span></dt><dd class="glossdef"><p>The OpenStack service that provides a simple YAML-based language to
write workflows (tasks and transition rules) and a service that
allows to upload them, modify, run them at scale and in a highly
available manner, manage and monitor workflow execution state and state
of individual tasks.</p></dd></dl></div><div class="glossdiv" id="id-1.9.29"><h3 class="title">X</h3><dl><dt id="id-1.9.29.3"><span><span class="glossterm">Xen</span> <a title="Permalink" class="permalink" href="#id-1.9.29.3">#</a></span></dt><dd class="glossdef"><p>Xen is a hypervisor using a microkernel design, providing
services that allow multiple computer operating systems to
execute on the same computer hardware concurrently.</p></dd><dt id="id-1.9.29.4"><span><span class="glossterm">Xen API</span> <a title="Permalink" class="permalink" href="#id-1.9.29.4">#</a></span></dt><dd class="glossdef"><p>The Xen administrative API, which is supported by
Compute.</p></dd><dt id="id-1.9.29.5"><span><span class="glossterm">Xen Cloud Platform (XCP)</span> <a title="Permalink" class="permalink" href="#id-1.9.29.5">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.9.29.6"><span><span class="glossterm">Xen Storage Manager Volume Driver</span> <a title="Permalink" class="permalink" href="#id-1.9.29.6">#</a></span></dt><dd class="glossdef"><p>A Block Storage volume plug-in that enables communication with
the Xen Storage Manager API.</p></dd><dt id="id-1.9.29.7"><span><span class="glossterm">XenServer</span> <a title="Permalink" class="permalink" href="#id-1.9.29.7">#</a></span></dt><dd class="glossdef"><p>An OpenStack-supported hypervisor.</p></dd><dt id="id-1.9.29.8"><span><span class="glossterm">XFS</span> <a title="Permalink" class="permalink" href="#id-1.9.29.8">#</a></span></dt><dd class="glossdef"><p>High-performance 64-bit file system created by Silicon
Graphics. Excels in parallel I/O operations and data
consistency.</p></dd></dl></div><div class="glossdiv" id="id-1.9.30"><h3 class="title">Z</h3><dl><dt id="id-1.9.30.3"><span><span class="glossterm">zaqar</span> <a title="Permalink" class="permalink" href="#id-1.9.30.3">#</a></span></dt><dd class="glossdef"><p>Codename for the <a class="xref" href="#term-message-service-zaqar" title="Message service (zaqar)">Message service (zaqar)</a>.</p></dd><dt id="id-1.9.30.4"><span><span class="glossterm">ZeroMQ</span> <a title="Permalink" class="permalink" href="#id-1.9.30.4">#</a></span></dt><dd class="glossdef"><p>Message queue software supported by OpenStack. An alternative to
RabbitMQ. Also spelled 0MQ.</p></dd><dt id="id-1.9.30.5"><span><span class="glossterm">Zuul</span> <a title="Permalink" class="permalink" href="#id-1.9.30.5">#</a></span></dt><dd class="glossdef"><p>Tool used in OpenStack development to ensure correctly ordered
testing of changes in parallel.</p></dd></dl></div></div></div></div><div class="page-bottom"><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2022 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>