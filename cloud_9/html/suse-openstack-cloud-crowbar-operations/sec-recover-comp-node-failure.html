<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Recovering from Compute Node Failure</title><meta name="generator" content="DocBook XSL Stylesheets V1.79.2" /><style type="text/css">
body { background-image: url('static/images/draft.png');
       background-repeat: no-repeat;
       background-position: top left;
       /* The following properties make the watermark "fixed" on the page. */
       /* I think that's just a bit too distracting for the reader... */
       /* background-attachment: fixed; */
       /* background-position: center center; */
     }</style><link rel="home" href="index.html" title="SUSE OpenStack Cloud Crowbar 9 Documentation" /><link rel="up" href="sec-maintenance.html" title="Chapter 1. Maintenance" /><link rel="prev" href="sec-upgrade-8-9.html" title="Upgrading from SUSE OpenStack Cloud Crowbar 8 to SUSE OpenStack Cloud Crowbar 9" /><link rel="next" href="sec-bootstrap-compute-plane.html" title="Bootstrapping the Compute Plane" /></head><body onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Recovering from Compute Node Failure</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="sec-upgrade-8-9.html">Prev</a> </td><th width="60%" align="center">Chapter 1. Maintenance</th><td width="20%" align="right"> <a accesskey="n" href="sec-bootstrap-compute-plane.html">Next</a></td></tr></table><hr /></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="sec-recover-comp-node-failure"></a>Recovering from Compute Node Failure</h2></div></div></div><p>
      The following procedure assumes that there is at least one Compute Node
      already running. Otherwise, see
      <a class="xref" href="sec-bootstrap-compute-plane.html" title="Bootstrapping the Compute Plane">the section called “Bootstrapping the Compute Plane”</a>.
    </p><div class="procedure"><a id="pro-recover-compute-node-failure"></a><p class="title"><strong>Procedure 1.1. Procedure for Recovering from Compute Node Failure</strong></p><ol class="procedure" type="1"><li class="step"><a id="st-compnode-failed-reason"></a><p>
          If the Compute Node failed, it should have been fenced. Verify that this is
          the case. Otherwise, check <code class="filename">/var/log/pacemaker.log</code> on
          the Designated Coordinator to determine why the Compute Node was not fenced.
          The most likely reason is a problem with STONITH devices.
        </p></li><li class="step"><p>
          Determine the cause of the Compute Node's failure.
        </p></li><li class="step"><p>
          Rectify the root cause.
        </p></li><li class="step"><p>
          Boot the Compute Node again.
        </p></li><li class="step"><p>
          Check whether the <code class="systemitem">crowbar_join</code> script ran
          successfully on the Compute Node. If this is not the case, check the log
          files to find out the reason. Refer to
          <a class="xref" href="cha-deploy-logs.html#sec-deploy-logs-crownodes" title="On All Other Crowbar Nodes">the section called “On All Other Crowbar Nodes”</a> to find the exact
          location of the log file.
        </p></li><li class="step"><p>
          If the <code class="systemitem">chef-client</code> agent triggered by
          <code class="systemitem">crowbar_join</code> succeeded, confirm that the
          <code class="systemitem">pacemaker_remote</code> service is up and running.
        </p></li><li class="step"><p>
          Check whether the remote node is registered and considered healthy by the
          core cluster. If this is not the case check
          <code class="filename">/var/log/pacemaker.log</code> on the Designated Coordinator
          to determine the cause. There should be a remote primitive running on the
          core cluster (active/passive). This primitive is responsible for
          establishing a TCP connection to the
          <code class="systemitem">pacemaker_remote</code> service on port 3121 of the
          Compute Node. Ensure that nothing is preventing this particular TCP
          connection from being established (for example, problems with NICs,
          switches, firewalls etc.). One way to do this is to run the following
          commands:
        </p><pre class="screen"><code class="prompt">tux &gt; </code>lsof -i tcp:3121
          <code class="prompt">tux &gt; </code>tcpdump tcp port 3121
        </pre></li><li class="step"><p>
          If Pacemaker can communicate with the remote node, it should start the
          <code class="systemitem">nova-compute</code> service on it as part of the cloned
          group <code class="literal">cl-g-nova-compute</code> using the NovaCompute OCF
          resource agent. This cloned group will block startup of
          <code class="systemitem">nova-evacuate</code> until at least one clone is
          started.
        </p><p>
          A necessary, related but different procedure is described in
          <a class="xref" href="sec-bootstrap-compute-plane.html" title="Bootstrapping the Compute Plane">the section called “Bootstrapping the Compute Plane”</a>.
        </p></li><li class="step"><p>
          It may happen that <code class="systemitem">novaCompute</code> has been launched
          correctly on the Compute Node by <code class="systemitem">lrmd</code>, but the
          <code class="systemitem">openstack-nova-compute</code> service is still not
          running. This usually happens when <code class="systemitem">nova-evacuate</code>
          did not run correctly.
        </p><p>
          If <code class="systemitem">nova-evacuate</code> is not
          running on one of the core cluster nodes, make sure that the service is
          marked as started (<code class="literal">target-role="Started"</code>). If this is
          the case, then your cloud does not have any Compute Nodes already running as
          assumed by this procedure.
        </p><p>
          If <code class="systemitem">nova-evacuate</code> is started but it is
          failing, check the Pacemaker logs to determine the cause.
        </p><p>
          If <code class="systemitem">nova-evacuate</code> is started and
          functioning correctly, it should call nova's
          <code class="literal">evacuate</code> API to release resources used by the
          Compute Node and resurrect elsewhere any VMs that died when it failed.
        </p></li><li class="step"><p>
          If <code class="systemitem">openstack-nova-compute</code> is running, but VMs are
          not booted on the node, check that the service is not disabled or forced
          down using the <span class="command"><strong>openstack compute service list</strong></span>
          command. In case the service is disabled, run the <span class="command"><strong>openstack
            compute service set –enable
            <em class="replaceable"><code>SERVICE_ID</code></em></strong></span> command. If the service is
          forced down, run the following commands:
        </p><pre class="screen"><code class="prompt">tux &gt; </code>fence_nova_param () {
          key="$1"
          cibadmin -Q -A "//primitive[@id="fence-nova"]//nvpair[@name='$key']" | \
          sed -n '/.*value="/{s///;s/".*//;p}'
          }
          <code class="prompt">tux &gt; </code>fence_compute \
          --auth-url=`fence_nova_param auth-url` \
          --endpoint-type=`fence_nova_param endpoint-type` \
          --tenant-name=`fence_nova_param tenant-name` \
          --domain=`fence_nova_param domain` \
          --username=`fence_nova_param login` \
          --password=`fence_nova_param passwd` \
          -n <em class="replaceable"><code>COMPUTE_HOSTNAME</code></em> \
          --action=on
        </pre></li></ol></div><p>
      The above steps should be performed automatically after the node is
      booted. If that does not happen, try the following debugging techniques.
    </p><p>
      Check the <code class="literal">evacuate</code> attribute for the Compute Node in the
      Pacemaker cluster's <code class="systemitem">attrd</code> service using the
      command:
    </p><pre class="screen"><code class="prompt">tux &gt; </code>attrd_updater -p -n evacuate -N <em class="replaceable"><code>NODE</code></em></pre><p>
      Possible results are the following:
    </p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>
          The attribute is not set. Refer to
          <a class="xref" href="sec-recover-comp-node-failure.html#st-compnode-failed-reason" title="Step 1">Step 1</a> in
          <a class="xref" href="sec-recover-comp-node-failure.html#pro-recover-compute-node-failure" title="Procedure 1.1. Procedure for Recovering from Compute Node Failure">Procedure 1.1, “Procedure for Recovering from Compute Node Failure”</a>.
        </p></li><li class="listitem"><p>
          The attribute is set to <code class="literal">yes</code>. This means that the
          Compute Node was fenced, but <code class="systemitem">nova-evacuate</code> never
          initiated the recovery procedure by calling nova's evacuate API.
        </p></li><li class="listitem"><p>
          The attribute contains a time stamp, in which case the recovery procedure
          was initiated at the time indicated by the time stamp, but has not
          completed yet.
        </p></li><li class="listitem"><p>
          If the attribute is set to <code class="literal">no</code>, the recovery procedure
          recovered successfully and the cloud is ready for the Compute Node to
          rejoin.
        </p></li></ul></div><p>
      If the attribute is stuck with the wrong value, it can be set to
      <code class="literal">no</code> using the command:
    </p><pre class="screen"><code class="prompt">tux &gt; </code>attrd_updater -n evacuate -U no -N <em class="replaceable"><code>NODE</code></em></pre><p>
      After standard fencing has been performed, fence agent
      <code class="systemitem">fence_compute</code> should activate the secondary
      fencing device (<code class="literal">fence-nova</code>). It does this by setting
      the attribute to <code class="literal">yes</code> to mark the node as needing
      recovery. The agent also calls nova's
      <code class="systemitem">force_down</code> API to notify it that the host is down.
      You should be able to see this in
      <code class="filename">/var/log/nova/fence_compute.log</code> on the node in the core
      cluster that was running the <code class="systemitem">fence-nova</code> agent at
      the time of fencing. During the recovery, <code class="literal">fence_compute</code>
      tells nova that the host is up and running again.
    </p></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="sec-upgrade-8-9.html">Prev</a> </td><td width="20%" align="center"><a accesskey="u" href="sec-maintenance.html">Up</a></td><td width="40%" align="right"> <a accesskey="n" href="sec-bootstrap-compute-plane.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Upgrading from <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud Crowbar</span></span> 8 to <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud Crowbar</span></span> 9 </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> Bootstrapping the Compute Plane</td></tr></table></div></body></html>