<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Installing Baremetal (Ironic) | Deployment Guide using Cloud Lifecycle Manager | SUSE OpenStack Cloud 9</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.2.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.81.0 (based on DocBook XSL Stylesheets 1.79.2) - chunked" /><meta name="product-name" content="SUSE OpenStack Cloud" /><meta name="product-number" content="9" /><meta name="book-title" content="Deployment Guide using Cloud Lifecycle Manager" /><meta name="chapter-title" content="Chapter 29. Installing Baremetal (Ironic)" /><meta name="description" content="Bare Metal as a Service is enabled in this release for deployment of nova instances on bare metal nodes using flat networking." /><meta name="tracker-url" content="https://bugzilla.suse.com/enter_bug.cgi" /><meta name="tracker-type" content="bsc" /><meta name="tracker-bsc-component" content="Documentation" /><meta name="tracker-bsc-product" content="SUSE OpenStack Cloud 9" /><link rel="home" href="index.html" title="Documentation" /><link rel="up" href="cloudinstallation.html" title="Part IV. Cloud Installation" /><link rel="prev" href="integrate-nsx-vsphere.html" title="Chapter 28. Integrating NSX for vSphere" /><link rel="next" href="install-swift.html" title="Chapter 30. Installation for SUSE OpenStack Cloud Entry-scale Cloud with Swift Only" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css"></link>');
}
else {
  document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-navigation">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #E11;"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs"><a class="book-link" href="index.html" title="Documentation"><span class="book-icon">Documentation</span></a><span> › </span><a class="crumb" href="book-deployment.html">Deployment Guide using Cloud Lifecycle Manager</a><span> › </span><a class="crumb" href="cloudinstallation.html">Cloud Installation</a><span> › </span><a class="crumb" href="install-ironic-overview.html">Installing Baremetal (Ironic)</a></div><div class="clearme"></div></div></div><div id="_toolbar-wrap"><div id="_toolbar"><div id="_toc-area" class="inactive"><a id="_toc-area-button" class="tool" title="Contents" accesskey="c" href="index.html"><span class="tool-spacer"><span class="toc-icon">Contents</span><span class="clearme"></span></span><span class="tool-label">Contents</span></a><div class="active-contents bubble-corner"></div><div class="active-contents bubble"><div class="bubble-container"><h6>Deployment Guide using Cloud Lifecycle Manager</h6><div id="_bubble-toc"><ol><li class="inactive"><a href="planning-index.html"><span class="number">I </span><span class="name">Planning an Installation using Cloud Lifecycle Manager</span></a><ol><li class="inactive"><a href="register-suse-overview.html"><span class="number">1 </span><span class="name">Registering SLES</span></a></li><li class="inactive"><a href="min-hardware.html"><span class="number">2 </span><span class="name">Hardware and Software Support Matrix</span></a></li><li class="inactive"><a href="idg-planning-planning-recommended-hardware-minimums-xml-1.html"><span class="number">3 </span><span class="name">Recommended Hardware Minimums for the Example Configurations</span></a></li><li class="inactive"><a href="HP3-0HA.html"><span class="number">4 </span><span class="name">High Availability</span></a></li></ol></li><li class="inactive"><a href="architecture.html"><span class="number">II </span><span class="name">Cloud Lifecycle Manager Overview</span></a><ol><li class="inactive"><a href="cha-input-model-intro-concept.html"><span class="number">5 </span><span class="name">Input Model</span></a></li><li class="inactive"><a href="configurationobjects.html"><span class="number">6 </span><span class="name">Configuration Objects</span></a></li><li class="inactive"><a href="othertopics.html"><span class="number">7 </span><span class="name">Other Topics</span></a></li><li class="inactive"><a href="cpinfofiles.html"><span class="number">8 </span><span class="name">Configuration Processor Information Files</span></a></li><li class="inactive"><a href="example-configurations.html"><span class="number">9 </span><span class="name">Example Configurations</span></a></li><li class="inactive"><a href="modify-compute-input-model.html"><span class="number">10 </span><span class="name">Modifying Example Configurations for Compute Nodes</span></a></li><li class="inactive"><a href="modify-input-model.html"><span class="number">11 </span><span class="name">Modifying Example Configurations for Object Storage using Swift</span></a></li><li class="inactive"><a href="alternative-configurations.html"><span class="number">12 </span><span class="name">Alternative Configurations</span></a></li></ol></li><li class="inactive"><a href="preinstall.html"><span class="number">III </span><span class="name">Pre-Installation</span></a><ol><li class="inactive"><a href="preinstall-overview.html"><span class="number">13 </span><span class="name">Overview</span></a></li><li class="inactive"><a href="preinstall-checklist.html"><span class="number">14 </span><span class="name">Pre-Installation Checklist</span></a></li><li class="inactive"><a href="cha-depl-dep-inst.html"><span class="number">15 </span><span class="name">Installing the Cloud Lifecycle Manager server</span></a></li><li class="inactive"><a href="app-deploy-smt-lcm.html"><span class="number">16 </span><span class="name">Installing and Setting Up an SMT Server on the Cloud Lifecycle Manager server (Optional)</span></a></li><li class="inactive"><a href="cha-depl-repo-conf-lcm.html"><span class="number">17 </span><span class="name">Software Repository Setup</span></a></li><li class="inactive"><a href="multipath-boot-from-san.html"><span class="number">18 </span><span class="name">Boot from SAN and Multipath Configuration</span></a></li></ol></li><li class="inactive"><a href="cloudinstallation.html"><span class="number">IV </span><span class="name">Cloud Installation</span></a><ol><li class="inactive"><a href="cloudinstallation-overview.html"><span class="number">19 </span><span class="name">Overview</span></a></li><li class="inactive"><a href="preparing-standalone.html"><span class="number">20 </span><span class="name">Preparing for Stand-Alone Deployment</span></a></li><li class="inactive"><a href="install-gui.html"><span class="number">21 </span><span class="name">Installing with the Install UI</span></a></li><li class="inactive"><a href="using-git.html"><span class="number">22 </span><span class="name">Using Git for Configuration Management</span></a></li><li class="inactive"><a href="install-standalone.html"><span class="number">23 </span><span class="name">Installing a Stand-Alone Cloud Lifecycle Manager</span></a></li><li class="inactive"><a href="install-kvm.html"><span class="number">24 </span><span class="name">Installing Mid-scale and Entry-scale KVM</span></a></li><li class="inactive"><a href="DesignateInstallOverview.html"><span class="number">25 </span><span class="name">DNS Service Installation Overview</span></a></li><li class="inactive"><a href="MagnumOverview.html"><span class="number">26 </span><span class="name">Magnum Overview</span></a></li><li class="inactive"><a href="install-esx-ovsvapp.html"><span class="number">27 </span><span class="name">Installing ESX Computes and OVSvAPP</span></a></li><li class="inactive"><a href="integrate-nsx-vsphere.html"><span class="number">28 </span><span class="name">Integrating NSX for vSphere</span></a></li><li class="inactive"><a href="install-ironic-overview.html"><span class="number">29 </span><span class="name">Installing Baremetal (Ironic)</span></a></li><li class="inactive"><a href="install-swift.html"><span class="number">30 </span><span class="name">Installation for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Entry-scale Cloud with Swift Only</span></a></li><li class="inactive"><a href="install-sles-compute.html"><span class="number">31 </span><span class="name">Installing SLES Compute</span></a></li><li class="inactive"><a href="install-ardana-manila.html"><span class="number">32 </span><span class="name">Installing manila and Creating manila Shares</span></a></li><li class="inactive"><a href="install-heat-templates.html"><span class="number">33 </span><span class="name">Installing SUSE CaaS Platform heat Templates</span></a></li><li class="inactive"><a href="install-caasp-terraform.html"><span class="number">34 </span><span class="name">Installing SUSE CaaS Platform v4 using terraform</span></a></li><li class="inactive"><a href="integrations.html"><span class="number">35 </span><span class="name">Integrations</span></a></li><li class="inactive"><a href="troubleshooting-installation.html"><span class="number">36 </span><span class="name">Troubleshooting the Installation</span></a></li><li class="inactive"><a href="esx-troubleshooting-installation.html"><span class="number">37 </span><span class="name">Troubleshooting the ESX</span></a></li></ol></li><li class="inactive"><a href="post-install.html"><span class="number">V </span><span class="name">Post-Installation</span></a><ol><li class="inactive"><a href="cloud-verification.html"><span class="number">38 </span><span class="name">Post Installation Tasks</span></a></li><li class="inactive"><a href="ui-verification.html"><span class="number">39 </span><span class="name">UI Verification</span></a></li><li class="inactive"><a href="install-openstack-clients.html"><span class="number">40 </span><span class="name">Installing OpenStack Clients</span></a></li><li class="inactive"><a href="tls30.html"><span class="number">41 </span><span class="name">Configuring Transport Layer Security (TLS)</span></a></li><li class="inactive"><a href="config-availability-zones.html"><span class="number">42 </span><span class="name">Configuring Availability Zones</span></a></li><li class="inactive"><a href="OctaviaInstall.html"><span class="number">43 </span><span class="name">Configuring Load Balancer as a Service</span></a></li><li class="inactive"><a href="postinstall-checklist.html"><span class="number">44 </span><span class="name">Other Common Post-Installation Tasks</span></a></li></ol></li><li class="inactive"><a href="cha-inst-trouble.html"><span class="number">VI </span><span class="name">Support</span></a><ol><li class="inactive"><a href="sec-depl-trouble-faq.html"><span class="number">45 </span><span class="name">FAQ</span></a></li><li class="inactive"><a href="sec-installation-trouble-support.html"><span class="number">46 </span><span class="name">Support</span></a></li><li class="inactive"><a href="inst-support-ptf.html"><span class="number">47 </span><span class="name">
    Applying PTFs (Program Temporary Fixes) Provided by SUSE L3 Support
   </span></a></li><li class="inactive"><a href="inst-support-ptf-test.html"><span class="number">48 </span><span class="name">
    Testing PTFs (Program Temporary Fixes) on a Single Node
   </span></a></li></ol></li></ol></div><div class="clearme"></div></div></div></div><div id="_nav-area" class="inactive"><div class="tool"><span class="nav-inner"><span class="tool-label">Navigation</span><a accesskey="p" class="tool-spacer" title="Chapter 28. Integrating NSX for vSphere" href="integrate-nsx-vsphere.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 30. Installation for SUSE OpenStack Cloud Entry-scale Cloud with Swift Only" href="install-swift.html"><span class="next-icon">→</span></a></span></div></div></div></div><div id="_fixed-header-wrap" style="background-color: #E11;" class="inactive"><div id="_fixed-header"><div class="crumbs"><a class="book-link" href="index.html" title="Documentation"><span class="book-icon">Documentation</span></a><span> › </span><a class="crumb" href="book-deployment.html">Deployment Guide using Cloud Lifecycle Manager</a><span> › </span><a class="crumb" href="cloudinstallation.html">Cloud Installation</a><span> › </span><a class="crumb" href="install-ironic-overview.html">Installing Baremetal (Ironic)</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="button"><a accesskey="p" class="tool-spacer" title="Chapter 28. Integrating NSX for vSphere" href="integrate-nsx-vsphere.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 30. Installation for SUSE OpenStack Cloud Entry-scale Cloud with Swift Only" href="install-swift.html"><span class="next-icon">→</span></a></div><div class="clearme"></div></div><div class="clearme"></div></div></div><div id="_content" class="draft "><div class="documentation"><div class="chapter " id="install-ironic-overview"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname "><span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span></span> <span class="productnumber ">9</span></div><div><h2 class="title"><span class="number">29 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installing Baremetal (Ironic)</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_ironic_overview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_ironic_overview.xml</li><li><span class="ds-label">ID: </span>install-ironic-overview</li></ul></div></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="install-ironic-overview.html#install-ironic"><span class="number">29.1 </span><span class="name">Installation for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Entry-scale Cloud with Ironic Flat Network</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-multi-control-plane"><span class="number">29.2 </span><span class="name">ironic in Multiple Control Plane</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-provisioning"><span class="number">29.3 </span><span class="name">Provisioning Bare-Metal Nodes with Flat Network Model</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-provisioning-multi-tenancy"><span class="number">29.4 </span><span class="name">Provisioning Baremetal Nodes with Multi-Tenancy</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-system-details"><span class="number">29.5 </span><span class="name">View Ironic System Details</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-toubleshooting"><span class="number">29.6 </span><span class="name">Troubleshooting ironic Installation</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-node-cleaning"><span class="number">29.7 </span><span class="name">Node Cleaning</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-oneview"><span class="number">29.8 </span><span class="name">Ironic and HPE OneView</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-raid-config"><span class="number">29.9 </span><span class="name">RAID Configuration for Ironic</span></a></span></dt><dt><span class="section"><a href="install-ironic-overview.html#ironic-audit-support"><span class="number">29.10 </span><span class="name">Audit Support for Ironic</span></a></span></dt></dl></div></div><p>
  Bare Metal as a Service is enabled in this release for deployment of nova
  instances on bare metal nodes using flat networking.
 </p><div class="sect1" id="install-ironic"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Installation for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Entry-scale Cloud with Ironic Flat Network</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#install-ironic">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span>install-ironic</li></ul></div></div></div></div><p>
  This page describes the installation step requirements for the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span>
  Entry-scale Cloud with ironic Flat Network.
 </p><div class="sect2" id="id-1.3.6.12.3.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Your Environment</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Prior to deploying an operational environment with ironic, operators need to
   be aware of the nature of TLS certificate authentication. As pre-built
   deployment agent ramdisks images are supplied, these ramdisk images will
   only authenticate known third-party TLS Certificate Authorities in the
   interest of end-to-end security. As such, uses of self-signed certificates
   and private certificate authorities will be unable to leverage ironic
   without modifying the supplied ramdisk images.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Set up your configuration files, as follows:
    </p><ol type="a" class="substeps "><li class="step "><p>
       See the sample sets of configuration files in the
       <code class="literal">~/openstack/examples/</code> directory. Each set will have an
       accompanying README.md file that explains the contents of each of the
       configuration files.
      </p></li><li class="step "><p>
       Copy the example configuration files into the required setup directory
       and edit them to contain the details of your environment:
      </p><div class="verbatim-wrap"><pre class="screen">cp -r ~/openstack/examples/entry-scale-ironic-flat-network/* \
  ~/openstack/my_cloud/definition/</pre></div></li></ol></li><li class="step "><p><span class="step-optional">(Optional)</span> 
     You can use the <code class="literal">ardanaencrypt.py</code> script to
     encrypt your IPMI passwords. This script uses OpenSSL.
    </p><ol type="a" class="substeps "><li class="step "><p>
       Change to the Ansible directory:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible</pre></div></li><li class="step "><p>
       Put the encryption key into the following environment variable:
      </p><div class="verbatim-wrap"><pre class="screen">export ARDANA_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</pre></div></li><li class="step "><p>
       Run the python script below and follow the instructions. Enter a
       password that you want to encrypt.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>./ardanaencrypt.py</pre></div></li><li class="step "><p>
       Take the string generated and place it in the
       <code class="literal">ilo-password</code> field in your
       <code class="filename">~/openstack/my_cloud/definition/data/servers.yml</code>
       file, remembering to enclose it in quotes.
      </p></li><li class="step "><p>
       Repeat the above for each server.
      </p><div id="id-1.3.6.12.3.3.3.2.2.5.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
        Before you run any playbooks, remember that you need to export the
        encryption key in the following environment variable: <code class="literal">export
        ARDANA_USER_PASSWORD_ENCRYPT_KEY=&lt;encryption key&gt;</code>
       </p></div></li></ol></li><li class="step "><p>
     Commit your configuration to the local git repo
     (<a class="xref" href="using-git.html" title="Chapter 22. Using Git for Configuration Management">Chapter 22, <em>Using Git for Configuration Management</em></a>), as follows:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>git add -A
<code class="prompt user">ardana &gt; </code>git commit -m "My config or other commit message"</pre></div><div id="id-1.3.6.12.3.3.3.3.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
      This step needs to be repeated any time you make changes to your
      configuration files before you move on to the following steps. See
      <a class="xref" href="using-git.html" title="Chapter 22. Using Git for Configuration Management">Chapter 22, <em>Using Git for Configuration Management</em></a> for more information.
     </p></div></li></ol></div></div></div><div class="sect2" id="sec-ironic-provision"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provisioning Your Baremetal Nodes</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision</li></ul></div></div></div></div><p>
   To provision the baremetal nodes in your cloud deployment you can either use
   the automated operating system installation process provided by <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> or
   you can use the 3rd party installation tooling of your choice. We will
   outline both methods below:
  </p><div class="sect3" id="id-1.3.6.12.3.4.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">29.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using Third Party Baremetal Installers</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.4.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    If you do not wish to use the automated operating system installation
    tooling included with <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> then the requirements that have to be met
    using the installation tooling of your choice are:
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      The operating system must be installed via the SLES ISO provided on
      the <a class="link" href="https://scc.suse.com/" target="_blank">SUSE Customer Center</a>.
     </p></li><li class="listitem "><p>
      Each node must have SSH keys in place that allows the same user from the
      Cloud Lifecycle Manager node who will be doing the deployment to SSH to each node without a
      password.
     </p></li><li class="listitem "><p>
      Passwordless sudo needs to be enabled for the user.
     </p></li><li class="listitem "><p>
      There should be a LVM logical volume as <code class="literal">/root</code> on each
      node.
     </p></li><li class="listitem "><p>
      If the LVM volume group name for the volume group holding the
      <code class="literal">root</code> LVM logical volume is
      <code class="literal">ardana-vg</code>, then it will align with the disk input
      models in the examples.
     </p></li><li class="listitem "><p>
      <span class="phrase">Ensure that <code class="literal">openssh-server</code>,
      <code class="literal">python</code>, <code class="literal">python-apt</code>, and
      <code class="literal">rsync</code> are installed.</span>
     </p></li></ul></div><p>
    If you chose this method for installing your baremetal hardware, skip
    forward to the step
    <em class="citetitle ">Running the Configuration Processor</em>.
   </p></div><div class="sect3" id="id-1.3.6.12.3.4.4"><div class="titlepage"><div><div><h4 class="title"><span class="number">29.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using the Automated Operating System Installation Provided by <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.4.4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
    If you would like to use the automated operating system installation tools
    provided by <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span>, complete the steps below.
   </p><div class="sect4" id="id-1.3.6.12.3.4.4.3"><div class="titlepage"><div><div><h5 class="title"><span class="number">29.1.2.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying Cobbler</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.4.4.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
     This phase of the install process takes the baremetal information that was
     provided in <code class="literal">servers.yml</code> and installs the Cobbler
     provisioning tool and loads this information into Cobbler. This sets each
     node to <code class="literal">netboot-enabled: true</code> in Cobbler. Each node
     will be automatically marked as <code class="literal">netboot-enabled: false</code>
     when it completes its operating system install successfully. Even if the
     node tries to PXE boot subsequently, Cobbler will not serve it. This is
     deliberate so that you cannot reimage a live node by accident.
    </p><p>
     The <code class="literal">cobbler-deploy.yml</code> playbook prompts for a password
     - this is the password that will be encrypted and stored in Cobbler, which
     is associated with the user running the command on the Cloud Lifecycle Manager, that you
     will use to log in to the nodes via their consoles after install. The
     username is the same as the user set up in the initial dialogue when
     installing the Cloud Lifecycle Manager from the ISO, and is the same user that is running
     the cobbler-deploy play.
    </p><div id="id-1.3.6.12.3.4.4.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      When imaging servers with your own tooling, it is still necessary to have
      ILO/IPMI settings for all nodes. Even if you are not using Cobbler, the
      username and password fields in <code class="filename">servers.yml</code> need to
      be filled in with dummy settings. For example, add the following to
      <code class="filename">servers.yml</code>:
     </p><div class="verbatim-wrap"><pre class="screen">ilo-user: manual
ilo-password: deployment</pre></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
       Run the following playbook which confirms that there is IPMI connectivity
       for each of your nodes so that they are accessible to be re-imaged in a
       later step:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost bm-power-status.yml</pre></div></li><li class="step "><p>
       Run the following playbook to deploy Cobbler:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost cobbler-deploy.yml</pre></div></li></ol></div></div></div><div class="sect4" id="id-1.3.6.12.3.4.4.4"><div class="titlepage"><div><div><h5 class="title"><span class="number">29.1.2.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Imaging the Nodes</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.4.4.4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h5><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
     This phase of the install process goes through a number of distinct steps:
    </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
       Powers down the nodes to be installed
      </p></li><li class="step "><p>
       Sets the nodes hardware boot order so that the first option is a network
       boot.
      </p></li><li class="step "><p>
       Powers on the nodes. (The nodes will then boot from the network and be
       installed using infrastructure set up in the previous phase)
      </p></li><li class="step "><p>
       Waits for the nodes to power themselves down (this indicates a
       successful install). This can take some time.
      </p></li><li class="step "><p>
       Sets the boot order to hard disk and powers on the nodes.
      </p></li><li class="step "><p>
       Waits for the nodes to be reachable by SSH and verifies that they have the
       signature expected.
      </p></li></ol></div></div><p>
     Deploying nodes has been automated in the Cloud Lifecycle Manager and requires the
     following:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       All of your nodes using SLES must already be installed, either
       manually or via Cobbler.
      </p></li><li class="listitem "><p>
       Your input model should be configured for your SLES nodes.
      </p></li><li class="listitem "><p>
       You should have run the configuration processor and the
       <code class="filename">ready-deployment.yml</code> playbook.
      </p></li></ul></div><p>
     Execute the following steps to re-image one or more nodes after you have
     run the <code class="filename">ready-deployment.yml</code> playbook.
    </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
       Run the following playbook, specifying your SLES nodes using the
       nodelist. This playbook will reconfigure Cobbler for the nodes listed.
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook prepare-sles-grub2.yml -e \
      nodelist=node1[,node2,node3]</pre></div></li><li class="step "><p>
       Re-image the node(s) with the following command:
      </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost bm-reimage.yml \
      -e nodelist=node1[,node2,node3]</pre></div></li></ol></div></div><p>
     If a nodelist is not specified then the set of nodes in Cobbler with
     <code class="literal">netboot-enabled: True</code> is selected. The playbook pauses
     at the start to give you a chance to review the set of nodes that it is
     targeting and to confirm that it is correct.
    </p><p>
     You can use the command below which will list all of your nodes with the
     <code class="literal">netboot-enabled: True</code> flag set:
    </p><div class="verbatim-wrap"><pre class="screen">sudo cobbler system find --netboot-enabled=1</pre></div></div></div></div><div class="sect2" id="sec-ironic-config-processor"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Running the Configuration Processor</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-config-processor">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span>sec-ironic-config-processor</li></ul></div></div></div></div><p>
   Once you have your configuration files setup, you need to run the
   configuration processor to complete your configuration.
  </p><p>
   When you run the configuration processor, you will be prompted for two
   passwords. Enter the first password to make the configuration processor
   encrypt its sensitive data, which consists of the random inter-service
   passwords that it generates and the ansible <code class="literal">group_vars</code>
   and <code class="literal">host_vars</code> that it produces for subsequent deploy
   runs. You will need this password for subsequent Ansible deploy and
   configuration processor runs. If you wish to change an encryption password
   that you have already used when running the configuration processor then
   enter the new password at the second prompt, otherwise just press
   <span class="keycap">Enter</span> to bypass this.
  </p><p>
   Run the configuration processor with this command:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost config-processor-run.yml</pre></div><p>
   For automated installation (for example CI), you can specify the required
   passwords on the ansible command line. For example, the command below will
   disable encryption by the configuration processor:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost config-processor-run.yml \
  -e encrypt="" -e rekey=""</pre></div><p>
   If you receive an error during this step, there is probably an issue with
   one or more of your configuration files. Verify that all information in each
   of your configuration files is correct for your environment. Then commit
   those changes to Git using the instructions in the previous section before
   re-running the configuration processor again.
  </p><p>
   For any troubleshooting information regarding these steps, see
   <a class="xref" href="troubleshooting-installation.html#sec-trouble-config-processor" title="36.2. Issues while Updating Configuration Files">Section 36.2, “Issues while Updating Configuration Files”</a>.
  </p></div><div class="sect2" id="sec-ironic-deploy"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deploying the Cloud</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-deploy">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span>sec-ironic-deploy</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Use the playbook below to create a deployment directory:
    </p><div class="verbatim-wrap"><pre class="screen">cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</pre></div></li><li class="step "><p>
     [OPTIONAL] - Run the <code class="literal">wipe_disks.yml</code> playbook to ensure
     all of your non-OS partitions on your nodes are completely wiped before
     continuing with the installation. The <code class="filename">wipe_disks.yml</code>
     playbook is only meant to be run on systems immediately after running
     <code class="filename">bm-reimage.yml</code>. If used for any other case, it may
     not wipe all of the expected partitions.
    </p><p>
     If you are using fresh machines this step may not be necessary.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts wipe_disks.yml</pre></div><p>
     If you have used an encryption password when running the configuration
     processor use the command below and enter the encryption password when
     prompted:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts wipe_disks.yml --ask-vault-pass</pre></div></li><li class="step "><p>
     Run the <code class="literal">site.yml</code> playbook below:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts site.yml</pre></div><p>
     If you have used an encryption password when running the configuration
     processor use the command below and enter the encryption password when
     prompted:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts site.yml --ask-vault-pass</pre></div><div id="id-1.3.6.12.3.6.2.3.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
      The step above runs <code class="literal">osconfig</code> to configure the cloud
      and <code class="literal">ardana-deploy</code> to deploy the cloud. Therefore, this
      step may run for a while, perhaps 45 minutes or more, depending on the
      number of nodes in your environment.
     </p></div></li><li class="step "><p>
     Verify that the network is working correctly. Ping each IP in the
     <code class="literal">/etc/hosts</code> file from one of the controller nodes.
    </p></li></ol></div></div><p>
   For any troubleshooting information regarding these steps, see
   <a class="xref" href="troubleshooting-installation.html#sec-trouble-deploy-cloud" title="36.3. Issues while Deploying the Cloud">Section 36.3, “Issues while Deploying the Cloud”</a>.
  </p></div><div class="sect2" id="id-1.3.6.12.3.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ironic configuration</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-install_entryscale_ironic.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-install_entryscale_ironic.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Run the <code class="literal">ironic-cloud-configure.yml</code> playbook below:
  </p><div class="verbatim-wrap"><pre class="screen">cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ironic-cloud-configure.yml</pre></div><p>
   This step configures ironic flat network, uploads glance images and sets the
   ironic configuration.
  </p><p>
   To see the images uploaded to glance, run:
  </p><div class="verbatim-wrap"><pre class="screen">$ source ~/service.osrc
$ openstack image list</pre></div><p>
   This will produce output like the following example, showing three images
   that have been added by ironic:
  </p><div class="verbatim-wrap"><pre class="screen">+--------------------------------------+--------------------------+
| ID                                   | Name                     |
+--------------------------------------+--------------------------+
| d4e2a0ff-9575-4bed-ac5e-5130a1553d93 | ir-deploy-iso-HOS3.0     |
| b759a1f0-3b33-4173-a6cb-be5706032124 | ir-deploy-kernel-HOS3.0  |
| ce5f4037-e368-46f2-941f-c01e9072676c | ir-deploy-ramdisk-HOS3.0 |
+--------------------------------------+--------------------------+</pre></div><p>
   To see the network created by ironic, run:
  </p><div class="verbatim-wrap"><pre class="screen">$ openstack network list</pre></div><p>
   This returns details of the "flat-net" generated by the ironic install:
  </p><div class="verbatim-wrap"><pre class="screen"> +---------------+----------+-------------------------------------------------------+
 | id            | name     | subnets                                               |
 +---------------+----------+-------------------------------------------------------+
 | f9474...11010 | flat-net | ca8f8df8-12c8-4e58-b1eb-76844c4de7e8 192.168.245.0/24 |
 +---------------+----------+-------------------------------------------------------+</pre></div></div><div class="sect2" id="ironic-node-config"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Node Configuration</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-node-config">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_config.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_config.xml</li><li><span class="ds-label">ID: </span>ironic-node-config</li></ul></div></div></div></div><div class="sect3" id="id-1.3.6.12.3.8.2"><div class="titlepage"><div><div><h4 class="title"><span class="number">29.1.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DHCP</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.8.2">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_config.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_config.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Once booted, nodes obtain network configuration via DHCP. If multiple
   interfaces are to be utilized, you may want to pre-build images with
   settings to execute DHCP on all interfaces. An easy way to build custom
   images is with KIWI, the command line utility to build Linux system
   appliances.
  </p><p>
   For information about building custom KIWI images, see
   <a class="xref" href="install-ironic-overview.html#sec-ironic-provision-kiwi" title="29.3.13. Building glance Images Using KIWI">Section 29.3.13, “Building glance Images Using KIWI”</a>.
   For more information, see the KIWI documentation at
   <a class="link" href="https://osinside.github.io/kiwi/" target="_blank">https://osinside.github.io/kiwi/</a>.
  </p></div><div class="sect3" id="id-1.3.6.12.3.8.3"><div class="titlepage"><div><div><h4 class="title"><span class="number">29.1.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configuration Drives</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.3.8.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_config.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_config.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div id="id-1.3.6.12.3.8.3.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
    Configuration Drives are stored unencrypted and should not include any
    sensitive data.
   </p></div><p>
   You can use Configuration Drives to store metadata for initial boot
   setting customization. Configuration Drives are extremely useful for
   initial machine configuration. However, as a general security practice,
   they should not include any
   sensitive data. Configuration Drives should only be trusted upon the initial
   boot of an instance. <code class="literal">cloud-init</code> utilizes a lock file for
   this purpose. Custom instance images should not rely upon the integrity of a
   Configuration Drive beyond the initial boot of a host as an administrative
   user within a deployed instance can potentially modify a configuration drive
   once written to disk and released for use.
  </p><p>
   For more information about Configuration Drives, see
   <a class="link" href="http://docs.openstack.org/user-guide/cli_config_drive.html" target="_blank">http://docs.openstack.org/user-guide/cli_config_drive.html</a>.
  </p></div></div><div class="sect2" id="ironic-tls"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.1.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">TLS Certificates with Ironic Python Agent (IPA) Images</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-tls">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_tls.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_tls.xml</li><li><span class="ds-label">ID: </span>ironic-tls</li></ul></div></div></div></div><p>
  As part of <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> 9, ironic Python Agent, better known as IPA in the
  OpenStack community, images are supplied and loaded into glance. Two types of
  image exist. One is a traditional boot ramdisk which is used by the
  <code class="literal">agent_ipmitool</code>, <code class="literal">pxe_ipmitool</code>, and
  <code class="literal">pxe_ilo</code> drivers. The other is an ISO image that is
  supplied as virtual media to the host when using the
  <code class="literal">agent_ilo</code> driver.
 </p><p>
  As these images are built in advance, they are unaware of any private
  certificate authorities. Users attempting to utilize self-signed certificates
  or a private certificate authority will need to inject their signing
  certificate(s) into the image in order for IPA to be able to boot on a remote
  node, and ensure that the TLS endpoints being connected to in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> can be
  trusted. This is not an issue with publicly signed certificates.
 </p><p>
  As two different types of images exist, below are instructions for
  disassembling the image ramdisk file or the ISO image. Once this has been
  done, you will need to re-upload the files to glance, and update any impacted
  node's <code class="literal">driver_info</code>, for example, the
  <code class="literal">deploy_ramdisk</code> and <code class="literal">ilo_deploy_iso</code>
  settings that were set when the node was first defined. Respectively, this
  can be done with the
 </p><div class="verbatim-wrap"><pre class="screen">ironic node-update &lt;node&gt; replace driver_info/deploy_ramdisk=&lt;glance_id&gt;</pre></div><p>
  or
 </p><div class="verbatim-wrap"><pre class="screen">ironic node-update &lt;node&gt; replace driver_info/ilo_deploy_iso=&lt;glance_id&gt;</pre></div><div class="sect3" id="cert-ramdisk"><div class="titlepage"><div><div><h4 class="title"><span class="number">29.1.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add New Trusted CA Certificate Into Deploy Images</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#cert-ramdisk">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-cert_ramdisk.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-cert_ramdisk.xml</li><li><span class="ds-label">ID: </span>cert-ramdisk</li></ul></div></div></div></div><p>
  Perform the following steps.
 </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    To upload your trusted CA certificate to the Cloud Lifecycle Manager, follow the directions
    in <a class="xref" href="tls30.html#sec-upload-toclm" title="41.7. Upload to the Cloud Lifecycle Manager">Section 41.7, “Upload to the Cloud Lifecycle Manager”</a>.
   </p></li><li class="step "><p>
    Delete the deploy images.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>openstack image delete ir-deploy-iso-ARDANA5.0
<code class="prompt user">ardana &gt; </code>openstack image delete ir-deploy-ramdisk-ARDANA5.0</pre></div></li><li class="step "><p>
    On the deployer, run <code class="filename">ironic-reconfigure.yml</code> playbook
    to re-upload the images that include the new trusted CA bundle.
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd /var/lib/ardana/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></li><li class="step "><p>
    Update the existing ironic nodes with the new image IDs accordingly. For
    example,
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>openstack baremetal node set --driver-info \
deploy_ramdisk=<em class="replaceable ">NEW_RAMDISK_ID</em> <em class="replaceable ">NODE_ID</em></pre></div></li></ol></div></div></div></div></div><div class="sect1" id="ironic-multi-control-plane"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">ironic in Multiple Control Plane</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-multi-control-plane">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_multi_control_plane.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_multi_control_plane.xml</li><li><span class="ds-label">ID: </span>ironic-multi-control-plane</li></ul></div></div></div></div><p>
  <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> 9 introduces the concept of multiple control planes - see the
  Input Model documentation for the relevant <a class="xref" href="cha-input-model-intro-concept.html#concept-controlplanes-regions" title="5.2.2.1. Control Planes and Regions">Section 5.2.2.1, “Control Planes and Regions”</a> and <a class="xref" href="configurationobjects.html#configobj-multiple-control-planes" title="6.2.3. Multiple Control Planes">Section 6.2.3, “Multiple Control Planes”</a>. This document covers the use
  of an ironic region in a multiple control plane cloud model in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span>.
 </p><div class="sect2" id="id-1.3.6.12.4.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Networking for Baremetal in Multiple Control Plane</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.4.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_multi_control_plane.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_multi_control_plane.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>IRONIC-FLAT-NET</strong></span> is the network
   configuration for baremetal control plane.
  </p><p>
   You need to set the environment variable <span class="bold"><strong>OS_REGION_NAME</strong></span> to the ironic region in baremetal
   control plane. This will set up the ironic flat networking in
   neutron.
  </p><div class="verbatim-wrap"><pre class="screen">export OS_REGION_NAME=&lt;ironic_region&gt;</pre></div><p>
   To see details of the <code class="literal">IRONIC-FLAT-NETWORK</code> created during
   configuration, use the following command:
  </p><div class="verbatim-wrap"><pre class="screen">openstack network list</pre></div><p>
   Referring to the diagram below, the Cloud Lifecycle Manager is a shared service that runs in a
   Core API Controller in a Core API Cluster. ironic Python Agent (IPA) must
   be able to make REST API calls to the ironic API (the connection is
   represented by the green line to Internal routing). The IPA connect to
   swift to get user images (the gray line connecting to swift routing).
  </p><div class="figure" id="id-1.3.6.12.4.3.8"><div class="figure-contents"><div class="mediaobject"><a xmlns="" href="images/media-ironic-ironic_multi_control_plane.png" target="_blank"><img src="images/media-ironic-ironic_multi_control_plane.png" width="" alt="Architecture of Multiple Control Plane with ironic" /></a></div></div><div class="figure-title-wrap"><h6 class="figure-title"><span class="number">Figure 29.1: </span><span class="name">Architecture of Multiple Control Plane with ironic </span><a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.4.3.8">#</a></h6></div></div></div><div class="sect2" id="id-1.3.6.12.4.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Handling Optional swift Service</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.4.4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_multi_control_plane.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_multi_control_plane.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   swift is resource-intensive and as a result, it is now optional in the
   <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> control plane. A number of services depend on swift, and if it is
   not present, they must provide a fallback strategy. For example, glance can
   use the filesystem in place of swift for its backend store.
  </p><p>
   In ironic, agent-based drivers require swift. If it is not present, it is
   necessary to disable access to this ironic feature in the control plane. The
   <code class="literal">enable_agent_driver</code> flag has been added to the ironic
   configuration data and can have values of <code class="literal">true</code> or
   <code class="literal">false</code>. Setting this flag to <code class="literal">false</code> will
   disable swift configurations and the agent based drivers in the ironic
   control plane.
  </p></div><div class="sect2" id="id-1.3.6.12.4.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Instance Provisioning</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.4.5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_multi_control_plane.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_multi_control_plane.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   In a multiple control plane cloud setup, changes for glance container name
   in the swift namespace of <code class="literal">ironic-conductor.conf</code>
   introduces a conflict with the one in <code class="literal">glance-api.conf</code>.
   Provisioning with agent-based drivers requires the container name to be the
   same in ironic and glance. Hence, on instance provisioning with agent-based
   drivers (swift-enabled), the agent is not able to fetch the images from
   glance store and fails at that point.
  </p><p>
   You can resolve this issue using the following steps:
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Copy the value of <code class="literal">swift_store_container</code> from the file
     <code class="filename">/opt/stack/service/glance-api/etc/glance-api.conf</code>
    </p></li><li class="step "><p>
     Log in to the Cloud Lifecycle Manager and use the value for
     <code class="literal">swift_container</code> in glance namespace of
     <code class="filename">~/scratch/ansible/next/ardana/ansible/roles/ironic-common/templates/ironic-conductor.conf.j2</code>
    </p></li><li class="step "><p>
     Run the following playbook:
    </p><div class="verbatim-wrap"><pre class="screen">cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></li></ol></div></div></div></div><div class="sect1" id="ironic-provisioning"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provisioning Bare-Metal Nodes with Flat Network Model</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-provisioning">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>ironic-provisioning</li></ul></div></div></div></div><div id="id-1.3.6.12.5.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>
   Providing bare-metal resources to an untrusted third party is not advised
   as a malicious user can potentially modify hardware firmware.
  </p></div><div id="id-1.3.6.12.5.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
   The steps outlined in <a class="xref" href="install-ironic-overview.html#ironic-tls" title="29.1.7. TLS Certificates with Ironic Python Agent (IPA) Images">Section 29.1.7, “TLS Certificates with Ironic Python Agent (IPA) Images”</a>
   <span class="emphasis"><em>must</em></span> be performed.
  </p></div><p>
  A number of drivers are available to provision and manage bare-metal
  machines. The drivers are named based on the deployment mode and the power
  management interface. <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> has been tested with the following drivers:
 </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
    agent_ilo
   </p></li><li class="listitem "><p>
    agent_ipmi
   </p></li><li class="listitem "><p>
    pxe_ilo
   </p></li><li class="listitem "><p>
    pxe_ipmi
   </p></li><li class="listitem "><p>
    Redfish
   </p></li></ul></div><p>
  Before you start, you should be aware that:
 </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
    Node Cleaning is enabled for all the drivers in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> 9.
   </p></li><li class="listitem "><p>
    Node parameter settings must have matching flavors in terms of
    <code class="literal">cpus</code>, <code class="literal">local_gb</code>, and
    <code class="literal">memory_mb</code>, <code class="literal">boot_mode</code> and
    <code class="literal">cpu_arch</code>.
   </p></li><li class="listitem "><p>
    It is advisable that nodes enrolled for ipmitool drivers are pre-validated
    in terms of BIOS settings, in terms of boot mode, prior to setting
    capabilities.
   </p></li><li class="listitem "><p>
    Network cabling and interface layout should also be pre-validated in any
    given particular boot mode or configuration that is registered.
   </p></li><li class="listitem "><p>
    The use of <code class="literal">agent_</code> drivers is predicated upon glance
    images being backed by a swift image store, specifically the need for the
    temporary file access features. Using the file system as a glance back-end
    image store means that the <code class="literal">agent_</code> drivers cannot be
    used.
   </p></li><li class="listitem "><p>
    Manual Cleaning (RAID) and Node inspection is supported by ilo drivers
    (<code class="literal">agent_ilo</code> and <code class="literal">pxe_ilo)</code>
   </p></li></ol></div><div class="sect2" id="id-1.3.6.12.5.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Redfish Protocol Support</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.5.8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Redfish is a successor to the Intelligent Platform Management Interface
   (IPMI) with the ability to scale to larger and more diverse cloud
   deployments. It has an API that allows users to collect performance data
   from heterogeneous server installations and more data sources than could be
   handled previously. It is based on an industry standard protocol with a
   RESTful interface for managing cloud assets that are compliant with the
   <a class="link" href="https://redfish.dmtf.org/" target="_blank">Redfish protocol</a>.
  </p><div id="id-1.3.6.12.5.8.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
    There are two known limitations to using Redfish.
   </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      RAID configuration does not work due to missing HPE Smart Storage
      Administrator CLI (HPE SSACLI) in the default deploy RAM disk. This is a
      licensing issue.
     </p></li><li class="listitem "><p>
      The ironic <code class="literal">inspector</code> inspect interface is not supported.
     </p></li></ul></div></div><p>
   Enable the Redfish driver with the following steps:
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Install the Sushy library on the ironic-conductor nodes. Sushy is a Python
     library for communicating with Redfish-based systems with ironic. More
     information is available at <a class="link" href="https://opendev.org/openstack/sushy/" target="_blank">https://opendev.org/openstack/sushy/</a>.
    </p><div class="verbatim-wrap"><pre class="screen">sudo pip install sushy</pre></div></li><li class="step "><p>
     Add <code class="literal">redfish</code> to the list of
     <code class="literal">enabled_hardware_types</code>,
     <code class="literal">enabled_power_interfaces</code> and
     <code class="literal">enabled_management_interfaces</code> in
     <code class="filename">/etc/ironic/ironic.conf</code> as shown below:
    </p><div class="verbatim-wrap"><pre class="screen">[DEFAULT]
...
enabled_hardware_types = ipmi,redfish
enabled_power_interfaces = ipmitool,redfish
enabled_management_interfaces = ipmitool,redfish</pre></div></li><li class="step "><p>
     Restart the ironic-conductor service:
    </p><div class="verbatim-wrap"><pre class="screen">sudo systemctl restart openstack-ironic-conductor</pre></div></li></ol></div></div><p>
   To continue with Redfish, see <a class="xref" href="install-ironic-overview.html#register-redfish-node" title="29.3.4. Registering a Node with the Redfish Driver">Section 29.3.4, “Registering a Node with the Redfish Driver”</a>.
  </p></div><div class="sect2" id="sec-ironic-provision-image"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Supplied Images</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-image">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-image</li></ul></div></div></div></div><p>
   As part of the <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Entry-scale ironic Cloud installation,
   ironic Python Agent (IPA) images are supplied and loaded into glance.
   To see the images that have been loaded, execute the following commands on
   the deployer node:
  </p><div class="verbatim-wrap"><pre class="screen">$ source ~/service.osrc
openstack image list</pre></div><p>
   This will display three images that have been added by ironic:
  </p><div class="verbatim-wrap"><pre class="screen">Deploy_iso : openstack-ironic-image.x86_64-8.0.0.kernel.4.4.120-94.17-default
Deploy_kernel : openstack-ironic-image.x86_64-8.0.0.xz
Deploy_ramdisk : openstack-ironic-image.x86_64-8.0.0.iso</pre></div><p>
   The <code class="literal">ir-deploy-ramdisk</code> image is a traditional boot ramdisk
   used by the <code class="literal">agent_ipmitool</code>,
   <code class="literal">pxe_ipmitool</code>, and <code class="literal">pxe_ilo</code> drivers
   while <code class="literal">ir-deploy-iso</code> is an ISO image that is supplied as
   virtual media to the host when using the <code class="literal">agent_ilo</code>
   driver.
  </p></div><div class="sect2" id="sec-ironic-provision-provision"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provisioning a Node</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-provision">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-provision</li></ul></div></div></div></div><p>
   The information required to provision a node varies slightly depending on
   the driver used. In general the following details are required.
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     Network access information and credentials to connect to the management
     interface of the node.
    </p></li><li class="listitem "><p>
     Sufficient properties to allow for nova flavor matching.
    </p></li><li class="listitem "><p>
     A deployment image to perform the actual deployment of the guest operating
     system to the bare-metal node.
    </p></li></ul></div><p>
   A combination of the <code class="literal">ironic node-create</code> and
   <code class="literal">ironic node-update</code> commands are used for registering a
   node's characteristics with the ironic service. In particular,
   <code class="literal">ironic node-update &lt;nodeid&gt;
   <em class="replaceable ">add</em></code> and <code class="literal">ironic node-update
   &lt;nodeid&gt; <em class="replaceable ">replace</em></code> can be used to
   modify the properties of a node after it has been created while
   <code class="literal">ironic node-update &lt;nodeid&gt;
   <em class="replaceable ">remove</em></code> will remove a property.
  </p></div><div class="sect2" id="register-redfish-node"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Registering a Node with the Redfish Driver</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#register-redfish-node">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>register-redfish-node</li></ul></div></div></div></div><p>
   Nodes configured to use the Redfish driver should have the driver property
   set to <code class="literal">redfish</code>.
  </p><p>
   The following properties are specified in the <code class="literal">driver_info</code>
   field of the node:
  </p><div class="variablelist "><dl class="variablelist"><dt id="id-1.3.6.12.5.11.4.1"><span class="term "><code class="literal">redfish_address</code> (required)</span></dt><dd><p>
      The URL address to the Redfish controller. It must include the authority
      portion of the URL, and can optionally include the scheme. If the scheme
      is missing, HTTPS is assumed.
     </p></dd><dt id="id-1.3.6.12.5.11.4.2"><span class="term "><code class="literal">redfish_system_id</code> (required)</span></dt><dd><p>
      The canonical path to the system resource that the driver interacts
      with. It should include the root service, version and the unique path to
      the system resource. For example,<code class="literal">
      /redfish/v1/Systems/1</code>.
     </p></dd><dt id="id-1.3.6.12.5.11.4.3"><span class="term "><code class="literal">redfish_user</code> name (recommended)</span></dt><dd><p>
      User account with admin and server-profile access privilege.
     </p></dd><dt id="id-1.3.6.12.5.11.4.4"><span class="term "><code class="literal">redfish_password</code> (recommended)</span></dt><dd><p>
      User account password.
     </p></dd><dt id="id-1.3.6.12.5.11.4.5"><span class="term "><code class="literal">redfish_verify_ca</code> (optional)</span></dt><dd><p>
      If <code class="literal">redfish_address</code> has the HTTPS scheme, the driver
      will use a secure (TLS) connection when talking to the Redfish
      controller. By default (if this is not set or set to
      <code class="literal">True</code>), the driver will try to verify the host
      certificates. This can be set to the path of a certificate file or
      directory with trusted certificates that the driver will use for
      verification. To disable verifying TLS, set this to
      <code class="literal">False</code>.
     </p></dd></dl></div><p>
   The <code class="command">openstack baremetal node create</code> command is used
   to enroll a node with the Redfish driver. For example:
  </p><div class="verbatim-wrap"><pre class="screen">openstack baremetal node create --driver redfish --driver-info \
redfish_address=https://example.com --driver-info \
redfish_system_id=/redfish/v1/Systems/CX34R87 --driver-info \
redfish_username=admin --driver-info redfish_password=password</pre></div></div><div class="sect2" id="sec-ironic-provision-create-ilo"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Node Using <code class="command">agent_ilo</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-create-ilo">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-create-ilo</li></ul></div></div></div></div><p>
   If you want to use a boot mode of BIOS as opposed to UEFI, then you need to
   ensure that the boot mode has been set correctly on the IPMI:
  </p><p>
   While the iLO driver can automatically set a node to boot in UEFI mode via
   the <code class="literal">boot_mode</code> defined capability, it cannot set BIOS boot
   mode once UEFI mode has been set.
  </p><p>
   Use the <code class="literal">ironic node-create</code> command to specify the
   <code class="literal">agent_ilo</code> driver, network access and credential
   information for the IPMI, properties of the node and the glance ID of the
   supplied ISO IPA image. Note that memory size is specified in megabytes while
   disk size is specified in gigabytes.
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-create -d agent_ilo -i ilo_address=<em class="replaceable ">IP_ADDRESS</em> -i \
  ilo_username=Administrator -i ilo_password=<em class="replaceable ">PASSWORD</em> \
  -p cpus=2 -p cpu_arch=x86_64 -p memory_mb=64000 -p local_gb=99 \
  -i ilo_deploy_iso=<em class="replaceable ">DEPLOY_UUID</em></pre></div><p>
   This will generate output similar to the following:
  </p><div class="verbatim-wrap"><pre class="screen">+--------------+---------------------------------------------------------------+
| Property     | Value                                                         |
+--------------+---------------------------------------------------------------+
| uuid         | <em class="replaceable ">NODE_UUID</em>                                                     |
| driver_info  | {u'ilo_address': u'<em class="replaceable ">IP_ADDRESS</em>', u'ilo_password': u'******',   |
|              | u'ilo_deploy_iso': u'<em class="replaceable ">DEPLOY_UUID</em>',                            |
|              | u'ilo_username': u'Administrator'}                            |
| extra        | {}                                                            |
| driver       | agent_ilo                                                     |
| chassis_uuid |                                                               |
| properties   | {u'memory_mb': 64000, u'local_gb': 99, u'cpus': 2,            |
|              | u'cpu_arch': u'x86_64'}                                       |
| name         | None                                                          |
+--------------+---------------------------------------------------------------+</pre></div><p>
   Now update the node with <code class="literal">boot_mode</code> and
   <code class="literal">boot_option</code> properties:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-update <em class="replaceable ">NODE_UUID</em> add \
  properties/capabilities="boot_mode:bios,boot_option:local"</pre></div><p>
   The <code class="literal">ironic node-update</code> command returns details for all of
   the node's characteristics.
  </p><div class="verbatim-wrap"><pre class="screen">+------------------------+------------------------------------------------------------------+
| Property               | Value                                                            |
+------------------------+------------------------------------------------------------------+
| target_power_state     | None                                                             |
| extra                  | {}                                                               |
| last_error             | None                                                             |
| updated_at             | None                                                             |
| maintenance_reason     | None                                                             |
| provision_state        | available                                                        |
| clean_step             | {}                                                               |
| uuid                   | <em class="replaceable ">NODE_UUID</em>                                                        |
| console_enabled        | False                                                            |
| target_provision_state | None                                                             |
| provision_updated_at   | None                                                             |
| maintenance            | False                                                            |
| inspection_started_at  | None                                                             |
| inspection_finished_at | None                                                             |
| power_state            | None                                                             |
| driver                 | agent_ilo                                                        |
| reservation            | None                                                             |
| properties             | {u'memory_mb': 64000, u'cpu_arch': u'x86_64', u'local_gb': 99,   |
|                        | u'cpus': 2, u'capabilities': u'boot_mode:bios,boot_option:local'}|
| instance_uuid          | None                                                             |
| name                   | None                                                             |
| driver_info            | {u'ilo_address': u'10.1.196.117', u'ilo_password': u'******',    |
|                        | u'ilo_deploy_iso': u'<em class="replaceable ">DEPLOY_UUID</em>',                               |
|                        | u'ilo_username': u'Administrator'}                               |
| created_at             | 2016-03-11T10:17:10+00:00                                        |
| driver_internal_info   | {}                                                               |
| chassis_uuid           |                                                                  |
| instance_info          | {}                                                               |
+------------------------+------------------------------------------------------------------+</pre></div></div><div class="sect2" id="sec-ironic-provision-create-ipmi"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Node Using <code class="command">agent_ipmi</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-create-ipmi">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-create-ipmi</li></ul></div></div></div></div><p>
   Use the <code class="literal">ironic node-create</code> command to specify the
   <code class="literal">agent_ipmi</code> driver, network access and credential
   information for the IPMI, properties of the node and the glance IDs of the
   supplied kernel and ramdisk images. Note that memory size is specified in
   megabytes while disk size is specified in gigabytes.
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-create -d <span class="bold"><strong>agent_ipmitool</strong></span> \
  -i ipmi_address=<em class="replaceable ">IP_ADDRESS</em> \
  -i ipmi_username=Administrator -i ipmi_password=<em class="replaceable ">PASSWORD</em> \
  -p cpus=2 -p memory_mb=64000 -p local_gb=99 -p cpu_arch=x86_64 \
  -i deploy_kernel=<em class="replaceable ">KERNEL_UUID</em> \
  -i deploy_ramdisk=<em class="replaceable ">RAMDISK_UUID</em></pre></div><p>
   This will generate output similar to the following:
  </p><div class="verbatim-wrap"><pre class="screen">+--------------+-----------------------------------------------------------------------+
| Property     | Value                                                                 |
+--------------+-----------------------------------------------------------------------+
| uuid         | <em class="replaceable ">NODE2_UUID</em>                                                            |
| driver_info  | {u'deploy_kernel': u'<em class="replaceable ">KERNEL_UUID</em>',                                    |
|              | u'ipmi_address': u'<em class="replaceable ">IP_ADDRESS</em>', u'ipmi_username': u'Administrator',   |
|              | u'ipmi_password': u'******',                                          |
|              | u'deploy_ramdisk': u'<em class="replaceable ">RAMDISK_UUID</em>'}                                   |
| extra        | {}                                                                    |
| driver       | agent_ipmitool                                                        |
| chassis_uuid |                                                                       |
| properties   | {u'memory_mb': 64000, u'cpu_arch': u'x86_64', u'local_gb': 99,        |
|              | u'cpus': 2}                                                           |
| name         | None                                                                  |
+--------------+-----------------------------------------------------------------------+</pre></div><p>
   Now update the node with <code class="literal">boot_mode</code> and
   <code class="literal">boot_option</code> properties:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-update <em class="replaceable ">NODE_UUID</em> add \
  properties/capabilities="boot_mode:bios,boot_option:local"</pre></div><p>
   The <code class="literal">ironic node-update</code> command returns details for all of
   the node's characteristics.
  </p><div class="verbatim-wrap"><pre class="screen">+------------------------+-----------------------------------------------------------------+
| Property               | Value                                                           |
+------------------------+-----------------------------------------------------------------+
| target_power_state     | None                                                            |
| extra                  | {}                                                              |
| last_error             | None                                                            |
| updated_at             | None                                                            |
| maintenance_reason     | None                                                            |
| provision_state        | available                                                       |
| clean_step             | {}                                                              |
| uuid                   | <em class="replaceable ">NODE2_UUID</em>                                                      |
| console_enabled        | False                                                           |
| target_provision_state | None                                                            |
| provision_updated_at   | None                                                            |
| maintenance            | False                                                           |
| inspection_started_at  | None                                                            |
| inspection_finished_at | None                                                            |
| power_state            | None                                                            |
| driver                 | agent_ipmitool                                                  |
| reservation            | None                                                            |
| properties             | {u'memory_mb': 64000, u'cpu_arch': u'x86_64',                   |
|                        | u'local_gb': 99, u'cpus': 2,                                    |
|                        | u'capabilities': u'boot_mode:bios,boot_option:local'}           |
| instance_uuid          | None                                                            |
| name                   | None                                                            |
| driver_info            | {u'ipmi_password': u'******', u'ipmi_address': u'<em class="replaceable ">IP_ADDRESS</em>',   |
|                        | u'ipmi_username': u'Administrator', u'deploy_kernel':           |
|                        | u'<em class="replaceable ">KERNEL_UUID</em>',                                                 |
|                        | u'deploy_ramdisk': u'<em class="replaceable ">RAMDISK_UUID</em>'}                             |
| created_at             | 2016-03-11T14:19:18+00:00                                       |
| driver_internal_info   | {}                                                              |
| chassis_uuid           |                                                                 |
| instance_info          | {}                                                              |
+------------------------+-----------------------------------------------------------------+</pre></div><p>
   For more information on node enrollment, see the <span class="productname">OpenStack</span> documentation at
   <a class="link" href="http://docs.openstack.org/developer/ironic/deploy/install-guide.html#enrollment" target="_blank">http://docs.openstack.org/developer/ironic/deploy/install-guide.html#enrollment</a>.
  </p></div><div class="sect2" id="sec-ironic-provision-flavor"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Flavor</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-flavor">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-flavor</li></ul></div></div></div></div><p>
   nova uses flavors when fulfilling requests for bare-metal nodes. The nova
   scheduler attempts to match the requested flavor against the properties of
   the created ironic nodes. So an administrator needs to set up flavors that
   correspond to the available bare-metal nodes using the command
   <code class="command">openstack flavor create</code>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack flavor create bmtest auto 64000  99 2

+----------------+--------+--------+------+-----------+------+-------+-------------+-----------+
| ID             | Name   | Mem_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----------------+--------+--------+------+-----------+------+-------+-------------+-----------+
| 645de0...b1348 | bmtest | 64000  | 99   | 0         |      | 2     | 1.0         | True      |
+----------------+--------+--------+------+-----------+------+-------+-------------+-----------+</pre></div><p>
   To see a list of all the available flavors, run <code class="command">openstack flavor
   list</code>:
  </p><div class="verbatim-wrap"><pre class="screen">openstack flavor list

+-------------+--------------+--------+------+-----------+------+-------+--------+-----------+
| ID          | Name         | Mem_MB | Disk | Ephemeral | Swap | VCPUs |  RXTX  | Is_Public |
|             |              |        |      |           |      |       | Factor |           |
+-------------+--------------+--------+------+-----------+------+-------+--------+-----------+
| 1           | m1.tiny      | 512    | 1    | 0         |      | 1     | 1.0    | True      |
| 2           | m1.small     | 2048   | 20   | 0         |      | 1     | 1.0    | True      |
| 3           | m1.medium    | 4096   | 40   | 0         |      | 2     | 1.0    | True      |
| 4           | m1.large     | 8192   | 80   | 0         |      | 4     | 1.0    | True      |
| 5           | m1.xlarge    | 16384  | 160  | 0         |      | 8     | 1.0    | True      |
| 6           | m1.baremetal | 4096   | 80   | 0         |      | 2     | 1.0    | True      |
| 645d...1348 | bmtest       | 64000  | 99   | 0         |      | 2     | 1.0    | True      |
+-------------+--------------+--------+------+-----------+------+-------+--------+-----------+</pre></div><p>
   Now set the CPU architecture and boot mode and boot option capabilities:
  </p><div class="verbatim-wrap"><pre class="screen">openstack flavor set 645de08d-2bc6-43f1-8a5f-2315a75b1348 set cpu_arch=x86_64
openstack flavor set 645de08d-2bc6-43f1-8a5f-2315a75b1348 set capabilities:boot_option="local"
openstack flavor set 645de08d-2bc6-43f1-8a5f-2315a75b1348 set capabilities:boot_mode="bios"</pre></div><p>
   For more information on flavor creation, see the <span class="productname">OpenStack</span> documentation at
   <a class="link" href="http://docs.openstack.org/developer/ironic/deploy/install-guide.html#flavor-creation" target="_blank">http://docs.openstack.org/developer/ironic/deploy/install-guide.html#flavor-creation</a>.
  </p></div><div class="sect2" id="sec-ironic-provision-net"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Network Port</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-net">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-net</li></ul></div></div></div></div><p>
   Register the MAC addresses of all connected physical network interfaces
   intended for use with the bare-metal node.
  </p><div class="verbatim-wrap"><pre class="screen">ironic port-create -a 5c:b9:01:88:f0:a4 -n ea7246fd-e1d6-4637-9699-0b7c59c22e67</pre></div></div><div class="sect2" id="sec-ironic-provision-glance-image"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a glance Image</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-glance-image">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-glance-image</li></ul></div></div></div></div><p>
   You can create a complete disk image using the instructions at
   <a class="xref" href="install-ironic-overview.html#sec-ironic-provision-kiwi" title="29.3.13. Building glance Images Using KIWI">Section 29.3.13, “Building glance Images Using KIWI”</a>.
  </p><p>
   The image you create can then be loaded into glance:
  </p><div class="verbatim-wrap"><pre class="screen">openstack image create --name='leap' --disk-format=raw \
  --container-format=bare \
  --file /tmp/myimage/LimeJeOS-Leap-42.3.x86_64-1.42.3.raw

+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 45a4a06997e64f7120795c68beeb0e3c     |
| container_format | bare                                 |
| created_at       | 2018-02-17T10:42:14Z                 |
| disk_format      | raw                                  |
| id               | <span class="bold"><strong>17e4915a-ada0-4b95-bacf-ba67133f39a7</strong></span> |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | leap                                 |
| owner            | 821b7bb8148f439191d108764301af64     |
| protected        | False                                |
| size             | 372047872                            |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2018-02-17T10:42:23Z                 |
| virtual_size     | None                                 |
| visibility       | private                              |
+------------------+--------------------------------------+</pre></div><p>
   This image will subsequently be used to boot the bare-metal node.
  </p></div><div class="sect2" id="sec-ironic-provision-key"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Generating a Key Pair</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-key">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-key</li></ul></div></div></div></div><p>
   Create a key pair that you will use when you login to the newly booted node:
  </p><div class="verbatim-wrap"><pre class="screen">openstack keypair create <span class="bold"><strong>ironic_kp</strong></span> &gt; ironic_kp.pem</pre></div></div><div class="sect2" id="sec-ironic-provision-neutron-id"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Determining the neutron Network ID</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-neutron-id">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-neutron-id</li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">openstack network list

+---------------+----------+----------------------------------------------------+
| id            | name     | subnets                                            |
+---------------+----------+----------------------------------------------------+
| <span class="bold"><strong>c0102...1ca8c </strong></span>| flat-net | 709ee2a1-4110-4b26-ba4d-deb74553adb9 192.3.15.0/24 |
+---------------+----------+----------------------------------------------------+</pre></div></div><div class="sect2" id="sec-ironic-provision-boot"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.12 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Booting the Node</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-boot">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-boot</li></ul></div></div></div></div><p>
   Before booting, it is advisable to power down the node:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-set-power-state ea7246fd-e1d6-4637-9699-0b7c59c22e67 off</pre></div><p>
   You can now boot the bare-metal node with the information compiled in the
   preceding steps, using the neutron network ID, the whole disk image ID, the
   matching flavor and the key name:
  </p><div class="verbatim-wrap"><pre class="screen">openstack server create --nic net-id=c010267c-9424-45be-8c05-99d68531ca8c \
  --image 17e4915a-ada0-4b95-bacf-ba67133f39a7 \
  --flavor 645de08d-2bc6-43f1-8a5f-2315a75b1348 \
  --key-name ironic_kp leap</pre></div><p>
   This command returns information about the state of the node that is booting:
  </p><div class="verbatim-wrap"><pre class="screen">+--------------------------------------+------------------------+
| Property                             | Value                  |
+--------------------------------------+------------------------+
| OS-EXT-AZ:availability_zone          |                        |
| OS-EXT-SRV-ATTR:host                 | -                      |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                      |
| OS-EXT-SRV-ATTR:instance_name        | instance-00000001      |
| OS-EXT-STS:power_state               | 0                      |
| OS-EXT-STS:task_state                | scheduling             |
| OS-EXT-STS:vm_state                  | building               |
| OS-SRV-USG:launched_at               | -                      |
| OS-SRV-USG:terminated_at             | -                      |
| accessIPv4                           |                        |
| accessIPv6                           |                        |
| adminPass                            | adpHw3KKTjHk           |
| config_drive                         |                        |
| created                              | 2018-03-11T11:00:28Z   |
| flavor                               | bmtest (645de...b1348) |
| hostId                               |                        |
| id                                   | a9012...3007e          |
| image                                | leap (17e49...f39a7)   |
| key_name                             | ironic_kp              |
| metadata                             | {}                     |
| name                                 | leap                   |
| os-extended-volumes:volumes_attached | []                     |
| progress                             | 0                      |
| security_groups                      | default                |
| status                               | BUILD                  |
| tenant_id                            | d53bcaf...baa60dd      |
| updated                              | 2016-03-11T11:00:28Z   |
| user_id                              | e580c64...4aaf990      |
+--------------------------------------+------------------------+</pre></div><p>
   The boot process can take up to 10 minutes. Monitor the progress with the
   IPMI console or with <code class="literal">openstack server list</code>,
   <code class="literal">openstack server show
   &lt;nova_node_id&gt;</code>, and <code class="literal">ironic node-show
   &lt;ironic_node_id&gt;</code> commands.
  </p><div class="verbatim-wrap"><pre class="screen">openstack server list

+---------------+--------+--------+------------+-------------+----------------------+
| ID            | Name   | Status | Task State | Power State | Networks             |
+---------------+--------+--------+------------+-------------+----------------------+
| a9012...3007e | leap   | BUILD  | spawning   | NOSTATE     | flat-net=192.3.15.12 |
+---------------+--------+--------+------------+-------------+----------------------+</pre></div><p>
   During the boot procedure, a login prompt will appear for SLES:
  </p><p>
   Ignore this login screen and wait for the login screen of your target
   operating system to appear:
  </p><p>
   If you now run the command <code class="command">openstack server list</code>, it should show the
   node in the running state:
  </p><div class="verbatim-wrap"><pre class="screen">openstack server list
+---------------+--------+--------+------------+-------------+----------------------+
| ID            | Name   | Status | Task State | Power State | Networks             |
+---------------+--------+--------+------------+-------------+----------------------+
| a9012...3007e | leap   | ACTIVE | -          | Running     | flat-net=<span class="bold"><strong>192.3.15.14</strong></span> |
+---------------+--------+--------+------------+-------------+----------------------+</pre></div><p>
   You can now log in to the booted node using the key you generated earlier.
   (You may be prompted to change the permissions of your private key files, so
   that they are not accessible by others).
  </p><div class="verbatim-wrap"><pre class="screen">ssh leap@192.3.15.14 -i ironic_kp.pem</pre></div></div><div class="sect2" id="sec-ironic-provision-kiwi"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.13 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Building glance Images Using KIWI</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-kiwi">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-kiwi</li></ul></div></div></div></div><p>
   The following sections show you how to create your own images using KIWI,
   the command line utility to build Linux system appliances. For information
   on installing KIWI, see <a class="link" href="https://osinside.github.io/kiwi/installation.html" target="_blank">https://osinside.github.io/kiwi/installation.html</a>.
  </p><p>
   KIWI creates images in a two-step process:
  </p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>
     The <code class="literal">prepare</code> operation generates an unpacked image tree
     using the information provided in the image description.
    </p></li><li class="listitem "><p>
     The <code class="literal">create</code> operation creates the packed image based on
     the unpacked image and the information provided in the configuration file
     (<code class="filename">config.xml</code>).
    </p></li></ol></div><p>
   Instructions for installing KIWI are available at
   <a class="link" href="https://osinside.github.io/kiwi/installation.html" target="_blank">https://osinside.github.io/kiwi/installation.html</a>.
  </p><p>
   Image creation with KIWI is automated and does not require any user
   interaction. The information required for the image creation process is
   provided by the image description.
  </p><p>
   To use and run KIWI requires:
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     A recent Linux distribution such as:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       openSUSE Leap 42.3
      </p></li><li class="listitem "><p>
       SUSE Linux Enterprise 12 SP4
      </p></li><li class="listitem "><p>
       openSUSE Tumbleweed
      </p></li></ul></div></li><li class="listitem "><p>
     Enough free disk space to build and store the image (a minimum of 10 GB is
     recommended).
    </p></li><li class="listitem "><p>
     Python version 2.7, 3.4 or higher. KIWI supports both Python 2 and 3
     versions
    </p></li><li class="listitem "><p>
     Git (package <span class="package ">git-core</span>) to clone a repository.
    </p></li><li class="listitem "><p>
     Virtualization technology to start the image (QEMU is recommended).
    </p></li></ul></div></div><div class="sect2" id="sec-ironic-provision-opensuse"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.3.14 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating an openSUSE Image with KIWI</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#sec-ironic-provision-opensuse">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning.xml</li><li><span class="ds-label">ID: </span>sec-ironic-provision-opensuse</li></ul></div></div></div></div><p>
   The following example shows how to build an openSUSE Leap image that is
   ready to run in QEMU.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Retrieve the example image descriptions.
    </p><div class="verbatim-wrap"><pre class="screen">git clone https://github.com/SUSE/kiwi-descriptions</pre></div></li><li class="step "><p>
     Build the image with KIWI:
    </p><div class="verbatim-wrap"><pre class="screen">sudo kiwi-ng --type vmx system build \
  --description kiwi-descriptions/suse/x86_64/suse-leap-42.3-JeOS \
  --target-dir /tmp/myimage</pre></div><p>
     A <code class="filename">.raw</code> image will be built in the
     <code class="filename">/tmp/myimage</code> directory.
    </p></li><li class="step "><p>
     Test the live image with QEMU:
    </p><div class="verbatim-wrap"><pre class="screen">qemu \
  -drive file=LimeJeOS-Leap-42.3.x86_64-1.42.3.raw,format=raw,if=virtio \
  -m 4096</pre></div></li><li class="step "><p>
     With a successful test, the image is complete.
    </p></li></ol></div></div><p>
   By default, KIWI generates a file in the <code class="filename">.raw</code> format.
   The <code class="filename">.raw</code> file is a disk image with a structure
   equivalent to a physical hard disk. <code class="filename">.raw</code> images are
   supported by any hypervisor, but are not compressed and do not offer the
   best performance.
  </p><p>
   Virtualization systems support their own formats (such as
   <code class="literal">qcow2</code> or <code class="literal">vmdk</code>) with compression and
   improved I/O performance. To build an image in a format other than
   <code class="filename">.raw</code>, add the format attribute to the type definition
   in the preferences section of <code class="filename">config.xml</code>. Using
   <code class="literal">qcow2</code> for example:
  </p><div class="verbatim-wrap"><pre class="screen">&lt;image ...&gt;
  &lt;preferences&gt;
    &lt;type format="qcow2" .../&gt;
    ...
  &lt;/preferences&gt;
  ...
&lt;/image</pre></div><p>
   More information about KIWI is at
   <a class="link" href="https://osinside.github.io/kiwi/" target="_blank">https://osinside.github.io/kiwi/</a>.
  </p></div></div><div class="sect1" id="ironic-provisioning-multi-tenancy"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Provisioning Baremetal Nodes with Multi-Tenancy</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-provisioning-multi-tenancy">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_provisioning_multi_tenancy.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_provisioning_multi_tenancy.xml</li><li><span class="ds-label">ID: </span>ironic-provisioning-multi-tenancy</li></ul></div></div></div></div><p>
  To enable ironic multi-tenancy, you must first manually install the
  <code class="literal">python-networking-generic-switch</code> package along with all
  its dependents on all neutron nodes.
 </p><p>
  To manually enable the <code class="literal">genericswitch</code> mechanism driver in
  neutron, the <code class="literal">networking-generic-switch</code> package must be
  installed first. Do the following steps in each of the controllers where
  neutron is running.
 </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    Comment out the <code class="literal">multi_tenancy_switch_config</code> section in
    <code class="filename">~/openstack/my_cloud/definition/data/ironic/ironic_config.yml</code>.
   </p></li><li class="step "><p>
    SSH into the controller node
   </p></li><li class="step "><p>
    Change to root
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>sudo -i</pre></div></li><li class="step "><p>
    Activate the neutron venv
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo . /opt/stack/venv/neutron-20180528T093206Z/bin/activate</pre></div></li><li class="step "><p>
    Install netmiko package
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo pip install netmiko</pre></div></li><li class="step "><p>
    Clone the <code class="literal">networking-generic-switch</code> source code into
    <code class="filename">/tmp</code>
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo cd /tmp
<code class="prompt user">tux &gt; </code>sudo git clone
   https://github.com/openstack/networking-generic-switch.git</pre></div></li><li class="step "><p>
    Install <code class="literal">networking_generic_switch</code> package
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>sudo python setup.py install</pre></div></li></ol></div></div><p>
  After the <code class="literal">networking_generic_switch</code> package is installed,
  the <code class="literal">genericswitch</code> settings must be enabled in the input
  model. The following process must be run again any time a maintenance update
  is installed that updates the neutron venv.
 </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    SSH into the deployer node as the user <code class="literal">ardana</code>.
   </p></li><li class="step "><p>
    Edit the ironic configuration data in the input model
    <code class="filename">~/openstack/my_cloud/definition/data/ironic/ironic_config.yml</code>. Make
    sure the <code class="literal">multi_tenancy_switch_config:</code> section is
    uncommented and has the appropriate settings. <code class="literal">driver_type</code> should be <code class="literal">genericswitch</code> and
    <code class="literal">device_type</code> should be
    <code class="literal">netmiko_hp_comware</code>.
   </p><div class="verbatim-wrap"><pre class="screen">multi_tenancy_switch_config:
  -
    id: switch1
    driver_type: genericswitch
    device_type: netmiko_hp_comware
    ip_address: 192.168.75.201
    username: IRONICSHARE
    password: 'k27MwbEDGzTm'</pre></div></li><li class="step "><p>
    Run the configure process to generate the model
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost config-processor-run.yml
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost ready-deployment.yml</pre></div></li><li class="step "><p>
    Run <code class="filename">neutron-reconfigure.yml</code>
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost neutron-reconfigure.yml</pre></div></li><li class="step "><p>
    Run <code class="filename">neutron-status.yml</code> to make sure everything is OK
   </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts neutron-status.yml</pre></div></li></ol></div></div><p>
  With the <code class="literal">networking-generic-switch</code> package installed and
  enabled, you can proceed with provisioning baremetal nodes with multi-tenancy.
 </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    Create a network and a subnet:
   </p><div class="verbatim-wrap"><pre class="screen">$ openstack network create guest-net-1
Created a new network:
+---------------------------+--------------------------------------+
| Field                     | Value                                |
+---------------------------+--------------------------------------+
| admin_state_up            | True                                 |
| availability_zone_hints   |                                      |
| availability_zones        |                                      |
| created_at                | 2017-06-10T02:49:56Z                 |
| description               |                                      |
| id                        | 256d55a6-9430-4f49-8a4c-cc5192f5321e |
| ipv4_address_scope        |                                      |
| ipv6_address_scope        |                                      |
| mtu                       | 1500                                 |
| name                      | guest-net-1                          |
| project_id                | 57b792cdcdd74d16a08fc7a396ee05b6     |
| provider:network_type     | vlan                                 |
| provider:physical_network | physnet1                             |
| provider:segmentation_id  | 1152                                 |
| revision_number           | 2                                    |
| router:external           | False                                |
| shared                    | False                                |
| status                    | ACTIVE                               |
| subnets                   |                                      |
| tags                      |                                      |
| tenant_id                 | 57b792cdcdd74d16a08fc7a396ee05b6     |
| updated_at                | 2017-06-10T02:49:57Z                 |
+---------------------------+--------------------------------------+

$ openstack subnet create guest-net-1 200.0.0.0/24
Created a new subnet:
+-------------------+----------------------------------------------+
| Field             | Value                                        |
+-------------------+----------------------------------------------+
| allocation_pools  | {"start": "200.0.0.2", "end": "200.0.0.254"} |
| cidr              | 200.0.0.0/24                                 |
| created_at        | 2017-06-10T02:53:08Z                         |
| description       |                                              |
| dns_nameservers   |                                              |
| enable_dhcp       | True                                         |
| gateway_ip        | 200.0.0.1                                    |
| host_routes       |                                              |
| id                | 53accf35-ae02-43ae-95d8-7b5efed18ae9         |
| ip_version        | 4                                            |
| ipv6_address_mode |                                              |
| ipv6_ra_mode      |                                              |
| name              |                                              |
| network_id        | 256d55a6-9430-4f49-8a4c-cc5192f5321e         |
| project_id        | 57b792cdcdd74d16a08fc7a396ee05b6             |
| revision_number   | 2                                            |
| service_types     |                                              |
| subnetpool_id     |                                              |
| tenant_id         | 57b792cdcdd74d16a08fc7a396ee05b6             |
| updated_at        | 2017-06-10T02:53:08Z                         |
+-------------------+----------------------------------------------+</pre></div></li><li class="step "><p>
    Review glance image list
   </p><div class="verbatim-wrap"><pre class="screen">$ openstack image list
+--------------------------------------+--------------------------+
| ID                                   | Name                     |
+--------------------------------------+--------------------------+
| 0526d2d7-c196-4c62-bfe5-a13bce5c7f39 | cirros-0.4.0-x86_64      |
+--------------------------------------+--------------------------+</pre></div></li><li class="step "><p>
    Create ironic node
   </p><div class="verbatim-wrap"><pre class="screen">$ ironic --ironic-api-version 1.22 node-create -d agent_ipmitool \
  -n test-node-1 -i ipmi_address=192.168.9.69 -i ipmi_username=ipmi_user \
  -i ipmi_password=XXXXXXXX --network-interface neutron -p  memory_mb=4096 \
  -p cpu_arch=x86_64 -p local_gb=80 -p cpus=2 \
  -p capabilities=boot_mode:bios,boot_option:local \
  -p root_device='{"name":"/dev/sda"}' \
  -i deploy_kernel=db3d131f-2fb0-4189-bb8d-424ee0886e4c \
  -i deploy_ramdisk=304cae15-3fe5-4f1c-8478-c65da5092a2c

+-------------------+-------------------------------------------------------------------+
| Property          | Value                                                             |
+-------------------+-------------------------------------------------------------------+
| chassis_uuid      |                                                                   |
| driver            | agent_ipmitool                                                    |
| driver_info       | {u'deploy_kernel': u'db3d131f-2fb0-4189-bb8d-424ee0886e4c',       |
|                   | u'ipmi_address': u'192.168.9.69',                                 |
|                   | u'ipmi_username': u'gozer', u'ipmi_password': u'******',          |
|                   | u'deploy_ramdisk': u'304cae15-3fe5-4f1c-8478-c65da5092a2c'}       |
| extra             | {}                                                                |
| name              | test-node-1                                                       |
| network_interface | neutron                                                           |
| properties        | {u'cpu_arch': u'x86_64', u'root_device': {u'name': u'/dev/sda'},  |
|                   | u'cpus': 2, u'capabilities': u'boot_mode:bios,boot_option:local', |
|                   | u'memory_mb': 4096, u'local_gb': 80}                              |
| resource_class    | None                                                              |
| uuid              | cb4dda0d-f3b0-48b9-ac90-ba77b8c66162                              |
+-------------------+-------------------------------------------------------------------+</pre></div><p>
    ipmi_address, ipmi_username and ipmi_password are IPMI access parameters for
    baremetal ironic node. Adjust memory_mb, cpus, local_gb to your node size
    requirements. They also need to be reflected in flavor setting (see below).
    Use capabilities boot_mode:bios for baremetal nodes operating in Legacy
    BIOS mode. For UEFI baremetal nodes, use boot_mode:uefi lookup
    deploy_kernel and deploy_ramdisk in glance image list output above.
   </p><div id="id-1.3.6.12.6.8.3.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
     Since we are using ironic API version 1.22, node is created initial state
     <span class="bold"><strong>enroll</strong></span>. It needs to be explicitly moved
     to <span class="bold"><strong>available</strong></span> state. This behavior changed
     in API version 1.11
    </p></div></li><li class="step "><p>
    Create port
   </p><div class="verbatim-wrap"><pre class="screen">$ ironic --ironic-api-version 1.22 port-create --address f0:92:1c:05:6c:40 \
  --node cb4dda0d-f3b0-48b9-ac90-ba77b8c66162 -l switch_id=e8:f7:24:bf:07:2e -l \
  switch_info=hp59srv1-a-11b -l port_id="Ten-GigabitEthernet 1/0/34" \
  --pxe-enabled true
+-----------------------+--------------------------------------------+
| Property              | Value                                      |
+-----------------------+--------------------------------------------+
| address               | f0:92:1c:05:6c:40                          |
| extra                 | {}                                         |
| local_link_connection | {u'switch_info': u'hp59srv1-a-11b',        |
|                       | u'port_id': u'Ten-GigabitEthernet 1/0/34', |
|                       | u'switch_id': u'e8:f7:24:bf:07:2e'}        |
| node_uuid             | cb4dda0d-f3b0-48b9-ac90-ba77b8c66162       |
| pxe_enabled           | True                                       |
| uuid                  | a49491f3-5595-413b-b4a7-bb6f9abec212       |
+-----------------------+--------------------------------------------+</pre></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      for <code class="option">--address</code>, use MAC of 1st NIC of ironic baremetal
      node, which will be used for PXE boot
     </p></li><li class="listitem "><p>
      for <code class="option">--node</code>, use ironic node uuid (see above)
     </p></li><li class="listitem "><p>
      for <code class="option">-l switch_id</code>, use switch management interface MAC
      address. It can be
      retrieved by pinging switch management IP and looking up MAC address in
      'arp -l -n' command output.
     </p></li><li class="listitem "><p>
      for <code class="option">-l switch_info</code>, use switch_id from
      <code class="filename">data/ironic/ironic_config.yml</code>
      file. If you have several switch config definitions, use the right switch
      your baremetal node is connected to.
     </p></li><li class="listitem "><p>
      for -l port_id, use port ID on the switch
     </p></li></ul></div></li><li class="step "><p>
    Move ironic node to manage and then available state
   </p><div class="verbatim-wrap"><pre class="screen">$ ironic node-set-provision-state test-node-1 manage
$ ironic node-set-provision-state test-node-1 provide</pre></div></li><li class="step "><p>
    Once node is successfully moved to available state, its resources should
    be included into nova hypervisor statistics
   </p><div class="verbatim-wrap"><pre class="screen">$ openstack hypervisor stats show
+----------------------+-------+
| Property             | Value |
+----------------------+-------+
| count                | 1     |
| current_workload     | 0     |
| disk_available_least | 80    |
| free_disk_gb         | 80    |
| free_ram_mb          | 4096  |
| local_gb             | 80    |
| local_gb_used        | 0     |
| memory_mb            | 4096  |
| memory_mb_used       | 0     |
| running_vms          | 0     |
| vcpus                | 2     |
| vcpus_used           | 0     |
+----------------------+-------+</pre></div></li><li class="step "><p>
    Prepare a keypair, which will be used for logging into the node
   </p><div class="verbatim-wrap"><pre class="screen">$ openstack keypair create ironic_kp &gt; ironic_kp.pem</pre></div></li><li class="step "><p>
    Obtain user image and upload it to glance. Please refer to OpenStack
    documentation on user image creation:
    <a class="link" href="https://docs.openstack.org/project-install-guide/baremetal/draft/configure-glance-images.html" target="_blank">https://docs.openstack.org/project-install-guide/baremetal/draft/configure-glance-images.html</a>.
   </p><div id="id-1.3.6.12.6.8.8.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
     Deployed images are already populated by <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> installer.
    </p></div><div class="verbatim-wrap"><pre class="screen">$ openstack image create --name='Ubuntu Trusty 14.04' --disk-format=qcow2 \
  --container-format=bare --file ~/ubuntu-trusty.qcow2
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | d586d8d2107f328665760fee4c81caf0     |
| container_format | bare                                 |
| created_at       | 2017-06-13T22:38:45Z                 |
| disk_format      | qcow2                                |
| id               | 9fdd54a3-ccf5-459c-a084-e50071d0aa39 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | Ubuntu Trusty 14.04                  |
| owner            | 57b792cdcdd74d16a08fc7a396ee05b6     |
| protected        | False                                |
| size             | 371508736                            |
| status           | active                               |
| tags             | []                                   |
| updated_at       | 2017-06-13T22:38:55Z                 |
| virtual_size     | None                                 |
| visibility       | private                              |
+------------------+--------------------------------------+

$ openstack image list
+--------------------------------------+---------------------------+
| ID                                   | Name                      |
+--------------------------------------+---------------------------+
| 0526d2d7-c196-4c62-bfe5-a13bce5c7f39 | cirros-0.4.0-x86_64       |
| 83eecf9c-d675-4bf9-a5d5-9cf1fe9ee9c2 | ir-deploy-iso-<em class="replaceable ">EXAMPLE</em>     |
| db3d131f-2fb0-4189-bb8d-424ee0886e4c | ir-deploy-kernel-<em class="replaceable ">EXAMPLE</em>  |
| 304cae15-3fe5-4f1c-8478-c65da5092a2c | ir-deploy-ramdisk-<em class="replaceable "> EXAMPLE</em> |
| 9fdd54a3-ccf5-459c-a084-e50071d0aa39 | Ubuntu Trusty 14.04       |
+--------------------------------------+---------------------------+</pre></div></li><li class="step "><p>
    Create a baremetal flavor and set flavor keys specifying requested node
    size, architecture and boot mode. A flavor can be re-used for several nodes
    having the same size, architecture and boot mode
   </p><div class="verbatim-wrap"><pre class="screen">$ openstack flavor create m1.ironic auto 4096 80 2
+-------------+-----------+--------+------+---------+------+-------+-------------+-----------+
| ID          | Name      | Mem_MB | Disk | Ephemrl | Swap | VCPUs | RXTX_Factor | Is_Public |
+-------------+-----------+--------+------+---------+------+-------+-------------+-----------+
| ab69...87bf | m1.ironic | 4096   | 80   | 0       |      | 2     | 1.0         | True      |
+-------------+-----------+--------+------+---------+------+-------+-------------+-----------+

$ openstack flavor set ab6988...e28694c87bf set cpu_arch=x86_64
$ openstack flavor set ab6988...e28694c87bf set capabilities:boot_option="local"
$ openstack flavor set ab6988...e28694c87bf set capabilities:boot_mode="bios"</pre></div><p>
    Parameters must match parameters of ironic node above. Use
    <code class="literal">capabilities:boot_mode="bios"</code> for Legacy BIOS nodes. For
    UEFI nodes, use <code class="literal">capabilities:boot_mode="uefi"</code>
   </p></li><li class="step "><p>
    Boot the node
   </p><div class="verbatim-wrap"><pre class="screen">$ openstack server create --flavor m1.ironic --image 9fdd54a3-ccf5-459c-a084-e50071d0aa39 \
  --key-name ironic_kp --nic net-id=256d55a6-9430-4f49-8a4c-cc5192f5321e \
  test-node-1
+--------------------------------------+-------------------------------------------------+
| Property                             | Value                                           |
+--------------------------------------+-------------------------------------------------+
| OS-DCF:diskConfig                    | MANUAL                                          |
| OS-EXT-AZ:availability_zone          |                                                 |
| OS-EXT-SRV-ATTR:host                 | -                                               |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                               |
| OS-EXT-SRV-ATTR:instance_name        |                                                 |
| OS-EXT-STS:power_state               | 0                                               |
| OS-EXT-STS:task_state                | scheduling                                      |
| OS-EXT-STS:vm_state                  | building                                        |
| OS-SRV-USG:launched_at               | -                                               |
| OS-SRV-USG:terminated_at             | -                                               |
| accessIPv4                           |                                                 |
| accessIPv6                           |                                                 |
| adminPass                            | XXXXXXXXXXXX                                    |
| config_drive                         |                                                 |
| created                              | 2017-06-14T21:25:18Z                            |
| flavor                               | m1.ironic (ab69881...5a-497d-93ae-6e28694c87bf) |
| hostId                               |                                                 |
| id                                   | f1a8c63e-da7b-4d9a-8648-b1baa6929682            |
| image                                | Ubuntu Trusty 14.04 (9fdd54a3-ccf5-4a0...0aa39) |
| key_name                             | ironic_kp                                       |
| metadata                             | {}                                              |
| name                                 | test-node-1                                     |
| os-extended-volumes:volumes_attached | []                                              |
| progress                             | 0                                               |
| security_groups                      | default                                         |
| status                               | BUILD                                           |
| tenant_id                            | 57b792cdcdd74d16a08fc7a396ee05b6                |
| updated                              | 2017-06-14T21:25:17Z                            |
| user_id                              | cc76d7469658401fbd4cf772278483d9                |
+--------------------------------------+-------------------------------------------------+</pre></div><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      for <code class="option">--image</code>, use the ID of user image created at
      previous step
     </p></li><li class="listitem "><p>
      for <code class="option">--nic net-id</code>, use ID of
      the tenant network created at the beginning
     </p></li></ul></div><div id="id-1.3.6.12.6.8.10.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>
     During the node provisioning, the following is happening in the
     background:
    </p><p>
     neutron connects to switch management interfaces and assigns provisioning
     VLAN to baremetal node port on the switch. ironic powers up the node using
     IPMI interface. Node is booting IPA image via PXE. IPA image is writing
     provided user image onto specified root device
     (<code class="filename">/dev/sda</code>) and powers node
     down. neutron connects to switch management interfaces and assigns tenant
     VLAN to baremetal node port on the switch. A VLAN ID is selected from
     provided range. ironic powers up the node using IPMI interface. Node is
     booting user image from disk.
    </p></div></li><li class="step "><p>
    Once provisioned, node will join the private tenant network. Access to
    private network from other networks is defined by switch configuration.
   </p></li></ol></div></div></div><div class="sect1" id="ironic-system-details"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View Ironic System Details</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-system-details">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-system_details.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-system_details.xml</li><li><span class="ds-label">ID: </span>ironic-system-details</li></ul></div></div></div></div><div class="sect2" id="id-1.3.6.12.7.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.5.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View details about the server using <code class="command">openstack server show &lt;nova-node-id&gt;</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.7.2">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-system_details.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-system_details.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">openstack server show a90122ce-bba8-496f-92a0-8a7cb143007e

+--------------------------------------+-----------------------------------------------+
| Property                             | Value                                         |
+--------------------------------------+-----------------------------------------------+
| OS-EXT-AZ:availability_zone          | nova                                          |
| OS-EXT-SRV-ATTR:host                 | ardana-cp1-ir-compute0001-mgmt                |
| OS-EXT-SRV-ATTR:hypervisor_hostname  | ea7246fd-e1d6-4637-9699-0b7c59c22e67          |
| OS-EXT-SRV-ATTR:instance_name        | instance-0000000a                             |
| OS-EXT-STS:power_state               | 1                                             |
| OS-EXT-STS:task_state                | -                                             |
| OS-EXT-STS:vm_state                  | active                                        |
| OS-SRV-USG:launched_at               | 2016-03-11T12:26:25.000000                    |
| OS-SRV-USG:terminated_at             | -                                             |
| accessIPv4                           |                                               |
| accessIPv6                           |                                               |
| config_drive                         |                                               |
| created                              | 2016-03-11T12:17:54Z                          |
| flat-net network                     | 192.3.15.14                                   |
| flavor                               | bmtest (645de08d-2bc6-43f1-8a5f-2315a75b1348) |
| hostId                               | ecafa4f40eb5f72f7298...3bad47cbc01aa0a076114f |
| id                                   | a90122ce-bba8-496f-92a0-8a7cb143007e          |
| image                                | ubuntu (17e4915a-ada0-4b95-bacf-ba67133f39a7) |
| key_name                             | ironic_kp                                     |
| metadata                             | {}                                            |
| name                                 | ubuntu                                        |
| os-extended-volumes:volumes_attached | []                                            |
| progress                             | 0                                             |
| security_groups                      | default                                       |
| status                               | ACTIVE                                        |
| tenant_id                            | d53bcaf15afb4cb5aea3adaedbaa60dd              |
| updated                              | 2016-03-11T12:26:26Z                          |
| user_id                              | e580c645bfec4faeadef7dbd24aaf990              |
+--------------------------------------+-----------------------------------------------+</pre></div></div><div class="sect2" id="id-1.3.6.12.7.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.5.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View detailed information about a node using <code class="command">ironic node-show &lt;ironic-node-id&gt;</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.7.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-system_details.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-system_details.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">ironic node-show  ea7246fd-e1d6-4637-9699-0b7c59c22e67

+------------------------+--------------------------------------------------------------------------+
| Property               | Value                                                                    |
+------------------------+--------------------------------------------------------------------------+
| target_power_state     | None                                                                     |
| extra                  | {}                                                                       |
| last_error             | None                                                                     |
| updated_at             | 2016-03-11T12:26:25+00:00                                                |
| maintenance_reason     | None                                                                     |
| provision_state        | active                                                                   |
| clean_step             | {}                                                                       |
| uuid                   | ea7246fd-e1d6-4637-9699-0b7c59c22e67                                     |
| console_enabled        | False                                                                    |
| target_provision_state | None                                                                     |
| provision_updated_at   | 2016-03-11T12:26:25+00:00                                                |
| maintenance            | False                                                                    |
| inspection_started_at  | None                                                                     |
| inspection_finished_at | None                                                                     |
| power_state            | power on                                                                 |
| driver                 | agent_ilo                                                                |
| reservation            | None                                                                     |
| properties             | {u'memory_mb': 64000, u'cpu_arch': u'x86_64', u'local_gb': 99,           |
|                        | u'cpus': 2, u'capabilities': u'boot_mode:bios,boot_option:local'}        |
| instance_uuid          | a90122ce-bba8-496f-92a0-8a7cb143007e                                     |
| name                   | None                                                                     |
| driver_info            | {u'ilo_address': u'10.1.196.117', u'ilo_password': u'******',            |
|                        | u'ilo_deploy_iso': u'b9499494-7db3-4448-b67f-233b86489c1f',              |
|                        | u'ilo_username': u'Administrator'}                                       |
| created_at             | 2016-03-11T10:17:10+00:00                                                |
| driver_internal_info   | {u'agent_url': u'http://192.3.15.14:9999',                               |
|                        | u'is_whole_disk_image': True, u'agent_last_heartbeat': 1457699159}       |
| chassis_uuid           |                                                                          |
| instance_info          | {u'root_gb': u'99', u'display_name': u'ubuntu', u'image_source': u       |
|                        | '17e4915a-ada0-4b95-bacf-ba67133f39a7', u'capabilities': u'{"boot_mode": |
|                        | "bios", "boot_option": "local"}', u'memory_mb': u'64000', u'vcpus':      |
|                        | u'2', u'image_url': u'http://192.168.12.2:8080/v1/AUTH_ba121db7732f4ac3a |
|                        | 50cc4999a10d58d/glance/17e4915a-ada0-4b95-bacf-ba67133f39a7?temp_url_sig |
|                        | =ada691726337805981ac002c0fbfc905eb9783ea&amp;temp_url_expires=1457699878',  |
|                        | u'image_container_format': u'bare', u'local_gb': u'99',                  |
|                        | u'image_disk_format': u'qcow2', u'image_checksum':                       |
|                        | u'2d7bb1e78b26f32c50bd9da99102150b', u'swap_mb': u'0'}                   |
+------------------------+--------------------------------------------------------------------------+</pre></div></div><div class="sect2" id="id-1.3.6.12.7.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.5.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View detailed information about a port using <code class="command">ironic port-show &lt;ironic-port-id&gt;</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.7.4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-system_details.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-system_details.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">ironic port-show a17a4ef8-a711-40e2-aa27-2189c43f0b67

+------------+-----------------------------------------------------------+
| Property   | Value                                                     |
+------------+-----------------------------------------------------------+
| node_uuid  | ea7246fd-e1d6-4637-9699-0b7c59c22e67                      |
| uuid       | a17a4ef8-a711-40e2-aa27-2189c43f0b67                      |
| extra      | {u'vif_port_id': u'82a5ab28-76a8-4c9d-bfb4-624aeb9721ea'} |
| created_at | 2016-03-11T10:40:53+00:00                                 |
| updated_at | 2016-03-11T12:17:56+00:00                                 |
| address    | 5c:b9:01:88:f0:a4                                         |
+------------+-----------------------------------------------------------+</pre></div></div><div class="sect2" id="id-1.3.6.12.7.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.5.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View detailed information about a hypervisor using <code class="command">openstack
  hypervisor list</code> and <code class="command">openstack hypervisor show</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.7.5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-system_details.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-system_details.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">openstack hypervisor list

+-----+--------------------------------------+-------+---------+
| ID  | Hypervisor hostname                  | State | Status  |
+-----+--------------------------------------+-------+---------+
| 541 | ea7246fd-e1d6-4637-9699-0b7c59c22e67 | up    | enabled |
+-----+--------------------------------------+-------+---------+</pre></div><div class="verbatim-wrap"><pre class="screen">openstack hypervisor show ea7246fd-e1d6-4637-9699-0b7c59c22e67

+-------------------------+--------------------------------------+
| Property                | Value                                |
+-------------------------+--------------------------------------+
| cpu_info                |                                      |
| current_workload        | 0                                    |
| disk_available_least    | 0                                    |
| free_disk_gb            | 0                                    |
| free_ram_mb             | 0                                    |
| host_ip                 | 192.168.12.6                         |
| hypervisor_hostname     | ea7246fd-e1d6-4637-9699-0b7c59c22e67 |
| hypervisor_type         | ironic                               |
| hypervisor_version      | 1                                    |
| id                      | 541                                  |
| local_gb                | 99                                   |
| local_gb_used           | 99                                   |
| memory_mb               | 64000                                |
| memory_mb_used          | 64000                                |
| running_vms             | 1                                    |
| service_disabled_reason | None                                 |
| service_host            | ardana-cp1-ir-compute0001-mgmt       |
| service_id              | 25                                   |
| state                   | up                                   |
| status                  | enabled                              |
| vcpus                   | 2                                    |
| vcpus_used              | 2                                    |
+-------------------------+--------------------------------------+</pre></div></div><div class="sect2" id="id-1.3.6.12.7.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.5.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">View a list of all running services using <code class="command">openstack compute
  service list</code></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.7.6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-system_details.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-system_details.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">openstack compute service list

+----+------------------+-----------------------+----------+---------+-------+------------+----------+
| Id | Binary           | Host                  | Zone     | Status  | State | Updated_at | Disabled |
|    |                  |                       |          |         |       |            | Reason   |
+----+------------------+-----------------------+----------+---------+-------+------------+----------+
| 1  | nova-conductor   | ardana-cp1-c1-m1-mgmt | internal | enabled | up    | date:time  | -        |
| 7  | nova-conductor   |  " -cp1-c1-m2-mgmt    | internal | enabled | up    | date:time  | -        |
| 10 | nova-conductor   |  " -cp1-c1-m3-mgmt    | internal | enabled | up    | date:time  | -        |
| 13 | nova-scheduler   |  " -cp1-c1-m1-mgmt    | internal | enabled | up    | date:time  | -        |
| 16 | nova-scheduler   |  " -cp1-c1-m3-mgmt    | internal | enabled | up    | date:time  | -        |
| 19 | nova-scheduler   |  " -cp1-c1-m2-mgmt    | internal | enabled | up    | date:time  | -        |
| 25 | nova-compute     |  " -cp1-ir- | nova    |          | enabled | up    | date:time  | -        |
|    |                  |      compute0001-mgmt |          |         |       |            |          |
+----+------------------+-----------------------+----------+---------+-------+------------+----------+</pre></div></div></div><div class="sect1" id="ironic-toubleshooting"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting ironic Installation</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-toubleshooting">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span>ironic-toubleshooting</li></ul></div></div></div></div><p>
  Sometimes the <code class="literal">openstack server create</code> command does not
  succeed and when you do a <code class="literal">openstack server list</code>, you will see output
  like the following:
 </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>openstack server list

+------------------+--------------+--------+------------+-------------+----------+
| ID               | Name         | Status | Task State | Power State | Networks |
+------------------+--------------+--------+------------+-------------+----------+
| ee08f82...624e5f | OpenSUSE42.3 | ERROR  | -          | NOSTATE     |          |
+------------------+--------------+--------+------------+-------------+----------+</pre></div><p>
  You should execute the <code class="literal">openstack server show &lt;nova-node-id&gt;</code> and
  <code class="literal">ironic node-show &lt;ironic-node-id&gt;</code> commands to get
  more information about the error.
 </p><div class="sect2" id="id-1.3.6.12.8.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Error: No valid host was found.</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The error <code class="literal">No valid host was found. There are not enough
   hosts.</code> is typically seen when performing the <code class="literal">openstack
   server create</code> where there is a mismatch between the properties set
   on the node and the flavor used. For example, the output from a
   <code class="literal">openstack server show</code> command may look like this:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>openstack server show ee08f82e-8920-4360-be51-a3f995624e5f

+------------------------+------------------------------------------------------------------------------+
| Property               | Value                                                                        |
+------------------------+------------------------------------------------------------------------------+
| OS-EXT-AZ:             |                                                                              |
|   availability_zone    |                                                                              |
| OS-EXT-SRV-ATTR:host   | -                                                                            |
| OS-EXT-SRV-ATTR:       |                                                                              |
|   hypervisor_hostname  | -                                                                            |
| OS-EXT-SRV-ATTR:       |                                                                              |
|   instance_name        | instance-00000001                                                            |
| OS-EXT-STS:power_state | 0                                                                            |
| OS-EXT-STS:task_state  | -                                                                            |
| OS-EXT-STS:vm_state    | error                                                                        |
| OS-SRV-USG:launched_at | -                                                                            |
| OS-SRV-USG:            |                                                                              |
|    terminated_at       | -                                                                            |
| accessIPv4             |                                                                              |
| accessIPv6             |                                                                              |
| config_drive           |                                                                              |
| created                | 2016-03-11T11:00:28Z                                                         |
| fault                  | {"message": "<span class="bold"><strong>No valid host was found. There are not enough hosts             |
|                        |  available.</strong></span>", "code": 500, "details": "  File \<span class="bold"><strong>"/opt/stack/                  |
|                        |  venv/nova-20160308T002421Z/lib/python2.7/site-packages/nova/                |
|                        |  conductor/manager.py\"</strong></span>, line 739, in build_instances                        |
|                        |     request_spec, filter_properties)                                         |
|                        |   File \<span class="bold"><strong>"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/nova/scheduler/utils.py\"</strong></span>, line 343, in wrapped              |
|                        |     return func(*args, **kwargs)                                             |
|                        |   File \<span class="bold"><strong>"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/nova/scheduler/client/__init__.py\"</strong></span>, line 52,                |
|                        |     in select_destinations context, request_spec, filter_properties)         |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/nova/scheduler/client/__init__.py\",line 37,in __run_method  |
|                        |     return getattr(self.instance, __name)(*args, **kwargs)                   |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/nova/scheduler/client/query.py\", line 34,                   |
|                        |     in select_destinations context, request_spec, filter_properties)         |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/nova/scheduler/rpcapi.py\", line 120, in select_destinations |
|                        |     request_spec=request_spec, filter_properties=filter_properties)          |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/oslo_messaging/rpc/client.py\", line 158, in call            |
|                        |     retry=self.retry)                                                        |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/oslo_messaging/transport.py\", line 90, in _send             |
|                        |     timeout=timeout, retry=retry)                                            |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/oslo_messaging/_drivers/amqpdriver.py\", line 462, in send   |
|                        |     retry=retry)                                                             |
|                        |   File \"/opt/stack/venv/nova-20160308T002421Z/lib/python2.7/                |
|                        |   site-packages/oslo_messaging/_drivers/amqpdriver.py\", line 453, in _send  |
|                        |     raise result                                                             |
|                        | ", "created": "2016-03-11T11:00:29Z"}                                        |
| flavor                 | bmtest (645de08d-2bc6-43f1-8a5f-2315a75b1348)                                |
| hostId                 |                                                                              |
| id                     | ee08f82e-8920-4360-be51-a3f995624e5f                                         |
| image                  | opensuse (17e4915a-ada0-4b95-bacf-ba67133f39a7)                              |
| key_name               | ironic_kp                                                                    |
| metadata               | {}                                                                           |
| name                   | opensuse                                                                     |
| os-extended-volumes:   |                                                                              |
|    volumes_attached    | []                                                                           |
| status                 | ERROR                                                                        |
| tenant_id              | d53bcaf15afb4cb5aea3adaedbaa60dd                                             |
| updated                | 2016-03-11T11:00:28Z                                                         |
| user_id                | e580c645bfec4faeadef7dbd24aaf990                                             |
+------------------------+------------------------------------------------------------------------------+</pre></div><p>
   You can find more information about the error by inspecting the log file at
   <code class="literal">/var/log/nova/nova-scheduler.log</code> or alternatively by
   viewing the error location in the source files listed in the stack-trace (in
   bold above).
  </p><p>
   To find the mismatch, compare the properties of the ironic node:
  </p><div class="verbatim-wrap"><pre class="screen">+------------------------+---------------------------------------------------------------------+
| Property               | Value                                                               |
+------------------------+---------------------------------------------------------------------+
| target_power_state     | None                                                                |
| extra                  | {}                                                                  |
| last_error             | None                                                                |
| updated_at             | None                                                                |
| maintenance_reason     | None                                                                |
| provision_state        | available                                                           |
| clean_step             | {}                                                                  |
| uuid                   | ea7246fd-e1d6-4637-9699-0b7c59c22e67                                |
| console_enabled        | False                                                               |
| target_provision_state | None                                                                |
| provision_updated_at   | None                                                                |
| maintenance            | False                                                               |
| inspection_started_at  | None                                                                |
| inspection_finished_at | None                                                                |
| power_state            | None                                                                |
| driver                 | agent_ilo                                                           |
| reservation            | None                                                                |
| properties             | <span class="bold"><strong>{u'memory_mb': 64000, u'local_gb': 99, u'cpus': 2, u'capabilities':</strong></span> |
|                        | <span class="bold"><strong>u'boot_mode:bios,boot_option:local'} </strong></span>                               |
| instance_uuid          | None                                                                |
| name                   | None                                                                |
| driver_info            | {u'ilo_address': u'10.1.196.117', u'ilo_password': u'******',       |
|                        | u'ilo_deploy_iso': u'b9499494-7db3-4448-b67f-233b86489c1f',         |
|                        | u'ilo_username': u'Administrator'}                                  |
| created_at             | 2016-03-11T10:17:10+00:00                                           |
| driver_internal_info   | {}                                                                  |
| chassis_uuid           |                                                                     |
| instance_info          | {}                                                                  |
+------------------------+---------------------------------------------------------------------+</pre></div><p>
   with the flavor characteristics:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>openstack flavor show

+----------------------------+-------------------------------------------------------------------+
| Property                   | Value                                                             |
+----------------------------+-------------------------------------------------------------------+
| OS-FLV-DISABLED:disabled   | False                                                             |
| OS-FLV-EXT-DATA:ephemeral  | 0                                                                 |
| disk                       | <span class="bold"><strong>99 </strong></span>                                                               |
| extra_specs                | <span class="bold"><strong>{"capabilities:boot_option": "local", "cpu_arch": "x86_64",       |
|                            | "capabilities:boot_mode": "bios"}</strong></span>                                 |
| id                         | 645de08d-2bc6-43f1-8a5f-2315a75b1348                              |
| name                       | bmtest                                                            |
| os-flavor-access:is_public | True                                                              |
| ram                        | <span class="bold"><strong>64000</strong></span>                                                             |
| rxtx_factor                | 1.0                                                               |
| swap                       |                                                                   |
| vcpus                      | <span class="bold"><strong>2</strong></span>                                                                 |
+----------------------------+-------------------------------------------------------------------+</pre></div><p>
   In this instance, the problem is caused by the absence of the
   <span class="bold"><strong>"cpu_arch": "x86_64"</strong></span> property on the ironic
   node. This can be resolved by updating the ironic node, adding the missing
   property:
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ironic node-update ea7246fd-e1d6-4637-9699-0b7c59c22e67 \
  <span class="bold"><strong>add properties/cpu_arch=x86_64</strong></span></pre></div><p>
   and then re-running the <code class="literal">openstack server create</code> command.
  </p></div><div class="sect2" id="id-1.3.6.12.8.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Node fails to deploy because it has timed out</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>Possible cause: </strong></span> The neutron API session
   timed out before port creation was completed.
  </p><p>
   <span class="bold"><strong>Resolution: </strong></span> Switch response time varies
   by vendor; the value of <code class="literal">url_timeout</code> must be increased to
   allow for switch response.
  </p><p>
   Check ironic Conductor logs
   (<code class="filename">/var/log/ironic/ironic-conductor.log</code>) for
   <code class="literal">ConnectTimeout</code> errors while connecting to neutron for
   port creation. For example:
  </p><div class="verbatim-wrap"><pre class="screen">19-03-20 19:09:14.557 11556 ERROR ironic.conductor.utils
[req-77f3a7b...1b10c5b - default default] Unexpected error while preparing
to deploy to node 557316...84dbdfbe8b0: ConnectTimeout: Request to
https://192.168.75.1:9696/v2.0/ports timed out</pre></div><p>
   Use the following steps to increase the value of
   <code class="literal">url_timeout</code>.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Log in to the deployer node.
    </p></li><li class="step "><p>
     Edit <code class="filename">./roles/ironic-common/defaults/main.yml</code>,
     increasing the value of <code class="literal">url_timeout</code>.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd /var/lib/ardana/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>vi ./roles/ironic-common/defaults/main.yml</pre></div><p>
     Increase the value of the <code class="literal">url_timeout</code> parameter in the
     <code class="literal">ironic_neutron:</code> section. Increase the parameter from
     the default (60 seconds) to 120 and then in increments of 60 seconds until
     the node deploys successfully.
    </p></li><li class="step "><p>
     Reconfigure ironic.
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></li></ol></div></div></div><div class="sect2" id="id-1.3.6.12.8.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Deployment to a node fails and in "ironic node-list" command, the power_state column for the node is shown as "None"</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>Possible cause: </strong></span> The IPMI commands to the
   node take longer to change the power state of the server.
  </p><p>
   <span class="bold"><strong>Resolution: </strong></span> Check if the node power state
   can be changed using the following command
  </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>ironic node-set-power-state $NODEUUID on</pre></div><p>
   If the above command succeeds and the power_state column is updated
   correctly, then the following steps are required to increase the power sync
   interval time.
  </p><p>
   On the first controller, reconfigure ironic to increase the power sync
   interval time. In the example below, it is set to 120 seconds. This value
   may have to be tuned based on the setup.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Go to the <code class="literal">~/openstack/my_cloud/config/ironic/</code> directory
     and edit <code class="literal">ironic-conductor.conf.j2</code> to set the
     <code class="literal">sync_power_state_interval</code> value:
    </p><div class="verbatim-wrap"><pre class="screen">[conductor]
sync_power_state_interval = 120</pre></div></li><li class="step "><p>
     Save the file and then run the following playbooks:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost config-processor-run.yml
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost ready-deployment.yml
<code class="prompt user">ardana &gt; </code>cd ~/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></li></ol></div></div></div><div class="sect2" id="id-1.3.6.12.8.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Error Downloading Image</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   If you encounter the error below during the deployment:
  </p><div class="verbatim-wrap"><pre class="screen">"u'message': u'Error downloading image: Download of image id 77700...96551 failed:
Image download failed for all URLs.',
u'code': 500,
u'type': u'ImageDownloadError',
u'details': u'Download of image id 77700b53-9e15-406c-b2d5-13e7d9b96551 failed:
Image download failed for all URLs.'"</pre></div><p>
   you should visit the Single Sign-On Settings in the Security page of IPMI and
   change the Single Sign-On Trust Mode setting from the default of "Trust None
   (SSO disabled)" to "Trust by Certificate".
  </p></div><div class="sect2" id="id-1.3.6.12.8.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Using <code class="literal">node-inspection</code> can cause temporary claim of IP addresses</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.9">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>Possible cause: </strong></span> Running
   <code class="literal">node-inspection</code> on a node discovers all the NIC ports
   including the NICs that do not have any connectivity. This causes a
   temporary consumption of the network IPs and increased usage of the
   allocated quota. As a result, other nodes are deprived of IP addresses and
   deployments can fail.
  </p><p>
   <span class="bold"><strong>Resolution:</strong></span>You can add node properties
   manually added instead of using the inspection tool.
  </p><p>
   Note: Upgrade <code class="literal">ipmitool</code> to a version &gt;= 1.8.15 or it
   may not return detailed information about the NIC interface for
   <code class="literal">node-inspection</code>.
  </p></div><div class="sect2" id="id-1.3.6.12.8.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Node permanently stuck in deploying state</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.10">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>Possible causes:</strong></span>
  </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
     ironic conductor service associated with the node could go down.
    </p></li><li class="listitem "><p>
     There might be a properties mismatch. MAC address registered for the node
     could be incorrect.
    </p></li></ul></div><p>
   <span class="bold"><strong>Resolution:</strong></span> To recover from this
   condition, set the provision state of the node to <code class="literal">Error</code>
   and maintenance to <code class="literal">True</code>. Delete the node and re-register
   again.
  </p></div><div class="sect2" id="id-1.3.6.12.8.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">The NICs in the baremetal node should come first in boot order</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.11">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>Possible causes:</strong></span> By default, the boot
   order of baremetal node is set as NIC1, HDD and NIC2. If NIC1 fails, the
   nodes starts booting from HDD and the provisioning fails.
  </p><p>
   <span class="bold"><strong>Resolution:</strong></span> Set boot order so that all the
   NICs appear before the hard disk of the baremetal as NIC1, NIC2…, HDD.
  </p></div><div class="sect2" id="id-1.3.6.12.8.12"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Increase in the number of nodes can cause power commands to fail</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.12">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <span class="bold"><strong>Possible causes:</strong></span>ironic periodically
   performs a power state sync with all the baremetal nodes. When the number of
   nodes increase, ironic does not get sufficient time to perform power
   operations.
  </p><p>
   <span class="bold"><strong>Resolution:</strong></span> The following procedure gives a
   way to increase <code class="literal">sync_power_state_interval</code>:
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Edit the file
     <code class="literal">~/openstack/my_cloud/config/ironic/ironic-conductor.conf.j2</code>
     and navigate to the section for <code class="literal">[conductor]</code>
    </p></li><li class="step "><p>
     Increase the <code class="literal">sync_power_state_interval</code>. For example,
     for 100 nodes, set <code class="literal">sync_power_state_interval = 90</code> and
     save the file.
    </p></li><li class="step "><p>
     Execute the following set of commands to reconfigure ironic:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>cd ~/openstack/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost config-processor-run.yml
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost ready-deployment.yml
<code class="prompt user">ardana &gt; </code>cd ~/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></li></ol></div></div></div><div class="sect2" id="id-1.3.6.12.8.13"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.6.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">DHCP succeeds with PXE but times out with iPXE</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.13">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   If you see DHCP error "No configuration methods succeeded" in iPXE right
   after successful DHCP performed by embedded NIC firmware, there may be an
   issue with Spanning Tree Protocol on the switch.
  </p><p>
   To avoid this error, Rapid Spanning Tree Protocol needs to be enabled on the
   switch. If this is not an option due to conservative loop detection
   strategies, use the steps outlined below to install the iPXE binary with
   increased DHCP timeouts.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Clone iPXE source code
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>git clone git://git.ipxe.org/ipxe.git
<code class="prompt user">tux &gt; </code>cd ipxe/src</pre></div></li><li class="step "><p>
     Modify lines 22-25 in file <code class="literal">config/dhcp.h</code>, which declare
     reduced DHCP timeouts (1-10 secs). Comment out lines with reduced timeouts
     and uncomment normal PXE timeouts (4-32)
    </p><div class="verbatim-wrap"><pre class="screen">//#define DHCP_DISC_START_TIMEOUT_SEC     1
//#define DHCP_DISC_END_TIMEOUT_SEC       10
#define DHCP_DISC_START_TIMEOUT_SEC   4       /* as per PXE spec */
#define DHCP_DISC_END_TIMEOUT_SEC     32      /* as per PXE spec */</pre></div></li><li class="step "><p>
     Make <code class="literal">undionly.kpxe</code> (BIOS) and
     <code class="literal">ipxe.efi</code> (UEFI) images
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>make bin/undionly.kpxe
<code class="prompt user">tux &gt; </code>make bin-x86_64-efi/ipxe.efi</pre></div></li><li class="step "><p>
     Copy iPXE images to Cloud Lifecycle Manager
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>scp bin/undionly.kpxe bin-x86_64-efi/ipxe.efi stack@10.0.0.4:
stack@10.0.0.4's password:
undionly.kpxe                                    100%   66KB  65.6KB/s   00:00
ipxe.efi                                         100%  918KB 918.2KB/s   00:00</pre></div></li><li class="step "><p>
     From deployer, distribute image files onto all 3 controllers
    </p><div class="verbatim-wrap"><pre class="screen">stack@ardana-cp1-c1-m1-mgmt:<code class="prompt user">ardana &gt; </code>cd ~/scratch/ansible/next/ardana/ansible/

stack@ardana-cp1-c1-m1-mgmt:<code class="prompt user">ardana &gt; </code>~/scratch/ansible/next/ardana/ansible$ ansible -i hosts/verb_hosts \
IRN-CND -m copy -b -a 'src=~/ipxe.efi dest=/tftpboot'
...
stack@ardana-cp1-c1-m1-mgmt:<code class="prompt user">ardana &gt; </code>~/scratch/ansible/next/ardana/ansible$ ansible -i hosts/verb_hosts \
IRN-CND -m copy -b -a 'src=~/undionly.kpxe dest=/tftpboot'
...</pre></div></li></ol></div></div><p>
   There is no need to restart services. With next PXE boot attempt, iPXE
   binary with the increased timeout will be downloaded to the target node via
   TFTP.
  </p><div class="sect3" id="id-1.3.6.12.8.13.6"><div class="titlepage"><div><div><h4 class="title"><span class="number">29.6.9.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">ironic Support and Limitations</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.8.13.6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_troubleshooting.xml" title="Edit the source file for this section">Edit source</a></h4><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_troubleshooting.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The following drivers are supported and tested:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
      <code class="systemitem">pxe_ipmitool</code> (UEFI and Legacy BIOS mode, flat-network)
     </p></li><li class="listitem "><p>
      <code class="systemitem">pxe_ipmitool</code> (UEFI and Legacy BIOS mode, flat-network)
     </p></li><li class="listitem "><p>
      <code class="systemitem">pxe_ilo</code> (UEFI and Legacy BIOS mode, flat-network)
     </p></li><li class="listitem "><p>
      <code class="systemitem">agent_ipmitool</code> (UEFI and Legacy BIOS mode, flat-network)
     </p></li><li class="listitem "><p>
      <code class="systemitem">agent_ilo</code> (UEFI and Legacy BIOS mode, flat-network)
     </p></li></ul></div><p>
    <span class="bold"><strong>ISO Image Exceeds Free Space</strong></span>
   </p><p>
   When using the <code class="systemitem">agent_ilo</code> driver, provisioning will
   fail if the size of the user ISO image exceeds the free space available on
   the ramdisk partition. This will produce an error in the ironic Conductor
   logs that may look like as follows:
  </p><div class="verbatim-wrap"><pre class="screen">"ERROR root [-] Command failed: prepare_image, error: Error downloading
image: Download of image id 0c4d74e4-58f1-4f8d-8c1d-8a49129a2163 failed: Unable
to write image to /tmp/0c4d74e4-58f1-4f8d-8c1d-8a49129a2163. Error: [Errno 28]
No space left on device: ImageDownloadError: Error downloading image: Download
of image id 0c4d74e4-58f1-4f8d-8c1d-8a49129a2163 failed: Unable to write image
to /tmp/0c4d74e4-58f1-4f8d-8c1d-8a49129a2163. Error: [Errno 28] No space left
on device"</pre></div><p>
   By default, the total amount of space allocated to ramdisk is 4GB. To
   increase the space allocated for the ramdisk, you can update the deploy
   ISO image using the following workaround.
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Save the deploy ISO to a file:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>openstack image save --file deploy.iso<em class="replaceable ">IMAGE_ID</em></pre></div><p>
    Replace <em class="replaceable ">IMAGE_ID</em> with the ID of the deploy ISO
    stored in glance. The ID can be obtained using the <code class="command">openstack image list</code>.
   </p></li><li class="step "><p>
     Mount the saved ISO:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>mkdir /tmp/mnt
<code class="prompt user">tux &gt; </code>sudo mount -t iso9660 -o loop deploy.iso /tmp/mnt</pre></div><p>
     Since the mount directory is read-only, it is necessary to copy its
     content to be able to make modifications.
    </p></li><li class="step "><p>
     Copy the content of the mount directory to a custom directory:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>mkdir /tmp/custom
<code class="prompt user">tux &gt; </code>cp -aRvf /tmp/mnt/* /tmp/custom/</pre></div></li><li class="step "><p>
     Modify the bootloader files to increase the size of the ramdisk:
    </p><div class="verbatim-wrap"><pre class="screen">/tmp/custom/boot/x86_64/loader/isolinux.cfg
/tmp/custom/EFI/BOOT/grub.cfg
/tmp/custom/boot/grub2/grub.cfg</pre></div><p>
     Find the <code class="literal">openstack-ironic-image</code> label and modify the
     <code class="literal">ramdisk_size</code> parameter in the <code class="literal">append</code>
     property. The <code class="literal">ramdisk_size</code> value must be specified in Kilobytes.
    </p><div class="verbatim-wrap"><pre class="screen">label openstack-ironic-image
  kernel linux
  append initrd=initrd ramdisk_size=10485760 ramdisk_blocksize=4096 \
boot_method=vmedia showopts</pre></div><p>
      Make sure that your baremetal node has the
      amount of RAM that equals or exceeds  the <code class="literal">ramdisk_size</code> value.
     </p></li><li class="step "><p>
     Repackage the ISO using the genisoimage tool:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>cd /tmp/custom
<code class="prompt user">tux &gt; </code>genisoimage -b boot/x86_64/loader/isolinux.bin -R -J -pad -joliet-long \
-iso-level 4 -A '0xaa2dab53' -no-emul-boot -boot-info-table \
-boot-load-size 4 -c boot/x86_64/boot.catalog -hide boot/x86_64/boot.catalog \
-hide-joliet boot/x86_64/boot.catalog -eltorito-alt-boot -b boot/x86_64/efi \
-no-emul-boot -joliet-long -hide glump -hide-joliet glump -o /tmp/custom_deploy.iso ./</pre></div><div id="id-1.3.6.12.8.13.6.8.5.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>
       When repackaging the ISO, make sure that you use the same label. You can
       find the label file in the <code class="filename">/tmp/custom/boot/</code>
       directory. The label begins with <code class="literal">0x</code>. For example, <code class="literal">0x51e568cb</code>.
      </p></div></li><li class="step "><p>
     Delete the existing deploy ISO in glance:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>openstack image delete <em class="replaceable ">IMAGE_ID</em></pre></div></li><li class="step "><p>
     Create a new image with <code class="literal">custom_deploy.iso</code>:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">tux &gt; </code>openstack image create --container-format bare \
--disk-format iso --public --file custom_deploy.iso ir-deploy-iso-ARDANA5.0</pre></div></li><li class="step "><p>
     Re-deploy the ironic node.
    </p></li></ol></div></div><p>
    <span class="bold"><strong>Partition Image Exceeds Free Space</strong></span>
   </p><p>
   The previous procedure applies to ISO images. It does not apply to
   <code class="literal">partition images</code>, although there will be a similar error
   in the ironic logs. However the resolution is different. An option must be
   added to the <code class="literal">PXE</code> line in the
   <code class="filename">main.yml</code> file to increase the <code class="filename">/tmp</code>
   disk size with the following workaround:
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Edit
     <code class="filename">/openstack/ardana/ansible/roles/ironic-common/defaults/main.yml</code>.
    </p></li><li class="step "><p>
     Add <code class="literal">suse.tmpsize=4G</code> to
     <code class="literal">pxe_append_params</code>. Adjust the size of
     <code class="literal">suse.tmpsize</code> as needed for the partition image.
    </p><div class="verbatim-wrap"><pre class="screen">pxe_append_params : "nofb nomodeset vga=normal elevator=deadline
                     security=apparmor crashkernel=256M console=tty0
                     console=ttyS0 suse.tmpsize=4G"</pre></div></li><li class="step "><p>
     Update Git and run playbooks:
    </p><div class="verbatim-wrap"><pre class="screen"><code class="prompt user">ardana &gt; </code>git add -A
<code class="prompt user">ardana &gt; </code>git commit -m "Add suse.tmpsize variable"
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost config-processor-run.yml
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/localhost ready-deployment.yml
<code class="prompt user">ardana &gt; </code>cd /var/lib/ardana/scratch/ansible/next/ardana/ansible
<code class="prompt user">ardana &gt; </code>ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></li><li class="step "><p>
     Re-deploy the ironic node.
    </p></li></ol></div></div></div></div></div><div class="sect1" id="ironic-node-cleaning"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Node Cleaning</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-node-cleaning">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_cleaning.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_cleaning.xml</li><li><span class="ds-label">ID: </span>ironic-node-cleaning</li></ul></div></div></div></div><p>
  Cleaning is the process by which data is removed after a previous tenant has
  used the node. Cleaning requires use of ironic's agent_ drivers. It is
  extremely important to note that if the pxe_ drivers are utilized, no node
  cleaning operations will occur, and a previous tenant's data could be found
  on the node. The same risk of a previous tenant's data possibly can occur if
  cleaning is explicitly disabled as part of the installation.
 </p><p>
  By default, cleaning attempts to utilize ATA secure erase to wipe the
  contents of the disk. If secure erase is unavailable, the cleaning
  functionality built into the ironic Python Agent falls back to an operation
  referred to as "shred" where random data is written over the contents of the
  disk, and then followed up by writing "0"s across the disk. This can be a
  time-consuming process.
 </p><p>
  An additional feature of cleaning is the ability to update firmware or
  potentially assert new hardware configuration, however, this is an advanced
  feature that must be built into the ironic Python Agent image. Due to the
  complex nature of such operations, and the fact that no one size fits all,
  this requires a custom ironic Python Agent image to be constructed with an
  appropriate hardware manager. For more information on hardware managers, see
  <a class="link" href="http://docs.openstack.org/developer/ironic-python-agent/#hardware-managers" target="_blank">http://docs.openstack.org/developer/ironic-python-agent/#hardware-managers</a>
 </p><p>
  ironic's upstream documentation for cleaning may be found here:
  <a class="link" href="http://docs.openstack.org/developer/ironic/deploy/cleaning.html" target="_blank">http://docs.openstack.org/developer/ironic/deploy/cleaning.html</a>
 </p><div class="sect2" id="id-1.3.6.12.9.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.7.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Setup</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.9.6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_cleaning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_cleaning.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Cleaning is enabled by default in ironic when installed via the Cloud Lifecycle Manager.
   You can verify this by examining the ironic-conductor.conf file.
   Look for:
  </p><div class="verbatim-wrap"><pre class="screen">[conductor]
clean_nodes=true</pre></div></div><div class="sect2" id="id-1.3.6.12.9.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.7.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">In use</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.9.7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_cleaning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_cleaning.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   When enabled, cleaning will be run automatically when nodes go from active
   to available state or from manageable to available. To monitor what step of
   cleaning the node is in, run <code class="literal">ironic node-show</code>:
  </p><div class="verbatim-wrap"><pre class="screen">stack@ardana-cp1-c1-m1-mgmt:~$ ironic node-show 4e6d4273-2535-4830-a826-7f67e71783ed
+------------------------+-----------------------------------------------------------------------+
| Property               | Value                                                                 |
+------------------------+-----------------------------------------------------------------------+
| target_power_state     | None                                                                  |
| extra                  | {}                                                                    |
| last_error             | None                                                                  |
| updated_at             | 2016-04-15T09:33:16+00:00                                             |
| maintenance_reason     | None                                                                  |
| provision_state        | cleaning                                                              |
| clean_step             | {}                                                                    |
| uuid                   | 4e6d4273-2535-4830-a826-7f67e71783ed                                  |
| console_enabled        | False                                                                 |
| target_provision_state | available                                                             |
| provision_updated_at   | 2016-04-15T09:33:16+00:00                                             |
| maintenance            | False                                                                 |
| inspection_started_at  | None                                                                  |
| inspection_finished_at | None                                                                  |
| power_state            | power off                                                             |
| driver                 | agent_ilo                                                             |
| reservation            | ardana-cp1-c1-m1-mgmt                                                 |
| properties             | {u'memory_mb': 4096, u'cpu_arch': u'amd64', u'local_gb': 80,          |
|                        | u'cpus': 2, u'capabilities': u'boot_mode:uefi,boot_option:local'}     |
| instance_uuid          | None                                                                  |
| name                   | None                                                                  |
| driver_info            | {u'ilo_deploy_iso': u'249bf095-e741-441d-bc28-0f44a9b8cd80',          |
|                        | u'ipmi_username': u'Administrator', u'deploy_kernel':                 |
|                        | u'3a78c0a9-3d8d-4764-9300-3e9c00e167a1', u'ilo_address':              |
|                        | u'10.1.196.113', u'ipmi_address': u'10.1.196.113', u'deploy_ramdisk': |
|                        | u'd02c811c-e521-4926-9f26-0c88bbd2ee6d', u'ipmi_password': u'******', |
|                        | u'ilo_password': u'******', u'ilo_username': u'Administrator'}        |
| created_at             | 2016-04-14T08:30:08+00:00                                             |
| driver_internal_info   | {<span class="bold"><strong>u'clean_steps': None</strong></span>,                      |
|                        | u'hardware_manager_version': {u'generic_hardware_manager': u'1.0'},   |
|                        | u'is_whole_disk_image': True, u'agent_erase_devices_iterations': 1,   |
|                        | u'agent_url': u'http://192.168.246.245:9999',                         |
|                        | u'agent_last_heartbeat': 1460633166}                                  |
| chassis_uuid           |                                                                       |
| instance_info          | {}                                                                    |
+------------------------+-----------------------------------------------------------------------+</pre></div><p>
   The status will be in the <code class="literal">driver_internal_info</code> field. You
   will also be able to see the <code class="literal">clean_steps</code> list there.
  </p></div><div class="sect2" id="id-1.3.6.12.9.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.7.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.9.8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_cleaning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_cleaning.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   If an error occurs during the cleaning process, the node will enter the
   clean failed state so that it is not deployed. The node remains powered on
   for debugging purposes. The node can be moved to the manageable state to
   attempt a fix using the following command:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-set-provision-state &lt;node id&gt; manage</pre></div><p>
   Once you have identified and fixed the issue, you can return the node to
   available state by executing the following commands:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-set-maintenance &lt;node id&gt; false
ironic node-set-provision-state &lt;node id&gt; provide</pre></div><p>
   This will retry the cleaning steps and set the node to available state upon
   their successful completion.
  </p></div><div class="sect2" id="id-1.3.6.12.9.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.7.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disabling Node Cleaning</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.9.9">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-node_cleaning.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-node_cleaning.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   To disable node cleaning, edit
   <code class="literal">~/openstack/my_cloud/definition/data/ironic/ironic_config.yml</code>
   and set <code class="literal">enable_node_cleaning</code> to <code class="literal">false</code>.
  </p><p>
   Commit your changes:
  </p><div class="verbatim-wrap"><pre class="screen">cd ~/openstack/ardana/ansible
git add -A
git commit -m "disable node cleaning"</pre></div><p>
   Deploy these changes by re-running the configuration processor and
   reconfigure the ironic installation:
  </p><div class="verbatim-wrap"><pre class="screen">cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml
ansible-playbook -i hosts/localhost ready-deployment.yml
cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div></div></div><div class="sect1" id="ironic-oneview"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ironic and HPE OneView</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-oneview">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span>ironic-oneview</li></ul></div></div></div></div><div class="sect2" id="id-1.3.6.12.10.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling Ironic HPE OneView driver in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span></span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.2">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Edit the file
   <code class="literal">~/openstack/my_cloud/definition/data/ironic/ironicconfig.yml</code>
   and set the value
  </p><div class="verbatim-wrap"><pre class="screen">enable_oneview: true</pre></div><p>
   This will enable the HPE OneView driver for ironic in <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span>.
  </p></div><div class="sect2" id="id-1.3.6.12.10.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Adding HPE OneView Appliance Credentials</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">manage_url: https://&lt;Onview appliance URL&gt;

oneview_username: "&lt;Appliance username&gt;"

oneview_encrypted_password: "&lt;Encrypted password&gt;"

oneview_allow_insecure_connections: &lt;true/false&gt;

tls_cacert_file: &lt;CA certificate for connection&gt;</pre></div></div><div class="sect2" id="id-1.3.6.12.10.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Encrypting the HPE OneView Password</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Encryption can be applied using <code class="literal">ardanaencrypt.py</code> or using
   <code class="literal">openssl</code>. On the Cloud Lifecycle Manager node, export the key
   used for encryption as environment variable:
  </p><div class="verbatim-wrap"><pre class="screen">export ARDANA_USER_PASSWORD_ENCRYPT_KEY="<em class="replaceable ">ENCRYPTION_KEY</em>"</pre></div><p>
   And then execute the following commands:
  </p><div class="verbatim-wrap"><pre class="screen">cd ~/openstack/ardana/ansible
python ardanaencrypt.py</pre></div><p>
   Enter password to be encrypted when prompted. The script uses the key that
   was exported in the <code class="literal">ARDANA_USER_PASSWORD_ENCRYPT_KEY</code> to do
   the encryption.
  </p><p>
   For more information, see <span class="intraxref">Book “Security Guide”, Chapter 10 “Encryption of Passwords and Sensitive Data”</span>.
  </p></div><div class="sect2" id="id-1.3.6.12.10.5"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Decrypting the HPE OneView Password</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.5">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Before running the <code class="literal">site.yml</code> playbook, export the key used
   for encryption as environment variable:
  </p><div class="verbatim-wrap"><pre class="screen">export ARDANA_USER_PASSWORD_ENCRYPT_KEY="<em class="replaceable ">ENCRYPTION_KEY</em>"</pre></div><p>
   The decryption of the password is then automatically handled in
   ironic-ansible playbooks.
  </p></div><div class="sect2" id="id-1.3.6.12.10.6"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.5 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Registering Baremetal Node for HPE OneView Driver</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.6">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">ironic node-create -d agent_pxe_oneview</pre></div><p>
   Update node driver-info:
  </p><div class="verbatim-wrap"><pre class="screen"> ironic node-update $NODE_UUID add driver_info/server_hardware_uri=$SH_URI</pre></div></div><div class="sect2" id="id-1.3.6.12.10.7"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.6 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Updating Node Properties</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.7">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">ironic node-update $NODE_UUID add \
  properties/capabilities=server_hardware_type_uri:$SHT_URI,\
        enclosure_group_uri:$EG_URI,server_profile_template_uri=$SPT_URI</pre></div></div><div class="sect2" id="id-1.3.6.12.10.8"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.7 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating Port for Driver</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.8">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><div class="verbatim-wrap"><pre class="screen">ironic port-create -n $NODE_UUID -a $MAC_ADDRESS</pre></div></div><div class="sect2" id="id-1.3.6.12.10.9"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.8 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Creating a Node</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.9">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Create Node:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-create -n ovbay7 -d agent_pxe_oneview</pre></div><p>
   Update driver info:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-update $ID add driver_info/server_hardware_uri="/rest/server-hardware/3037...464B" \
driver_info/deploy_kernel="$KERNELDISK" driver_info/deploy_ramdisk="$RAMDISK"</pre></div><p>
   Update node properties:
  </p><div class="verbatim-wrap"><pre class="screen">ironic node-update $ID add properties/local_gb=10
ironic node-update $ID add properties/cpus=24 properties/memory_mb=262144 \
properties/cpu_arch=x86_64</pre></div><div class="verbatim-wrap"><pre class="screen">ironic node-update \
$ID add properties/capabilities=server_hardware_type_uri:'/rest/server-hardware-types/B31...F69E',\
enclosure_group_uri:'/rest/enclosure-groups/80efe...b79fa',\
server_profile_template_uri:'/rest/server-profile-templates/faafc3c0-6c81-47ca-a407-f67d11262da5'</pre></div></div><div class="sect2" id="id-1.3.6.12.10.10"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Getting Data using REST API</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.10">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   GET login session auth id:
  </p><div class="verbatim-wrap"><pre class="screen">curl -k https://<em class="replaceable ">ONEVIEW_MANAGER_URL</em>/rest/login-sessions \
  -H "content-type:application/json" \
  -X POST \
  -d '{"userName":"<em class="replaceable ">USER_NAME</em>", "password":"<em class="replaceable ">PASSWORD</em>"}'</pre></div><p>
   Get the complete node details in JSON format:
  </p><div class="verbatim-wrap"><pre class="screen">curl -k "https://<em class="replaceable ">ONEVIEW_MANAGER_URL</em>;/rest/server-hardware/30373237-3132-4753-4835-32325652464B" -H "content-type:application/json" -H "Auth:&lt;auth_session_id&gt;"| python -m json.tool</pre></div></div><div class="sect2" id="id-1.3.6.12.10.11"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.8.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Ironic HPE OneView CLI</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.10.11">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_oneview.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_oneview.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   <code class="literal">ironic-oneview-cli</code> is already installed in
   <code class="literal">ironicclient</code> venv with a symbolic link to it. To generate
   an <code class="literal">rc</code> file for the HPE OneView CLI, follow these steps:
  </p><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
     Run the following commands:
    </p><div class="verbatim-wrap"><pre class="screen">source ~/service.osrc
openstack image list</pre></div></li><li class="step "><p>
     Note the <code class="literal">deploy-kernel</code> and
     <code class="literal">deploy-ramdisk</code> UUID and then run the following command
     to generate the <code class="literal">rc</code> file:
    </p><div class="verbatim-wrap"><pre class="screen">ironic-oneview genrc</pre></div><p>
     You will be prompted to enter:
    </p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>
       HPE OneView Manager URL
      </p></li><li class="listitem "><p>
       Username
      </p></li><li class="listitem "><p>
       deploy-kernel
      </p></li><li class="listitem "><p>
       deploy-ramdisk
      </p></li><li class="listitem "><p>
       allow_insecure_connection
      </p></li><li class="listitem "><p>
       cacert file
      </p></li></ul></div><p>
     The <code class="literal">ironic-oneview.rc</code> file will be generated in the
     current directory, by default. It is possible to specify a different
     location.
    </p></li><li class="step "><p>
     Source the generated file:
    </p><div class="verbatim-wrap"><pre class="screen">source ironic-oneview.rc</pre></div><p>
     Now enter the password of the HPE OneView appliance.
    </p></li><li class="step "><p>
     You can now use the CLI for node and flavor creation as follows:
    </p><div class="verbatim-wrap"><pre class="screen">ironic-oneview node-create
ironic-oneview flavor-create</pre></div></li></ol></div></div></div></div><div class="sect1" id="ironic-raid-config"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.9 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">RAID Configuration for Ironic</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-raid-config">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_raid_config.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_raid_config.xml</li><li><span class="ds-label">ID: </span>ironic-raid-config</li></ul></div></div></div></div><div class="procedure "><div class="procedure-contents"><ol class="procedure" type="1"><li class="step "><p>
    Node Creation:
   </p><p>
    Check the raid capabilities of the driver:
   </p><div class="verbatim-wrap"><pre class="screen">ironic --ironic-api-version 1.15 driver-raid-logical-disk-properties pxe_ilo</pre></div><p>
    This will generate output similar to the following:
   </p><div class="verbatim-wrap"><pre class="screen">+----------------------+-------------------------------------------------------------------------+
| Property             | Description                                                             |
+----------------------+-------------------------------------------------------------------------+
| controller           | Controller to use for this logical disk. If not specified, the          |
|                      | driver will choose a suitable RAID controller on the bare metal node.   |
|                      | Optional.                                                               |
| disk_type            | The type of disk preferred. Valid values are 'hdd' and 'ssd'. If this   |
|                      | is not specified, disk type will not be a selection criterion for       |
|                      | choosing backing physical disks. Optional.                              |
| interface_type       | The interface type of disk. Valid values are 'sata', 'scsi' and 'sas'.  |
|                      | If this is not specified, interface type will not be a selection        |
|                      | criterion for choosing backing physical disks. Optional.                |
| is_root_volume       | Specifies whether this disk is a root volume. By default, this is False.|
|                      | Optional.                                                               |
| #_of_physical_disks  | Number of physical disks to use for this logical disk. By default, the  |
|                      | driver uses the minimum number of disks required for that RAID level.   |
|                      | Optional.                                                               |
| physical_disks       | The physical disks to use for this logical disk. If not specified, the  |
|                      | driver will choose suitable physical disks to use. Optional.            |
| <span class="bold"><strong>raid_level           | RAID level for the logical disk. Valid values are '0', '1', '2', '5', </strong></span>  |
|                      | <span class="bold"><strong>'6', '1+0', '5+0' and '6+0'. Required.</strong></span>                                  |
| share_physical_disks | Specifies whether other logical disks can share physical disks with this|
|                      | logical disk. By default, this is False. Optional.                      |
| <span class="bold"><strong>size_gb              | Size in GiB (Integer) for the logical disk. Use 'MAX' as size_gb if </strong></span>    |
|                      | <span class="bold"><strong>this logical disk is supposed to use the rest of</strong></span>                        |
|                      | <span class="bold"><strong>the space available. Required.</strong></span>                                          |
| volume_name          | Name of the volume to be created. If this is not specified, it will be  |
|                      | auto-generated. Optional.                                               |
+----------------------+-------------------------------------------------------------------------+</pre></div><p>
    Node State will be <span class="bold"><strong>Available</strong></span>
   </p><div class="verbatim-wrap"><pre class="screen">ironic node-create -d pxe_ilo -i ilo_address=&lt;ip_address&gt; \
  -i ilo_username=&lt;username&gt; -i ilo_password=&lt;password&gt; \
  -i ilo_deploy_iso=&lt;iso_id&gt; -i deploy_kernel=&lt;kernel_id&gt; \
  -i deploy_ramdisk=&lt;ramdisk_id&gt; -p cpus=2 -p memory_mb=4096 \
  -p local_gb=80  -p cpu_arch=amd64 \
  -p capabilities="boot_option:local,boot_mode:bios"</pre></div><div class="verbatim-wrap"><pre class="screen">ironic port-create -a &lt;port&gt; -n &lt;node-uuid&gt;</pre></div></li><li class="step "><p>
    Apply the target raid configuration on the node:
   </p><p>
    See the OpenStack documentation for RAID configuration at
    <a class="link" href="http://docs.openstack.org/developer/ironic/deploy/raid.html" target="_blank">http://docs.openstack.org/developer/ironic/deploy/raid.html</a>.
   </p><p>
    Set the target RAID configuration by editing the file
    <code class="literal">raid_conf.json</code> and setting the appropriate values, for
    example:
   </p><div class="verbatim-wrap"><pre class="screen">{ "logical_disks": [ {"size_gb": 5, "raid_level": "0", "is_root_volume": true} ] }</pre></div><p>
    and then run the following command:
   </p><div class="verbatim-wrap"><pre class="screen">ironic --ironic-api-version 1.15 node-set-target-raid-config &lt;node-uuid&gt; raid_conf.json</pre></div><p>
    The output produced should be similar to the following:
   </p><div class="verbatim-wrap"><pre class="screen">+-----------------------+-------------------------------------------------------------------------+
| Property              | Value                                                                   |
+-----------------------+-------------------------------------------------------------------------+
| chassis_uuid          |                                                                         |
| clean_step            | {}                                                                      |
| console_enabled       | False                                                                   |
| created_at            | 2016-06-14T14:58:07+00:00                                               |
| driver                | pxe_ilo                                                                 |
| driver_info           | {u'ilo_deploy_iso': u'd43e589a-07db-4fce-a06e-98e2f38340b4',            |
|                       | u'deploy_kernel': u'915c5c74-1ceb-4f78-bdb4-8547a90ac9c0',              |
|                       | u'ilo_address': u'10.1.196.116', u'deploy_ramdisk':                     |
|                       | u'154e7024-bf18-4ad2-95b0-726c09ce417a', u'ilo_password': u'******',    |
|                       | u'ilo_username': u'Administrator'}                                      |
| driver_internal_info  | {u'agent_cached_clean_steps_refreshed': u'2016-06-15 07:16:08.264091',  |
|                       | u'agent_cached_clean_steps': {u'raid': [{u'interface': u'raid',         |
|                       | u'priority': 0, u'step': u'delete_configuration'}, {u'interface':       |
|                       | u'raid', u'priority': 0, u'step': u'create_configuration'}], u'deploy': |
|                       | [{u'priority': 10, u'interface': u'deploy', u'reboot_requested': False, |
|                       | u'abortable': True, u'step': u'erase_devices'}]}, u'clean_steps': None, |
|                       | u'hardware_manager_version': {u'generic_hardware_manager': u'3'},       |
|                       | u'agent_erase_devices_iterations': 1, u'agent_url':                     |
|                       | u'http://192.168.245.143:9999', u'agent_last_heartbeat': 1465974974}    |
| extra                 | {}                                                                      |
| inspection_finished_at| None                                                                    |
| inspection_started_at | None                                                                    |
| instance_info         | {u'deploy_key': u'XXN2ON0V9ER429MECETJMUG5YHTKOQOZ'}                    |
| instance_uuid         | None                                                                    |
| last_error            | None                                                                    |
| maintenance           | False                                                                   |
| maintenance_reason    | None                                                                    |
| name                  | None                                                                    |
| power_state           | power off                                                               |
| properties            | {u'cpu_arch': u'amd64', u'root_device': {u'wwn': u'0x600508b1001ce286'},|
|                       | u'cpus': 2, u'capabilities':                                            |
|                       | u'boot_mode:bios,raid_level:6,boot_option:local', u'memory_mb': 4096,   |
|                       | u'local_gb': 4}                                                         |
| provision_state       | available                                                               |
| provision_updated_at  | 2016-06-15T07:16:27+00:00                                               |
| reservation           | padawan-ironic-cp1-c1-m2-mgmt                                           |
| target_power_state    | power off                                                               |
| target_provision_state| None                                                                    |
| <span class="bold"><strong>target_raid_config</strong></span>    | {u'logical_disks': [{u'size_gb': 5, <span class="bold"><strong>u'raid_level': u'6',</strong></span>                |
|                       | u'is_root_volume': True}]}                                              |
| updated_at            | 2016-06-15T07:44:22+00:00                                               |
| uuid                  | 22ab9f85-71a1-4748-8d6b-f6411558127e                                    |
+-----------------------+-------------------------------------------------------------------------+</pre></div><p>
    Now set the state of the node to
    <span class="bold"><strong>manageable</strong></span>:
   </p><div class="verbatim-wrap"><pre class="screen">ironic --ironic-api-version latest node-set-provision-state &lt;node-uuid&gt; manage</pre></div></li><li class="step "><p>
    Manual cleaning steps:
   </p><p>
    Manual cleaning is enabled by default in production - the following are the
    steps to enable cleaning if the manual cleaning has been disabled.
   </p><ol type="a" class="substeps "><li class="step "><p>
      Provide <code class="literal">cleaning_network_uuid</code> in
      <code class="literal">ironic-conductor.conf</code>
     </p></li><li class="step "><p>
      Edit the file
      <code class="literal">~/openstack/my_cloud/definition/data/ironic/ironic_config.yml</code>
      and set <code class="literal">enable_node_cleaning</code> to
      <code class="literal">true</code>.
     </p></li><li class="step "><p>
      Then run the following set of commands:
     </p><div class="verbatim-wrap"><pre class="screen">cd ~/openstack/ardana/ansible
git add -A
git commit -m "enabling node cleaning"
cd ~/openstack/ardana/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml
ansible-playbook -i hosts/localhost ready-deployment.yml
cd ~/scratch/ansible/next/ardana/ansible
ansible-playbook -i hosts/verb_hosts ironic-reconfigure.yml</pre></div><p>
      After performing these steps, the state of the node will become
      <span class="bold"><strong>Cleaning</strong></span>.
     </p></li></ol><p>
    Run the following command:
   </p><div class="verbatim-wrap"><pre class="screen">ironic --ironic-api-version latest node-set-provision-state 2123254e-8b31...aa6fd \
  clean --clean-steps '[{ "interface": "raid","step": "delete_configuration"}, \
  { "interface": "raid" ,"step": "create_configuration"}]'</pre></div><p>
    Node-information after a Manual cleaning:
   </p><div class="verbatim-wrap"><pre class="screen">+-----------------------+-------------------------------------------------------------------------+
| Property              | Value                                                                   |
+-----------------------+-------------------------------------------------------------------------+
| chassis_uuid          |                                                                         |
| clean_step            | {}                                                                      |
| console_enabled       | False                                                                   |
| created_at            | 2016-06-14T14:58:07+00:00                                               |
| driver                | pxe_ilo                                                                 |
| driver_info           | {u'ilo_deploy_iso': u'd43e589a-07db-4fce-a06e-98e2f38340b4',            |
|                       | u'deploy_kernel': u'915c5c74-1ceb-4f78-bdb4-8547a90ac9c0',              |
|                       | u'ilo_address': u'10.1.196.116', u'deploy_ramdisk':                     |
|                       | u'154e7024-bf18-4ad2-95b0-726c09ce417a', u'ilo_password': u'******',    |
|                       | u'ilo_username': u'Administrator'}                                      |
| driver_internal_info  | {u'agent_cached_clean_steps_refreshed': u'2016-06-15 07:16:08.264091',  |
|                       | u'agent_cached_clean_steps': {u'raid': [{u'interface': u'raid',         |
|                       | u'priority': 0, u'step': u'delete_configuration'}, {u'interface':       |
|                       | u'raid', u'priority': 0, u'step': u'create_configuration'}], u'deploy': |
|                       | [{u'priority': 10, u'interface': u'deploy', u'reboot_requested': False, |
|                       | u'abortable': True, u'step': u'erase_devices'}]}, u'clean_steps': None, |
|                       | u'hardware_manager_version': {u'generic_hardware_manager': u'3'},       |
|                       | u'agent_erase_devices_iterations': 1, u'agent_url':                     |
|                       | u'http://192.168.245.143:9999', u'agent_last_heartbeat': 1465974974}    |
| extra                 | {}                                                                      |
| inspection_finished_at| None                                                                    |
| inspection_started_at | None                                                                    |
| instance_info         | {u'deploy_key': u'XXN2ON0V9ER429MECETJMUG5YHTKOQOZ'}                    |
| instance_uuid         | None                                                                    |
| last_error            | None                                                                    |
| maintenance           | False                                                                   |
| maintenance_reason    | None                                                                    |
| name                  | None                                                                    |
| power_state           | power off                                                               |
| properties            | {u'cpu_arch': u'amd64', u'root_device': {u'wwn': u'0x600508b1001ce286'},|
|                       | u'cpus': 2, u'capabilities':                                            |
|                       | u'boot_mode:bios,raid_level:6,boot_option:local', u'memory_mb': 4096,   |
|                       | u'local_gb': 4}                                                         |
| provision_state       | manageable                                                              |
| provision_updated_at  | 2016-06-15T07:16:27+00:00                                               |
| raid_config           | {u'last_updated': u'2016-06-15 07:16:14.584014', u'physical_disks':     |
|                       | [{u'status': u'ready', u'size_gb': 1024, u'interface_type': u'sata',    |
|                       | u'firmware': u'HPGC', u'controller': u'Smart Array P440ar in Slot 0     |
|                       | (Embedded)', u'model': u'ATA     MM1000GBKAL', u'disk_type': u'hdd',    |
|                       | u'id': u'1I:3:3'}, {u'status': u'ready', u'size_gb': 1024,              |
|                       | u'interface_type': u'sata', u'firmware': u'HPGC', u'controller': u'Smart|
|                       | Array P440ar in Slot 0 (Embedded)', u'model': u'ATA     MM1000GBKAL',   |
|                       | u'disk_type': u'hdd', u'id': u'1I:3:1'}, {u'status': u'active',         |
|                       | u'size_gb': 1024, u'interface_type': u'sata', u'firmware': u'HPGC',     |
|                       | u'controller': u'Smart Array P440ar in Slot 0 (Embedded)', u'model':    |
|                       | u'ATA     MM1000GBKAL', u'disk_type': u'hdd', u'id': u'1I:3:2'},        |
|                       | {u'status': u'active', u'size_gb': 1024, u'interface_type': u'sata',    |
|                       | u'firmware': u'HPGC', u'controller': u'Smart Array P440ar in Slot 0     |
|                       | (Embedded)', u'model': u'ATA     MM1000GBKAL', u'disk_type': u'hdd',    |
|                       | u'id': u'2I:3:6'}, {u'status': u'active', u'size_gb': 1024,             |
|                       | u'interface_type': u'sata', u'firmware': u'HPGC', u'controller': u'Smart|
|                       | Array P440ar in Slot 0 (Embedded)', u'model': u'ATA     MM1000GBKAL',   |
|                       | u'disk_type': u'hdd', u'id': u'2I:3:5'}, {u'status': u'active',         |
|                       | u'size_gb': 1024, u'interface_type': u'sata', u'firmware': u'HPGC',     |
|                       | u'controller': u'Smart Array P440ar in Slot 0 (Embedded)', u'model':    |
|                       | u'ATA     MM1000GBKAL', u'disk_type': u'hdd', u'id': u'1I:3:4'}],       |
|                       | u'logical_disks': [{u'size_gb': 4, u'physical_disks': [u'1I:3:2',       |
|                       | u'2I:3:6', u'2I:3:5', u'1I:3:4'], u'raid_level': u'6',                  |
|                       | u'is_root_volume': True, u'root_device_hint': {u'wwn':                  |
|                       | u'0x600508b1001ce286'}, u'controller': u'Smart Array P440ar in Slot 0   |
|                       | (Embedded)', u'volume_name': u'015E795CPDNLH0BRH8N406AAB7'}]}           |
| reservation           | padawan-ironic-cp1-c1-m2-mgmt                                           |
| target_power_state    | power off                                                               |
| target_provision_state| None                                                                    |
| target_raid_config    | {u'logical_disks': [{u'size_gb': 5, u'raid_level': u'6',                |
|                       | u'is_root_volume': True}]}                                              |
| updated_at            | 2016-06-15T07:44:22+00:00                                               |
| uuid                  | 22ab9f85-71a1-4748-8d6b-f6411558127e                                    |
+-----------------------+-------------------------------------------------------------------------+</pre></div><p>
    After the manual cleaning, run the following command to change the state of
    a node to <span class="bold"><strong>available</strong></span>:
   </p><div class="verbatim-wrap"><pre class="screen">ironic --ironic-api-version latest node-set-provision-state &lt;node-uuid&gt; \
  provide</pre></div></li></ol></div></div></div><div class="sect1" id="ironic-audit-support"><div class="titlepage"><div><div><h2 class="title"><span class="number">29.10 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Audit Support for Ironic</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#ironic-audit-support">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_audit_support.xml" title="Edit the source file for this section">Edit source</a></h2><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_audit_support.xml</li><li><span class="ds-label">ID: </span>ironic-audit-support</li></ul></div></div></div></div><div class="sect2" id="id-1.3.6.12.12.2"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.10.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">API Audit Logging</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.12.2">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_audit_support.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_audit_support.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   Audit middleware supports delivery of CADF audit events via Oslo messaging
   notifier capability. Based on <code class="literal">notification_driver</code>
   configuration, audit events can be routed to messaging infrastructure
   (<code class="literal">notification_driver = messagingv2</code>) or can be routed to a
   log file (<code class="literal">notification_driver = log</code>).
  </p><p>
   Audit middleware creates two events per REST API interaction. The first
   event has information extracted from request data and the second one
   contains information on the request outcome (response).
  </p></div><div class="sect2" id="id-1.3.6.12.12.3"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.10.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Enabling API Audit Logging</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.12.3">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_audit_support.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_audit_support.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   You can enable audit logging for ironic by changing the configuration in the
   input model. Edit the file
   <code class="literal">~/openstack/my_cloud/definition/cloudConfig.yml</code> and in the
   <code class="literal">audit-settings</code> section, change the
   <code class="literal">default</code> value to <code class="literal">enabled</code>. The
   ironic-ansible playbooks will now enable audit support for ironic.
  </p><p>
   API audit events will be logged in the corresponding audit directory, for
   example, <code class="literal">/var/audit/ironic/ironic-api-audit.log</code>. An audit
   event will be logged in the log file for every request and response for an
   API call.
  </p></div><div class="sect2" id="id-1.3.6.12.12.4"><div class="titlepage"><div><div><h3 class="title"><span class="number">29.10.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Sample Audit Event</span> <a title="Permalink" class="permalink" href="install-ironic-overview.html#id-1.3.6.12.12.4">#</a><a class="report-bug" target="_blank" href="https://github.com/SUSE-Cloud/doc-cloud/blob/maintenance/cloud_9/xml/installation-installation-ironic-ironic_audit_support.xml" title="Edit the source file for this section">Edit source</a></h3><div class="doc-status"><ul><li><span class="ds-label">File Name: </span>installation-installation-ironic-ironic_audit_support.xml</li><li><span class="ds-label">ID: </span><span class="ds-message">no ID found</span></li></ul></div></div></div></div><p>
   The following output is an example of an audit event for an <code class="literal">ironic
   node-list</code> command:
  </p><div class="verbatim-wrap"><pre class="screen">{
   "event_type":"audit.http.request",
   "timestamp":"2016-06-15 06:04:30.904397",
   "payload":{
      "typeURI":"http://schemas.dmtf.org/cloud/audit/1.0/event",
      "eventTime":"2016-06-15T06:04:30.903071+0000",
      "target":{
         "id":"ironic",
         "typeURI":"unknown",
         "addresses":[
            {
               "url":"http://{ironic_admin_host}:6385",
               "name":"admin"
            },
           {
               "url":"http://{ironic_internal_host}:6385",
               "name":"private"
           },
           {
               "url":"http://{ironic_public_host}:6385",
               "name":"public"
           }
         ],
         "name":"ironic"
      },
      "observer":{
         "id":"target"
      },
      "tags":[
         "correlation_id?value=685f1abb-620e-5d5d-b74a-b4135fb32373"
      ],
      "eventType":"activity",
      "initiator":{
         "typeURI":"service/security/account/user",
         "name":"admin",
         "credential":{
            "token":"***",
            "identity_status":"Confirmed"
         },
         "host":{
            "agent":"python-ironicclient",
            "address":"10.1.200.129"
         },
         "project_id":"d8f52dd7d9e1475dbbf3ba47a4a83313",
         "id":"8c1a948bad3948929aa5d5b50627a174"
      },
      "action":"read",
      "outcome":"pending",
      "id":"061b7aa7-5879-5225-a331-c002cf23cb6c",
      "requestPath":"/v1/nodes/?associated=True"
   },
   "priority":"INFO",
   "publisher_id":"ironic-api",
   "message_id":"2f61ebaa-2d3e-4023-afba-f9fca6f21fc2"
}</pre></div></div></div></div></div><div class="page-bottom"><div id="_bottom-navigation"><a class="nav-link" href="install-swift.html"><span class="next-icon">→</span><span class="nav-label"><span class="number">Chapter 30 </span>Installation for <span class="phrase"><span class="phrase">SUSE <span class="productname">OpenStack</span> Cloud</span></span> Entry-scale Cloud with Swift Only</span></a><a class="nav-link" href="integrate-nsx-vsphere.html"><span class="prev-icon">←</span><span class="nav-label"><span class="number">Chapter 28 </span>Integrating NSX for vSphere</span></a></div><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2021 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>